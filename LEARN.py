#!/usr/bin/env python3
"""
LEARN.py - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ
ç‹¬ç«‹çš„å­¦ä¹ ææ–™ç”Ÿæˆå·¥å…·ï¼Œæ”¯æŒäº¤äº’æ¨¡å¼å’Œç›´æ¥è°ƒç”¨
"""

import os
import sys
import argparse
import subprocess
import json
import time
import datetime
from pathlib import Path
from typing import Dict, Any, Optional

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# Parameter mappings for bilingual support
MODE_MAPPING = {
    # Chinese
    'åˆå­¦è€…': 'åˆå­¦è€…',
    'ä¸­çº§': 'ä¸­çº§', 
    'é«˜çº§': 'é«˜çº§',
    'ä¸“å®¶': 'ä¸“å®¶',
    # English
    'beginner': 'åˆå­¦è€…',
    'intermediate': 'ä¸­çº§',
    'advanced': 'é«˜çº§', 
    'expert': 'ä¸“å®¶',
    # Capitalized English
    'Beginner': 'åˆå­¦è€…',
    'Intermediate': 'ä¸­çº§',
    'Advanced': 'é«˜çº§',
    'Expert': 'ä¸“å®¶'
}

STYLE_MAPPING = {
    # Chinese
    'ç®€æ´æ˜äº†': 'ç®€æ´æ˜äº†',
    'è¯¦ç»†æ·±å…¥': 'è¯¦ç»†æ·±å…¥',
    'å®ä¾‹ä¸°å¯Œ': 'å®ä¾‹ä¸°å¯Œ',
    'ç†è®ºå¯¼å‘': 'ç†è®ºå¯¼å‘',
    # English
    'concise': 'ç®€æ´æ˜äº†',
    'detailed': 'è¯¦ç»†æ·±å…¥',
    'example-rich': 'å®ä¾‹ä¸°å¯Œ',
    'theory-oriented': 'ç†è®ºå¯¼å‘',
    # Alternative English
    'brief': 'ç®€æ´æ˜äº†',
    'comprehensive': 'è¯¦ç»†æ·±å…¥',
    'practical': 'å®ä¾‹ä¸°å¯Œ',
    'theoretical': 'ç†è®ºå¯¼å‘',
    # Capitalized/other variants
    'Concise': 'ç®€æ´æ˜äº†',
    'Detailed': 'è¯¦ç»†æ·±å…¥',
    'Practical': 'å®ä¾‹ä¸°å¯Œ',
    'Theoretical': 'ç†è®ºå¯¼å‘',
    'Witty': 'å®ä¾‹ä¸°å¯Œ',  # Legacy support
    # Additional test mappings
    'RichExamples': 'å®ä¾‹ä¸°å¯Œ',
    'TheoryOriented': 'ç†è®ºå¯¼å‘'
}

# å…¨å±€æ—¶é—´è·Ÿè¸ªå™¨
LEARN_START_TIME = None

def get_elapsed_time():
    """è·å–ä»LEARNå¼€å§‹è¿è¡Œä»¥æ¥çš„ç»è¿‡æ—¶é—´"""
    if LEARN_START_TIME is None:
        return "00:00"
    elapsed = time.time() - LEARN_START_TIME
    minutes = int(elapsed // 60)
    seconds = int(elapsed % 60)
    return f"{minutes:02d}:{seconds:02d}"

def log_progress(message, level="INFO"):
    """è¾“å‡ºå¸¦æ—¶é—´æˆ³çš„è¿›åº¦ä¿¡æ¯"""
    elapsed = get_elapsed_time()
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}|{elapsed}] {level}: {message}")

def start_timer():
    """å¯åŠ¨å…¨å±€è®¡æ—¶å™¨"""
    global LEARN_START_TIME
    LEARN_START_TIME = time.time()
    log_progress("LEARNç³»ç»Ÿå¯åŠ¨", "START")

def normalize_parameters(args):
    """Normalize bilingual parameters to Chinese equivalents"""
    if args.mode and args.mode in MODE_MAPPING:
        args.mode = MODE_MAPPING[args.mode]
    elif args.mode and args.mode not in MODE_MAPPING:
        # If not found, suggest available options
        available_modes = list(set(MODE_MAPPING.keys()))
        print(f"é”™è¯¯: æ— æ•ˆçš„æ¨¡å¼ '{args.mode}'. å¯ç”¨é€‰é¡¹: {', '.join(available_modes)}")
        return None
        
    if args.style and args.style in STYLE_MAPPING:
        args.style = STYLE_MAPPING[args.style]
    elif args.style and args.style not in STYLE_MAPPING:
        # If not found, suggest available options
        available_styles = list(set(STYLE_MAPPING.keys()))
        print(f"é”™è¯¯: æ— æ•ˆçš„é£æ ¼ '{args.style}'. å¯ç”¨é€‰é¡¹: {', '.join(available_styles)}")
        return None
        
    return args

def is_run_environment(command_identifier=None):
    """Check if running in RUN environment by checking environment variables"""
    if command_identifier:
        return os.environ.get(f'RUN_IDENTIFIER_{command_identifier}') == 'True'
    return False

def write_to_json_output(data, command_identifier=None):
    """å°†ç»“æœå†™å…¥åˆ°æŒ‡å®šçš„ JSON è¾“å‡ºæ–‡ä»¶ä¸­"""
    if not is_run_environment(command_identifier):
        return False
    
    # Get the specific output file for this command identifier
    if command_identifier:
        output_file = os.environ.get(f'RUN_DATA_FILE_{command_identifier}')
    else:
        output_file = os.environ.get('RUN_DATA_FILE')
    
    if not output_file:
        return False
    
    try:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"Error writing to JSON output file: {e}")
        return False

def clear_terminal():
    """Clear the terminal screen."""
    os.system('clear' if os.name == 'posix' else 'cls')


def interactive_select(prompt, options, default_index=0):
    """Interactive selection with numbered options."""
    print(f"{prompt}")
    for i, option in enumerate(options):
        print(f"  {i+1}. {option}")
    
    while True:
        try:
            choice = input(f"Choose (1-{len(options)}, default: {default_index+1}): ").strip()
            if not choice:
                print(f"Selected: {options[default_index]}")
                return default_index
            
            choice_num = int(choice) - 1
            if 0 <= choice_num < len(options):
                print(f"Selected: {options[choice_num]}")
                return choice_num
            else:
                print(f"Please enter a number between 1 and {len(options)}")
        except ValueError:
            print(f"Please enter a valid number between 1 and {len(options)}")
        except KeyboardInterrupt:
            print("\nCancelled.")
            return None


def check_and_confirm_overwrite(output_dir, not_default=False, no_override_material=False):
    """Check if tutorial.md or question.md exists and handle overwrite based on options."""
    tutorial_path = Path(output_dir) / "tutorial.md"
    question_path = Path(output_dir) / "question.md"
    
    existing_files = []
    if tutorial_path.exists():
        existing_files.append("tutorial.md")
    if question_path.exists():
        existing_files.append("question.md")
    
    if not existing_files:
        return True, output_dir  # No files to overwrite, use original directory
    
    # å¦‚æœæŒ‡å®šäº†--no-override-materialï¼Œè‡ªåŠ¨é‡å‘½å
    if no_override_material:
        return handle_auto_rename(output_dir)
    
    # é»˜è®¤æ¨¡å¼ï¼ˆ--not-defaultæœªæŒ‡æ˜ï¼‰ï¼šç›´æ¥è¦†ç›–
    if not not_default:
        print(f"ğŸ“ é»˜è®¤æ¨¡å¼ï¼šå°†è¦†ç›– {output_dir} ä¸­çš„ç°æœ‰æ–‡ä»¶: {', '.join(existing_files)}")
        return True, output_dir
    
    # äº¤äº’æ¨¡å¼ï¼šè¯¢é—®ç”¨æˆ·
    print(f"\nâš ï¸  ä»¥ä¸‹æ–‡ä»¶å·²å­˜åœ¨äº {output_dir}:")
    for file in existing_files:
        print(f"  - {file}")
    
    while True:
        try:
            choice = input("\né€‰æ‹©æ“ä½œ: (o)è¦†ç›– / (r)é‡å‘½å / (c)å–æ¶ˆ [o/r/c]: ").strip().lower()
            if choice in ['o', 'overwrite', 'è¦†ç›–']:
                return True, output_dir
            elif choice in ['r', 'rename', 'é‡å‘½å']:
                return handle_auto_rename(output_dir)
            elif choice in ['c', 'cancel', 'å–æ¶ˆ', '']:
                return False, None
            else:
                print("è¯·è¾“å…¥ o (è¦†ç›–) / r (é‡å‘½å) / c (å–æ¶ˆ)")
        except KeyboardInterrupt:
            print("\næ“ä½œå·²å–æ¶ˆ")
            return False, None


def handle_auto_rename(output_dir):
    """Handle automatic renaming of output directory to avoid overwriting files."""
    output_path = Path(output_dir)
    base_name = output_path.name
    parent_dir = output_path.parent
    
    counter = 1
    while True:
        new_name = f"{base_name}_{counter}"
        new_path = parent_dir / new_name
        
        # æ£€æŸ¥æ–°ç›®å½•ä¸­æ˜¯å¦ä¹Ÿæœ‰å†²çªæ–‡ä»¶
        tutorial_path = new_path / "tutorial.md"
        question_path = new_path / "question.md"
        
        if not new_path.exists() or (not tutorial_path.exists() and not question_path.exists()):
            # åˆ›å»ºæ–°ç›®å½•
            new_path.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ è‡ªåŠ¨é‡å‘½åè¾“å‡ºç›®å½•ä¸º: {new_path}")
            return True, str(new_path)
        
        counter += 1
        if counter > 100:  # é˜²æ­¢æ— é™å¾ªç¯
            print("âŒ æ— æ³•æ‰¾åˆ°åˆé€‚çš„ç›®å½•åï¼Œè¯·æ‰‹åŠ¨æ¸…ç†è¾“å‡ºç›®å½•")
            return False, None


def get_output_directory():
    """Get output directory using tkinter directory selection."""
    print("é€‰æ‹©é¡¹ç›®ç›®å½•...")
    return get_output_directory_tkinter()


def get_output_directory_tkinter():
    """Get output directory using tkinter as fallback."""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        print("ğŸ“ è¯·åœ¨å¼¹å‡ºçš„çª—å£ä¸­é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹...")
        
        # åˆ›å»ºtkinteræ ¹çª—å£å¹¶éšè—
        root = tk.Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        
        # æ‰“å¼€ç›®å½•é€‰æ‹©å¯¹è¯æ¡†
        selected_dir = filedialog.askdirectory(
            title="é€‰æ‹©é¡¹ç›®ç›®å½•"
        )
        
        # é”€æ¯tkinterçª—å£
        root.destroy()
        
        if selected_dir:
            print(f"âœ… é€‰æ‹©ç›®å½•: {selected_dir}")
            return selected_dir
        else:
            print("âŒ æœªé€‰æ‹©ç›®å½•")
            return None
            
    except ImportError:
        print("âŒ tkinterä¸å¯ç”¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ç›®å½•è·¯å¾„")
        return None
    except Exception as e:
        print(f"âŒ ç›®å½•é€‰æ‹©å¤±è´¥: {e}")
        return None


def get_paper_file():
    """Get paper file using tkinter file selection."""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        print("ğŸ“„ è¯·åœ¨å¼¹å‡ºçš„çª—å£ä¸­é€‰æ‹©è®ºæ–‡æ–‡ä»¶...")
        
        # åˆ›å»ºtkinteræ ¹çª—å£å¹¶éšè—
        root = tk.Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        
        # æ‰“å¼€æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†
        selected_file = filedialog.askopenfilename(
            title="é€‰æ‹©è®ºæ–‡æ–‡ä»¶",
            filetypes=[
                ("PDFæ–‡ä»¶", "*.pdf"),
                ("Markdownæ–‡ä»¶", "*.md"),
                ("æ–‡æœ¬æ–‡ä»¶", "*.txt"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        # é”€æ¯tkinterçª—å£
        root.destroy()
        
        if selected_file:
            print(f"âœ… é€‰æ‹©æ–‡ä»¶: {selected_file}")
            return selected_file
        else:
            print("âŒ æœªé€‰æ‹©æ–‡ä»¶")
            return None
            
    except ImportError:
        print("âŒ tkinterä¸å¯ç”¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥æ–‡ä»¶è·¯å¾„")
        return None
    except Exception as e:
        print(f"âŒ æ–‡ä»¶é€‰æ‹©å¤±è´¥: {e}")
        return None


def run_interactive_mode():
    """Run in interactive mode to collect parameters."""
    clear_terminal()
    print("=== LEARN æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ ===")
    print("æ¬¢è¿ä½¿ç”¨æ™ºèƒ½å­¦ä¹ å†…å®¹ç”Ÿæˆå·¥å…·ï¼")
    print()
    
    # Step 1: Select learning type
    print("ğŸ“š ç¬¬1æ­¥ï¼šé€‰æ‹©å­¦ä¹ ç±»å‹")
    type_choice = interactive_select(
        "å­¦ä¹ ç±»å‹:",
        ["é€šç”¨ä¸»é¢˜å­¦ä¹ ", "åŸºäºå­¦æœ¯è®ºæ–‡å­¦ä¹ "]
    )
    if type_choice is None:
        return None
    
    params = {}
    
    if type_choice == 0:  # General topic
        params["type"] = "general"
        
        # Get topic
        print("\nğŸ“ ç¬¬2æ­¥ï¼šè¾“å…¥å­¦ä¹ ä¸»é¢˜")
        while True:
            topic = input("è¯·è¾“å…¥å­¦ä¹ ä¸»é¢˜ (ä¾‹å¦‚: PythonåŸºç¡€, æœºå™¨å­¦ä¹ , æ•°æ®ç»“æ„): ").strip()
            if topic:
                try:
                    # è§£ææ–‡ä»¶å¼•ç”¨
                    expanded_topic, has_file_ref = parse_file_references(topic)
                    params["topic"] = expanded_topic
                    params["has_file_reference"] = has_file_ref
                    # å¦‚æœæ£€æµ‹åˆ°æ–‡ä»¶å¼•ç”¨ï¼Œè‡ªåŠ¨å¯ç”¨contextæ¨¡å¼
                    if has_file_ref:
                        params['context_mode'] = True
                        print("ğŸ“„ æ£€æµ‹åˆ°@æ–‡ä»¶å¼•ç”¨ï¼Œè‡ªåŠ¨å¯ç”¨--contextæ¨¡å¼")
                    break
                except (FileNotFoundError, ValueError) as e:
                    print(f"âŒ é”™è¯¯: {e}")
                    print("è¯·é‡æ–°è¾“å…¥æ­£ç¡®çš„ä¸»é¢˜æˆ–æ–‡ä»¶è·¯å¾„")
                    continue
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„ä¸»é¢˜")
        
    else:  # Paper-based
        params["type"] = "paper"
        
        print("\nğŸ“„ ç¬¬2æ­¥ï¼šé€‰æ‹©è®ºæ–‡è¾“å…¥æ–¹å¼")
        input_choice = interactive_select(
            "è®ºæ–‡è¾“å…¥æ–¹å¼:",
            ["æœ¬åœ°Markdownæ–‡ä»¶", "æœ¬åœ°PDFæ–‡ä»¶", "è®ºæ–‡URL", "è®ºæ–‡æè¿°/æœç´¢"]
        )
        if input_choice is None:
            return None
            
        params["input_type"] = input_choice
        
        if input_choice == 0:  # Markdown file
            paper_file = get_paper_file()
            if not paper_file:
                return None
            params["paper_path"] = paper_file
            
            # Read markdown content
            try:
                with open(paper_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                params["paper_content"] = content
                print(f"âœ… è¯»å–Markdownæ–‡ä»¶: {len(content)} å­—ç¬¦")
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
                return None
                
        elif input_choice == 1:  # PDF file
            paper_file = get_paper_file()
            if not paper_file:
                return None
            params["paper_path"] = paper_file
            
            # Ask about image processing
            print("\nğŸ–¼ï¸  å›¾åƒå¤„ç†é€‰é¡¹")
            image_choice = interactive_select(
                "æ˜¯å¦å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼ï¼Ÿ",
                ["å¦ (ä»…æå–æ–‡æœ¬ï¼Œé€Ÿåº¦å¿«)", "æ˜¯ (å®Œæ•´å¤„ç†ï¼Œéœ€è¦APIè°ƒç”¨)"]
            )
            params["read_images"] = image_choice == 1
            
        elif input_choice == 2:  # URL
            while True:
                url = input("è¯·è¾“å…¥è®ºæ–‡URL: ").strip()
                if url:
                    params["paper_url"] = url
                    break
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„URL")
                
            # Ask about image processing
            print("\nğŸ–¼ï¸  å›¾åƒå¤„ç†é€‰é¡¹")
            image_choice = interactive_select(
                "æ˜¯å¦å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼ï¼Ÿ",
                ["å¦ (ä»…æå–æ–‡æœ¬ï¼Œé€Ÿåº¦å¿«)", "æ˜¯ (å®Œæ•´å¤„ç†ï¼Œéœ€è¦APIè°ƒç”¨)"]
            )
            params["read_images"] = image_choice == 1
            
        elif input_choice == 3:  # Description/Search
            while True:
                description = input("è¯·è¾“å…¥è®ºæ–‡æè¿°æˆ–å…³é”®è¯: ").strip()
                if description:
                    params["paper_description"] = description
                    break
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æè¿°")
                
            # Ask about image processing
            print("\nğŸ–¼ï¸  å›¾åƒå¤„ç†é€‰é¡¹")
            image_choice = interactive_select(
                "æ˜¯å¦å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼ï¼Ÿ",
                ["å¦ (ä»…æå–æ–‡æœ¬ï¼Œé€Ÿåº¦å¿«)", "æ˜¯ (å®Œæ•´å¤„ç†ï¼Œéœ€è¦APIè°ƒç”¨)"]
            )
            params["read_images"] = image_choice == 1
    
    # Step 3: Select learning level
    print("\nğŸ¯ ç¬¬3æ­¥ï¼šé€‰æ‹©å­¦ä¹ æ°´å¹³")
    mode_choice = interactive_select(
        "å­¦ä¹ æ°´å¹³:",
        ["åˆå­¦è€…", "ä¸­çº§", "é«˜çº§", "ä¸“å®¶"]
    )
    if mode_choice is None:
        return None
    
    modes = ["åˆå­¦è€…", "ä¸­çº§", "é«˜çº§", "ä¸“å®¶"]
    params["mode"] = modes[mode_choice]
    
    # Step 4: Select explanation style
    print("\nğŸ“– ç¬¬4æ­¥ï¼šé€‰æ‹©è§£é‡Šé£æ ¼")
    style_choice = interactive_select(
        "è§£é‡Šé£æ ¼:",
        ["ç®€æ´æ˜äº†", "è¯¦ç»†æ·±å…¥", "å®ä¾‹ä¸°å¯Œ", "ç†è®ºå¯¼å‘"]
    )
    if style_choice is None:
        return None
    
    styles = ["ç®€æ´æ˜äº†", "è¯¦ç»†æ·±å…¥", "å®ä¾‹ä¸°å¯Œ", "ç†è®ºå¯¼å‘"]
    params["style"] = styles[style_choice]
    
    # Step 5: Get output directory
    print("\nğŸ“ ç¬¬5æ­¥ï¼šé€‰æ‹©è¾“å‡ºç›®å½•")
    output_dir = get_output_directory()
    if not output_dir:
        return None
    
    params["output_dir"] = output_dir
    
    # Check for existing files and handle overwrite
    can_continue, final_output_dir = check_and_confirm_overwrite(
        output_dir, 
        params.get('not_default', False),
        params.get('no_override_material', False)
    )
    
    if not can_continue:
        print("æ“ä½œå·²å–æ¶ˆ")
        return None
    
    # Update output directory if it was renamed
    if final_output_dir != output_dir:
        params["output_dir"] = final_output_dir
    
    return params


def parse_direct_command(args):
    """Parse direct command line arguments."""
    parser = argparse.ArgumentParser(description='LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ')
    
    # Basic options
    parser.add_argument('topic', nargs='?', help='å­¦ä¹ ä¸»é¢˜')
    parser.add_argument('-o', '--output-dir', help='è¾“å‡ºç›®å½•')
    parser.add_argument('-m', '--mode', choices=list(MODE_MAPPING.keys()), 
                       default='ä¸­çº§', help='å­¦ä¹ æ°´å¹³ (Learning level)')
    parser.add_argument('-s', '--style', choices=list(STYLE_MAPPING.keys()),
                       default='è¯¦ç»†æ·±å…¥', help='è§£é‡Šé£æ ¼ (Explanation style)')
    
    # File options
    parser.add_argument('--file', help='ç›´æ¥å¤„ç†æ–‡ä»¶è·¯å¾„ (æ”¯æŒPDFã€MDã€TXT)')
    parser.add_argument('-u', '--url', help='è®ºæ–‡URL')
    parser.add_argument('-d', '--description', help='è®ºæ–‡æè¿°/æœç´¢å…³é”®è¯')
    parser.add_argument('--negative', help='è´Ÿé¢æç¤ºè¯ï¼šæŒ‡å®šä¸æƒ³è¦çš„å†…å®¹æˆ–è®ºæ–‡ç±»å‹')
    parser.add_argument('--read-images', action='store_true', help='å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼')
    parser.add_argument('--gen-command', help='æ ¹æ®æè¿°ç”ŸæˆLEARNå‘½ä»¤')
    parser.add_argument('--paper-based', action='store_true', help='å¼ºåˆ¶ä½¿ç”¨åŸºäºè®ºæ–‡çš„å­¦ä¹ æ¨¡å¼ï¼Œå³ä½¿åªæä¾›äº†æè¿°ä¹Ÿä¼šæœç´¢å’Œä¸‹è½½è®ºæ–‡')
    parser.add_argument('--sources', help='æŒ‡å®šè®ºæ–‡æœç´¢å¼•æ“ï¼Œç”¨é€—å·åˆ†éš” (arxiv,google_scholar)ï¼Œé»˜è®¤ä¸ºè‡ªåŠ¨æ¨è')
    
    # Model options
    parser.add_argument('--model', help='æŒ‡å®šOpenRouteræ¨¡å‹')
    parser.add_argument('--max-tokens', type=int, help='æœ€å¤§tokenæ•°')
    parser.add_argument('--temperature', type=float, help='æ¸©åº¦å‚æ•° (0.0-2.0ï¼Œæ§åˆ¶å›å¤çš„åˆ›é€ æ€§)')
    parser.add_argument('--key', help='æŒ‡å®šOpenRouter APIå¯†é’¥')
    parser.add_argument('--not-default', action='store_true', help='éé»˜è®¤æ¨¡å¼ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤')
    parser.add_argument('--no-override-material', action='store_true', help='ä¸è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œè‡ªåŠ¨é‡å‘½å')
    parser.add_argument('--brainstorm-only', action='store_true', help='ä¸è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶ï¼Œä»…ç”Ÿæˆå†…å®¹')
    parser.add_argument('--context', action='store_true', help='å°†descriptionè§†ä½œç›´æ¥contextè¿›å…¥brainstormingï¼Œè·³è¿‡è®ºæ–‡æœç´¢')
    
    try:
        parsed_args = parser.parse_args(args)
    except SystemExit:
        return None
    
    # Normalize bilingual parameters
    parsed_args = normalize_parameters(parsed_args)
    if parsed_args is None:
        return None
    
    # æ£€æŸ¥äº’æ–¥å‚æ•°
    if parsed_args.context and parsed_args.brainstorm_only:
        print("âŒ é”™è¯¯: --context å’Œ --brainstorm-only é€‰é¡¹äº’æ–¥ï¼Œä¸èƒ½åŒæ—¶ä½¿ç”¨")
        print("   --context: è·³è¿‡brainstormingï¼Œç›´æ¥ç”Ÿæˆæ•™ç¨‹")
        print("   --brainstorm-only: åªè¿›è¡Œbrainstormingï¼Œä¸ç”Ÿæˆæ•™ç¨‹")
        return None
    
    # Check if output is required for actual operation (not for --help)
    if not parsed_args.output_dir and not any(arg in ['-h', '--help'] for arg in args):
        # Default to current directory if not specified
        parsed_args.output_dir = str(Path.cwd())
        print(f"â„¹ï¸  æœªæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨å½“å‰ç›®å½•: {parsed_args.output_dir}")
    
    # Build parameters
    params = {
        'mode': parsed_args.mode,
        'style': parsed_args.style,
        'output_dir': parsed_args.output_dir,
        'not_default': parsed_args.not_default,
        'no_override_material': parsed_args.no_override_material,
        'brainstorm_only': parsed_args.brainstorm_only,
        'context_mode': parsed_args.context
    }
    
    if parsed_args.model:
        params['selected_model'] = parsed_args.model
    if parsed_args.max_tokens:
        params['max_tokens'] = parsed_args.max_tokens
    if parsed_args.temperature is not None:
        params['temperature'] = parsed_args.temperature
    if parsed_args.key:
        params['api_key'] = parsed_args.key
    
    # Determine type based on arguments
    if parsed_args.file:
        # --fileé€‰é¡¹å¤„ç†
        file_path = parsed_args.file
        params['type'] = 'paper'
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­ç±»å‹
        if file_path.endswith('.md'):
            params['input_type'] = 0  # Markdown file
            # è¯»å–markdownæ–‡ä»¶å†…å®¹
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    params['paper_content'] = f.read()
                params['paper_path'] = file_path
            except Exception as e:
                print(f"âŒ è¯»å–markdownæ–‡ä»¶å¤±è´¥: {e}")
                return 1
        elif file_path.endswith('.txt'):
            params['input_type'] = 0  # Text file (treated as markdown)
            # è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    params['paper_content'] = f.read()
                params['paper_path'] = file_path
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {e}")
                return 1
        elif file_path.endswith('.pdf'):
            params['input_type'] = 1  # PDF file
            params['paper_path'] = file_path
        else:
            # é»˜è®¤æŒ‰PDFå¤„ç†
            params['input_type'] = 1  # PDF file
            params['paper_path'] = file_path
        params['read_images'] = parsed_args.read_images
    elif parsed_args.url:
        params['type'] = 'paper'
        params['input_type'] = 2  # URL
        params['paper_url'] = parsed_args.url
        params['read_images'] = parsed_args.read_images
    elif parsed_args.description:
        params['type'] = 'paper'
        params['input_type'] = 3  # Description/Search
        try:
            expanded_description, has_file_ref = parse_file_references(parsed_args.description)
            params['paper_description'] = expanded_description
            params['has_file_reference'] = has_file_ref
            # å¦‚æœæ£€æµ‹åˆ°æ–‡ä»¶å¼•ç”¨ï¼Œè‡ªåŠ¨å¯ç”¨contextæ¨¡å¼
            if has_file_ref:
                params['context_mode'] = True
                print("ğŸ“„ æ£€æµ‹åˆ°@æ–‡ä»¶å¼•ç”¨ï¼Œè‡ªåŠ¨å¯ç”¨--contextæ¨¡å¼")
        except (FileNotFoundError, ValueError) as e:
            print(f"âŒ é”™è¯¯: {e}")
            return None
        params['negative_prompt'] = parsed_args.negative
        params['read_images'] = parsed_args.read_images
        params['sources'] = parsed_args.sources
    elif parsed_args.topic:
        try:
            expanded_topic, has_file_ref = parse_file_references(parsed_args.topic)
            
            # æ£€æŸ¥topicæ˜¯å¦æ˜¯ä¸€ä¸ªæ–‡ä»¶è·¯å¾„
            topic_path = Path(parsed_args.topic)
            if topic_path.exists() and topic_path.is_file():
                # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼ŒæŒ‰æ–‡ä»¶ç±»å‹å¤„ç†
                file_ext = topic_path.suffix.lower()
                if file_ext == '.pdf':
                    params['type'] = 'paper'
                    params['input_type'] = 1  # PDF file
                    params['paper_path'] = str(topic_path)
                    params['read_images'] = parsed_args.read_images
                    print(f"ğŸ“„ æ£€æµ‹åˆ°PDFæ–‡ä»¶è·¯å¾„ï¼Œåˆ‡æ¢åˆ°è®ºæ–‡å­¦ä¹ æ¨¡å¼: {topic_path}")
                elif file_ext in ['.md', '.txt']:
                    params['type'] = 'paper'
                    params['input_type'] = 0 if file_ext == '.md' else 4  # Markdown or direct file
                    if file_ext == '.md':
                        # è¯»å–markdownæ–‡ä»¶å†…å®¹
                        with open(topic_path, 'r', encoding='utf-8') as f:
                            params['paper_content'] = f.read()
                        params['paper_path'] = str(topic_path)
                    else:
                        params['file_path'] = str(topic_path)
                    params['read_images'] = parsed_args.read_images
                else:
                    # å…¶ä»–æ–‡ä»¶ç±»å‹ä»ç„¶æŒ‰ä¸€èˆ¬ä¸»é¢˜å¤„ç†
                    params['type'] = 'general'
                    params['topic'] = expanded_topic
                    params['has_file_reference'] = has_file_ref
            else:
                # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†--paper-basedæ ‡å¿—
                if parsed_args.paper_based:
                    # å¼ºåˆ¶ä½¿ç”¨è®ºæ–‡æ¨¡å¼ï¼Œå°†topicä½œä¸ºè®ºæ–‡æè¿°æœç´¢
                    params['type'] = 'paper'
                    params['input_type'] = 3  # Description/Search
                    params['paper_description'] = expanded_topic
                    params['has_file_reference'] = has_file_ref
                    params['negative_prompt'] = parsed_args.negative
                    params['read_images'] = parsed_args.read_images
                    params['sources'] = parsed_args.sources
                    print(f"ğŸ” --paper-basedæ¨¡å¼ï¼šå°†ä¸»é¢˜ä½œä¸ºè®ºæ–‡æœç´¢å…³é”®è¯: {expanded_topic}")
                else:
                    # ä¸æ˜¯æ–‡ä»¶è·¯å¾„ï¼ŒæŒ‰ä¸€èˆ¬ä¸»é¢˜å¤„ç†
                    params['type'] = 'general'
                    params['topic'] = expanded_topic
                    params['has_file_reference'] = has_file_ref
            
            # å¦‚æœæ£€æµ‹åˆ°@æ–‡ä»¶å¼•ç”¨ï¼Œè‡ªåŠ¨å¯ç”¨contextæ¨¡å¼
            if has_file_ref:
                params['context_mode'] = True
                print("ğŸ“„ æ£€æµ‹åˆ°@æ–‡ä»¶å¼•ç”¨ï¼Œè‡ªåŠ¨å¯ç”¨--contextæ¨¡å¼")
        except (FileNotFoundError, ValueError) as e:
            print(f"âŒ é”™è¯¯: {e}")
            return None
    else:
        print("é”™è¯¯ï¼šå¿…é¡»æŒ‡å®šå­¦ä¹ ä¸»é¢˜æˆ–è®ºæ–‡ä¿¡æ¯")
        return None
    
    # Check for existing files and handle overwrite in direct mode
    if params['output_dir']:
        can_continue, final_output_dir = check_and_confirm_overwrite(
            params['output_dir'], 
            params.get('not_default', False),
            params.get('no_override_material', False)
        )
        
        if not can_continue:
            print("æ“ä½œå·²å–æ¶ˆ")
            return None
        
        # Update output directory if it was renamed
        if final_output_dir != params['output_dir']:
            params['output_dir'] = final_output_dir
    
    return params


def get_openrouter_models():
    """Get available OpenRouter models."""
    try:
        script_dir = Path(__file__).parent
        openrouter_data_file = script_dir / "OPENROUTER_PROJ" / "openrouter_models.json"
        
        if openrouter_data_file.exists():
            import json
            with open(openrouter_data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                models_dict = data.get('models', {})
                if isinstance(models_dict, dict):
                    # Extract model names from dictionary format
                    models = list(models_dict.keys())
                    model_details = models_dict
                else:
                    # Handle list format (legacy)
                    models = models_dict
                    model_details = data.get('model_details', {})
                return models, model_details
        else:
            # Fallback to default models
            default_models = [
                "deepseek/deepseek-r1:free",
                "deepseek/deepseek-chat",
                "openai/gpt-4o-mini",
                "anthropic/claude-3-haiku"
            ]
            return default_models, {}
    except Exception as e:
        print(f"âš ï¸  è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        # Return minimal fallback
        return ["deepseek/deepseek-r1:free"], {}


def select_openrouter_model(params):
    """Select OpenRouter model with token limits."""
    models, model_details = get_openrouter_models()
    
    if not models:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
        return None, None
    
    # Check if model is already specified
    if params.get("selected_model"):
        selected_model = params["selected_model"]
        max_tokens = params.get("max_tokens", 4000)
        print(f"âœ… ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {selected_model}")
        return selected_model, max_tokens
    
    # Auto-select for default mode (use "auto" for automatic model selection)
    if not params.get('not_default', False):
        selected_model = "auto"  # ä½¿ç”¨autoæ¨¡å¼è‡ªåŠ¨é€‰æ‹©
        max_tokens = 4000
        print(f"ğŸš€ é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨æ¨¡å‹é€‰æ‹©")
        return selected_model, max_tokens
    
    # Interactive mode - let user choose
    print(f"\nğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
    print("=" * 80)
    for i, model in enumerate(models):
        model_info = model_details.get(model, {})
        input_cost = model_info.get('input_cost_per_1m', 0)
        output_cost = model_info.get('output_cost_per_1m', 0)
        context_length = model_info.get('context_length', 0)
        
        print(f" {i+1}. {model}")
        print(f"    ğŸ“Š è´¹ç‡: è¾“å…¥ ${input_cost:.2f}/1M, è¾“å‡º ${output_cost:.2f}/1M")
        print(f"    ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦: {context_length:,} tokens")
        print()
    
    print(f" {len(models)+1}. auto (è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹)")
    print("    ğŸ¤– ç³»ç»Ÿä¼šæŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨é€‰æ‹©å¯ç”¨æ¨¡å‹")
    print()
    
    while True:
        try:
            choice = input(f"é€‰æ‹©æ¨¡å‹ (1-{len(models)+1}, é»˜è®¤: auto): ").strip()
            
            if not choice or choice.lower() == 'auto':
                selected_model = "auto"
                break
            
            choice_num = int(choice)
            if choice_num == len(models) + 1:  # autoé€‰é¡¹
                selected_model = "auto"
                break
            elif 1 <= choice_num <= len(models):
                selected_model = models[choice_num - 1]
                break
            else:
                print(f"âŒ è¯·è¾“å…¥1-{len(models)+1}ä¹‹é—´çš„æ•°å­—")
                
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nâŒ ç”¨æˆ·å–æ¶ˆ")
            return None, None
    
    # Set max tokens based on model
    if selected_model == "auto":
        max_tokens = 40960  # æ›´é«˜çš„é»˜è®¤å€¼ï¼Œä¼šåœ¨å®é™…è°ƒç”¨æ—¶åŠ¨æ€è°ƒæ•´
        print(f"ğŸ¤– é€‰æ‹©è‡ªåŠ¨æ¨¡å¼")
    else:
        model_info = model_details.get(selected_model, {})
        context_length = model_info.get('context_length', 4000)
        max_tokens = context_length // 4  # Use 1/4 of context length
        print(f"âœ… é€‰æ‹©æ¨¡å‹: {selected_model} (max_tokens: {max_tokens})")
    
    return selected_model, max_tokens


def generate_content_structure_prompt(params):
    """Generate prompt for content structure brainstorming."""
    if params["type"] == "general":
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶å¼•ç”¨
        if params.get("has_file_reference", False):
            print("ğŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶å¼•ç”¨ï¼Œå°†åŸºäºæ–‡ä»¶å†…å®¹åˆ›å»ºæ•™ç¨‹")
            return f'åŸºäºä»¥ä¸‹å†…å®¹åˆ›å»ºè¯¦ç»†çš„å­¦ä¹ æ•™ç¨‹ç»“æ„ï¼Œé€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ï¼š\n\n{topic}'
        else:
            return f'è¯·ä¸º"{topic}"åˆ›å»ºè¯¦ç»†çš„å­¦ä¹ æ•™ç¨‹ç»“æ„ï¼Œé€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚'
        
    elif params["type"] == "paper":
        mode = params['mode']
        style = params['style']
        
        # é¦–å…ˆè¿›è¡Œæ¨¡å‹é€‰æ‹©ï¼ˆå¦‚æœè¿˜æ²¡æœ‰é€‰æ‹©çš„è¯ï¼‰
        if not params.get("selected_model"):
            selected_model, max_tokens = select_openrouter_model(params)
            if not selected_model:
                print("âŒ æœªé€‰æ‹©æ¨¡å‹")
                return None
            
            # Store selected model info in params
            params["selected_model"] = selected_model
            params["max_tokens"] = max_tokens
        
        # For paper type, prepare content first
        paper_content, paper_path, token_count = prepare_paper_content(params)
        if not paper_content:
            return None
            
        # Store prepared content in params
        params['paper_content'] = paper_content
        params['paper_path'] = paper_path
        params['token_count'] = token_count
        
        # Check if content is too long and needs summarization
        # è·å–åŠ¨æ€max_tokensè®¾ç½®
        dynamic_max_tokens = params.get("max_tokens", 40960)  # é»˜è®¤å€¼
        
        # å¦‚æœæ˜¯è‡ªåŠ¨æ¨¡å¼ï¼Œä½¿ç”¨æ›´åˆç†çš„é˜ˆå€¼ï¼ˆåŸºäºdeepseekæ¨¡å‹çš„context lengthï¼‰
        if params.get("selected_model") == "auto" or not params.get("selected_model"):
            # è‡ªåŠ¨æ¨¡å¼ï¼šä½¿ç”¨deepseekæ¨¡å‹çš„å®é™…context lengthè®¡ç®—é˜ˆå€¼
            deepseek_context_length = 163840
            dynamic_max_tokens = deepseek_context_length // 4  # 40960
            content_threshold = dynamic_max_tokens  # ç›´æ¥ä½¿ç”¨max_tokensä½œä¸ºé˜ˆå€¼
        else:
            # ç›´æ¥ä½¿ç”¨max_tokensä½œä¸ºé˜ˆå€¼
            content_threshold = dynamic_max_tokens
        
        if token_count > content_threshold:
            print(f"âš ï¸  è®ºæ–‡å†…å®¹è¾ƒé•¿ ({token_count:,} tokens)ï¼Œè¶…å‡ºæ¨èå¤„ç†é•¿åº¦ ({content_threshold:,} tokens)")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºé»˜è®¤æ¨¡å¼
            if params.get("not_default", False):
                # éé»˜è®¤æ¨¡å¼ï¼šè¯¢é—®ç”¨æˆ·é€‰æ‹©
                approach_choice = interactive_select(
                    "å†…å®¹å¤„ç†æ–¹å¼:",
                    ["ç›´æ¥ä½¿ç”¨ (å¯èƒ½è¶…å‡ºæ¨¡å‹é™åˆ¶)", "æ™ºèƒ½æ‘˜è¦ (æ¨è)", "æ‰‹åŠ¨æˆªå–å‰éƒ¨åˆ†"]
                )
            else:
                # é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªé€‰é¡¹
                print("å†…å®¹å¤„ç†æ–¹å¼:")
                print("  1. ç›´æ¥ä½¿ç”¨ (å¯èƒ½è¶…å‡ºæ¨¡å‹é™åˆ¶)")
                print("  2. æ™ºèƒ½æ‘˜è¦ (æ¨è)")
                print("  3. æ‰‹åŠ¨æˆªå–å‰éƒ¨åˆ†")
                print("Choose (1-3, default: 1): 1")
                print("Selected: ç›´æ¥ä½¿ç”¨ (å¯èƒ½è¶…å‡ºæ¨¡å‹é™åˆ¶)")
                approach_choice = 0  # å¯¹åº”ç¬¬ä¸€ä¸ªé€‰é¡¹
            
            if approach_choice == 1:  # Smart summary
                print("ğŸ“ æ­£åœ¨ç”Ÿæˆè®ºæ–‡æ‘˜è¦...")
                # Generate summary prompt
                summary_prompt = f"""è¯·ä¸ºä»¥ä¸‹å­¦æœ¯è®ºæ–‡ç”Ÿæˆè¯¦ç»†æ‘˜è¦ï¼Œä¿ç•™å…³é”®æŠ€æœ¯ç»†èŠ‚ï¼š

{paper_content[:20000]}

è¯·åŒ…å«ï¼š
1. ç ”ç©¶èƒŒæ™¯å’Œé—®é¢˜
2. ä¸»è¦æ–¹æ³•å’ŒæŠ€æœ¯
3. å…³é”®åˆ›æ–°ç‚¹
4. å®éªŒç»“æœ
5. ç»“è®ºå’Œæ„ä¹‰

æ‘˜è¦åº”è¯¥è¯¦ç»†ä½†ç®€æ´ï¼Œé€‚åˆåç»­æ•™ç¨‹åˆ›å»ºã€‚"""
                
                # Call API for summary
                summary_response, summary_token_info, _ = call_openrouter_with_retry(
                    summary_prompt, 
                    params.get("selected_model", "deepseek/deepseek-r1:free"), 
                    params.get("max_tokens", 4000), 
                    "è®ºæ–‡æ‘˜è¦ç”Ÿæˆ",
                    params=params
                )
                
                if summary_response:
                    paper_content = summary_response
                    print(f"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ ({count_tokens(paper_content)} tokens)")
                else:
                    print("âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                    
            elif approach_choice == 2:  # Manual truncate
                paper_content = paper_content[:60000]  # Keep first 60k characters
                print(f"âœ… æˆªå–å‰éƒ¨åˆ†å†…å®¹ ({count_tokens(paper_content)} tokens)")
        
        # Update params with processed content
        params['paper_content'] = paper_content
        
        # Generate brainstorming prompt for paper
        return f"""è¯·åˆ†æè¿™ç¯‡å­¦æœ¯è®ºæ–‡çš„å†…å®¹ï¼Œä¸ºåˆ›å»ºæ•™ç¨‹åšå‡†å¤‡ï¼š

è®ºæ–‡è·¯å¾„ï¼š{paper_path}
å­¦ä¹ æ°´å¹³ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

è®ºæ–‡å†…å®¹ï¼š
{paper_content}

è¯·åˆ†æï¼š
1. è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®å’Œåˆ›æ–°ç‚¹
2. å…³é”®æ¦‚å¿µå’ŒæŠ€æœ¯æ–¹æ³•
3. é€‚åˆ{mode}æ°´å¹³å­¦ä¹ è€…çš„é‡ç‚¹å†…å®¹
4. å¯èƒ½çš„éš¾ç‚¹å’Œè§£é‡Šç­–ç•¥
5. å®è·µåº”ç”¨å’Œæ‰©å±•æ€è€ƒ

è¯·æä¾›ç»“æ„åŒ–åˆ†æï¼Œä¸ºåç»­åˆ›å»ºè¯¦ç»†æ•™ç¨‹åšå‡†å¤‡ã€‚"""
    
    return None


def call_openrouter_for_structure(prompt, model=None, max_tokens=None, retry_count=0, temperature=None, api_key=None):
    """Call OpenRouter API for structure generation with improved error handling."""
    import time
    import json
    import re
    
    try:
        script_dir = Path(__file__).parent
        run_path = script_dir / "RUN.py"
        
        if retry_count == 0:
            print("ğŸ”„ æ­£åœ¨è¿æ¥OpenRouter API...", file=sys.stderr)
        else:
            print(f"ğŸ”„ é‡è¯•APIè°ƒç”¨ (ç¬¬{retry_count}æ¬¡)...", file=sys.stderr)
            
        # å¤„ç†æ¨¡å‹é€‰æ‹©
        if not model or model == "auto":
            print("ğŸ¤– ä½¿ç”¨è‡ªåŠ¨æ¨¡å‹é€‰æ‹©", file=sys.stderr)
            # ä½¿ç”¨call_openrouter_with_auto_modelè¿›è¡Œè‡ªåŠ¨é€‰æ‹©
            result = call_openrouter_with_auto_model(prompt, model="auto")
            
            if result['success']:
                content = result['content']
                usage_info = {
                    'input_tokens': result['usage']['input_tokens'],
                    'output_tokens': result['usage']['output_tokens'],
                    'total_tokens': result['usage']['total_tokens'],
                    'cost': result['cost'],
                    'model': result['model'],
                    'api_duration': 0  # call_openrouter_with_auto_model doesn't return duration
                }
                return content, usage_info
            else:
                return f"ERROR: {result['error']}", {"error": result['error']}
        
        else:
            # ä½¿ç”¨æŒ‡å®šæ¨¡å‹
            print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}", file=sys.stderr)
            if max_tokens:
                print(f"ğŸ”¢ æœ€å¤§tokens: {max_tokens}", file=sys.stderr)
            print("â³ è¿™å¯èƒ½éœ€è¦ä¸€ä¼šï¼Œè¯·è€å¿ƒç­‰å¾…...", file=sys.stderr)
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # æ„å»ºå‘½ä»¤ - ä½¿ç”¨RUN --showè°ƒç”¨OPENROUTERå·¥å…·ï¼Œé€šè¿‡stdinä¼ é€’prompt
            cmd = [sys.executable, str(run_path), "--show", "OPENROUTER"]
            
            if model:
                cmd.extend(["--model", model])
            
            # ä¼ å…¥max-tokenså‚æ•°ï¼ˆOPENROUTERå·¥å…·ä¼šè‡ªåŠ¨å¤„ç†åŠ¨æ€è°ƒæ•´ï¼‰
            if max_tokens:
                cmd.extend(["--max-tokens", str(max_tokens)])
            
            # ä¼ å…¥temperatureå‚æ•°
            if temperature is not None:
                cmd.extend(["--temperature", str(temperature)])
            
            # ä¼ å…¥APIå¯†é’¥å‚æ•°
            if api_key:
                cmd.extend(["--key", api_key])
            
            # ä½¿ç”¨RUN --showæ¨¡å¼è°ƒç”¨OPENROUTERå·¥å…·ï¼Œé¿å…å“åº”è¢«æˆªæ–­
            try:
                result = subprocess.run(
                    cmd,
                    input=prompt,
                    text=True,
                    capture_output=True,
                    timeout=120,  # 2åˆ†é’Ÿè¶…æ—¶
                    encoding='utf-8'
                )
                
                # è®°å½•ç»“æŸæ—¶é—´
                end_time = time.time()
                api_duration = end_time - start_time
                
                # è§£æJSONå“åº”
                if result.returncode == 0:
                    try:
                        response_data = json.loads(result.stdout)
                        
                        if response_data.get('success'):
                            content = response_data.get('content', '')
                            
                            # æå–tokenä½¿ç”¨ä¿¡æ¯
                            usage = response_data.get('usage', {})
                            cost = response_data.get('cost', 0)
                            model_used = response_data.get('model', model)
                            
                            usage_info = {
                                'input_tokens': usage.get('input_tokens', 0),
                                'output_tokens': usage.get('output_tokens', 0),
                                'total_tokens': usage.get('total_tokens', 0),
                                'cost': cost,
                                'model': model_used,
                                'api_duration': api_duration
                            }
                            
                            print(f"âœ… OpenRouter APIè°ƒç”¨æˆåŠŸ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                            return content, usage_info
                        else:
                            error_msg = response_data.get('error', 'Unknown error')
                            print(f"âŒ OpenRouter APIè¿”å›é”™è¯¯: {error_msg}", file=sys.stderr)
                            return f"ERROR: {error_msg}", {"error": error_msg}
                            
                    except json.JSONDecodeError as e:
                        print(f"âŒ è§£æOpenRouterå“åº”å¤±è´¥: {e}", file=sys.stderr)
                        print(f"åŸå§‹å“åº”: {result.stdout[:500]}...", file=sys.stderr)
                        return f"ERROR: JSONè§£æå¤±è´¥: {e}", {"error": f"JSONè§£æå¤±è´¥: {e}"}
                else:
                    error_msg = result.stderr or "å‘½ä»¤æ‰§è¡Œå¤±è´¥"
                    print(f"âŒ OpenRouterå‘½ä»¤æ‰§è¡Œå¤±è´¥: {error_msg}", file=sys.stderr)
                    return f"ERROR: {error_msg}", {"error": error_msg}
                    
            except subprocess.TimeoutExpired:
                print("âŒ OpenRouter APIè°ƒç”¨è¶…æ—¶", file=sys.stderr)
                return "ERROR: APIè°ƒç”¨è¶…æ—¶", {"error": "APIè°ƒç”¨è¶…æ—¶"}
            except Exception as e:
                print(f"âŒ OpenRouter APIè°ƒç”¨å¼‚å¸¸: {e}", file=sys.stderr)
                return f"ERROR: {e}", {"error": str(e)}
        
    except Exception as e:
        print(f"âŒ call_openrouter_for_structureå¼‚å¸¸: {e}", file=sys.stderr)
        return f"ERROR: {e}", {"error": str(e)}


def extract_response_data(response_data):
    """Extract response content and usage info from API response."""
    response_content = ""
    usage_info = {}
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯RUN --showçš„åŒ…è£…æ ¼å¼
    if 'output' in response_data:
        try:
            output_content = response_data['output']
            if output_content.strip().startswith('{'):
                # outputæ˜¯JSONæ ¼å¼
                import json
                inner_data = json.loads(output_content)
                if inner_data.get('success'):
                    response_content = inner_data.get('content', '')
                    usage = inner_data.get('usage', {})
                    usage_info = {
                        'input_tokens': usage.get('input_tokens', 0),
                        'output_tokens': usage.get('output_tokens', 0),
                        'total_tokens': usage.get('total_tokens', 0),
                        'cost': inner_data.get('cost', 0)
                    }
                else:
                    response_content = output_content
            else:
                # outputæ˜¯çº¯æ–‡æœ¬ï¼Œä½†æ£€æŸ¥æ˜¯å¦æœ‰RUN_DATA_FILE
                response_content = output_content
                # å°è¯•ä»RUN_DATA_FILEä¸­è¯»å–tokenä¿¡æ¯
                if '_RUN_DATA_file' in response_data:
                    try:
                        import json
                        with open(response_data['_RUN_DATA_file'], 'r', encoding='utf-8') as f:
                            run_data = json.load(f)
                            if 'usage' in run_data:
                                usage = run_data['usage']
                                usage_info = {
                                    'input_tokens': usage.get('input_tokens', 0),
                                    'output_tokens': usage.get('output_tokens', 0),
                                    'total_tokens': usage.get('total_tokens', 0),
                                    'cost': run_data.get('cost', 0)
                                }
                    except (FileNotFoundError, json.JSONDecodeError, KeyError):
                        pass
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨outputå†…å®¹
            response_content = response_data['output']
    else:
        # ç›´æ¥ä»response_dataä¸­æå–
        response_content = response_data.get('content', 
                          response_data.get('response', 
                          response_data.get('message', '')))
        usage = response_data.get('usage', {})
        usage_info = {
            'input_tokens': usage.get('input_tokens', 0),
            'output_tokens': usage.get('output_tokens', 0),
            'total_tokens': usage.get('total_tokens', 0),
            'cost': response_data.get('cost', 0)
        }
    
    return response_content, usage_info


def clean_markdown_wrapper(content):
    """Clean markdown code block wrapper if present."""
    if '```markdown' in content:
        # ä½¿ç”¨```markdownåˆ†å‰²å†…å®¹
        parts = content.split('```markdown')
        if len(parts) >= 2:
            # å–ç¬¬äºŒéƒ¨åˆ†ï¼ˆ```markdownä¹‹åçš„å†…å®¹ï¼‰
            markdown_content = parts[1]
            # ç§»é™¤æœ€åçš„```ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if '```' in markdown_content:
                markdown_content = markdown_content.split('```')[0]
            return markdown_content.strip()
    return content


def generate_tutorial_prompt(params, brainstorming_response):
    """Generate prompt for tutorial.md creation."""
    if params["type"] == "general":
        # General topic
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        brainstorming_summary = brainstorming_response
        
        prompt = f"""è¯·ä¸º"{topic}"åˆ›å»ºä¸€ä¸ªç®€æ´çš„tutorial.mdæ–‡ä»¶ã€‚

å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹è¦ç‚¹åˆ›å»ºæ•™ç¨‹ï¼š
{brainstorming_summary}

è¯·åˆ›å»ºä¸€ä¸ªç»“æ„ç®€æ´çš„tutorial.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š
1. æ ‡é¢˜å’Œç›®å½•
2. 3-4ä¸ªæ ¸å¿ƒæ¦‚å¿µçš„è¯¦ç»†è§£é‡Šï¼ˆåŒ…å«ä»£ç ç¤ºä¾‹ï¼Œä¾‹é¢˜ç­‰ï¼Œif applicableï¼‰
3. ç®€æ˜çš„å­¦ä¹ è·¯å¾„æŒ‡å¯¼
4. 2-3ä¸ªå®è·µç»ƒä¹ å»ºè®®
5. ç²¾é€‰èµ„æºæ¨è

è¯·ç¡®ä¿å†…å®¹é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œå¹¶é‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚
è¯·ç›´æ¥æä¾›markdownæ ¼å¼çš„å†…å®¹ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•åˆ†éš”ç¬¦ã€‚"""
        
    else:
        # Paper-based
        paper_path = params.get('paper_path', 'è®ºæ–‡')
        paper_content = params.get('paper_content', '')
        mode = params['mode']
        style = params['style']
        
        # Use brainstorming response if available, otherwise use paper content directly
        if brainstorming_response:
            content_base = f"""å¤´è„‘é£æš´åˆ†æç»“æœï¼š
{brainstorming_response}

åŸè®ºæ–‡å†…å®¹ï¼ˆå‚è€ƒï¼‰ï¼š
{paper_content[:5000]}{'...' if len(paper_content) > 5000 else ''}"""
        else:
            content_base = f"""è®ºæ–‡å†…å®¹ï¼š
{paper_content}"""
        
        prompt = f"""è¯·åŸºäºå­¦æœ¯è®ºæ–‡å†…å®¹åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„tutorial.mdæ•™ç¨‹æ–‡ä»¶ã€‚

è®ºæ–‡ï¼š{paper_path}
å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹å†…å®¹åˆ›å»ºæ•™ç¨‹ï¼š
{content_base}

è¯·åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„tutorial.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š

1. **è®ºæ–‡æ¦‚è§ˆ**
   - è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å‘è¡¨ä¿¡æ¯
   - ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº
   - ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

2. **æ ¸å¿ƒæ¦‚å¿µè¯¦è§£**
   - å…³é”®æ¦‚å¿µçš„å®šä¹‰å’Œè§£é‡Š
   - æŠ€æœ¯æ–¹æ³•çš„è¯¦ç»†è¯´æ˜
   - ç®—æ³•æˆ–æ¨¡å‹çš„å·¥ä½œåŸç†

3. **æŠ€æœ¯ç»†èŠ‚**
   - å®ç°æ–¹æ³•å’ŒæŠ€æœ¯è·¯çº¿
   - å®éªŒè®¾è®¡å’Œè¯„ä¼°æ–¹æ³•
   - ç»“æœåˆ†æå’Œè®¨è®º

4. **å­¦ä¹ è¦ç‚¹**
   - é‡ç‚¹çŸ¥è¯†ç‚¹æ€»ç»“
   - ä¸ç°æœ‰æ–¹æ³•çš„æ¯”è¾ƒ
   - ä¼˜åŠ¿å’Œå±€é™æ€§åˆ†æ

5. **æ‰©å±•é˜…è¯»**
   - ç›¸å…³è®ºæ–‡æ¨è
   - è¿›ä¸€æ­¥å­¦ä¹ èµ„æº

è¯·ç¡®ä¿å†…å®¹é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚
è¯·ç›´æ¥æä¾›markdownæ ¼å¼çš„å†…å®¹ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•åˆ†éš”ç¬¦ã€‚"""
    
    return prompt


def generate_question_prompt(params, tutorial_content):
    """Generate prompt for question.md creation."""
    if params["type"] == "general":
        # General topic
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        tutorial_summary = tutorial_content
        
        prompt = f"""è¯·ä¸º"{topic}"åˆ›å»ºç®€æ´çš„ç»ƒä¹ é¢˜æ–‡ä»¶question.mdã€‚

å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹æ•™ç¨‹å†…å®¹åˆ›å»ºç»ƒä¹ é¢˜ï¼š
{tutorial_summary}

è¯·åˆ›å»ºä¸€ä¸ªç®€æ´çš„question.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š
1. åŸºç¡€çŸ¥è¯†æµ‹è¯•é¢˜ï¼ˆ3é¢˜ï¼‰
2. ç†è§£åº”ç”¨é¢˜ï¼ˆ3é¢˜ï¼‰
3. å®è·µç»ƒä¹ é¢˜ï¼ˆ2é¢˜ï¼‰
4. æ€è€ƒé¢˜ï¼ˆ2é¢˜ï¼‰
5. æ¯ä¸ªé—®é¢˜éƒ½è¦æœ‰ç®€æ´æ˜ç¡®çš„ç­”æ¡ˆ

è¯·ä½¿ç”¨HTMLçš„details/summaryæ ‡ç­¾æ¥åˆ›å»ºå¯å±•å¼€çš„ç­”æ¡ˆåŒºåŸŸã€‚
è¯·ç¡®ä¿é—®é¢˜é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ã€‚
è¯·æ§åˆ¶å†…å®¹é•¿åº¦ï¼Œä¿æŒç®€æ´ã€‚"""
        
    else:
        # Paper-based
        paper_path = params.get('paper_path', 'è®ºæ–‡')
        mode = params['mode']
        style = params['style']
        
        tutorial_summary = tutorial_content
        
        prompt = f"""è¯·åŸºäºå­¦æœ¯è®ºæ–‡æ•™ç¨‹åˆ›å»ºcomprehensiveçš„ç»ƒä¹ é¢˜æ–‡ä»¶question.mdã€‚

è®ºæ–‡ï¼š{paper_path}
å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹æ•™ç¨‹å†…å®¹åˆ›å»ºç»ƒä¹ é¢˜ï¼š
{tutorial_summary}

è¯·åˆ›å»ºä¸€ä¸ªå…¨é¢çš„question.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š

1. **è®ºæ–‡ç†è§£é¢˜ï¼ˆ4é¢˜ï¼‰**
   - ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœºç†è§£
   - ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹
   - æŠ€æœ¯æ–¹æ³•å’ŒåŸç†
   - å®éªŒç»“æœå’Œç»“è®º

2. **æ¦‚å¿µè§£é‡Šé¢˜ï¼ˆ3é¢˜ï¼‰**
   - å…³é”®æ¦‚å¿µå®šä¹‰
   - æŠ€æœ¯æœ¯è¯­è§£é‡Š
   - æ–¹æ³•æ¯”è¾ƒåˆ†æ

3. **æ‰¹åˆ¤æ€§æ€è€ƒé¢˜ï¼ˆ3é¢˜ï¼‰**
   - æ–¹æ³•ä¼˜ç¼ºç‚¹åˆ†æ
   - æ”¹è¿›å»ºè®®å’Œæ‰©å±•
   - åº”ç”¨åœºæ™¯è®¨è®º

4. **å®è·µåº”ç”¨é¢˜ï¼ˆ2é¢˜ï¼‰**
   - å®é™…åº”ç”¨è®¾è®¡
   - å®ç°æ€è·¯åˆ†æ

æ¯ä¸ªé—®é¢˜éƒ½å¿…é¡»ï¼š
- åŸºäºæ•™ç¨‹ä¸­çš„å…·ä½“å†…å®¹
- æœ‰è¯¦ç»†å‡†ç¡®çš„ç­”æ¡ˆ
- ä½¿ç”¨HTMLçš„<details>å’Œ<summary>æ ‡ç­¾å®ç°ç­”æ¡ˆæŠ˜å 

æ ¼å¼ç¤ºä¾‹ï¼š
### é—®é¢˜1ï¼šè¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

[è¯¦ç»†ç­”æ¡ˆå†…å®¹...]

</details>

è¯·ç¡®ä¿é—®é¢˜é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚"""
    
    return prompt


def create_learning_files_from_responses(params, tutorial_response, question_response, prompts_and_responses=None):
    """Create learning files from separate tutorial and question responses."""
    log_progress("å¼€å§‹åˆ›å»ºæ–‡ä»¶", "FILE")
    output_dir = params['output_dir']
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    log_progress(f"è¾“å‡ºç›®å½•å‡†å¤‡å®Œæˆ: {output_dir}", "FILE")
    
    try:
        # åˆ›å»ºtutorial.md
        log_progress("åˆ›å»ºtutorial.mdæ–‡ä»¶", "FILE")
        tutorial_path = Path(output_dir) / "tutorial.md"
        with open(tutorial_path, 'w', encoding='utf-8') as f:
            f.write(tutorial_response)
        log_progress(f"tutorial.mdåˆ›å»ºæˆåŠŸ: {tutorial_path}", "FILE")
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {tutorial_path}")
        
        # åˆ›å»ºquestion.md
        log_progress("åˆ›å»ºquestion.mdæ–‡ä»¶", "FILE")
        question_path = Path(output_dir) / "question.md"
        with open(question_path, 'w', encoding='utf-8') as f:
            f.write(question_response)
        log_progress(f"question.mdåˆ›å»ºæˆåŠŸ: {question_path}", "FILE")
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {question_path}")
        
        # åˆ›å»ºOPENROUTER_promptsæ–‡ä»¶å¤¹å¹¶ä¿å­˜promptså’Œresponses
        if prompts_and_responses:
            prompts_dir = Path(output_dir) / "OPENROUTER_prompts"
            prompts_dir.mkdir(exist_ok=True)
            
            for i, (prompt, response, token_info) in enumerate(prompts_and_responses, 1):
                # ä¿å­˜prompt
                prompt_path = prompts_dir / f"prompt_{i}.txt"
                with open(prompt_path, 'w', encoding='utf-8') as f:
                    f.write(prompt)
                    f.write(f"\n\n--- Openrouter API Call Info ---\n")
                    f.write(f"model: {token_info.get('model', 'unknown')}\n")
                    f.write(f"prompt_tokens: {token_info.get('prompt_tokens', 0)}\n")
                    f.write(f"completion_tokens: {token_info.get('completion_tokens', 0)}\n")
                    f.write(f"total_tokens: {token_info.get('total_tokens', 0)}\n")
                    f.write(f"cost: ${token_info.get('cost', 0):.6f}\n")
                    f.write(f"api_duration: {token_info.get('api_duration', 0):.2f} seconds\n")
                
                # ä¿å­˜response
                response_path = prompts_dir / f"response_{i}.txt"
                with open(response_path, 'w', encoding='utf-8') as f:
                    f.write(response)
                    f.write(f"\n\n--- Openrouter API Call Info ---\n")
                    f.write(f"model: {token_info.get('model', 'unknown')}\n")
                    f.write(f"prompt_tokens: {token_info.get('prompt_tokens', 0)}\n")
                    f.write(f"completion_tokens: {token_info.get('completion_tokens', 0)}\n")
                    f.write(f"total_tokens: {token_info.get('total_tokens', 0)}\n")
                    f.write(f"cost: ${token_info.get('cost', 0):.6f}\n")
                    f.write(f"api_duration: {token_info.get('api_duration', 0):.2f} seconds\n")
                
                print(f"âœ… ä¿å­˜promptå’Œresponse: {prompt_path.name}, {response_path.name}")
                model_used = token_info.get('model', 'unknown')
                cost = token_info.get('cost', 0)
                print(f"ğŸ“Š Tokenä½¿ç”¨: {token_info.get('total_tokens', 0)} tokens - æ¨¡å‹: {model_used} - è´¹ç”¨: ${cost:.6f} - ç”¨æ—¶: {token_info.get('api_duration', 0):.2f}ç§’")
        
        file_count = 2 + (len(prompts_and_responses) * 2 if prompts_and_responses else 0)
        print(f"\nğŸ“ åˆ›å»ºäº† {file_count} ä¸ªæ–‡ä»¶:")
        print(f"  - {tutorial_path}")
        print(f"  - {question_path}")
        if prompts_and_responses:
            print(f"  - OPENROUTER_prompts/ æ–‡ä»¶å¤¹åŒ…å« {len(prompts_and_responses)} ç»„promptå’Œresponse")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False


def call_openrouter_with_retry(prompt, model, max_tokens, step_name, max_retries=3, params=None):
    """Call OpenRouter API with retry mechanism and model switching."""
    log_progress(f"å¼€å§‹{step_name}", "API")
    current_model = model
    
    # æå–é¢å¤–å‚æ•°
    temperature = params.get('temperature') if params else None
    api_key = params.get('api_key') if params else None
    
    for attempt in range(max_retries):
        log_progress(f"{step_name} - ç¬¬{attempt + 1}æ¬¡å°è¯•", "API")
        response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, attempt, temperature, api_key)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸï¼ˆä¸æ˜¯Noneä¸”ä¸æ˜¯é”™è¯¯ï¼‰
        if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
            log_progress(f"{step_name}æˆåŠŸå®Œæˆ - ä½¿ç”¨æ¨¡å‹: {current_model}", "API")
            return response, token_info, current_model
        
        log_progress(f"{step_name}å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•) - é”™è¯¯: {str(response)[:100]}...", "ERROR")
        print(f"âŒ {step_name}å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•)", file=sys.stderr)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯429é”™è¯¯ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰æˆ–å…¶ä»–é”™è¯¯éœ€è¦åˆ‡æ¢æ¨¡å‹
        if should_switch_model(response, attempt, max_retries):
            current_model = handle_model_switching(current_model, params, step_name)
            if not current_model:
                break
            
            # ç”¨æ–°æ¨¡å‹é‡è¯•
            response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, 0, temperature, api_key)
            if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
                return response, token_info, current_model
    
    return None, None, current_model


def should_switch_model(response, attempt, max_retries):
    """Determine if we should switch models based on error type and attempt."""
    if response and isinstance(response, str):
        # ç«‹å³åˆ‡æ¢çš„æƒ…å†µï¼š429é”™è¯¯
        if "429" in response or "rate-limited" in response:
            return True
        # æœ€åä¸€æ¬¡é‡è¯•æ—¶åˆ‡æ¢çš„æƒ…å†µï¼šå…¶ä»–é”™è¯¯
        if attempt == max_retries - 1:
            return True
    return False


def handle_model_switching(current_model, params, step_name):
    """Handle model switching logic."""
    # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
    all_models, model_details = get_openrouter_models()
    if not all_models:
        print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨", file=sys.stderr)
        return None
    
    # ç§»é™¤å½“å‰å¤±è´¥çš„æ¨¡å‹
    available_models = [m for m in all_models if m != current_model]
    if not available_models:
        print("âŒ æ²¡æœ‰å…¶ä»–å¯ç”¨æ¨¡å‹", file=sys.stderr)
        return None
    
    # åˆ†ç±»æ¨¡å‹
    free_models = [m for m in available_models if ":free" in m]
    paid_models = [m for m in available_models if ":free" not in m]
    
    # é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨åˆ‡æ¢
    if params and not params.get('not_default', False):
        if current_model and ":free" in current_model and free_models:
            new_model = free_models[0]
            print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå…è´¹æ¨¡å‹: {new_model}", file=sys.stderr)
            return new_model
        elif paid_models:
            new_model = paid_models[0]
            print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä»˜è´¹æ¨¡å‹: {new_model}", file=sys.stderr)
            return new_model
    else:
        # äº¤äº’æ¨¡å¼ï¼šè®©ç”¨æˆ·é€‰æ‹©
        return interactive_model_selection(current_model, free_models, paid_models, step_name)
    
    return None


def interactive_model_selection(failed_model, free_models, paid_models, step_name):
    """Interactive model selection when switching models."""
    print(f"\nâš ï¸  æ¨¡å‹ '{failed_model}' è°ƒç”¨å¤±è´¥", file=sys.stderr)
    print("å¯ç”¨çš„æ›¿ä»£æ¨¡å‹ï¼š", file=sys.stderr)
    
    all_available = []
    if free_models:
        print("å…è´¹æ¨¡å‹ï¼š", file=sys.stderr)
        for i, model_name in enumerate(free_models):
            print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
            all_available.append(model_name)
    
    if paid_models:
        print("ä»˜è´¹æ¨¡å‹ï¼š", file=sys.stderr)
        for i, model_name in enumerate(paid_models):
            print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
            all_available.append(model_name)
    
    try:
        choice = input(f"\né€‰æ‹©æ¨¡å‹ (1-{len(all_available)}) æˆ–æŒ‰å›è½¦è·³è¿‡: ").strip()
        if choice and choice.isdigit():
            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(all_available):
                new_model = all_available[choice_idx]
                print(f"âœ… åˆ‡æ¢åˆ°æ¨¡å‹: {new_model}", file=sys.stderr)
                return new_model
    except (KeyboardInterrupt, EOFError):
        print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ", file=sys.stderr)
    
    return None


def generate_learning_content(params):
    """Generate learning content based on collected parameters."""
    log_progress("å¼€å§‹ç”Ÿæˆå­¦ä¹ å†…å®¹", "MAIN")
    print("\nğŸ¤– æ­£åœ¨ç”Ÿæˆå­¦ä¹ å†…å®¹ç»“æ„...")
    
    # ç”¨äºä¿å­˜æ‰€æœ‰çš„promptså’Œresponsesï¼Œç°åœ¨åŒ…å«tokenä¿¡æ¯
    prompts_and_responses = []
    
    # For paper type, model selection might already be done in generate_content_structure_prompt
    if params["type"] == "paper" and params.get("selected_model"):
        selected_model = params["selected_model"]
        max_tokens = params["max_tokens"]
        log_progress(f"ä½¿ç”¨é¢„é€‰æ¨¡å‹: {selected_model}", "MODEL")
        print(f"âœ… ä½¿ç”¨å·²é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
    else:
        # è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹
        log_progress("å¼€å§‹æ¨¡å‹é€‰æ‹©æµç¨‹", "MODEL")
        selected_model, max_tokens = select_openrouter_model(params)
        if not selected_model:
            log_progress("æ¨¡å‹é€‰æ‹©å¤±è´¥", "ERROR")
            print("âŒ æœªé€‰æ‹©æ¨¡å‹")
            return None
        
        log_progress(f"æ¨¡å‹é€‰æ‹©å®Œæˆ: {selected_model}", "MODEL")
        # Store selected model info in params for later use
        params["selected_model"] = selected_model
        params["max_tokens"] = max_tokens
    
    # Step 1: Brainstorming (optional for papers)
    brainstorming_response = None
    brainstorming_token_info = None
    
    # æ£€æŸ¥æ˜¯å¦è·³è¿‡brainstormingï¼ˆåªæœ‰contextæ¨¡å¼æ‰è·³è¿‡ï¼‰
    if params.get("context_mode", False):
        log_progress("è·³è¿‡å¤´è„‘é£æš´æ­¥éª¤ï¼ˆcontextæ¨¡å¼ï¼‰", "SKIP")
        print("\nâ­ï¸  è·³è¿‡å¤´è„‘é£æš´æ­¥éª¤ï¼ˆ--contextæ¨¡å¼ï¼‰")
        # ç›´æ¥å‡†å¤‡è®ºæ–‡å†…å®¹ç”¨äºåç»­æ­¥éª¤
        if params["type"] == "paper":
            structure_prompt = generate_content_structure_prompt(params)
            if structure_prompt is None:
                print("âŒ å†…å®¹å‡†å¤‡å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ç”Ÿæˆå­¦ä¹ ææ–™")
                return None
    else:
        print("\nğŸ“ ç¬¬1æ­¥ï¼šè¯¢é—®AIè¿›è¡Œå¤´è„‘é£æš´...")
        structure_prompt = generate_content_structure_prompt(params)
        
        # Check if content preparation failed (e.g., PDF extraction failed)
        if structure_prompt is None and params["type"] == "paper":
            print("âŒ å†…å®¹å‡†å¤‡å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ç”Ÿæˆå­¦ä¹ ææ–™")
            return None
    
    if structure_prompt and not params.get("context_mode", False):  # Brainstorming was requested
        log_progress("å¼€å§‹å¤´è„‘é£æš´æ­¥éª¤", "STEP")
        print("æŸ¥è¯¢å†…å®¹:")
        print("-" * 40)
        print(structure_prompt[:500] + "..." if len(structure_prompt) > 500 else structure_prompt)
        print("-" * 40)
        
        # Call OpenRouter API for brainstorming with retry
        brainstorming_response, brainstorming_token_info, current_model = call_openrouter_with_retry(
            structure_prompt, selected_model, max_tokens, "å¤´è„‘é£æš´", params=params
        )
        
        if brainstorming_response is None:
            log_progress("å¤´è„‘é£æš´æ­¥éª¤å¤±è´¥", "ERROR")
            print("âŒ å¤´è„‘é£æš´å¤±è´¥")
            return None
        
        log_progress("å¤´è„‘é£æš´æ­¥éª¤å®Œæˆ", "STEP")
        # ä¿å­˜ç¬¬ä¸€ç»„promptå’Œresponse
        prompts_and_responses.append((structure_prompt, brainstorming_response, brainstorming_token_info))
        
        # å¦‚æœæ˜¯brainstorm_onlyæ¨¡å¼ï¼Œåªè¿”å›brainstormingç»“æœ
        if params.get("brainstorm_only", False):
            log_progress("ä»…å¤´è„‘é£æš´æ¨¡å¼ï¼Œè¿”å›ç»“æœ", "COMPLETE")
            print("\nğŸ“‹ å¤´è„‘é£æš´å®Œæˆï¼ä»¥ä¸‹æ˜¯ç”Ÿæˆçš„ç»“æ„å»ºè®®ï¼š")
            print("=" * 60)
            print(brainstorming_response)
            print("=" * 60)
            print("\nğŸ’¡ ä½ å¯ä»¥åŸºäºä»¥ä¸Šå»ºè®®æ‰‹åŠ¨åˆ›å»ºtutorial.mdå’Œquestion.mdæ–‡ä»¶")
            return {
                'brainstorming_response': brainstorming_response,
                'prompts_and_responses': prompts_and_responses
            }
    else:
        print("â­ï¸  è·³è¿‡å¤´è„‘é£æš´ï¼Œç›´æ¥ç”Ÿæˆæ•™ç¨‹")
        
        # For paper type without brainstorming, check if we should continue
        if params["type"] == "paper":
            creation_mode = determine_creation_mode(params, selected_model)
            if creation_mode == "manual":
                params["brainstorm_only"] = True
    
    # Step 2: Generate tutorial.md
    log_progress("å¼€å§‹ç”Ÿæˆtutorial.md", "STEP")
    print("\nğŸ“ ç¬¬2æ­¥ï¼šåŸºäºå†…å®¹ç”Ÿæˆtutorial.md...")
    tutorial_prompt = generate_tutorial_prompt(params, brainstorming_response)
    
    print("æŸ¥è¯¢å†…å®¹:")
    print("-" * 40)
    print(tutorial_prompt[:500] + "..." if len(tutorial_prompt) > 500 else tutorial_prompt)
    print("-" * 40)
    
    tutorial_response, tutorial_token_info, current_model = call_openrouter_with_retry(
        tutorial_prompt, selected_model, max_tokens, "tutorial.mdç”Ÿæˆ", params=params
    )
    
    if tutorial_response is None:
        log_progress("tutorial.mdç”Ÿæˆå¤±è´¥", "ERROR")
        print("âŒ tutorial.mdç”Ÿæˆå¤±è´¥")
        return None
    
    log_progress("tutorial.mdç”Ÿæˆå®Œæˆ", "STEP")
    # ä¿å­˜ç¬¬äºŒç»„promptå’Œresponse
    prompts_and_responses.append((tutorial_prompt, tutorial_response, tutorial_token_info))
    
    # Step 3: Generate question.md
    log_progress("å¼€å§‹ç”Ÿæˆquestion.md", "STEP")
    print("\nğŸ“ ç¬¬3æ­¥ï¼šåŸºäºtutorial.mdç”Ÿæˆquestion.md...")
    question_prompt = generate_question_prompt(params, tutorial_response)
    
    print("æŸ¥è¯¢å†…å®¹:")
    print("-" * 40)
    print(question_prompt[:500] + "..." if len(question_prompt) > 500 else question_prompt)
    print("-" * 40)
    
    question_response, question_token_info, current_model = call_openrouter_with_retry(
        question_prompt, selected_model, max_tokens, "question.mdç”Ÿæˆ", params=params
    )
    
    if question_response is None:
        log_progress("question.mdç”Ÿæˆå¤±è´¥", "ERROR")
        print("âŒ question.mdç”Ÿæˆå¤±è´¥")
        return None
    
    log_progress("question.mdç”Ÿæˆå®Œæˆ", "STEP")
    # ä¿å­˜ç¬¬ä¸‰ç»„promptå’Œresponse
    prompts_and_responses.append((question_prompt, question_response, question_token_info))
    
    log_progress("æ‰€æœ‰å†…å®¹ç”Ÿæˆå®Œæˆ", "COMPLETE")
    # è¿”å›æ‰€æœ‰ç”Ÿæˆçš„å†…å®¹
    return {
        'tutorial_response': tutorial_response,
        'question_response': question_response,
        'brainstorming_response': brainstorming_response,
        'prompts_and_responses': prompts_and_responses
    }


def determine_creation_mode(params, selected_model):
    """Determine creation mode for paper type without brainstorming."""
    # Auto-proceed in default mode or with free models
    if not params.get('not_default', False):
        print("ğŸš€ é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨é€‰æ‹©åˆ›å»ºæ¨¡å¼...")
        return "auto"
    
    # Check if using free model
    if selected_model:
        models, model_details = get_openrouter_models()
        if models:
            details = model_details.get(selected_model, {})
            is_free_model = details.get('input_cost_per_1m', 0) == 0
            if is_free_model:
                print("ğŸš€ å…è´¹æ¨¡å‹ï¼šè‡ªåŠ¨é€‰æ‹©åˆ›å»ºæ¨¡å¼...")
                return "auto"
    
    # Ask user about creation mode
    print("\nğŸ¯ é€‰æ‹©åˆ›å»ºæ¨¡å¼:")
    creation_choice = interactive_select(
        "åˆ›å»ºæ¨¡å¼:", 
        ["è‡ªåŠ¨åˆ›å»º (AIç”Ÿæˆ3æ¬¡)", "æ‰‹åŠ¨åˆ›å»º (AIç”Ÿæˆ1æ¬¡ï¼Œä½ æ¥åˆ›å»ºæ–‡ä»¶)"]
    )
    
    return "manual" if creation_choice == 1 else "auto"


def count_tokens(text):
    """Simple token counting approximation."""
    # Rough approximation: 1 token â‰ˆ 4 characters for Chinese/English mixed text
    return len(text) // 4


def prepare_paper_content(params):
    """Prepare paper content based on input type."""
    input_type = params.get("input_type", 1)
    paper_content = None
    paper_path = None
    
    if input_type == 0:  # Markdown file
        paper_content = params.get("paper_content")
        paper_path = params.get("paper_path")
        print("âœ… ä½¿ç”¨å·²æä¾›çš„Markdownå†…å®¹")
        
    elif input_type == 1:  # PDF file
        paper_path = params.get("paper_path")
        read_images = params.get("read_images", False)
        paper_content, processed_path = process_paper_with_extract_pdf(paper_path, read_images)
        if processed_path:
            paper_path = processed_path
            
    elif input_type == 2:  # URL
        paper_url = params.get("paper_url")
        print(f"ğŸ“¥ ä¸‹è½½è®ºæ–‡: {paper_url}")
        
        # Extract filename from URL or use generic name
        import urllib.parse
        parsed_url = urllib.parse.urlparse(paper_url)
        filename = Path(parsed_url.path).name or "downloaded_paper.pdf"
        
        downloaded_path, title = download_paper(paper_url, filename.replace('.pdf', ''), 
                                               output_dir=params.get('output_dir'))
        if downloaded_path:
            read_images = params.get("read_images", False)
            paper_content, processed_path = process_paper_with_extract_pdf(downloaded_path, read_images)
            if processed_path:
                paper_path = processed_path
        else:
            print("âŒ æ— æ³•ä¸‹è½½è®ºæ–‡")
            return None, None, 0
            
    elif input_type == 3:  # Description/Search
        paper_description = params.get("paper_description")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºcontextæ¨¡å¼ï¼ˆåŒ…æ‹¬æ–‡ä»¶å¼•ç”¨æˆ–æ‰‹åŠ¨å¯ç”¨ï¼‰
        if params.get("context_mode", False):
            print("ğŸ“„ Contextæ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨descriptionå†…å®¹è€Œéæœç´¢è®ºæ–‡")
            # ç›´æ¥ä½¿ç”¨descriptionä¸­çš„å†…å®¹
            paper_content = paper_description
            paper_path = "context_content"
            # ä¼°ç®—tokenæ•°é‡
            token_count = len(paper_content) // 4  # ç²—ç•¥ä¼°ç®—
            print(f"âœ… Contextå†…å®¹å¤„ç†å®Œæˆï¼Œå†…å®¹é•¿åº¦: {token_count} tokens")
        else:
            paper_content, downloaded_path, token_count = search_and_download_paper(paper_description, params)
            if paper_content:
                print(f"âœ… è®ºæ–‡å¤„ç†å®Œæˆï¼Œå†…å®¹é•¿åº¦: {token_count} tokens")
                paper_path = downloaded_path  # PDFè·¯å¾„
            else:
                print("âŒ æ— æ³•æ‰¾åˆ°æˆ–ä¸‹è½½è®ºæ–‡")
                return None, None, 0
    

    
    if not paper_content:
        print("âŒ æ— æ³•è·å–è®ºæ–‡å†…å®¹")
        return None, None, 0
    
    # Count tokens
    token_count = count_tokens(paper_content)
    print(f"\nğŸ“Š è®ºæ–‡å†…å®¹ç»Ÿè®¡:")
    print(f"   å­—ç¬¦æ•°: {len(paper_content):,}")
    print(f"   é¢„ä¼°tokenæ•°: {token_count:,}")
    
    return paper_content, paper_path, token_count


def call_openrouter_with_auto_model(prompt, model="auto", max_retries=3):
    """
    è°ƒç”¨OPENROUTER APIï¼Œæ”¯æŒè‡ªåŠ¨æ¨¡å‹é€‰æ‹©
    
    Args:
        prompt: æç¤ºè¯
        model: æ¨¡å‹IDï¼Œ"auto"è¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        APIè°ƒç”¨ç»“æœ
    """
    try:
        from OPENROUTER import call_openrouter_api, get_useable_models
        
        if model == "auto":
            # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
            useable_models = get_useable_models()
            if not useable_models:
                print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
                return {"success": False, "error": "No useable models available"}
            
            # å°è¯•æŒ‰é¡ºåºè°ƒç”¨æ¨¡å‹
            for i, model_id in enumerate(useable_models):
                print(f"ğŸ¤– å°è¯•æ¨¡å‹ {i+1}/{len(useable_models)}: {model_id}")
                
                try:
                    result = call_openrouter_api(prompt, model=model_id)
                    if result['success']:
                        print(f"âœ… æ¨¡å‹ {model_id} è°ƒç”¨æˆåŠŸ")
                        return result
                    else:
                        print(f"âš ï¸  æ¨¡å‹ {model_id} è°ƒç”¨å¤±è´¥: {result.get('error', 'Unknown error')}")
                        if i < len(useable_models) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªæ¨¡å‹
                            print(f"ğŸ”„ å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
                            continue
                        
                except Exception as e:
                    print(f"âš ï¸  æ¨¡å‹ {model_id} è°ƒç”¨å¼‚å¸¸: {e}")
                    if i < len(useable_models) - 1:
                        print(f"ğŸ”„ å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
                        continue
            
            # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†
            return {"success": False, "error": "All models failed"}
        
        else:
            # ä½¿ç”¨æŒ‡å®šæ¨¡å‹
            print(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {model}")
            return call_openrouter_api(prompt, model=model)
            
    except Exception as e:
        return {"success": False, "error": f"APIè°ƒç”¨å¼‚å¸¸: {e}"}


def optimize_search_query_with_ai(user_description):
    """ä½¿ç”¨AIä¼˜åŒ–æœç´¢æŸ¥è¯¢ï¼Œå°†ç”¨æˆ·æè¿°è½¬æ¢ä¸ºæ›´å¥½çš„è‹±æ–‡æœç´¢è¯"""
    try:
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯æœç´¢ä¸“å®¶ã€‚ç”¨æˆ·æƒ³è¦æœç´¢ä»¥ä¸‹ä¸»é¢˜çš„è®ºæ–‡ï¼š

ç”¨æˆ·æè¿°ï¼š{user_description}

è¯·å¸®åŠ©ä¼˜åŒ–è¿™ä¸ªæœç´¢æŸ¥è¯¢ï¼Œç”Ÿæˆ2-4ä¸ªæœ€ä½³çš„è‹±æ–‡æœç´¢å…³é”®è¯æˆ–çŸ­è¯­ï¼Œç”¨äºåœ¨å­¦æœ¯æ•°æ®åº“ä¸­æœç´¢ç›¸å…³è®ºæ–‡ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨è‹±æ–‡å…³é”®è¯æˆ–çŸ­è¯­
2. æ¯ä¸ªå…³é”®è¯/çŸ­è¯­ä¸è¶…è¿‡3ä¸ªå•è¯
3. æ€»è¯æ±‡é‡æ§åˆ¶åœ¨10ä¸ªå•è¯ä»¥å†…
4. åŒ…å«æ ¸å¿ƒæŠ€æœ¯æœ¯è¯­ï¼Œç¡®ä¿ç²¾ç¡®åŒ¹é…
5. é¿å…è¿‡äºå®½æ³›çš„è¯æ±‡ï¼ˆå¦‚å•ç‹¬çš„"machine learning"ï¼‰
6. é€‚åˆåœ¨arXivã€Google Scholarç­‰å¹³å°æœç´¢
7. ä¼˜å…ˆä½¿ç”¨å…·ä½“çš„ç®—æ³•åç§°æˆ–æŠ€æœ¯æœ¯è¯­

è¯·åªè¿”å›æœç´¢å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚

ä¾‹å¦‚ï¼š
- å¦‚æœç”¨æˆ·è¯´"3DGS mesh reconstruction"ï¼Œè¿”å›ï¼š"3D Gaussian Splatting, mesh reconstruction, neural rendering"
- å¦‚æœç”¨æˆ·è¯´"æœºå™¨å­¦ä¹ ä¼˜åŒ–ç®—æ³•"ï¼Œè¿”å›ï¼š"gradient descent optimization, SGD algorithms, optimization methods"
- å¦‚æœç”¨æˆ·è¯´"é¦™æ¸¯ç¯å¢ƒä¿æŠ¤è¿åŠ¨"ï¼Œè¿”å›ï¼š"Hong Kong environmental policy, sustainability initiatives, urban environmental management"

æœç´¢å…³é”®è¯ï¼š"""

        print("ğŸ¤– æ­£åœ¨è°ƒç”¨OpenRouterä¼˜åŒ–æœç´¢æŸ¥è¯¢...")
        result = call_openrouter_with_auto_model(prompt, model="auto")
        
        if result['success']:
            optimized_query = result['content'].strip()
            print(f"âœ… ä¼˜åŒ–åçš„æœç´¢è¯: {optimized_query}")
            return optimized_query
        else:
            print(f"âš ï¸  AIä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æè¿°: {result['error']}")
            return user_description
            
    except Exception as e:
        print(f"âš ï¸  AIä¼˜åŒ–å‡ºé”™ï¼Œä½¿ç”¨åŸå§‹æè¿°: {e}")
        return user_description


def recommend_search_engines_with_ai(user_description, optimized_query):
    """ä½¿ç”¨AIæ¨èæœ€é€‚åˆçš„è®ºæ–‡æœç´¢å¼•æ“"""
    try:
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯æœç´¢ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æœç´¢éœ€æ±‚æ¨èæœ€é€‚åˆçš„è®ºæ–‡æœç´¢å¹³å°ã€‚

ç”¨æˆ·æè¿°ï¼š{user_description}
ä¼˜åŒ–åçš„æœç´¢è¯ï¼š{optimized_query}

å¯ç”¨çš„æœç´¢å¹³å°ï¼š
1. arxiv - ä¸»è¦åŒ…å«è®¡ç®—æœºç§‘å­¦ã€ç‰©ç†å­¦ã€æ•°å­¦ã€ç»Ÿè®¡å­¦ç­‰é¢†åŸŸçš„é¢„å°æœ¬è®ºæ–‡
2. google_scholar - è¦†ç›–æ‰€æœ‰å­¦ç§‘é¢†åŸŸï¼ŒåŒ…æ‹¬å·²å‘è¡¨çš„æœŸåˆŠè®ºæ–‡ã€ä¼šè®®è®ºæ–‡ã€å­¦ä½è®ºæ–‡ç­‰

è¯·æ ¹æ®æœç´¢ä¸»é¢˜é€‰æ‹©æœ€åˆé€‚çš„æœç´¢å¹³å°ï¼š

- å¦‚æœæ˜¯è®¡ç®—æœºç§‘å­¦ã€AIã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç‰©ç†ã€æ•°å­¦ç­‰æŠ€æœ¯é¢†åŸŸï¼Œæ¨èï¼šarxiv,google_scholar
- å¦‚æœæ˜¯ä¼˜åŒ–ç®—æ³•ã€æœºå™¨å­¦ä¹ ç®—æ³•ã€å…·ä½“ç®—æ³•ç ”ç©¶ç­‰ï¼Œæ¨èï¼šgoogle_scholar ï¼ˆGoogle Scholaræœ‰æ›´ä¸°å¯Œçš„ç®—æ³•è®ºæ–‡ï¼‰
- å¦‚æœæ˜¯ç¤¾ä¼šç§‘å­¦ã€ç¯å¢ƒæ”¿ç­–ã€ç»æµå­¦ã€ç®¡ç†å­¦ã€åŒ»å­¦ç­‰é¢†åŸŸï¼Œæ¨èï¼šgoogle_scholar
- å¦‚æœæ˜¯è·¨å­¦ç§‘æˆ–ä¸ç¡®å®šé¢†åŸŸï¼Œæ¨èï¼šarxiv,google_scholar

è¯·åªè¿”å›æ¨èçš„æœç´¢å¼•æ“ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
ä¾‹å¦‚ï¼šarxiv,google_scholar æˆ– google_scholar

æ¨èçš„æœç´¢å¼•æ“ï¼š"""

        print("ğŸ¤– æ­£åœ¨æ¨èæœ€é€‚åˆçš„æœç´¢å¼•æ“...")
        result = call_openrouter_with_auto_model(prompt, model="auto")
        
        if result['success']:
            recommended_sources = result['content'].strip()
            print(f"âœ… æ¨èçš„æœç´¢å¼•æ“: {recommended_sources}")
            return recommended_sources
        else:
            print(f"âš ï¸  æœç´¢å¼•æ“æ¨èå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: arxiv,google_scholar")
            return "arxiv,google_scholar"
            
    except Exception as e:
        print(f"âš ï¸  æœç´¢å¼•æ“æ¨èå‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤: {e}")
        return "arxiv,google_scholar"


def select_best_papers_with_ai(search_results, user_description, max_papers=3, negative_prompt=None):
    """ä½¿ç”¨AIä»æœç´¢ç»“æœä¸­é€‰æ‹©æœ€ç›¸å…³çš„è®ºæ–‡"""
    try:
        # å‡†å¤‡è®ºæ–‡ä¿¡æ¯
        papers_info = []
        for i, paper in enumerate(search_results[:10]):  # æœ€å¤šåˆ†æå‰10ç¯‡
            info = f"""è®ºæ–‡ {i+1}:
æ ‡é¢˜: {paper.get('title', 'Unknown')}
ä½œè€…: {', '.join(paper.get('authors', [])[:3])}
æ‘˜è¦: {paper.get('abstract', 'No abstract')[:300]}...
å‘è¡¨æ—¶é—´: {paper.get('published', 'Unknown')}
å¼•ç”¨é‡: {paper.get('citation_count', 'Unknown')}
æ¥æº: {paper.get('source', 'Unknown')}
"""
            papers_info.append(info)
        
        papers_text = '\n\n'.join(papers_info)
        
        # æ„å»ºåŸºç¡€prompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯ç ”ç©¶ä¸“å®¶ã€‚ç”¨æˆ·æ­£åœ¨å¯»æ‰¾ä»¥ä¸‹ä¸»é¢˜çš„è®ºæ–‡ï¼š

ç”¨æˆ·éœ€æ±‚ï¼š{user_description}

ä»¥ä¸‹æ˜¯æœç´¢åˆ°çš„è®ºæ–‡åˆ—è¡¨ï¼š

{papers_text}

è¯·ä»è¿™äº›è®ºæ–‡ä¸­é€‰æ‹©æœ€ç›¸å…³å’Œæœ€æœ‰ä»·å€¼çš„{max_papers}ç¯‡è®ºæ–‡ï¼Œè€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
1. ä¸ç”¨æˆ·éœ€æ±‚çš„ç›´æ¥ç›¸å…³æ€§ï¼ˆå¿…é¡»æœ‰æ˜ç¡®çš„ä¸»é¢˜å…³è”ï¼‰
2. è®ºæ–‡çš„è´¨é‡å’Œå½±å“åŠ›ï¼ˆå¼•ç”¨é‡ã€å‘è¡¨æ—¶é—´ç­‰ï¼‰
3. ç ”ç©¶çš„æ–°é¢–æ€§å’Œé‡è¦æ€§

**ç­›é€‰æ ‡å‡†**ï¼š
- è®ºæ–‡æ ‡é¢˜ã€æ‘˜è¦ä¸­å¿…é¡»åŒ…å«ä¸ç”¨æˆ·éœ€æ±‚ç›¸å…³çš„æ ¸å¿ƒæ¦‚å¿µæˆ–æŠ€æœ¯æœ¯è¯­
- å¯¹äºæŠ€æœ¯ä¸»é¢˜ï¼Œè®ºæ–‡åº”æ¶‰åŠç›¸åŒæˆ–ç›¸å…³çš„ç®—æ³•ã€æ–¹æ³•æˆ–æŠ€æœ¯é¢†åŸŸ
- å®Œå…¨æ— å…³çš„è®ºæ–‡ï¼ˆå¦‚ç”µå½±ç”Ÿæˆ vs ä¼˜åŒ–ç®—æ³•ã€å¤©çº¿è®¾è®¡ vs æœºå™¨å­¦ä¹ ï¼‰åº”è¯¥è¢«æ’é™¤
- å¦‚æœæ²¡æœ‰æ‰¾åˆ°çœŸæ­£ç›¸å…³çš„è®ºæ–‡ï¼Œè¯·è¯šå®è¯´æ˜"æ— ç›¸å…³è®ºæ–‡"

**ç¤ºä¾‹**ï¼š
- ç”¨æˆ·éœ€æ±‚"æœºå™¨å­¦ä¹ ä¼˜åŒ–ç®—æ³•" â†’ æ¥å—ï¼šæ¢¯åº¦ä¸‹é™ã€SGDã€Adamä¼˜åŒ–å™¨ç›¸å…³è®ºæ–‡
- ç”¨æˆ·éœ€æ±‚"æœºå™¨å­¦ä¹ ä¼˜åŒ–ç®—æ³•" â†’ æ‹’ç»ï¼šç”µå½±ç”Ÿæˆã€å¤©çº¿è®¾è®¡ã€åŒ»å­¦å½±åƒç­‰æ— å…³è®ºæ–‡"""

        # å¦‚æœæœ‰negative promptï¼Œæ·»åŠ åˆ°æŒ‡ä»¤ä¸­
        if negative_prompt:
            prompt += f"""

ç‰¹åˆ«æ³¨æ„ï¼šè¯·é¿å…é€‰æ‹©ä¸ä»¥ä¸‹æè¿°ç›¸å…³çš„è®ºæ–‡ï¼š{negative_prompt}
ä¼˜å…ˆé€‰æ‹©ä¸ç”¨æˆ·éœ€æ±‚ç›´æ¥ç›¸å…³ä¸”ä¸åŒ…å«ä¸Šè¿°ä¸æƒ³è¦å†…å®¹çš„è®ºæ–‡ã€‚"""

        prompt += f"""

è¯·è¿”å›é€‰æ‹©çš„è®ºæ–‡ç¼–å·ï¼ˆ1-{len(papers_info)}ï¼‰ï¼Œç”¨é€—å·åˆ†éš”ã€‚
ä¾‹å¦‚ï¼šå¦‚æœé€‰æ‹©ç¬¬1ã€3ã€5ç¯‡è®ºæ–‡ï¼Œè¿”å›ï¼š1,3,5

åªè¿”å›ç¼–å·ï¼Œä¸è¦å…¶ä»–è§£é‡Šï¼š"""

        print("ğŸ¤– æ­£åœ¨è°ƒç”¨OpenRouteræ™ºèƒ½ç­›é€‰æœ€ä½³è®ºæ–‡...")
        result = call_openrouter_with_auto_model(prompt, model="auto")
        
        if result['success']:
            selected_indices = result['content'].strip()
            print(f"âœ… AIæ¨èè®ºæ–‡: {selected_indices}")
            
            # æ£€æŸ¥æ˜¯å¦AIè®¤ä¸ºæ²¡æœ‰ç›¸å…³è®ºæ–‡ - ä½†å¦‚æœç”¨æˆ·æ˜ç¡®è¦æ±‚åŸºäºè®ºæ–‡å­¦ä¹ ï¼Œåˆ™æ”¾å®½æ ‡å‡†
            strict_no_relevant_keywords = ['æ— ç›¸å…³è®ºæ–‡', 'æ²¡æœ‰ç›¸å…³', 'no paper is highly relevant', 'none of the provided papers directly focus']
            if any(keyword in selected_indices.lower() for keyword in strict_no_relevant_keywords):
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤‡é€‰æ¨èï¼ˆå³ä½¿AIè®¤ä¸ºä¸æ˜¯å¾ˆç›¸å…³ï¼‰
                if any(char.isdigit() for char in selected_indices):
                    print("âš ï¸  AIè®¤ä¸ºè®ºæ–‡ç›¸å…³æ€§ä¸é«˜ï¼Œä½†ä»æä¾›äº†å¤‡é€‰æ¨èï¼Œç»§ç»­å¤„ç†...")
                else:
                    print("âŒ AIåˆ¤æ–­ï¼šæ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                    return []  # è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºæ²¡æœ‰ç›¸å…³è®ºæ–‡
            
            # è§£æé€‰æ‹©çš„è®ºæ–‡ç¼–å· - æ”¹è¿›çš„è§£æé€»è¾‘
            try:
                # æ–¹æ³•1: å°è¯•ç›´æ¥è§£æï¼ˆé€‚ç”¨äºç®€æ´å›ç­”å¦‚ "1,3,5"ï¼‰
                if ',' in selected_indices and len(selected_indices.strip()) < 20:
                    indices = [int(x.strip()) - 1 for x in selected_indices.split(',')]
                    selected_papers = [search_results[i] for i in indices if 0 <= i < len(search_results)]
                    return selected_papers[:max_papers]
                
                # æ–¹æ³•2: ä»é•¿æ–‡æœ¬ä¸­æå–æ•°å­—ï¼ˆé€‚ç”¨äºè¯¦ç»†è§£é‡Šï¼‰
                import re
                
                # æŸ¥æ‰¾ "Final selection:" æˆ–ç±»ä¼¼æ¨¡å¼åçš„æ•°å­—
                final_selection_patterns = [
                    r'Final selection:\s*([0-9,\s]+)',
                    r'final selection:\s*([0-9,\s]+)', 
                    r'é€‰æ‹©:\s*([0-9,\s]+)',
                    r'æ¨è:\s*([0-9,\s]+)'
                ]
                
                for pattern in final_selection_patterns:
                    match = re.search(pattern, selected_indices, re.IGNORECASE)
                    if match:
                        numbers_str = match.group(1).strip()
                        indices = [int(x.strip()) - 1 for x in numbers_str.split(',') if x.strip().isdigit()]
                        if indices:
                            selected_papers = [search_results[i] for i in indices if 0 <= i < len(search_results)]
                            print(f"âœ… ä»è¯¦ç»†å›å¤ä¸­æå–åˆ°é€‰æ‹©: {[i+1 for i in indices]}")
                            return selected_papers[:max_papers]
                
                # æ–¹æ³•3: æŸ¥æ‰¾æ‰€æœ‰æ•°å­—æ¨¡å¼ï¼ˆå¦‚ "8,6,9" æˆ– "8, 6, 9"ï¼‰
                number_patterns = re.findall(r'\b\d+(?:\s*,\s*\d+)+\b', selected_indices)
                if number_patterns:
                    # ä½¿ç”¨æœ€åä¸€ä¸ªæ‰¾åˆ°çš„æ•°å­—åºåˆ—ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆé€‰æ‹©ï¼‰
                    numbers_str = number_patterns[-1]
                    indices = [int(x.strip()) - 1 for x in numbers_str.split(',') if x.strip().isdigit()]
                    if indices:
                        selected_papers = [search_results[i] for i in indices if 0 <= i < len(search_results)]
                        print(f"âœ… ä»æ–‡æœ¬ä¸­æå–åˆ°æ•°å­—åºåˆ—: {[i+1 for i in indices]}")
                        return selected_papers[:max_papers]
                
                # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è¿›å…¥fallbacké€»è¾‘
                raise ValueError("æ— æ³•ä»AIå›å¤ä¸­æå–æœ‰æ•ˆçš„è®ºæ–‡ç¼–å·")
                
            except (ValueError, IndexError) as e:
                print(f"âš ï¸  è§£æAIé€‰æ‹©å¤±è´¥: {e}")
                # å¦‚æœè§£æå¤±è´¥ä¸”åŒ…å«"æ— ç›¸å…³"ç­‰å…³é”®è¯ï¼Œè¿”å›ç©ºåˆ—è¡¨
                if any(keyword in selected_indices for keyword in ['æ— ç›¸å…³è®ºæ–‡', 'æ— ç›¸å…³', 'no relevant']):
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                    return []
                print(f"ğŸ“„ è¿”å›å‰{max_papers}ç¯‡è®ºæ–‡ä½œä¸ºå¤‡é€‰")
                return search_results[:max_papers]
        else:
            print(f"âš ï¸  AIç­›é€‰å¤±è´¥ï¼Œè¿”å›å‰{max_papers}ç¯‡: {result['error']}")
            return search_results[:max_papers]
            
    except Exception as e:
        print(f"âš ï¸  AIç­›é€‰å‡ºé”™ï¼Œè¿”å›å‰{max_papers}ç¯‡: {e}")
        return search_results[:max_papers]


def process_paper_with_extract_pdf(paper_path, read_images=False):
    """ä½¿ç”¨EXTRACT_PDFå¤„ç†PDFæ–‡ä»¶ï¼Œè¿”å›å†…å®¹å’Œå¤„ç†åçš„è·¯å¾„"""
    try:
        import subprocess
        from pathlib import Path
        
        paper_path = Path(paper_path)
        if not paper_path.exists():
            print(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {paper_path}")
            return None, None
        
        # ä½¿ç”¨EXTRACT_PDFå¤„ç†PDF
        extract_pdf_path = Path(__file__).parent / "EXTRACT_PDF.py"
        if not extract_pdf_path.exists():
            print("âŒ EXTRACT_PDF.pyä¸å­˜åœ¨")
            return None, None
        
        print(f"ğŸ”„ ä½¿ç”¨EXTRACT_PDFå¤„ç†: {paper_path.name}")
        
        # æ„å»ºå‘½ä»¤
        cmd = ["/usr/bin/python3", str(extract_pdf_path)]
        cmd.append(str(paper_path))
        
        if not read_images:
            cmd.extend(["--engine", "basic-asyn"])
        
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode != 0:
            print(f"âŒ EXTRACT_PDFå¤„ç†å¤±è´¥: {result.stderr}")
            return None, None
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„markdownæ–‡ä»¶
        md_path = paper_path.with_suffix('.md')
        if md_path.exists():
            with open(md_path, 'r', encoding='utf-8') as f:
                content = f.read()
            print(f"âœ… PDFå¤„ç†å®Œæˆ: {md_path.name}")
            return content, str(md_path)
        else:
            print("âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„markdownæ–‡ä»¶")
            return None, None
            
    except Exception as e:
        print(f"âŒ å¤„ç†PDFæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None, None


def search_and_download_paper(paper_description, params=None):
    """Search for paper and download if found."""
    print(f"\nğŸ” æœç´¢è®ºæ–‡: {paper_description}")
    
    try:
        # æ­¥éª¤1: ä½¿ç”¨AIä¼˜åŒ–æœç´¢æŸ¥è¯¢
        print("ğŸ“ æ­¥éª¤1/10: ä½¿ç”¨AIä¼˜åŒ–æœç´¢æŸ¥è¯¢...")
        optimized_query = optimize_search_query_with_ai(paper_description)
        
        # æ­¥éª¤2: æ¨èæœç´¢å¼•æ“ï¼ˆå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šï¼‰
        print("ğŸ” æ­¥éª¤2/10: æ¨èæœç´¢å¼•æ“...")
        sources = params.get('sources') if params else None
        if not sources:
            sources = recommend_search_engines_with_ai(paper_description, optimized_query)
        else:
            print(f"âœ… ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æœç´¢å¼•æ“: {sources}")
        
        script_dir = Path(__file__).parent
        search_paper_path = script_dir / "SEARCH_PAPER"
        
        # æ­¥éª¤3: ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢å’Œæ¨èçš„æœç´¢å¼•æ“æœç´¢è®ºæ–‡
        print("ğŸ” æ­¥éª¤3/10: æ‰§è¡ŒSEARCH_PAPERæœç´¢...")
        
        # å¯¹äºæŠ€æœ¯ä¸»é¢˜ï¼Œå¢åŠ æœç´¢ç»“æœæ•°é‡ä»¥è·å¾—æ›´å¥½çš„åŒ¹é…
        max_results = 15 if any(keyword in paper_description.lower() 
                               for keyword in ['algorithm', 'optimization', 'machine learning', 'deep learning', 'neural']) else 10
        
        cmd = [str(search_paper_path), optimized_query, "--max-results", str(max_results)]
        if sources:
            cmd.extend(["--sources", sources])
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ æœç´¢å¤±è´¥: {result.stderr}")
            return None, None, 0
            
        print("âœ… SEARCH_PAPERæœç´¢å®Œæˆ")
        
        # æ­¥éª¤4: è§£ææœç´¢ç»“æœ
        print("ğŸ“Š æ­¥éª¤4/10: è§£ææœç´¢ç»“æœ...")
        search_results = parse_search_results()
        if not search_results:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
            return None, None, 0

        print(f"âœ… æ‰¾åˆ° {len(search_results)} ç¯‡ç›¸å…³è®ºæ–‡")
        
        # æ­¥éª¤5: ä½¿ç”¨AIç­›é€‰æœ€ä½³è®ºæ–‡
        print("ğŸ¤– æ­¥éª¤5/10: ä½¿ç”¨AIç­›é€‰æœ€ä½³è®ºæ–‡...")
        selected_papers = select_best_papers_with_ai(
            search_results, 
            paper_description, 
            max_papers=3, 
            negative_prompt=params.get('negative_prompt') if params else None
        )
        
        if not selected_papers:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®ºæ–‡ï¼Œæ— æ³•ç»§ç»­")
            return None, None, 0
        
        # æ­¥éª¤6: æ˜¾ç¤ºAIæ¨èçš„è®ºæ–‡ä¾›ç”¨æˆ·é€‰æ‹©
        print("âœ… AIç­›é€‰å®Œæˆ")
        print(f"ğŸ“‹ æ­¥éª¤6/10: æ˜¾ç¤ºAIæ¨èçš„{len(selected_papers)}ç¯‡æœ€ä½³è®ºæ–‡:")
        for i, paper in enumerate(selected_papers):
            title = paper.get('title', 'Unknown')
            authors = paper.get('authors', [])
            author_str = ', '.join(authors[:3]) + ('...' if len(authors) > 3 else '')
            citation_count = paper.get('citation_count', 'Unknown')
            print(f"  {i+1}. {title}")
            print(f"     ä½œè€…: {author_str}")
            print(f"     å¼•ç”¨é‡: {citation_count}")
            print()
        
        # æ­¥éª¤7: è®©ç”¨æˆ·é€‰æ‹©æˆ–è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ç¯‡
        print("ğŸ¯ æ­¥éª¤7/10: é€‰æ‹©è®ºæ–‡...")
        if len(selected_papers) == 1:
            selected_paper = selected_papers[0]
            print(f"âœ… è‡ªåŠ¨é€‰æ‹©å”¯ä¸€æ¨èè®ºæ–‡")
        else:
            # ç®€åŒ–é€‰æ‹©ï¼šè‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ç¯‡ï¼ˆAIæ¨èçš„æœ€ä½³è®ºæ–‡ï¼‰
            selected_paper = selected_papers[0]
            print(f"âœ… è‡ªåŠ¨é€‰æ‹©AIæ¨èçš„æœ€ä½³è®ºæ–‡: {selected_paper.get('title', 'Unknown')}")

        # æ­¥éª¤8: å°è¯•ä¸‹è½½è®ºæ–‡
        print("ğŸ“¥ æ­¥éª¤8/10: ä¸‹è½½è®ºæ–‡...")
        pdf_url = selected_paper.get('pdf_url')
        if not pdf_url:
            print("âŒ æœªæ‰¾åˆ°PDFä¸‹è½½é“¾æ¥")
            return None, None, 0
        
        print(f"ğŸ“¥ ä¸‹è½½è®ºæ–‡: {selected_paper.get('title', 'Unknown')}")
        # ç¡®å®šä¸‹è½½ç›®å½•ï¼šæµ‹è¯•æ—¶ä½¿ç”¨/tmpï¼Œæ­£å¸¸ä½¿ç”¨æ—¶ä½¿ç”¨paramsä¸­çš„output_dir
        download_dir = None
        if params and params.get('output_dir'):
            # å¦‚æœoutput_diræ˜¯æµ‹è¯•ç›®å½•ï¼ˆåŒ…å«testã€tmpç­‰ï¼‰ï¼Œä½¿ç”¨/tmp
            output_dir_str = str(params.get('output_dir')).lower()
            if any(keyword in output_dir_str for keyword in ['test', 'tmp', '/tmp']):
                download_dir = '/tmp'
            else:
                download_dir = params.get('output_dir')
        
        downloaded_path, original_title = download_paper(
            pdf_url, 
            selected_paper.get('title', 'paper'),
            output_dir=download_dir
        )
        
        if not downloaded_path:
            print("âŒ è®ºæ–‡ä¸‹è½½å¤±è´¥")
            return None, None, 0
        
        # æ­¥éª¤9: ä½¿ç”¨AIç»™PDFé‡å‘½åä¸ºç®€æ´æ˜äº†çš„åå­—
        print("ğŸ¤– æ­¥éª¤9/10: ä¸ºPDFç”Ÿæˆç®€æ´æ˜äº†çš„æ–‡ä»¶å...")
        new_filename = generate_simple_filename_with_ai(selected_paper, paper_description)
        
        # é‡å‘½åPDFæ–‡ä»¶
        downloaded_pdf_path = Path(downloaded_path)
        new_pdf_path = downloaded_pdf_path.parent / f"{new_filename}.pdf"
        
        try:
            downloaded_pdf_path.rename(new_pdf_path)
            print(f"âœ… PDFå·²é‡å‘½åä¸º: {new_pdf_path.name}")
            downloaded_path = str(new_pdf_path)
        except Exception as e:
            print(f"âš ï¸  é‡å‘½åå¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡ä»¶å: {e}")
        
        # æ­¥éª¤10: ä½¿ç”¨EXTRACT_PDFæå–è®ºæ–‡å†…å®¹
        print("ğŸ“„ æ­¥éª¤10/10: æå–PDFå†…å®¹...")
        markdown_path = extract_pdf_content(downloaded_path, params)
        
        if not markdown_path:
            print("âŒ PDFå†…å®¹æå–å¤±è´¥")
            return None, None, 0
        
        # æ­¥éª¤11: è¯»å–æå–çš„markdownå†…å®¹
        print("ğŸ“– æ­¥éª¤11/11: è¯»å–æå–çš„markdownå†…å®¹...")
        try:
            with open(markdown_path, 'r', encoding='utf-8') as f:
                paper_content = f.read()
            
            print(f"âœ… è®ºæ–‡å†…å®¹æå–å®Œæˆ: {markdown_path}")
            token_count = len(paper_content.split())  # ç®€å•çš„tokenä¼°ç®—
            print(f"ğŸ“Š æå–å†…å®¹é•¿åº¦: {token_count} tokens")
            
            # æ£€æŸ¥å†…å®¹é•¿åº¦ï¼Œå¦‚æœå¤ªå°‘å°±ä¸­æ–­
            min_content_length = 1000  # æœ€å°‘1000ä¸ªå­—ç¬¦
            if len(paper_content.strip()) < min_content_length:
                print(f"âŒ è®ºæ–‡å†…å®¹å¤ªå°‘ï¼ˆ{len(paper_content)}å­—ç¬¦ < {min_content_length}ï¼‰ï¼Œå¯èƒ½æå–å¤±è´¥")
                raise Exception(f"è®ºæ–‡å†…å®¹æå–ä¸å®Œæ•´ï¼šä»…æœ‰{len(paper_content)}å­—ç¬¦ï¼Œå°‘äºæœ€å°è¦æ±‚{min_content_length}å­—ç¬¦")
            
            return paper_content, downloaded_path, token_count
            
        except Exception as e:
            print(f"âŒ è¯»å–markdownæ–‡ä»¶å¤±è´¥: {e}")
            return None, None, 0
            
    except Exception as e:
        print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None, 0


def generate_simple_filename_with_ai(paper_info, user_description):
    """ä½¿ç”¨AIä¸ºè®ºæ–‡ç”Ÿæˆç®€æ´æ˜äº†çš„æ–‡ä»¶å"""
    try:
        title = paper_info.get('title', 'Unknown')
        authors = paper_info.get('authors', [])
        
        prompt = f"""è¯·ä¸ºä»¥ä¸‹å­¦æœ¯è®ºæ–‡ç”Ÿæˆä¸€ä¸ªç®€æ´æ˜äº†çš„è‹±æ–‡æ–‡ä»¶åï¼Œç”¨äºä¿å­˜PDFæ–‡ä»¶ã€‚

è®ºæ–‡ä¿¡æ¯ï¼š
æ ‡é¢˜: {title}
ä½œè€…: {', '.join(authors[:3])}
ç”¨æˆ·æœç´¢æè¿°: {user_description}

è¦æ±‚ï¼š
1. æ–‡ä»¶ååº”è¯¥ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦
2. åªä½¿ç”¨è‹±æ–‡å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦
3. é¿å…ç‰¹æ®Šç¬¦å·å’Œç©ºæ ¼
4. ä½“ç°è®ºæ–‡çš„æ ¸å¿ƒä¸»é¢˜
5. æ˜“äºç†è§£å’Œè¯†åˆ«

ä¾‹å¦‚ï¼š
- "3D Gaussian Splatting for Real-Time Radiance Field Rendering" -> "3DGS_Real_Time_Rendering"
- "Neural Radiance Fields" -> "NeRF"
- "Instant Neural Graphics Primitives" -> "Instant_NGP"

è¯·åªè¿”å›æ–‡ä»¶åï¼ˆä¸åŒ…å«.pdfæ‰©å±•åï¼‰ï¼Œä¸è¦å…¶ä»–è§£é‡Šï¼š"""

        result = call_openrouter_with_auto_model(prompt, model="auto")
        
        if result['success']:
            filename = result['content'].strip()
            # æ¸…ç†æ–‡ä»¶åï¼Œç¡®ä¿ç¬¦åˆæ–‡ä»¶ç³»ç»Ÿè¦æ±‚
            import re
            filename = re.sub(r'[^\w\-_]', '', filename)
            filename = re.sub(r'[-_]+', '_', filename)
            
            if len(filename) > 50:
                filename = filename[:50]
            
            print(f"âœ… AIç”Ÿæˆçš„æ–‡ä»¶å: {filename}")
            return filename
        else:
            print(f"âš ï¸  AIç”Ÿæˆæ–‡ä»¶åå¤±è´¥: {result['error']}")
            # ä½¿ç”¨ç®€åŒ–çš„æ ‡é¢˜ä½œä¸ºå¤‡é€‰
            import re
            safe_title = re.sub(r'[^\w\s-]', '', title)
            safe_title = re.sub(r'[-\s]+', '_', safe_title)
            return safe_title[:30]
            
    except Exception as e:
        print(f"âš ï¸  ç”Ÿæˆæ–‡ä»¶åå‡ºé”™: {e}")
        return "paper"


def extract_pdf_content(pdf_path, params=None):
    """ä½¿ç”¨EXTRACT_PDFæå–PDFå†…å®¹"""
    try:
        script_dir = Path(__file__).parent
        extract_pdf_path = script_dir / "EXTRACT_PDF"
        
        # æ„å»ºEXTRACT_PDFå‘½ä»¤
        cmd = [str(extract_pdf_path), str(pdf_path)]
        
        # æ ¹æ®LEARNå‚æ•°å†³å®šæ˜¯å¦å¤„ç†å›¾åƒ
        if params and params.get('read_images', False):
            print("ğŸ–¼ï¸  å¯ç”¨å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼å¤„ç†")
            cmd.extend(["--engine", "full"])  # ä½¿ç”¨fullæ¨¡å¼
        else:
            print("ğŸ“ ä»…æå–æ–‡æœ¬å†…å®¹ï¼ˆè·³è¿‡å›¾åƒå¤„ç†ï¼‰")
            cmd.extend(["--engine", "basic-asyn"])  # ä½¿ç”¨basic-asynæ¨¡å¼ï¼Œæ›´å¿«çš„å¼‚æ­¥å¤„ç†
        
        print(f"ğŸ”„ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # æ‰§è¡ŒEXTRACT_PDFå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=86400)  # 1 day timeout (dummy)
        
        if result.returncode == 0:
            # æŸ¥æ‰¾ç”Ÿæˆçš„markdownæ–‡ä»¶
            pdf_path_obj = Path(pdf_path)
            expected_md_path = pdf_path_obj.with_suffix('.md')
            
            if expected_md_path.exists():
                print(f"âœ… PDFå†…å®¹æå–æˆåŠŸ: {expected_md_path}")
                return str(expected_md_path)
            else:
                print(f"âŒ æœªæ‰¾åˆ°é¢„æœŸçš„markdownæ–‡ä»¶: {expected_md_path}")
                # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„markdownæ–‡ä»¶
                possible_paths = [
                    pdf_path_obj.parent / f"{pdf_path_obj.stem}.md",
                    Path.cwd() / f"{pdf_path_obj.stem}.md"
                ]
                for path in possible_paths:
                    if path.exists():
                        print(f"âœ… æ‰¾åˆ°markdownæ–‡ä»¶: {path}")
                        return str(path)
                return None
        else:
            print(f"âŒ EXTRACT_PDFæ‰§è¡Œå¤±è´¥:")
            print(f"   è¿”å›ç : {result.returncode}")
            print(f"   æ ‡å‡†è¾“å‡º: {result.stdout}")
            print(f"   é”™è¯¯è¾“å‡º: {result.stderr}")
            return None
            
    except subprocess.TimeoutExpired:
        print("âŒ PDFæå–è¶…æ—¶")
        return None
    except Exception as e:
        print(f"âŒ PDFæå–å‡ºé”™: {e}")
        return None


def parse_search_results():
    """Parse search results from SEARCH_PAPER_DATA."""
    try:
        script_dir = Path(__file__).parent
        search_data_dir = script_dir / "SEARCH_PAPER_DATA" / "results"
        
        if not search_data_dir.exists():
            return None
        
        # Get the most recent search results file
        result_files = list(search_data_dir.glob("search_results_*.json"))
        if not result_files:
            return None
        
        latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
        
        import json
        with open(latest_file, 'r', encoding='utf-8') as f:
            search_results = json.load(f)
        
        # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨æ ¼å¼
        if isinstance(search_results, dict):
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œå°è¯•æå–è®ºæ–‡åˆ—è¡¨
            if 'papers' in search_results:
                search_results = search_results['papers']
            elif 'results' in search_results:
                search_results = search_results['results']
            else:
                # å¦‚æœå­—å…¸ä¸­æ²¡æœ‰æ˜ç¡®çš„è®ºæ–‡åˆ—è¡¨ï¼Œå°†æ•´ä¸ªå­—å…¸ä½œä¸ºå•ä¸ªç»“æœ
                search_results = [search_results]
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨ä¸”ä¸ä¸ºç©º
        if isinstance(search_results, list) and search_results:
            return search_results
        else:
            return None
            
    except Exception as e:
        print(f"âŒ è§£ææœç´¢ç»“æœå¤±è´¥: {e}")
        return None


def download_paper(pdf_url, paper_title, output_dir=None):
    """Download paper from URL."""
    try:
        script_dir = Path(__file__).parent
        download_path = script_dir / "DOWNLOAD"
        
        # Create a safe filename
        import re
        safe_title = re.sub(r'[^\w\s-]', '', paper_title)
        safe_title = re.sub(r'[-\s]+', '-', safe_title)
        filename = f"{safe_title}.pdf"
        
        # Determine download directory
        if output_dir:
            download_dir = Path(output_dir)
            download_dir.mkdir(parents=True, exist_ok=True)
        else:
            download_dir = Path.cwd()
        
        target_path = download_dir / filename
        
        # Try to download
        print(f"ğŸ“¥ ä¸‹è½½ä¸­: {pdf_url}")
        print(f"ğŸ“ ç›®æ ‡ç›®å½•: {download_dir}")
        
        result = subprocess.run([
            str(download_path), pdf_url, str(target_path)
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            if target_path.exists():
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {target_path}")
                return str(target_path), paper_title
            else:
                print("âŒ ä¸‹è½½çš„æ–‡ä»¶ä¸å­˜åœ¨")
                return None, None
        else:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {result.stderr}")
            print("ğŸ”„ å°è¯•å…¶ä»–ä¸‹è½½é“¾æ¥...")
            return None, None
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None


def parse_file_references(text):
    """è§£ææ–‡æœ¬ä¸­çš„@"æ–‡ä»¶è·¯å¾„"å¼•ç”¨ï¼Œå±•å¼€ä¸ºæ–‡ä»¶å†…å®¹
    
    Returns:
        tuple: (expanded_text, has_file_reference)
    """
    import re
    from pathlib import Path
    
    # åŒ¹é… @"æ–‡ä»¶è·¯å¾„" æ¨¡å¼
    pattern = r'@"([^"]+)"'
    
    def clean_markdown_content(content, file_path):
        """æ¸…ç†markdownå†…å®¹ä¸­çš„placeholderå’Œæœ¬åœ°å›¾ç‰‡é“¾æ¥"""
        # ç§»é™¤å„ç§ç±»å‹çš„placeholder
        # [placeholder: xxx], [image: xxx], [formula: xxx], [table: xxx]
        content = re.sub(r'\[(?:placeholder|image|formula|table):\s*[^\]]*\]\s*\n?', '', content, flags=re.IGNORECASE)
        
        # ç§»é™¤åŒ…å«"placeholder"çš„æ•´è¡Œ
        lines = content.split('\n')
        cleaned_lines = []
        for line in lines:
            if '[placeholder:' not in line.lower() and '[image:' not in line.lower() and '[formula:' not in line.lower() and '[table:' not in line.lower() and '[formula:' not in line.lower():
                cleaned_lines.append(line)
        content = '\n'.join(cleaned_lines)
        
        # ç§»é™¤å›¾ç‰‡hash IDï¼ˆé€šå¸¸æ˜¯32-64ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        content = re.sub(r'\b[a-f0-9]{32,64}\b\s*\n?', '', content)
        
        # ç§»é™¤å›¾ç‰‡å¼•ç”¨ï¼ˆåŒ…å«hashçš„ï¼‰
        content = re.sub(r'!\[[^\]]*\]\([^)]*[a-f0-9]{32,64}[^)]*\)\s*\n?', '', content)
        
        # ç§»é™¤æœ¬åœ°å›¾ç‰‡å¼•ç”¨ ![...](images/xxx) æˆ– ![...](./images/xxx) ç­‰
        # ä¿ç•™ç½‘ç»œå›¾ç‰‡é“¾æ¥ (http/https)
        content = re.sub(r'!\[[^\]]*\]\((?!https?://)[^)]*\)\s*\n?', '', content)
        
        # ç§»é™¤é”™è¯¯ä¿¡æ¯å ä½ç¬¦
        content = re.sub(r'\[message:\s*[^\]]*\]\s*\n?', '', content, flags=re.IGNORECASE)
        
        # ç§»é™¤åŒ…å«ç‰¹å®šå…³é”®è¯çš„è¡Œï¼ˆæ›´å…¨é¢çš„æ¸…ç†ï¼‰
        forbidden_keywords = ['image_', 'formula_', 'table_', 'å›¾ç‰‡å¤„ç†å¤±è´¥', 'images/']
        lines = content.split('\n')
        cleaned_lines = []
        for line in lines:
            line_lower = line.lower()
            if not any(keyword.lower() in line_lower for keyword in forbidden_keywords):
                cleaned_lines.append(line)
        content = '\n'.join(cleaned_lines)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆ3ä¸ªæˆ–æ›´å¤šè¿ç»­ç©ºè¡Œå‹ç¼©ä¸º2ä¸ªï¼‰
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # ç§»é™¤è¡Œé¦–å°¾ç©ºç™½ä½†ä¿ç•™æ®µè½ç»“æ„
        lines = content.split('\n')
        cleaned_lines = [line.rstrip() for line in lines]
        content = '\n'.join(cleaned_lines)
        
        return content.strip()
    
    def replace_reference(match):
        file_path = match.group(1)
        try:
            path_obj = Path(file_path).expanduser().resolve()
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not path_obj.exists():
                raise FileNotFoundError(f"@ç¬¦å·å¼•ç”¨çš„æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¦å·é“¾æ¥æˆ–å…¶ä»–ç‰¹æ®Šæƒ…å†µ
            if not path_obj.is_file():
                raise ValueError(f"@ç¬¦å·å¼•ç”¨çš„è·¯å¾„ä¸æ˜¯æœ‰æ•ˆæ–‡ä»¶: {file_path}")
            
            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            allowed_extensions = {'.txt', '.md', '.pdf'}
            if path_obj.suffix.lower() not in allowed_extensions:
                return f"[ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path}ï¼Œä»…æ”¯æŒ .txtã€.md å’Œ .pdf æ–‡ä»¶]"
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            try:
                if path_obj.suffix.lower() == '.pdf':
                    # å¤„ç†PDFæ–‡ä»¶ - ä½¿ç”¨basicå¼•æ“è¿›è¡Œè§£æ
                    import tempfile
                    import subprocess
                    
                    print(f"ğŸ“ æ­£åœ¨è§£æPDFæ–‡ä»¶: {file_path} (ä½¿ç”¨basicå¼•æ“)")
                    
                    # åœ¨/tmpä¸­åˆ›å»ºä¸´æ—¶ç›®å½•è¿›è¡ŒPDFè§£æ
                    with tempfile.TemporaryDirectory(prefix='learn_pdf_', dir='/tmp') as temp_dir:
                        temp_dir_path = Path(temp_dir)
                        
                        # è°ƒç”¨EXTRACT_PDFè¿›è¡Œè§£æ
                        extract_cmd = [
                            'python3', str(Path(__file__).parent / 'EXTRACT_PDF.py'),
                            str(path_obj),
                            '--engine', 'basic-asyn',  # ä½¿ç”¨basicå¼•æ“ï¼Œä¸è¿›è¡Œå›¾åƒå¤„ç†
                            '--output', str(temp_dir_path)
                        ]
                        
                        try:
                            result = subprocess.run(extract_cmd, capture_output=True, text=True, timeout=60)
                            if result.returncode == 0:
                                # æŸ¥æ‰¾ç”Ÿæˆçš„markdownæ–‡ä»¶
                                md_files = list(temp_dir_path.glob('*.md'))
                                if md_files:
                                    md_file = md_files[0]
                                    with open(md_file, 'r', encoding='utf-8') as f:
                                        content = f.read()
                                    
                                    # æ¸…ç†PDFè§£æç”Ÿæˆçš„markdownå†…å®¹
                                    original_length = len(content)
                                    content = clean_markdown_content(content, file_path)
                                    cleaned_length = len(content)
                                    
                                    tokens_saved = (original_length - cleaned_length) // 4
                                    print(f"ğŸ“ PDFè§£æå®Œæˆ: {file_path} ({cleaned_length}å­—ç¬¦ï¼Œæ¸…ç†åèŠ‚çœçº¦{tokens_saved} tokens)")
                                    
                                    return f"\n\n--- å¼•ç”¨PDFæ–‡ä»¶: {file_path} ---\n{content}\n--- æ–‡ä»¶å¼•ç”¨ç»“æŸ ---\n"
                                else:
                                    return f"[PDFè§£æå¤±è´¥: {file_path} - æœªç”Ÿæˆmarkdownæ–‡ä»¶]"
                            else:
                                return f"[PDFè§£æå¤±è´¥: {file_path} - {result.stderr}]"
                        except subprocess.TimeoutExpired:
                            return f"[PDFè§£æè¶…æ—¶: {file_path}]"
                        except Exception as e:
                            return f"[PDFè§£æå‡ºé”™: {file_path} - {str(e)}]"
                
                else:
                    # å¤„ç†æ–‡æœ¬æ–‡ä»¶
                    with open(path_obj, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # å¦‚æœæ˜¯markdownæ–‡ä»¶ï¼Œè¿›è¡Œæ™ºèƒ½æ¸…ç†
                    if path_obj.suffix.lower() == '.md':
                        original_length = len(content)
                        content = clean_markdown_content(content, file_path)
                        cleaned_length = len(content)
                        
                        if original_length > cleaned_length:
                            tokens_saved = (original_length - cleaned_length) // 4  # ç²—ç•¥ä¼°ç®—èŠ‚çœçš„tokens
                            print(f"ğŸ“ å±•å¼€æ–‡ä»¶å¼•ç”¨: {file_path} ({cleaned_length}å­—ç¬¦ï¼Œæ¸…ç†åèŠ‚çœçº¦{tokens_saved} tokens)")
                        else:
                            print(f"ğŸ“ å±•å¼€æ–‡ä»¶å¼•ç”¨: {file_path} ({cleaned_length}å­—ç¬¦)")
                    else:
                        print(f"ğŸ“ å±•å¼€æ–‡ä»¶å¼•ç”¨: {file_path} ({len(content)}å­—ç¬¦)")
                    
                    return f"\n\n--- å¼•ç”¨æ–‡ä»¶: {file_path} ---\n{content}\n--- æ–‡ä»¶å¼•ç”¨ç»“æŸ ---\n"
                
            except (FileNotFoundError, ValueError):
                # é‡æ–°æŠ›å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆçš„å¼‚å¸¸
                raise
            except Exception as e:
                return f"[è¯»å–æ–‡ä»¶å¤±è´¥: {file_path} - {str(e)}]"
                
        except (FileNotFoundError, ValueError):
            # é‡æ–°æŠ›å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆçš„å¼‚å¸¸
            raise
        except Exception as e:
            return f"[æ–‡ä»¶è·¯å¾„è§£æå¤±è´¥: {file_path} - {str(e)}]"
    
    # æ›¿æ¢æ‰€æœ‰æ–‡ä»¶å¼•ç”¨
    expanded_text = re.sub(pattern, replace_reference, text)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼•ç”¨è¢«å±•å¼€
    has_file_reference = expanded_text != text
    if has_file_reference:
        print("ğŸ”— æ£€æµ‹åˆ°æ–‡ä»¶å¼•ç”¨ï¼Œå·²è‡ªåŠ¨å±•å¼€å¹¶æ¸…ç†æ— ç”¨å†…å®¹")
    
    return expanded_text, has_file_reference


def generate_learn_command(description):
    """æ ¹æ®ç”¨æˆ·æè¿°ç”ŸæˆLEARNå‘½ä»¤"""
    try:
        # è¯»å–LEARN.mdæ–‡æ¡£ä½œä¸ºå‚è€ƒ
        script_dir = Path(__file__).parent
        learn_md_path = script_dir / "LEARN.md"
        
        learn_doc = ""
        if learn_md_path.exists():
            with open(learn_md_path, 'r', encoding='utf-8') as f:
                learn_doc = f.read()
        
        # æ„å»ºprompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªLEARNå·¥å…·çš„ä¸“å®¶åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æè¿°ç”Ÿæˆå¯¹åº”çš„LEARNå‘½ä»¤ã€‚

LEARNå·¥å…·æ–‡æ¡£ï¼š
{learn_doc}

ç”¨æˆ·æè¿°ï¼š{description}

è¯·åˆ†æç”¨æˆ·çš„éœ€æ±‚ï¼Œå¹¶ç”Ÿæˆæœ€åˆé€‚çš„LEARNå‘½ä»¤ã€‚è€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
1. ç”¨æˆ·æ˜¯å¦éœ€è¦å­¦ä¹ ç‰¹å®šè®ºæ–‡ã€ä¸»é¢˜è¿˜æ˜¯é€šç”¨çŸ¥è¯†
2. å­¦ä¹ æ°´å¹³ï¼ˆåˆå­¦è€…ã€ä¸­çº§ã€é«˜çº§ã€ä¸“å®¶ï¼‰
3. è§£é‡Šé£æ ¼ï¼ˆç®€æ´æ˜äº†ã€è¯¦ç»†æ·±å…¥ã€å®ä¾‹ä¸°å¯Œã€ç†è®ºå¯¼å‘ï¼‰
4. æ˜¯å¦éœ€è¦ç‰¹æ®Šé€‰é¡¹ï¼ˆå¦‚--fileã€--descriptionã€--negativeã€--read-imagesç­‰ï¼‰
5. è¾“å‡ºç›®å½•å»ºè®®
6. OpenRouteræ¨¡å‹é€‰é¡¹ï¼š
   - --model: æŒ‡å®šç‰¹å®šçš„AIæ¨¡å‹
   - --max-tokens: æ§åˆ¶è¾“å‡ºé•¿åº¦
   - --temperature: æ§åˆ¶åˆ›é€ æ€§ï¼ˆ0.0-2.0ï¼Œæ•°å€¼è¶Šé«˜è¶Šæœ‰åˆ›é€ æ€§ï¼‰
   - --key: ä½¿ç”¨ç‰¹å®šçš„APIå¯†é’¥

è¯·ç›´æ¥è¿”å›å®Œæ•´çš„LEARNå‘½ä»¤ï¼Œä»¥"LEARN"å¼€å¤´ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
å¦‚æœéœ€è¦æ–‡ä»¶è·¯å¾„ï¼Œè¯·ä½¿ç”¨å ä½ç¬¦å¦‚"/path/to/file"ã€‚
å¦‚æœç”¨æˆ·éœ€è¦é«˜åˆ›é€ æ€§å›å¤ï¼Œå¯ä»¥æ·»åŠ --temperatureå‚æ•°ã€‚
å¦‚æœç”¨æˆ·éœ€è¦æŒ‡å®šæ¨¡å‹ï¼Œå¯ä»¥æ·»åŠ --modelå‚æ•°ã€‚

ç¤ºä¾‹æ ¼å¼ï¼š
LEARN -o ~/tutorials -m åˆå­¦è€… -s ç®€æ´æ˜äº† "PythonåŸºç¡€ç¼–ç¨‹"
LEARN -o ~/tutorials -m ä¸­çº§ --file "/path/to/paper.pdf"
LEARN -o ~/tutorials -m é«˜çº§ -d "æ·±åº¦å­¦ä¹ " --negative "GAN"
LEARN -o ~/tutorials -m ä¸“å®¶ -s å®ä¾‹ä¸°å¯Œ --temperature 0.8 "åˆ›æ„å†™ä½œæŠ€å·§"
LEARN -o ~/tutorials -m ä¸­çº§ --model "deepseek/deepseek-r1" --max-tokens 8000 "æœºå™¨å­¦ä¹ ç®—æ³•"

ç”Ÿæˆçš„å‘½ä»¤ï¼š"""

        print("ğŸ¤– æ­£åœ¨è°ƒç”¨OpenRouteråˆ†æç”¨æˆ·éœ€æ±‚ï¼Œç”ŸæˆLEARNå‘½ä»¤...")
        result = call_openrouter_with_auto_model(prompt, model="auto")
        
        if result['success']:
            command = result['content'].strip()
            print(f"\nâœ… ç”Ÿæˆçš„LEARNå‘½ä»¤ï¼š")
            print(f"```bash")
            print(f"{command}")
            print(f"```")
            return True
        else:
            print(f"âŒ å‘½ä»¤ç”Ÿæˆå¤±è´¥: {result['error']}")
            return False
            
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå‘½ä»¤æ—¶å‡ºé”™: {e}")
        return False


def main():
    """Main function."""
    # å¯åŠ¨å…¨å±€è®¡æ—¶å™¨ - æ”¾åœ¨æœ€å¼€å§‹ï¼Œç¡®ä¿åœ¨ä»»ä½•OpenRouterè°ƒç”¨ä¹‹å‰
    start_timer()
    
    # è·å–command_identifier
    args = sys.argv[1:]
    command_identifier = None
    
    # æ£€æŸ¥æ˜¯å¦è¢«RUNè°ƒç”¨ï¼ˆç¬¬ä¸€ä¸ªå‚æ•°æ˜¯command_identifierï¼‰
    if args and is_run_environment(args[0]):
        command_identifier = args[0]
        args = args[1:]  # ç§»é™¤command_identifierï¼Œä¿ç•™å®é™…å‚æ•°
        # é‡æ–°æ„å»ºsys.argvä»¥ä¾›argparseä½¿ç”¨
        sys.argv = [sys.argv[0]] + args
    
    # Check if running in interactive mode (no arguments)
    if len(args) == 0:
        print("LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ")
        print("å¯åŠ¨äº¤äº’æ¨¡å¼...")
        print()
        
        params = run_interactive_mode()
        if params is None:
            return 1
        
        # Generate learning content
        result = generate_learning_content(params)
        if result is None:
            return 1
        
        # å¦‚æœæ˜¯brainstorm_onlyæ¨¡å¼ï¼Œä¸åˆ›å»ºæ–‡ä»¶
        if params.get("brainstorm_only", False):
            print("âœ… å¤´è„‘é£æš´å®Œæˆï¼")
            return 0
        
        # åˆ›å»ºæ–‡ä»¶
        print("\nğŸ“ åˆ›å»ºæ•™ç¨‹æ–‡ä»¶...")
        success = create_learning_files_from_responses(
            params, 
            result['tutorial_response'], 
            result['question_response'], 
            result['prompts_and_responses']
        )
        
        if success:
            print("âœ… æ–‡ä»¶åˆ›å»ºå®Œæˆï¼")
            return 0
        else:
            print("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return 1
    
    # Parse direct command
    try:
        # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯--helpæ¨¡å¼
        if '--help' in sys.argv or '-h' in sys.argv:
            parser = argparse.ArgumentParser(description='LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ')
            parser.add_argument('topic', nargs='?', help='å­¦ä¹ ä¸»é¢˜')
            parser.add_argument('-o', '--output-dir', help='è¾“å‡ºç›®å½•')
            parser.add_argument('-m', '--mode', choices=list(MODE_MAPPING.keys()),
                               default='ä¸­çº§', help='å­¦ä¹ æ°´å¹³ (Learning level)')
            parser.add_argument('-s', '--style', choices=list(STYLE_MAPPING.keys()),
                               default='è¯¦ç»†æ·±å…¥', help='è§£é‡Šé£æ ¼ (Explanation style)')
            parser.add_argument('--file', help='ç›´æ¥å¤„ç†æ–‡ä»¶è·¯å¾„ (æ”¯æŒPDFã€MDã€TXT)')
            parser.add_argument('-u', '--url', help='è®ºæ–‡URL')
            parser.add_argument('-d', '--description', help='è®ºæ–‡æè¿°/æœç´¢å…³é”®è¯')
            parser.add_argument('--negative', help='è´Ÿé¢æç¤ºè¯ï¼šæŒ‡å®šä¸æƒ³è¦çš„å†…å®¹æˆ–è®ºæ–‡ç±»å‹')
            parser.add_argument('--read-images', action='store_true', help='å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼')
            parser.add_argument('--gen-command', help='æ ¹æ®æè¿°ç”ŸæˆLEARNå‘½ä»¤')
            parser.add_argument('--paper-based', action='store_true', help='å¼ºåˆ¶ä½¿ç”¨åŸºäºè®ºæ–‡çš„å­¦ä¹ æ¨¡å¼ï¼Œå³ä½¿åªæä¾›äº†æè¿°ä¹Ÿä¼šæœç´¢å’Œä¸‹è½½è®ºæ–‡')
            parser.add_argument('--sources', help='æŒ‡å®šè®ºæ–‡æœç´¢å¼•æ“ï¼Œç”¨é€—å·åˆ†éš” (arxiv,google_scholar)ï¼Œé»˜è®¤ä¸ºè‡ªåŠ¨æ¨è')
            parser.add_argument('--model', help='æŒ‡å®šOpenRouteræ¨¡å‹')
            parser.add_argument('--max-tokens', type=int, help='æœ€å¤§tokenæ•°')
            parser.add_argument('--temperature', type=float, help='æ¸©åº¦å‚æ•° (0.0-2.0ï¼Œæ§åˆ¶å›å¤çš„åˆ›é€ æ€§)')
            parser.add_argument('--key', help='æŒ‡å®šOpenRouter APIå¯†é’¥')
            parser.add_argument('--not-default', action='store_true', help='éé»˜è®¤æ¨¡å¼ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤')
            parser.add_argument('--no-override-material', action='store_true', help='ä¸è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œè‡ªåŠ¨é‡å‘½å')
            parser.add_argument('--brainstorm-only', action='store_true', help='ä¸è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶ï¼Œä»…ç”Ÿæˆå†…å®¹')
            parser.add_argument('--context', action='store_true', help='å°†descriptionè§†ä½œç›´æ¥contextè¿›å…¥brainstormingï¼Œè·³è¿‡è®ºæ–‡æœç´¢')
            
            # æ•è·helpè¾“å‡ºè€Œä¸æ˜¯è®©å®ƒexit
            import io
            from contextlib import redirect_stdout
            
            help_output = io.StringIO()
            try:
                with redirect_stdout(help_output):
                    parser.print_help()
                print(help_output.getvalue())
                return 0
            except:
                parser.print_help()
                return 0
        
        # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯gen-commandæ¨¡å¼
        elif '--gen-command' in sys.argv:
            parser = argparse.ArgumentParser(description='LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ')
            parser.add_argument('--gen-command', help='æ ¹æ®æè¿°ç”ŸæˆLEARNå‘½ä»¤')
            
            # åªè§£ægen-commandå‚æ•°ï¼Œå¿½ç•¥å…¶ä»–å‚æ•°
            args, _ = parser.parse_known_args()
            
            if args.gen_command:
                success = generate_learn_command(args.gen_command)
                return 0 if success else 1
        
        params = parse_direct_command(sys.argv[1:])
        
        # æ£€æŸ¥å‚æ•°æ”¶é›†æ˜¯å¦æˆåŠŸ
        if not params:
            return 1
        
        # Generate learning content
        result = generate_learning_content(params)
        if result is None:
            return 1
        
        # å¦‚æœæ˜¯brainstorm_onlyæ¨¡å¼ï¼Œä¸åˆ›å»ºæ–‡ä»¶
        if params.get("brainstorm_only", False):
            print("âœ… å¤´è„‘é£æš´å®Œæˆï¼")
            return 0
        
        # åˆ›å»ºæ–‡ä»¶
        print("\nğŸ“ åˆ›å»ºæ•™ç¨‹æ–‡ä»¶...")
        success = create_learning_files_from_responses(
            params, 
            result['tutorial_response'], 
            result['question_response'], 
            result['prompts_and_responses']
        )
        
        if success:
            print("âœ… æ–‡ä»¶åˆ›å»ºå®Œæˆï¼")
            return 0
        else:
            print("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return 1
    
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶å‡ºé”™: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())