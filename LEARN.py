#!/usr/bin/env python3
"""
LEARN.py - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ
ç‹¬ç«‹çš„å­¦ä¹ ææ–™ç”Ÿæˆå·¥å…·ï¼Œæ”¯æŒäº¤äº’æ¨¡å¼å’Œç›´æ¥è°ƒç”¨
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional


def clear_terminal():
    """Clear the terminal screen."""
    os.system('clear' if os.name == 'posix' else 'cls')


def interactive_select(prompt, options, default_index=0):
    """Interactive selection with numbered options."""
    print(f"{prompt}")
    for i, option in enumerate(options):
        print(f"  {i+1}. {option}")
    
    while True:
        try:
            choice = input(f"Choose (1-{len(options)}, default: {default_index+1}): ").strip()
            if not choice:
                print(f"Selected: {options[default_index]}")
                return default_index
            
            choice_num = int(choice) - 1
            if 0 <= choice_num < len(options):
                print(f"Selected: {options[choice_num]}")
                return choice_num
            else:
                print(f"Please enter a number between 1 and {len(options)}")
        except ValueError:
            print(f"Please enter a valid number between 1 and {len(options)}")
        except KeyboardInterrupt:
            print("\nCancelled.")
            return None


def check_and_confirm_overwrite(output_dir):
    """Check if tutorial.md or question.md exists and confirm overwrite."""
    tutorial_path = Path(output_dir) / "tutorial.md"
    question_path = Path(output_dir) / "question.md"
    
    existing_files = []
    if tutorial_path.exists():
        existing_files.append("tutorial.md")
    if question_path.exists():
        existing_files.append("question.md")
    
    if not existing_files:
        return True  # No files to overwrite
    
    print(f"\nâš ï¸  ä»¥ä¸‹æ–‡ä»¶å·²å­˜åœ¨äº {output_dir}:")
    for file in existing_files:
        print(f"  - {file}")
    
    while True:
        try:
            choice = input("\næ˜¯å¦è¦†ç›–è¿™äº›æ–‡ä»¶ï¼Ÿ (y/N): ").strip().lower()
            if choice in ['y', 'yes']:
                return True
            elif choice in ['n', 'no', '']:
                return False
            else:
                print("è¯·è¾“å…¥ y æˆ– n")
        except KeyboardInterrupt:
            print("\næ“ä½œå·²å–æ¶ˆ")
            return False


def get_output_directory():
    """Get output directory using tkinter directory selection."""
    print("é€‰æ‹©é¡¹ç›®ç›®å½•...")
    return get_output_directory_tkinter()


def get_output_directory_tkinter():
    """Get output directory using tkinter as fallback."""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        print("ğŸ“ è¯·åœ¨å¼¹å‡ºçš„çª—å£ä¸­é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹...")
        
        # åˆ›å»ºtkinteræ ¹çª—å£å¹¶éšè—
        root = tk.Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        
        # æ‰“å¼€ç›®å½•é€‰æ‹©å¯¹è¯æ¡†
        selected_dir = filedialog.askdirectory(
            title="é€‰æ‹©é¡¹ç›®ç›®å½•"
        )
        
        # é”€æ¯tkinterçª—å£
        root.destroy()
        
        if selected_dir:
            print(f"âœ… é€‰æ‹©ç›®å½•: {selected_dir}")
            return selected_dir
        else:
            print("âŒ æœªé€‰æ‹©ç›®å½•")
            return None
            
    except ImportError:
        print("âŒ tkinterä¸å¯ç”¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ç›®å½•è·¯å¾„")
        return None
    except Exception as e:
        print(f"âŒ ç›®å½•é€‰æ‹©å¤±è´¥: {e}")
        return None


def get_paper_file():
    """Get paper file using tkinter file selection."""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        print("ğŸ“„ è¯·åœ¨å¼¹å‡ºçš„çª—å£ä¸­é€‰æ‹©è®ºæ–‡æ–‡ä»¶...")
        
        # åˆ›å»ºtkinteræ ¹çª—å£å¹¶éšè—
        root = tk.Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        
        # æ‰“å¼€æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†
        selected_file = filedialog.askopenfilename(
            title="é€‰æ‹©è®ºæ–‡æ–‡ä»¶",
            filetypes=[
                ("PDFæ–‡ä»¶", "*.pdf"),
                ("Markdownæ–‡ä»¶", "*.md"),
                ("æ–‡æœ¬æ–‡ä»¶", "*.txt"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        # é”€æ¯tkinterçª—å£
        root.destroy()
        
        if selected_file:
            print(f"âœ… é€‰æ‹©æ–‡ä»¶: {selected_file}")
            return selected_file
        else:
            print("âŒ æœªé€‰æ‹©æ–‡ä»¶")
            return None
            
    except ImportError:
        print("âŒ tkinterä¸å¯ç”¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥æ–‡ä»¶è·¯å¾„")
        return None
    except Exception as e:
        print(f"âŒ æ–‡ä»¶é€‰æ‹©å¤±è´¥: {e}")
        return None


def run_interactive_mode():
    """Run in interactive mode to collect parameters."""
    clear_terminal()
    print("=== LEARN æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ ===")
    print("æ¬¢è¿ä½¿ç”¨æ™ºèƒ½å­¦ä¹ å†…å®¹ç”Ÿæˆå·¥å…·ï¼")
    print()
    
    # Step 1: Select learning type
    print("ğŸ“š ç¬¬1æ­¥ï¼šé€‰æ‹©å­¦ä¹ ç±»å‹")
    type_choice = interactive_select(
        "å­¦ä¹ ç±»å‹:",
        ["é€šç”¨ä¸»é¢˜å­¦ä¹ ", "åŸºäºå­¦æœ¯è®ºæ–‡å­¦ä¹ "]
    )
    if type_choice is None:
        return None
    
    params = {}
    
    if type_choice == 0:  # General topic
        params["type"] = "general"
        
        # Get topic
        print("\nğŸ“ ç¬¬2æ­¥ï¼šè¾“å…¥å­¦ä¹ ä¸»é¢˜")
        while True:
            topic = input("è¯·è¾“å…¥å­¦ä¹ ä¸»é¢˜ (ä¾‹å¦‚: PythonåŸºç¡€, æœºå™¨å­¦ä¹ , æ•°æ®ç»“æ„): ").strip()
            if topic:
                params["topic"] = topic
                break
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„ä¸»é¢˜")
        
    else:  # Paper-based
        params["type"] = "paper"
        
        print("\nğŸ“„ ç¬¬2æ­¥ï¼šé€‰æ‹©è®ºæ–‡è¾“å…¥æ–¹å¼")
        input_choice = interactive_select(
            "è®ºæ–‡è¾“å…¥æ–¹å¼:",
            ["æœ¬åœ°Markdownæ–‡ä»¶", "æœ¬åœ°PDFæ–‡ä»¶", "è®ºæ–‡URL", "è®ºæ–‡æè¿°/æœç´¢"]
        )
        if input_choice is None:
            return None
            
        params["input_type"] = input_choice
        
        if input_choice == 0:  # Markdown file
            paper_file = get_paper_file()
            if not paper_file:
                return None
            params["paper_path"] = paper_file
            
            # Read markdown content
            try:
                with open(paper_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                params["paper_content"] = content
                print(f"âœ… è¯»å–Markdownæ–‡ä»¶: {len(content)} å­—ç¬¦")
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
                return None
                
        elif input_choice == 1:  # PDF file
            paper_file = get_paper_file()
            if not paper_file:
                return None
            params["paper_path"] = paper_file
            
            # Ask about image processing
            print("\nğŸ–¼ï¸  å›¾åƒå¤„ç†é€‰é¡¹")
            image_choice = interactive_select(
                "æ˜¯å¦å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼ï¼Ÿ",
                ["å¦ (ä»…æå–æ–‡æœ¬ï¼Œé€Ÿåº¦å¿«)", "æ˜¯ (å®Œæ•´å¤„ç†ï¼Œéœ€è¦APIè°ƒç”¨)"]
            )
            params["read_images"] = image_choice == 1
            
        elif input_choice == 2:  # URL
            while True:
                url = input("è¯·è¾“å…¥è®ºæ–‡URL: ").strip()
                if url:
                    params["paper_url"] = url
                    break
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„URL")
                
            # Ask about image processing
            print("\nğŸ–¼ï¸  å›¾åƒå¤„ç†é€‰é¡¹")
            image_choice = interactive_select(
                "æ˜¯å¦å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼ï¼Ÿ",
                ["å¦ (ä»…æå–æ–‡æœ¬ï¼Œé€Ÿåº¦å¿«)", "æ˜¯ (å®Œæ•´å¤„ç†ï¼Œéœ€è¦APIè°ƒç”¨)"]
            )
            params["read_images"] = image_choice == 1
            
        elif input_choice == 3:  # Description/Search
            while True:
                description = input("è¯·è¾“å…¥è®ºæ–‡æè¿°æˆ–å…³é”®è¯: ").strip()
                if description:
                    params["paper_description"] = description
                    break
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æè¿°")
                
            # Ask about image processing
            print("\nğŸ–¼ï¸  å›¾åƒå¤„ç†é€‰é¡¹")
            image_choice = interactive_select(
                "æ˜¯å¦å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼ï¼Ÿ",
                ["å¦ (ä»…æå–æ–‡æœ¬ï¼Œé€Ÿåº¦å¿«)", "æ˜¯ (å®Œæ•´å¤„ç†ï¼Œéœ€è¦APIè°ƒç”¨)"]
            )
            params["read_images"] = image_choice == 1
    
    # Step 3: Select learning level
    print("\nğŸ¯ ç¬¬3æ­¥ï¼šé€‰æ‹©å­¦ä¹ æ°´å¹³")
    mode_choice = interactive_select(
        "å­¦ä¹ æ°´å¹³:",
        ["åˆå­¦è€…", "ä¸­çº§", "é«˜çº§", "ä¸“å®¶"]
    )
    if mode_choice is None:
        return None
    
    modes = ["åˆå­¦è€…", "ä¸­çº§", "é«˜çº§", "ä¸“å®¶"]
    params["mode"] = modes[mode_choice]
    
    # Step 4: Select explanation style
    print("\nğŸ“– ç¬¬4æ­¥ï¼šé€‰æ‹©è§£é‡Šé£æ ¼")
    style_choice = interactive_select(
        "è§£é‡Šé£æ ¼:",
        ["ç®€æ´æ˜äº†", "è¯¦ç»†æ·±å…¥", "å®ä¾‹ä¸°å¯Œ", "ç†è®ºå¯¼å‘"]
    )
    if style_choice is None:
        return None
    
    styles = ["ç®€æ´æ˜äº†", "è¯¦ç»†æ·±å…¥", "å®ä¾‹ä¸°å¯Œ", "ç†è®ºå¯¼å‘"]
    params["style"] = styles[style_choice]
    
    # Step 5: Get output directory
    print("\nğŸ“ ç¬¬5æ­¥ï¼šé€‰æ‹©è¾“å‡ºç›®å½•")
    output_dir = get_output_directory()
    if not output_dir:
        return None
    
    params["output_dir"] = output_dir
    
    # Check for existing files
    if not check_and_confirm_overwrite(output_dir):
        print("æ“ä½œå·²å–æ¶ˆ")
        return None
    
    return params


def parse_direct_command(args):
    """Parse direct command line arguments."""
    parser = argparse.ArgumentParser(description='LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ')
    
    # Basic options
    parser.add_argument('topic', nargs='?', help='å­¦ä¹ ä¸»é¢˜')
    parser.add_argument('-o', '--output', required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('-m', '--mode', choices=['åˆå­¦è€…', 'ä¸­çº§', 'é«˜çº§', 'ä¸“å®¶'], 
                       default='ä¸­çº§', help='å­¦ä¹ æ°´å¹³')
    parser.add_argument('-s', '--style', choices=['ç®€æ´æ˜äº†', 'è¯¦ç»†æ·±å…¥', 'å®ä¾‹ä¸°å¯Œ', 'ç†è®ºå¯¼å‘'],
                       default='è¯¦ç»†æ·±å…¥', help='è§£é‡Šé£æ ¼')
    
    # Paper options
    parser.add_argument('-p', '--paper', help='è®ºæ–‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-u', '--url', help='è®ºæ–‡URL')
    parser.add_argument('-d', '--description', help='è®ºæ–‡æè¿°/æœç´¢å…³é”®è¯')
    parser.add_argument('--read-images', action='store_true', help='å¤„ç†PDFä¸­çš„å›¾åƒã€å…¬å¼å’Œè¡¨æ ¼')
    
    # Model options
    parser.add_argument('--model', help='æŒ‡å®šOpenRouteræ¨¡å‹')
    parser.add_argument('--max-tokens', type=int, help='æœ€å¤§tokenæ•°')
    parser.add_argument('--not-default', action='store_true', help='éé»˜è®¤æ¨¡å¼ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤')
    parser.add_argument('--no-auto-create', action='store_true', help='ä¸è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶ï¼Œä»…ç”Ÿæˆå†…å®¹')
    
    try:
        parsed_args = parser.parse_args(args)
    except SystemExit:
        return None
    
    # Build parameters
    params = {
        'mode': parsed_args.mode,
        'style': parsed_args.style,
        'output_dir': parsed_args.output,
        'not_default': parsed_args.not_default,
        'no_auto_create': parsed_args.no_auto_create
    }
    
    if parsed_args.model:
        params['selected_model'] = parsed_args.model
    if parsed_args.max_tokens:
        params['max_tokens'] = parsed_args.max_tokens
    
    # Determine type based on arguments
    if parsed_args.paper:
        params['type'] = 'paper'
        params['input_type'] = 1  # PDF file
        params['paper_path'] = parsed_args.paper
        params['read_images'] = parsed_args.read_images
    elif parsed_args.url:
        params['type'] = 'paper'
        params['input_type'] = 2  # URL
        params['paper_url'] = parsed_args.url
        params['read_images'] = parsed_args.read_images
    elif parsed_args.description:
        params['type'] = 'paper'
        params['input_type'] = 3  # Description/Search
        params['paper_description'] = parsed_args.description
        params['read_images'] = parsed_args.read_images
    elif parsed_args.topic:
        params['type'] = 'general'
        params['topic'] = parsed_args.topic
    else:
        print("é”™è¯¯ï¼šå¿…é¡»æŒ‡å®šå­¦ä¹ ä¸»é¢˜æˆ–è®ºæ–‡ä¿¡æ¯")
        return None
    
    return params


def get_openrouter_models():
    """Get available OpenRouter models."""
    try:
        script_dir = Path(__file__).parent
        openrouter_data_file = script_dir / "OPENROUTER_DATA" / "openrouter_models.json"
        
        if openrouter_data_file.exists():
            import json
            with open(openrouter_data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                models_dict = data.get('models', {})
                if isinstance(models_dict, dict):
                    # Extract model names from dictionary format
                    models = list(models_dict.keys())
                    model_details = models_dict
                else:
                    # Handle list format (legacy)
                    models = models_dict
                    model_details = data.get('model_details', {})
                return models, model_details
        else:
            # Fallback to default models
            default_models = [
                "deepseek/deepseek-r1:free",
                "deepseek/deepseek-chat",
                "openai/gpt-4o-mini",
                "anthropic/claude-3-haiku"
            ]
            return default_models, {}
    except Exception as e:
        print(f"âš ï¸  è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        # Return minimal fallback
        return ["deepseek/deepseek-r1:free"], {}


def select_openrouter_model(params):
    """Select OpenRouter model with token limits."""
    models, model_details = get_openrouter_models()
    
    if not models:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
        return None, None
    
    # Check if model is already specified
    if params.get("selected_model"):
        selected_model = params["selected_model"]
        max_tokens = params.get("max_tokens", 4000)
        print(f"âœ… ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {selected_model}")
        return selected_model, max_tokens
    
    # Auto-select for default mode
    if not params.get('not_default', False):
        selected_model = models[0]  # Use first available model
        max_tokens = 4000
        print(f"ğŸš€ é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨é€‰æ‹©æ¨¡å‹ {selected_model}")
        return selected_model, max_tokens
    
    # Interactive model selection
    print(f"\nğŸ¤– é€‰æ‹©OpenRouteræ¨¡å‹")
    print("å¯ç”¨æ¨¡å‹:")
    
    # Categorize models
    free_models = []
    paid_models = []
    
    for model in models:
        details = model_details.get(model, {})
        if ":free" in model or details.get('input_cost_per_1m', 0) == 0:
            free_models.append(model)
        else:
            paid_models.append(model)
    
    all_models = []
    
    if free_models:
        print("\nå…è´¹æ¨¡å‹:")
        for model in free_models:
            print(f"  {len(all_models) + 1}. {model}")
            all_models.append(model)
    
    if paid_models:
        print("\nä»˜è´¹æ¨¡å‹:")
        for model in paid_models:
            details = model_details.get(model, {})
            cost = details.get('input_cost_per_1m', 0)
            cost_str = f" (${cost:.2f}/1M tokens)" if cost > 0 else ""
            print(f"  {len(all_models) + 1}. {model}{cost_str}")
            all_models.append(model)
    
    # Select model
    while True:
        try:
            choice = input(f"\né€‰æ‹©æ¨¡å‹ (1-{len(all_models)}, é»˜è®¤: 1): ").strip()
            if not choice:
                selected_model = all_models[0]
                break
            
            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(all_models):
                selected_model = all_models[choice_idx]
                break
            else:
                print(f"è¯·è¾“å…¥ 1-{len(all_models)} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
        except KeyboardInterrupt:
            print("\næ“ä½œå–æ¶ˆ")
            return None, None
    
    # Set token limit based on model
    details = model_details.get(selected_model, {})
    context_length = details.get('context_length', 8000)
    
    # Conservative token limit (reserve space for output)
    if context_length > 100000:
        max_tokens = 8000
    elif context_length > 32000:
        max_tokens = 4000
    else:
        max_tokens = 2000
    
    print(f"âœ… é€‰æ‹©æ¨¡å‹: {selected_model}")
    print(f"ğŸ“Š Tokené™åˆ¶: {max_tokens}")
    
    return selected_model, max_tokens


def generate_content_structure_prompt(params):
    """Generate prompt for content structure brainstorming."""
    if params["type"] == "general":
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        return f"""è¯·ä¸º"{topic}"è¿™ä¸ªå­¦ä¹ ä¸»é¢˜è¿›è¡Œå¤´è„‘é£æš´åˆ†æã€‚

å­¦ä¹ æ°´å¹³ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š
1. æ ¸å¿ƒæ¦‚å¿µå’ŒçŸ¥è¯†ç‚¹
2. å­¦ä¹ çš„é‡ç‚¹å’Œéš¾ç‚¹
3. é€‚åˆçš„å­¦ä¹ é¡ºåº
4. å®è·µç»ƒä¹ å»ºè®®
5. å¸¸è§é—®é¢˜å’Œè¯¯åŒº

è¯·æä¾›ç»“æ„åŒ–çš„åˆ†æï¼Œä¸ºåç»­åˆ›å»ºè¯¦ç»†æ•™ç¨‹åšå‡†å¤‡ã€‚"""

    elif params["type"] == "paper":
        mode = params['mode']
        style = params['style']
        
        # For paper type, prepare content first
        paper_content, paper_path, token_count = prepare_paper_content(params)
        if not paper_content:
            return None
            
        # Store prepared content in params
        params['paper_content'] = paper_content
        params['paper_path'] = paper_path
        params['token_count'] = token_count
        
        # Check if content is too long and needs summarization
        if token_count > 15000:
            print(f"âš ï¸  è®ºæ–‡å†…å®¹è¾ƒé•¿ ({token_count:,} tokens)ï¼Œå»ºè®®è¿›è¡Œå†…å®¹æ€»ç»“")
            
            # Ask user about processing approach
            approach_choice = interactive_select(
                "å†…å®¹å¤„ç†æ–¹å¼:",
                ["ç›´æ¥ä½¿ç”¨ (å¯èƒ½è¶…å‡ºæ¨¡å‹é™åˆ¶)", "æ™ºèƒ½æ‘˜è¦ (æ¨è)", "æ‰‹åŠ¨æˆªå–å‰éƒ¨åˆ†"]
            )
            
            if approach_choice == 1:  # Smart summary
                print("ğŸ“ æ­£åœ¨ç”Ÿæˆè®ºæ–‡æ‘˜è¦...")
                # Generate summary prompt
                summary_prompt = f"""è¯·ä¸ºä»¥ä¸‹å­¦æœ¯è®ºæ–‡ç”Ÿæˆè¯¦ç»†æ‘˜è¦ï¼Œä¿ç•™å…³é”®æŠ€æœ¯ç»†èŠ‚ï¼š

{paper_content[:20000]}

è¯·åŒ…å«ï¼š
1. ç ”ç©¶èƒŒæ™¯å’Œé—®é¢˜
2. ä¸»è¦æ–¹æ³•å’ŒæŠ€æœ¯
3. å…³é”®åˆ›æ–°ç‚¹
4. å®éªŒç»“æœ
5. ç»“è®ºå’Œæ„ä¹‰

æ‘˜è¦åº”è¯¥è¯¦ç»†ä½†ç®€æ´ï¼Œé€‚åˆåç»­æ•™ç¨‹åˆ›å»ºã€‚"""
                
                # Call API for summary
                summary_response, summary_token_info, _ = call_openrouter_with_retry(
                    summary_prompt, 
                    params.get("selected_model", "deepseek/deepseek-r1:free"), 
                    params.get("max_tokens", 4000), 
                    "è®ºæ–‡æ‘˜è¦ç”Ÿæˆ",
                    params=params
                )
                
                if summary_response:
                    paper_content = summary_response
                    print(f"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ ({count_tokens(paper_content)} tokens)")
                else:
                    print("âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                    
            elif approach_choice == 2:  # Manual truncate
                paper_content = paper_content[:60000]  # Keep first 60k characters
                print(f"âœ… æˆªå–å‰éƒ¨åˆ†å†…å®¹ ({count_tokens(paper_content)} tokens)")
        
        # Update params with processed content
        params['paper_content'] = paper_content
        
        # Generate brainstorming prompt for paper
        return f"""è¯·åˆ†æè¿™ç¯‡å­¦æœ¯è®ºæ–‡çš„å†…å®¹ï¼Œä¸ºåˆ›å»ºæ•™ç¨‹åšå‡†å¤‡ï¼š

è®ºæ–‡è·¯å¾„ï¼š{paper_path}
å­¦ä¹ æ°´å¹³ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

è®ºæ–‡å†…å®¹ï¼š
{paper_content}

è¯·åˆ†æï¼š
1. è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®å’Œåˆ›æ–°ç‚¹
2. å…³é”®æ¦‚å¿µå’ŒæŠ€æœ¯æ–¹æ³•
3. é€‚åˆ{mode}æ°´å¹³å­¦ä¹ è€…çš„é‡ç‚¹å†…å®¹
4. å¯èƒ½çš„éš¾ç‚¹å’Œè§£é‡Šç­–ç•¥
5. å®è·µåº”ç”¨å’Œæ‰©å±•æ€è€ƒ

è¯·æä¾›ç»“æ„åŒ–åˆ†æï¼Œä¸ºåç»­åˆ›å»ºè¯¦ç»†æ•™ç¨‹åšå‡†å¤‡ã€‚"""
    
    return None


def call_openrouter_for_structure(prompt, model=None, max_tokens=None, retry_count=0):
    """Call OpenRouter API for structure generation with improved error handling."""
    import time
    import json
    import re
    
    try:
        script_dir = Path(__file__).parent
        run_path = script_dir / "RUN.py"
        
        if retry_count == 0:
            print("ğŸ”„ æ­£åœ¨è¿æ¥OpenRouter API...", file=sys.stderr)
        else:
            print(f"ğŸ”„ é‡è¯•APIè°ƒç”¨ (ç¬¬{retry_count}æ¬¡)...", file=sys.stderr)
            
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
        if not model:
            print("ğŸ”„ æ­£åœ¨è¿æ¥OpenRouter API...", file=sys.stderr)
            models, model_details = get_openrouter_models()
            if not models:
                return None, {"error": "No useable models available"}
            model = models[0]
        
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}", file=sys.stderr)
        if max_tokens:
            print(f"ğŸ”¢ æœ€å¤§tokens: {max_tokens}", file=sys.stderr)
        print("â³ è¿™å¯èƒ½éœ€è¦ä¸€ä¼šï¼Œè¯·è€å¿ƒç­‰å¾…...", file=sys.stderr)
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # æ„å»ºå‘½ä»¤ - ä½¿ç”¨RUN --showè°ƒç”¨OPENROUTERå·¥å…·ï¼Œé€šè¿‡stdinä¼ é€’prompt
        cmd = [sys.executable, str(run_path), "--show", "OPENROUTER"]
        
        if model:
            cmd.extend(["--model", model])
        
        # ä¼ å…¥max-tokenså‚æ•°ï¼ˆOPENROUTERå·¥å…·ä¼šè‡ªåŠ¨å¤„ç†åŠ¨æ€è°ƒæ•´ï¼‰
        if max_tokens:
            cmd.extend(["--max-tokens", str(max_tokens)])
        
        # ä½¿ç”¨RUN --showæ¨¡å¼è°ƒç”¨OPENROUTERå·¥å…·ï¼Œé¿å…å“åº”è¢«æˆªæ–­
        try:
            process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, 
                                     stderr=subprocess.PIPE, text=True)
            try:
                stdout, stderr = process.communicate(input=prompt, timeout=120)  # å¢åŠ è¶…æ—¶æ—¶é—´
                
                # åˆ›å»ºä¸€ä¸ªresultå¯¹è±¡æ¥æ¨¡æ‹Ÿsubprocess.runçš„è¿”å›å€¼
                class Result:
                    def __init__(self, returncode, stdout, stderr):
                        self.returncode = returncode
                        self.stdout = stdout
                        self.stderr = stderr
                
                result = Result(process.returncode, stdout, stderr)
            except subprocess.TimeoutExpired:
                end_time = time.time()
                api_duration = end_time - start_time
                print(f"â° OpenRouter APIè°ƒç”¨è¶…æ—¶ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                process.kill()
                return None, None
        except KeyboardInterrupt:
            end_time = time.time()
            api_duration = end_time - start_time
            print(f"ğŸš« ç”¨æˆ·ä¸­æ–­APIè°ƒç”¨ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
            try:
                process.terminate()
                process.wait(timeout=5)
            except:
                process.kill()
            return None, None
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        api_duration = end_time - start_time
        
        if result.returncode == 0:
            print(f"âœ… OpenRouter APIè°ƒç”¨æˆåŠŸ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
            
            # è§£æJSONå“åº”
            try:
                # æ¸…ç†ANSIè½¬ä¹‰åºåˆ—
                clean_output = re.sub(r'\x1b\[[0-9;]*[mJKH]', '', result.stdout)
                
                response_data = json.loads(clean_output)
                
                if response_data.get('success'):
                    # æå–å“åº”å†…å®¹å’Œtokenä¿¡æ¯
                    response_content, usage_info = extract_response_data(response_data)
                    
                    # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
                    if not response_content or response_content.strip() == '':
                        print(f"âš ï¸  OpenRouter APIè¿”å›ç©ºå†…å®¹ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                        return None, None
                    
                    # å¤„ç†å¯èƒ½çš„markdownä»£ç å—åŒ…è£…
                    response_content = clean_markdown_wrapper(response_content)
                    
                    # æ„å»ºtokenä¿¡æ¯
                    token_info = {
                        'prompt_tokens': usage_info.get('input_tokens', 0),
                        'completion_tokens': usage_info.get('output_tokens', 0),
                        'total_tokens': usage_info.get('total_tokens', 0),
                        'cost': usage_info.get('cost', 0),
                        'api_duration': api_duration,
                        'model': model
                    }
                    
                    return response_content, token_info
                else:
                    error_msg = response_data.get('error', 'Unknown error')
                    print(f"âŒ OpenRouter APIè¿”å›é”™è¯¯: {error_msg} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                    return f"ERROR: {error_msg}", None
                    
            except json.JSONDecodeError as e:
                print(f"âŒ è§£æJSONå“åº”å¤±è´¥: {e} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                print(f"åŸå§‹è¾“å‡º: {result.stdout[:200]}...", file=sys.stderr)
                return None, None
                
        else:
            print(f"âŒ RUN --show OPENROUTERæ‰§è¡Œå¤±è´¥: {result.stderr} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
            return None, None

    except Exception as e:
        end_time = time.time()
        api_duration = end_time - start_time if 'start_time' in locals() else 0
        print(f"âŒ è°ƒç”¨OpenRouter APIæ—¶å‡ºé”™: {e} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
        return None, None


def extract_response_data(response_data):
    """Extract response content and usage info from API response."""
    response_content = ""
    usage_info = {}
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯RUN --showçš„åŒ…è£…æ ¼å¼
    if 'output' in response_data:
        try:
            output_content = response_data['output']
            if output_content.strip().startswith('{'):
                # outputæ˜¯JSONæ ¼å¼
                import json
                inner_data = json.loads(output_content)
                if inner_data.get('success'):
                    response_content = inner_data.get('content', '')
                    usage = inner_data.get('usage', {})
                    usage_info = {
                        'input_tokens': usage.get('input_tokens', 0),
                        'output_tokens': usage.get('output_tokens', 0),
                        'total_tokens': usage.get('total_tokens', 0),
                        'cost': inner_data.get('cost', 0)
                    }
                else:
                    response_content = output_content
            else:
                # outputæ˜¯çº¯æ–‡æœ¬ï¼Œä½†æ£€æŸ¥æ˜¯å¦æœ‰RUN_DATA_FILE
                response_content = output_content
                # å°è¯•ä»RUN_DATA_FILEä¸­è¯»å–tokenä¿¡æ¯
                if '_RUN_DATA_file' in response_data:
                    try:
                        import json
                        with open(response_data['_RUN_DATA_file'], 'r', encoding='utf-8') as f:
                            run_data = json.load(f)
                            if 'usage' in run_data:
                                usage = run_data['usage']
                                usage_info = {
                                    'input_tokens': usage.get('input_tokens', 0),
                                    'output_tokens': usage.get('output_tokens', 0),
                                    'total_tokens': usage.get('total_tokens', 0),
                                    'cost': run_data.get('cost', 0)
                                }
                    except (FileNotFoundError, json.JSONDecodeError, KeyError):
                        pass
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨outputå†…å®¹
            response_content = response_data['output']
    else:
        # ç›´æ¥ä»response_dataä¸­æå–
        response_content = response_data.get('content', 
                          response_data.get('response', 
                          response_data.get('message', '')))
        usage = response_data.get('usage', {})
        usage_info = {
            'input_tokens': usage.get('input_tokens', 0),
            'output_tokens': usage.get('output_tokens', 0),
            'total_tokens': usage.get('total_tokens', 0),
            'cost': response_data.get('cost', 0)
        }
    
    return response_content, usage_info


def clean_markdown_wrapper(content):
    """Clean markdown code block wrapper if present."""
    if '```markdown' in content:
        # ä½¿ç”¨```markdownåˆ†å‰²å†…å®¹
        parts = content.split('```markdown')
        if len(parts) >= 2:
            # å–ç¬¬äºŒéƒ¨åˆ†ï¼ˆ```markdownä¹‹åçš„å†…å®¹ï¼‰
            markdown_content = parts[1]
            # ç§»é™¤æœ€åçš„```ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if '```' in markdown_content:
                markdown_content = markdown_content.split('```')[0]
            return markdown_content.strip()
    return content


def generate_tutorial_prompt(params, brainstorming_response):
    """Generate prompt for tutorial.md creation."""
    if params["type"] == "general":
        # General topic
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        brainstorming_summary = brainstorming_response
        
        prompt = f"""è¯·ä¸º"{topic}"åˆ›å»ºä¸€ä¸ªç®€æ´çš„tutorial.mdæ–‡ä»¶ã€‚

å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹è¦ç‚¹åˆ›å»ºæ•™ç¨‹ï¼š
{brainstorming_summary}

è¯·åˆ›å»ºä¸€ä¸ªç»“æ„ç®€æ´çš„tutorial.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š
1. æ ‡é¢˜å’Œç›®å½•
2. 3-4ä¸ªæ ¸å¿ƒæ¦‚å¿µçš„è¯¦ç»†è§£é‡Šï¼ˆåŒ…å«ä»£ç ç¤ºä¾‹ï¼Œä¾‹é¢˜ç­‰ï¼Œif applicableï¼‰
3. ç®€æ˜çš„å­¦ä¹ è·¯å¾„æŒ‡å¯¼
4. 2-3ä¸ªå®è·µç»ƒä¹ å»ºè®®
5. ç²¾é€‰èµ„æºæ¨è

è¯·ç¡®ä¿å†…å®¹é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œå¹¶é‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚
è¯·ç›´æ¥æä¾›markdownæ ¼å¼çš„å†…å®¹ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•åˆ†éš”ç¬¦ã€‚"""
        
    else:
        # Paper-based
        paper_path = params.get('paper_path', 'è®ºæ–‡')
        paper_content = params.get('paper_content', '')
        mode = params['mode']
        style = params['style']
        
        # Use brainstorming response if available, otherwise use paper content directly
        if brainstorming_response:
            content_base = f"""å¤´è„‘é£æš´åˆ†æç»“æœï¼š
{brainstorming_response}

åŸè®ºæ–‡å†…å®¹ï¼ˆå‚è€ƒï¼‰ï¼š
{paper_content[:5000]}{'...' if len(paper_content) > 5000 else ''}"""
        else:
            content_base = f"""è®ºæ–‡å†…å®¹ï¼š
{paper_content}"""
        
        prompt = f"""è¯·åŸºäºå­¦æœ¯è®ºæ–‡å†…å®¹åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„tutorial.mdæ•™ç¨‹æ–‡ä»¶ã€‚

è®ºæ–‡ï¼š{paper_path}
å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹å†…å®¹åˆ›å»ºæ•™ç¨‹ï¼š
{content_base}

è¯·åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„tutorial.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š

1. **è®ºæ–‡æ¦‚è§ˆ**
   - è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å‘è¡¨ä¿¡æ¯
   - ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº
   - ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

2. **æ ¸å¿ƒæ¦‚å¿µè¯¦è§£**
   - å…³é”®æ¦‚å¿µçš„å®šä¹‰å’Œè§£é‡Š
   - æŠ€æœ¯æ–¹æ³•çš„è¯¦ç»†è¯´æ˜
   - ç®—æ³•æˆ–æ¨¡å‹çš„å·¥ä½œåŸç†

3. **æŠ€æœ¯ç»†èŠ‚**
   - å®ç°æ–¹æ³•å’ŒæŠ€æœ¯è·¯çº¿
   - å®éªŒè®¾è®¡å’Œè¯„ä¼°æ–¹æ³•
   - ç»“æœåˆ†æå’Œè®¨è®º

4. **å­¦ä¹ è¦ç‚¹**
   - é‡ç‚¹çŸ¥è¯†ç‚¹æ€»ç»“
   - ä¸ç°æœ‰æ–¹æ³•çš„æ¯”è¾ƒ
   - ä¼˜åŠ¿å’Œå±€é™æ€§åˆ†æ

5. **æ‰©å±•é˜…è¯»**
   - ç›¸å…³è®ºæ–‡æ¨è
   - è¿›ä¸€æ­¥å­¦ä¹ èµ„æº

è¯·ç¡®ä¿å†…å®¹é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚
è¯·ç›´æ¥æä¾›markdownæ ¼å¼çš„å†…å®¹ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•åˆ†éš”ç¬¦ã€‚"""
    
    return prompt


def generate_question_prompt(params, tutorial_content):
    """Generate prompt for question.md creation."""
    if params["type"] == "general":
        # General topic
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        tutorial_summary = tutorial_content
        
        prompt = f"""è¯·ä¸º"{topic}"åˆ›å»ºç®€æ´çš„ç»ƒä¹ é¢˜æ–‡ä»¶question.mdã€‚

å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹æ•™ç¨‹å†…å®¹åˆ›å»ºç»ƒä¹ é¢˜ï¼š
{tutorial_summary}

è¯·åˆ›å»ºä¸€ä¸ªç®€æ´çš„question.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š
1. åŸºç¡€çŸ¥è¯†æµ‹è¯•é¢˜ï¼ˆ3é¢˜ï¼‰
2. ç†è§£åº”ç”¨é¢˜ï¼ˆ3é¢˜ï¼‰
3. å®è·µç»ƒä¹ é¢˜ï¼ˆ2é¢˜ï¼‰
4. æ€è€ƒé¢˜ï¼ˆ2é¢˜ï¼‰
5. æ¯ä¸ªé—®é¢˜éƒ½è¦æœ‰ç®€æ´æ˜ç¡®çš„ç­”æ¡ˆ

è¯·ä½¿ç”¨HTMLçš„details/summaryæ ‡ç­¾æ¥åˆ›å»ºå¯å±•å¼€çš„ç­”æ¡ˆåŒºåŸŸã€‚
è¯·ç¡®ä¿é—®é¢˜é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ã€‚
è¯·æ§åˆ¶å†…å®¹é•¿åº¦ï¼Œä¿æŒç®€æ´ã€‚"""
        
    else:
        # Paper-based
        paper_path = params.get('paper_path', 'è®ºæ–‡')
        mode = params['mode']
        style = params['style']
        
        tutorial_summary = tutorial_content
        
        prompt = f"""è¯·åŸºäºå­¦æœ¯è®ºæ–‡æ•™ç¨‹åˆ›å»ºcomprehensiveçš„ç»ƒä¹ é¢˜æ–‡ä»¶question.mdã€‚

è®ºæ–‡ï¼š{paper_path}
å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹æ•™ç¨‹å†…å®¹åˆ›å»ºç»ƒä¹ é¢˜ï¼š
{tutorial_summary}

è¯·åˆ›å»ºä¸€ä¸ªå…¨é¢çš„question.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š

1. **è®ºæ–‡ç†è§£é¢˜ï¼ˆ4é¢˜ï¼‰**
   - ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœºç†è§£
   - ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹
   - æŠ€æœ¯æ–¹æ³•å’ŒåŸç†
   - å®éªŒç»“æœå’Œç»“è®º

2. **æ¦‚å¿µè§£é‡Šé¢˜ï¼ˆ3é¢˜ï¼‰**
   - å…³é”®æ¦‚å¿µå®šä¹‰
   - æŠ€æœ¯æœ¯è¯­è§£é‡Š
   - æ–¹æ³•æ¯”è¾ƒåˆ†æ

3. **æ‰¹åˆ¤æ€§æ€è€ƒé¢˜ï¼ˆ3é¢˜ï¼‰**
   - æ–¹æ³•ä¼˜ç¼ºç‚¹åˆ†æ
   - æ”¹è¿›å»ºè®®å’Œæ‰©å±•
   - åº”ç”¨åœºæ™¯è®¨è®º

4. **å®è·µåº”ç”¨é¢˜ï¼ˆ2é¢˜ï¼‰**
   - å®é™…åº”ç”¨è®¾è®¡
   - å®ç°æ€è·¯åˆ†æ

æ¯ä¸ªé—®é¢˜éƒ½å¿…é¡»ï¼š
- åŸºäºæ•™ç¨‹ä¸­çš„å…·ä½“å†…å®¹
- æœ‰è¯¦ç»†å‡†ç¡®çš„ç­”æ¡ˆ
- ä½¿ç”¨HTMLçš„<details>å’Œ<summary>æ ‡ç­¾å®ç°ç­”æ¡ˆæŠ˜å 

æ ¼å¼ç¤ºä¾‹ï¼š
### é—®é¢˜1ï¼šè¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

[è¯¦ç»†ç­”æ¡ˆå†…å®¹...]

</details>

è¯·ç¡®ä¿é—®é¢˜é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚"""
    
    return prompt


def create_learning_files_from_responses(params, tutorial_response, question_response, prompts_and_responses=None):
    """Create learning files from separate tutorial and question responses."""
    output_dir = params['output_dir']
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    try:
        # åˆ›å»ºtutorial.md
        tutorial_path = Path(output_dir) / "tutorial.md"
        with open(tutorial_path, 'w', encoding='utf-8') as f:
            f.write(tutorial_response)
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {tutorial_path}")
        
        # åˆ›å»ºquestion.md
        question_path = Path(output_dir) / "question.md"
        with open(question_path, 'w', encoding='utf-8') as f:
            f.write(question_response)
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {question_path}")
        
        # åˆ›å»ºOPENROUTER_promptsæ–‡ä»¶å¤¹å¹¶ä¿å­˜promptså’Œresponses
        if prompts_and_responses:
            prompts_dir = Path(output_dir) / "OPENROUTER_prompts"
            prompts_dir.mkdir(exist_ok=True)
            
            for i, (prompt, response, token_info) in enumerate(prompts_and_responses, 1):
                # ä¿å­˜prompt
                prompt_path = prompts_dir / f"prompt_{i}.txt"
                with open(prompt_path, 'w', encoding='utf-8') as f:
                    f.write(prompt)
                    f.write(f"\n\n--- Openrouter API Call Info ---\n")
                    f.write(f"model: {token_info.get('model', 'unknown')}\n")
                    f.write(f"prompt_tokens: {token_info.get('prompt_tokens', 0)}\n")
                    f.write(f"completion_tokens: {token_info.get('completion_tokens', 0)}\n")
                    f.write(f"total_tokens: {token_info.get('total_tokens', 0)}\n")
                    f.write(f"cost: ${token_info.get('cost', 0):.6f}\n")
                    f.write(f"api_duration: {token_info.get('api_duration', 0):.2f} seconds\n")
                
                # ä¿å­˜response
                response_path = prompts_dir / f"response_{i}.txt"
                with open(response_path, 'w', encoding='utf-8') as f:
                    f.write(response)
                    f.write(f"\n\n--- Openrouter API Call Info ---\n")
                    f.write(f"model: {token_info.get('model', 'unknown')}\n")
                    f.write(f"prompt_tokens: {token_info.get('prompt_tokens', 0)}\n")
                    f.write(f"completion_tokens: {token_info.get('completion_tokens', 0)}\n")
                    f.write(f"total_tokens: {token_info.get('total_tokens', 0)}\n")
                    f.write(f"cost: ${token_info.get('cost', 0):.6f}\n")
                    f.write(f"api_duration: {token_info.get('api_duration', 0):.2f} seconds\n")
                
                print(f"âœ… ä¿å­˜promptå’Œresponse: {prompt_path.name}, {response_path.name}")
                model_used = token_info.get('model', 'unknown')
                cost = token_info.get('cost', 0)
                print(f"ğŸ“Š Tokenä½¿ç”¨: {token_info.get('total_tokens', 0)} tokens (è¾“å…¥: {token_info.get('prompt_tokens', 0)}, è¾“å‡º: {token_info.get('completion_tokens', 0)}) - æ¨¡å‹: {model_used} - è´¹ç”¨: ${cost:.6f} - ç”¨æ—¶: {token_info.get('api_duration', 0):.2f}ç§’")
        
        file_count = 2 + (len(prompts_and_responses) * 2 if prompts_and_responses else 0)
        print(f"\nğŸ“ åˆ›å»ºäº† {file_count} ä¸ªæ–‡ä»¶:")
        print(f"  - {tutorial_path}")
        print(f"  - {question_path}")
        if prompts_and_responses:
            print(f"  - OPENROUTER_prompts/ æ–‡ä»¶å¤¹åŒ…å« {len(prompts_and_responses)} ç»„promptå’Œresponse")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False


def call_openrouter_with_retry(prompt, model, max_tokens, step_name, max_retries=3, params=None):
    """Call OpenRouter API with retry mechanism and model switching."""
    current_model = model
    
    for attempt in range(max_retries):
        response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, attempt)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸï¼ˆä¸æ˜¯Noneä¸”ä¸æ˜¯é”™è¯¯ï¼‰
        if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
            return response, token_info, current_model
        
        print(f"âŒ {step_name}å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•)", file=sys.stderr)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯429é”™è¯¯ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰æˆ–å…¶ä»–é”™è¯¯éœ€è¦åˆ‡æ¢æ¨¡å‹
        if should_switch_model(response, attempt, max_retries):
            current_model = handle_model_switching(current_model, params, step_name)
            if not current_model:
                break
            
            # ç”¨æ–°æ¨¡å‹é‡è¯•
            response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, 0)
            if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
                return response, token_info, current_model
    
    return None, None, current_model


def should_switch_model(response, attempt, max_retries):
    """Determine if we should switch models based on error type and attempt."""
    if response and isinstance(response, str):
        # ç«‹å³åˆ‡æ¢çš„æƒ…å†µï¼š429é”™è¯¯
        if "429" in response or "rate-limited" in response:
            return True
        # æœ€åä¸€æ¬¡é‡è¯•æ—¶åˆ‡æ¢çš„æƒ…å†µï¼šå…¶ä»–é”™è¯¯
        if attempt == max_retries - 1:
            return True
    return False


def handle_model_switching(current_model, params, step_name):
    """Handle model switching logic."""
    # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
    all_models, model_details = get_openrouter_models()
    if not all_models:
        print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨", file=sys.stderr)
        return None
    
    # ç§»é™¤å½“å‰å¤±è´¥çš„æ¨¡å‹
    available_models = [m for m in all_models if m != current_model]
    if not available_models:
        print("âŒ æ²¡æœ‰å…¶ä»–å¯ç”¨æ¨¡å‹", file=sys.stderr)
        return None
    
    # åˆ†ç±»æ¨¡å‹
    free_models = [m for m in available_models if ":free" in m]
    paid_models = [m for m in available_models if ":free" not in m]
    
    # é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨åˆ‡æ¢
    if params and not params.get('not_default', False):
        if current_model and ":free" in current_model and free_models:
            new_model = free_models[0]
            print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå…è´¹æ¨¡å‹: {new_model}", file=sys.stderr)
            return new_model
        elif paid_models:
            new_model = paid_models[0]
            print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä»˜è´¹æ¨¡å‹: {new_model}", file=sys.stderr)
            return new_model
    else:
        # äº¤äº’æ¨¡å¼ï¼šè®©ç”¨æˆ·é€‰æ‹©
        return interactive_model_selection(current_model, free_models, paid_models, step_name)
    
    return None


def interactive_model_selection(failed_model, free_models, paid_models, step_name):
    """Interactive model selection when switching models."""
    print(f"\nâš ï¸  æ¨¡å‹ '{failed_model}' è°ƒç”¨å¤±è´¥", file=sys.stderr)
    print("å¯ç”¨çš„æ›¿ä»£æ¨¡å‹ï¼š", file=sys.stderr)
    
    all_available = []
    if free_models:
        print("å…è´¹æ¨¡å‹ï¼š", file=sys.stderr)
        for i, model_name in enumerate(free_models):
            print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
            all_available.append(model_name)
    
    if paid_models:
        print("ä»˜è´¹æ¨¡å‹ï¼š", file=sys.stderr)
        for i, model_name in enumerate(paid_models):
            print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
            all_available.append(model_name)
    
    try:
        choice = input(f"\né€‰æ‹©æ¨¡å‹ (1-{len(all_available)}) æˆ–æŒ‰å›è½¦è·³è¿‡: ").strip()
        if choice and choice.isdigit():
            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(all_available):
                new_model = all_available[choice_idx]
                print(f"âœ… åˆ‡æ¢åˆ°æ¨¡å‹: {new_model}", file=sys.stderr)
                return new_model
    except (KeyboardInterrupt, EOFError):
        print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ", file=sys.stderr)
    
    return None


def generate_learning_content(params):
    """Generate learning content based on collected parameters."""
    print("\nğŸ¤– æ­£åœ¨ç”Ÿæˆå­¦ä¹ å†…å®¹ç»“æ„...")
    
    # ç”¨äºä¿å­˜æ‰€æœ‰çš„promptså’Œresponsesï¼Œç°åœ¨åŒ…å«tokenä¿¡æ¯
    prompts_and_responses = []
    
    # For paper type, model selection might already be done in generate_content_structure_prompt
    if params["type"] == "paper" and params.get("selected_model"):
        selected_model = params["selected_model"]
        max_tokens = params["max_tokens"]
        print(f"âœ… ä½¿ç”¨å·²é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
    else:
        # è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹
        selected_model, max_tokens = select_openrouter_model(params)
        if not selected_model:
            print("âŒ æœªé€‰æ‹©æ¨¡å‹")
            return None
        
        # Store selected model info in params for later use
        params["selected_model"] = selected_model
        params["max_tokens"] = max_tokens
    
    # Step 1: Brainstorming (optional for papers)
    brainstorming_response = None
    brainstorming_token_info = None
    
    print("\nğŸ“ ç¬¬1æ­¥ï¼šè¯¢é—®AIè¿›è¡Œå¤´è„‘é£æš´...")
    structure_prompt = generate_content_structure_prompt(params)
    
    if structure_prompt:  # Brainstorming was requested
        print("æŸ¥è¯¢å†…å®¹:")
        print("-" * 40)
        print(structure_prompt[:500] + "..." if len(structure_prompt) > 500 else structure_prompt)
        print("-" * 40)
        
        # Call OpenRouter API for brainstorming with retry
        brainstorming_response, brainstorming_token_info, current_model = call_openrouter_with_retry(
            structure_prompt, selected_model, max_tokens, "å¤´è„‘é£æš´", params=params
        )
        
        if brainstorming_response is None:
            print("âŒ å¤´è„‘é£æš´å¤±è´¥")
            return None
        
        # ä¿å­˜ç¬¬ä¸€ç»„promptå’Œresponse
        prompts_and_responses.append((structure_prompt, brainstorming_response, brainstorming_token_info))
        
        # å¦‚æœæ˜¯no_auto_createæ¨¡å¼ï¼Œåªè¿”å›brainstormingç»“æœ
        if params.get("no_auto_create", False):
            print("\nğŸ“‹ å¤´è„‘é£æš´å®Œæˆï¼ä»¥ä¸‹æ˜¯ç”Ÿæˆçš„ç»“æ„å»ºè®®ï¼š")
            print("=" * 60)
            print(brainstorming_response)
            print("=" * 60)
            print("\nğŸ’¡ ä½ å¯ä»¥åŸºäºä»¥ä¸Šå»ºè®®æ‰‹åŠ¨åˆ›å»ºtutorial.mdå’Œquestion.mdæ–‡ä»¶")
            return {
                'brainstorming_response': brainstorming_response,
                'prompts_and_responses': prompts_and_responses
            }
    else:
        print("â­ï¸  è·³è¿‡å¤´è„‘é£æš´ï¼Œç›´æ¥ç”Ÿæˆæ•™ç¨‹")
        
        # For paper type without brainstorming, check if we should continue
        if params["type"] == "paper":
            creation_mode = determine_creation_mode(params, selected_model)
            if creation_mode == "manual":
                params["no_auto_create"] = True
    
    # Step 2: Generate tutorial.md
    print("\nğŸ“ ç¬¬2æ­¥ï¼šåŸºäºå†…å®¹ç”Ÿæˆtutorial.md...")
    tutorial_prompt = generate_tutorial_prompt(params, brainstorming_response)
    
    print("æŸ¥è¯¢å†…å®¹:")
    print("-" * 40)
    print(tutorial_prompt[:500] + "..." if len(tutorial_prompt) > 500 else tutorial_prompt)
    print("-" * 40)
    
    tutorial_response, tutorial_token_info, current_model = call_openrouter_with_retry(
        tutorial_prompt, selected_model, max_tokens, "tutorial.mdç”Ÿæˆ", params=params
    )
    
    if tutorial_response is None:
        print("âŒ tutorial.mdç”Ÿæˆå¤±è´¥")
        return None
    
    # ä¿å­˜ç¬¬äºŒç»„promptå’Œresponse
    prompts_and_responses.append((tutorial_prompt, tutorial_response, tutorial_token_info))
    
    # Check if manual creation mode after tutorial generation
    if params.get("no_auto_create", False):
        print("\nğŸ“‹ Tutorialç”Ÿæˆå®Œæˆï¼")
        print("ğŸ’¡ ä½ å¯ä»¥åŸºäºä»¥ä¸‹å†…å®¹æ‰‹åŠ¨åˆ›å»ºquestion.mdæ–‡ä»¶")
        return {
            'tutorial_response': tutorial_response,
            'brainstorming_response': brainstorming_response,
            'prompts_and_responses': prompts_and_responses
        }
    
    # Step 3: Generate question.md
    print("\nğŸ“ ç¬¬3æ­¥ï¼šåŸºäºtutorial.mdç”Ÿæˆquestion.md...")
    question_prompt = generate_question_prompt(params, tutorial_response)
    
    print("æŸ¥è¯¢å†…å®¹:")
    print("-" * 40)
    print(question_prompt[:500] + "..." if len(question_prompt) > 500 else question_prompt)
    print("-" * 40)
    
    question_response, question_token_info, current_model = call_openrouter_with_retry(
        question_prompt, selected_model, max_tokens, "question.mdç”Ÿæˆ", params=params
    )
    
    if question_response is None:
        print("âŒ question.mdç”Ÿæˆå¤±è´¥")
        return None
    
    # ä¿å­˜ç¬¬ä¸‰ç»„promptå’Œresponse
    prompts_and_responses.append((question_prompt, question_response, question_token_info))
    
    # è¿”å›æ‰€æœ‰ç”Ÿæˆçš„å†…å®¹
    return {
        'tutorial_response': tutorial_response,
        'question_response': question_response,
        'brainstorming_response': brainstorming_response,
        'prompts_and_responses': prompts_and_responses
    }


def determine_creation_mode(params, selected_model):
    """Determine creation mode for paper type without brainstorming."""
    # Auto-proceed in default mode or with free models
    if not params.get('not_default', False):
        print("ğŸš€ é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨é€‰æ‹©åˆ›å»ºæ¨¡å¼...")
        return "auto"
    
    # Check if using free model
    if selected_model:
        models, model_details = get_openrouter_models()
        if models:
            details = model_details.get(selected_model, {})
            is_free_model = details.get('input_cost_per_1m', 0) == 0
            if is_free_model:
                print("ğŸš€ å…è´¹æ¨¡å‹ï¼šè‡ªåŠ¨é€‰æ‹©åˆ›å»ºæ¨¡å¼...")
                return "auto"
    
    # Ask user about creation mode
    print("\nğŸ¯ é€‰æ‹©åˆ›å»ºæ¨¡å¼:")
    creation_choice = interactive_select(
        "åˆ›å»ºæ¨¡å¼:", 
        ["è‡ªåŠ¨åˆ›å»º (AIç”Ÿæˆ3æ¬¡)", "æ‰‹åŠ¨åˆ›å»º (AIç”Ÿæˆ1æ¬¡ï¼Œä½ æ¥åˆ›å»ºæ–‡ä»¶)"]
    )
    
    return "manual" if creation_choice == 1 else "auto"


def count_tokens(text):
    """Simple token counting approximation."""
    # Rough approximation: 1 token â‰ˆ 4 characters for Chinese/English mixed text
    return len(text) // 4


def prepare_paper_content(params):
    """Prepare paper content based on input type."""
    input_type = params.get("input_type", 1)
    paper_content = None
    paper_path = None
    
    if input_type == 0:  # Markdown file
        paper_content = params.get("paper_content")
        paper_path = params.get("paper_path")
        print("âœ… ä½¿ç”¨å·²æä¾›çš„Markdownå†…å®¹")
        
    elif input_type == 1:  # PDF file
        paper_path = params.get("paper_path")
        read_images = params.get("read_images", False)
        paper_content, processed_path = process_paper_with_extract_pdf(paper_path, read_images)
        if processed_path:
            paper_path = processed_path
            
    elif input_type == 2:  # URL
        paper_url = params.get("paper_url")
        print(f"ğŸ“¥ ä¸‹è½½è®ºæ–‡: {paper_url}")
        
        # Extract filename from URL or use generic name
        import urllib.parse
        parsed_url = urllib.parse.urlparse(paper_url)
        filename = Path(parsed_url.path).name or "downloaded_paper.pdf"
        
        downloaded_path, title = download_paper(paper_url, filename.replace('.pdf', ''))
        if downloaded_path:
            read_images = params.get("read_images", False)
            paper_content, processed_path = process_paper_with_extract_pdf(downloaded_path, read_images)
            if processed_path:
                paper_path = processed_path
        else:
            print("âŒ æ— æ³•ä¸‹è½½è®ºæ–‡")
            return None, None, 0
            
    elif input_type == 3:  # Description/Search
        paper_description = params.get("paper_description")
        downloaded_path, title = search_and_download_paper(paper_description)
        if downloaded_path:
            read_images = params.get("read_images", False)
            paper_content, processed_path = process_paper_with_extract_pdf(downloaded_path, read_images)
            if processed_path:
                paper_path = processed_path
        else:
            print("âŒ æ— æ³•æ‰¾åˆ°æˆ–ä¸‹è½½è®ºæ–‡")
            return None, None, 0
    
    if not paper_content:
        print("âŒ æ— æ³•è·å–è®ºæ–‡å†…å®¹")
        return None, None, 0
    
    # Count tokens
    token_count = count_tokens(paper_content)
    print(f"\nğŸ“Š è®ºæ–‡å†…å®¹ç»Ÿè®¡:")
    print(f"   å­—ç¬¦æ•°: {len(paper_content):,}")
    print(f"   é¢„ä¼°tokenæ•°: {token_count:,}")
    
    return paper_content, paper_path, token_count


def search_and_download_paper(paper_description):
    """Search for paper and download if found."""
    print(f"\nğŸ” æœç´¢è®ºæ–‡: {paper_description}")
    
    try:
        script_dir = Path(__file__).parent
        search_paper_path = script_dir / "SEARCH_PAPER"
        
        # Search for papers
        result = subprocess.run([
            str(search_paper_path), paper_description, "--max-results", "5"
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ æœç´¢å¤±è´¥: {result.stderr}")
            return None, None
            
        print("âœ… æœç´¢å®Œæˆï¼Œæ­£åœ¨è§£æç»“æœ...")
        
        # Parse search results to find download URLs
        search_results = parse_search_results()
        if not search_results:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
            return None, None
        
        # Show papers to user and let them select
        selected_paper = interactive_paper_selection(search_results)
        if not selected_paper:
            return None, None
        
        # Try to download the paper
        pdf_url = selected_paper.get('pdf_url')
        if pdf_url:
            print(f"\nğŸ“¥ å°è¯•ä¸‹è½½è®ºæ–‡: {selected_paper.get('title', 'Unknown')}")
            return download_paper(pdf_url, selected_paper.get('title', 'paper'))
        else:
            print("âŒ æœªæ‰¾åˆ°PDFä¸‹è½½é“¾æ¥")
            return None, None
            
    except Exception as e:
        print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None


def parse_search_results():
    """Parse search results from SEARCH_PAPER_DATA."""
    try:
        script_dir = Path(__file__).parent
        search_data_dir = script_dir / "SEARCH_PAPER_DATA" / "results"
        
        if not search_data_dir.exists():
            return None
        
        # Get the most recent search results file
        result_files = list(search_data_dir.glob("search_results_*.json"))
        if not result_files:
            return None
        
        latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
        
        import json
        with open(latest_file, 'r', encoding='utf-8') as f:
            search_results = json.load(f)
        
        return search_results if search_results else None
        
    except Exception as e:
        print(f"âŒ è§£ææœç´¢ç»“æœå¤±è´¥: {e}")
        return None


def interactive_paper_selection(search_results):
    """Interactive paper selection from search results."""
    if not search_results or len(search_results) == 0:
        return None
    
    print(f"\næ‰¾åˆ° {len(search_results)} ç¯‡ç›¸å…³è®ºæ–‡:")
    for i, paper in enumerate(search_results[:5]):  # Show first 5
        title = paper.get('title', 'Unknown')
        authors = paper.get('authors', [])
        author_str = ', '.join(authors[:3]) + ('...' if len(authors) > 3 else '')
        print(f"  {i+1}. {title}")
        print(f"     ä½œè€…: {author_str}")
    
    # Let user select
    while True:
        try:
            choice = input(f"\né€‰æ‹©è®ºæ–‡ (1-{min(5, len(search_results))}, æˆ–è¾“å…¥ 'q' é€€å‡º): ").strip()
            if choice.lower() == 'q':
                return None
            
            choice_idx = int(choice) - 1
            if 0 <= choice_idx < min(5, len(search_results)):
                return search_results[choice_idx]
            else:
                print(f"è¯·è¾“å…¥ 1-{min(5, len(search_results))} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            return None


def download_paper(pdf_url, paper_title):
    """Download paper from URL."""
    try:
        script_dir = Path(__file__).parent
        download_path = script_dir / "DOWNLOAD"
        
        # Create a safe filename
        import re
        safe_title = re.sub(r'[^\w\s-]', '', paper_title)
        safe_title = re.sub(r'[-\s]+', '-', safe_title)
        filename = f"{safe_title}.pdf"
        
        # Try to download
        print(f"ğŸ“¥ ä¸‹è½½ä¸­: {pdf_url}")
        result = subprocess.run([
            str(download_path), pdf_url, filename
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            downloaded_path = Path.cwd() / filename
            if downloaded_path.exists():
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {downloaded_path}")
                return str(downloaded_path), paper_title
            else:
                print("âŒ ä¸‹è½½çš„æ–‡ä»¶ä¸å­˜åœ¨")
                return None, None
        else:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {result.stderr}")
            print("ğŸ”„ å°è¯•å…¶ä»–ä¸‹è½½é“¾æ¥...")
            return None, None
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None


def process_paper_with_extract_pdf(paper_path, read_images=False):
    """Process PDF with EXTRACT_PDF tool."""
    print(f"\nğŸ“„ å¤„ç†PDFæ–‡ä»¶: {paper_path}")
    
    try:
        script_dir = Path(__file__).parent
        extract_pdf_path = script_dir / "EXTRACT_PDF_PROJ" / "pdf_extractor.py"
        
        # Build command
        cmd = ["python", str(extract_pdf_path), paper_path]
        if read_images:
            cmd.append("--post")
        else:
            cmd.append("--no-image-api")
        
        print(f"ğŸ”„ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(script_dir))
        
        if result.returncode == 0:
            print("âœ… PDFå¤„ç†å®Œæˆ")
            
            # Find the generated markdown file
            paper_name = Path(paper_path).stem
            possible_md_files = [
                Path(paper_path).parent / f"{paper_name}.md",
                Path.cwd() / f"{paper_name}.md",
                script_dir / f"{paper_name}.md"
            ]
            
            for md_file in possible_md_files:
                if md_file.exists():
                    print(f"ğŸ“ æ‰¾åˆ°ç”Ÿæˆçš„Markdownæ–‡ä»¶: {md_file}")
                    with open(md_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    return content, str(md_file)
            
            print("âš ï¸  PDFå¤„ç†å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç”Ÿæˆçš„Markdownæ–‡ä»¶")
            return None, None
        else:
            print(f"âŒ PDFå¤„ç†å¤±è´¥: {result.stderr}")
            return None, None
            
    except Exception as e:
        print(f"âŒ PDFå¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None


def main():
    """Main function."""
    # Check if running in interactive mode (no arguments)
    if len(sys.argv) == 1:
        print("LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ")
        print("å¯åŠ¨äº¤äº’æ¨¡å¼...")
        print()
        
        params = run_interactive_mode()
        if params is None:
            return 1
        
        # Generate learning content
        result = generate_learning_content(params)
        if result is None:
            return 1
        
        # å¦‚æœæ˜¯no_auto_createæ¨¡å¼ï¼Œä¸åˆ›å»ºæ–‡ä»¶
        if params.get("no_auto_create", False):
            print("âœ… å¤´è„‘é£æš´å®Œæˆï¼")
            return 0
        
        # åˆ›å»ºæ–‡ä»¶
        print("\nğŸ“ åˆ›å»ºæ•™ç¨‹æ–‡ä»¶...")
        success = create_learning_files_from_responses(
            params, 
            result['tutorial_response'], 
            result['question_response'], 
            result['prompts_and_responses']
        )
        
        if success:
            print("âœ… æ–‡ä»¶åˆ›å»ºå®Œæˆï¼")
            return 0
        else:
            print("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return 1
    
    # Parse direct command
    try:
        params = parse_direct_command(sys.argv[1:])
        
        # æ£€æŸ¥å‚æ•°æ”¶é›†æ˜¯å¦æˆåŠŸ
        if not params:
            return 1
        
        # Generate learning content
        result = generate_learning_content(params)
        if result is None:
            return 1
        
        # å¦‚æœæ˜¯no_auto_createæ¨¡å¼ï¼Œä¸åˆ›å»ºæ–‡ä»¶
        if params.get("no_auto_create", False):
            print("âœ… å¤´è„‘é£æš´å®Œæˆï¼")
            return 0
        
        # åˆ›å»ºæ–‡ä»¶
        print("\nğŸ“ åˆ›å»ºæ•™ç¨‹æ–‡ä»¶...")
        success = create_learning_files_from_responses(
            params, 
            result['tutorial_response'], 
            result['question_response'], 
            result['prompts_and_responses']
        )
        
        if success:
            print("âœ… æ–‡ä»¶åˆ›å»ºå®Œæˆï¼")
            return 0
        else:
            print("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return 1
        
    except SystemExit:
        # argparse calls sys.exit on error
        return 1
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())