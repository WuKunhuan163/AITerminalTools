#!/usr/bin/env python3
"""
LEARN.py - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ
ç‹¬ç«‹çš„å­¦ä¹ ææ–™ç”Ÿæˆå·¥å…·ï¼Œæ”¯æŒäº¤äº’æ¨¡å¼å’Œç›´æ¥è°ƒç”¨
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional


def clear_terminal():
    """Clear the terminal screen."""
    os.system('clear' if os.name == 'posix' else 'cls')


def interactive_select(prompt, options, default_index=0):
    """Interactive selection with numbered options."""
    print(f"{prompt}")
    for i, option in enumerate(options):
        print(f"  {i+1}. {option}")
    
    while True:
        try:
            choice = input(f"Choose (1-{len(options)}, default: {default_index+1}): ").strip()
            if not choice:
                print(f"Selected: {options[default_index]}")
                return default_index
            
            choice_num = int(choice) - 1
            if 0 <= choice_num < len(options):
                print(f"Selected: {options[choice_num]}")
                return choice_num
            else:
                print(f"Please enter a number between 1 and {len(options)}")
        except ValueError:
            print(f"Please enter a valid number between 1 and {len(options)}")
        except KeyboardInterrupt:
            print("\nCancelled.")
            return None


def check_and_confirm_overwrite(output_dir):
    """Check if tutorial.md or question.md exists and confirm overwrite."""
    tutorial_path = Path(output_dir) / "tutorial.md"
    question_path = Path(output_dir) / "question.md"
    
    existing_files = []
    if tutorial_path.exists():
        existing_files.append("tutorial.md")
    if question_path.exists():
        existing_files.append("question.md")
    
    if not existing_files:
        return True  # No files to overwrite
    
    print(f"\nâš ï¸  ä»¥ä¸‹æ–‡ä»¶å·²å­˜åœ¨äº {output_dir}:")
    for file in existing_files:
        print(f"  - {file}")
    
    while True:
        try:
            choice = input("\næ˜¯å¦è¦†ç›–è¿™äº›æ–‡ä»¶ï¼Ÿ (y/N): ").strip().lower()
            if choice in ['y', 'yes']:
                return True
            elif choice in ['n', 'no', '']:
                return False
            else:
                print("è¯·è¾“å…¥ y æˆ– n")
        except KeyboardInterrupt:
            print("\næ“ä½œå·²å–æ¶ˆ")
            return False


def get_output_directory():
    """Get output directory using tkinter directory selection."""
    print("é€‰æ‹©é¡¹ç›®ç›®å½•...")
    return get_output_directory_tkinter()


def get_output_directory_tkinter():
    """Get output directory using tkinter as fallback."""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        print("ğŸ“ è¯·åœ¨å¼¹å‡ºçš„çª—å£ä¸­é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹...")
        
        # åˆ›å»ºtkinteræ ¹çª—å£å¹¶éšè—
        root = tk.Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        
        # æ‰“å¼€ç›®å½•é€‰æ‹©å¯¹è¯æ¡†
        selected_dir = filedialog.askdirectory(
            title="é€‰æ‹©é¡¹ç›®ç›®å½•"
        )
        
        root.destroy()
        
        if selected_dir:
            print(f"é€‰æ‹©çš„ç›®å½•: {selected_dir}")
            return selected_dir
        else:
            print("æœªé€‰æ‹©ç›®å½•")
            return None
            
    except ImportError:
        print("tkinterä¸å¯ç”¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ç›®å½•è·¯å¾„")
        output_dir = input("è¯·è¾“å…¥ç›®æ ‡ç›®å½•è·¯å¾„: ").strip()
        if output_dir and Path(output_dir).exists():
            return output_dir
        else:
            print("æ— æ•ˆçš„ç›®å½•è·¯å¾„")
            return None
    except Exception as e:
        print(f"ç›®å½•é€‰æ‹©å‡ºé”™: {e}")
        print("è¯·æ‰‹åŠ¨è¾“å…¥ç›®å½•è·¯å¾„")
        output_dir = input("è¯·è¾“å…¥ç›®æ ‡ç›®å½•è·¯å¾„: ").strip()
        if output_dir and Path(output_dir).exists():
            return output_dir
        else:
            print("æ— æ•ˆçš„ç›®å½•è·¯å¾„")
            return None


def get_topic_type():
    """Get the type of learning topic from user."""
    print("ä½ æƒ³å­¦ä¹ ä»€ä¹ˆå†…å®¹ï¼Ÿ")
    choice = interactive_select("å­¦ä¹ ç±»å‹:", ["é€šç”¨ä¸»é¢˜ (å¦‚Pythonã€æœºå™¨å­¦ä¹ ç­‰)", "å­¦æœ¯è®ºæ–‡ (PDFæ–‡ä»¶)"])
    if choice is None:
        return None
    elif choice == 0:
        return "general"
    else:
        return "paper"


def get_general_topic_params():
    """Get parameters for general topic learning."""
    # Get topic
    topic = input("è¯·è¾“å…¥è¦å­¦ä¹ çš„ä¸»é¢˜: ").strip()
    if not topic:
        topic = "Python basics"
        print(f"ä½¿ç”¨é»˜è®¤ä¸»é¢˜: {topic}")
    
    # Get mode
    mode_choice = interactive_select("å­¦ä¹ æ¨¡å¼:", ["Beginner (åˆå­¦è€…)", "Advanced (é«˜çº§)", "Practical (å®è·µå‹)"])
    if mode_choice is None:
        return None
    mode = ["Beginner", "Advanced", "Practical"][mode_choice]
    
    # Get style
    style_choice = interactive_select("è§£é‡Šé£æ ¼:", ["Rigorous (ä¸¥è°¨)", "Witty (å¹½é»˜)"])
    if style_choice is None:
        return None
    style = ["Rigorous", "Witty"][style_choice]
    
    # Get output directory
    output_dir = get_output_directory()
    if output_dir is None:
        return None
    
    return {
        "topic": topic,
        "mode": mode,
        "style": style,
        "type": "general",
        "output_dir": output_dir
    }


def get_paper_input_type():
    """Get paper input type."""
    return interactive_select(
        "è®ºæ–‡è¾“å…¥æ–¹å¼:", 
        [
            "å·²å¤„ç†çš„Markdownæ–‡ä»¶ (.md)", 
            "PDFæ–‡ä»¶è·¯å¾„",
            "è®ºæ–‡URLé“¾æ¥", 
            "è®ºæ–‡æè¿°/æ ‡é¢˜ (è‡ªåŠ¨æœç´¢)"
        ]
    )


def show_file_selection_guidance():
    """Show tkinter dialog to guide user through file selection process."""
    try:
        import tkinter as tk
        from tkinter import messagebox
        
        # Create root window but hide it
        root = tk.Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        
        # Show guidance message
        result = messagebox.askyesnocancel(
            "LEARN - è®ºæ–‡æ–‡ä»¶é€‰æ‹©",
            "æ¥ä¸‹æ¥å°†æ‰“å¼€æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†ã€‚\n\n"
            "è¯·é€‰æ‹©ä»¥ä¸‹ç±»å‹çš„æ–‡ä»¶ï¼š\n"
            "â€¢ PDFè®ºæ–‡æ–‡ä»¶ (.pdf)\n"
            "â€¢ Markdownè®ºæ–‡æ–‡ä»¶ (.md)\n\n"
            "å¦‚æœæ‚¨æ²¡æœ‰æœ¬åœ°æ–‡ä»¶ï¼Œè¯·ç‚¹å‡»\"å–æ¶ˆ\"ï¼Œ\n"
            "ç„¶åå¯ä»¥æä¾›è®ºæ–‡URLæˆ–æè¿°è¿›è¡Œæœç´¢ã€‚\n\n"
            "æ˜¯å¦ç»§ç»­æ–‡ä»¶é€‰æ‹©ï¼Ÿ",
            icon='question'
        )
        
        root.destroy()
        return result  # True = Yes, False = No, None = Cancel
        
    except ImportError:
        print("ğŸ“ æ¥ä¸‹æ¥å°†æ‰“å¼€æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†...")
        print("   - å¯ä»¥é€‰æ‹©PDFæˆ–Markdownè®ºæ–‡æ–‡ä»¶")
        print("   - å¦‚æœæ²¡æœ‰æœ¬åœ°æ–‡ä»¶ï¼Œå¯ä»¥å–æ¶ˆé€‰æ‹©ï¼Œç„¶åæä¾›URLæˆ–æè¿°")
        return True


def get_paper_params():
    """Get parameters for paper learning with enhanced input handling."""
    # Show guidance dialog first
    guidance_result = show_file_selection_guidance()
    
    paper_content = None
    paper_path = None
    paper_url = None
    paper_description = None
    input_type = None
    
    if guidance_result is True:  # User chose to proceed with file selection
        print("ğŸ“ æ‰“å¼€æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†...")
        try:
            script_dir = Path(__file__).parent
            file_select_path = script_dir / "FILE_SELECT"
            
            result = subprocess.run([
                str(file_select_path), "--types", "pdf,md", "--title", "é€‰æ‹©è®ºæ–‡æ–‡ä»¶ (PDFæˆ–Markdown)"
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                selected_file = result.stdout.strip()
                if selected_file and Path(selected_file).exists():
                    print(f"é€‰æ‹©çš„æ–‡ä»¶: {selected_file}")
                    
                    if selected_file.endswith('.md'):
                        # Markdown file
                        with open(selected_file, 'r', encoding='utf-8') as f:
                            paper_content = f.read()
                        paper_path = selected_file
                        input_type = 0
                        print("âœ… å·²è¯»å–Markdownè®ºæ–‡å†…å®¹")
                        
                    elif selected_file.endswith('.pdf'):
                        # PDF file
                        paper_path = selected_file
                        input_type = 1
                        print("âœ… å·²é€‰æ‹©PDFè®ºæ–‡æ–‡ä»¶")
                        
                else:
                    print("âš ï¸  æ–‡ä»¶é€‰æ‹©è¢«å–æ¶ˆæˆ–æ–‡ä»¶æ— æ•ˆ")
                    guidance_result = None  # Treat as cancel
            else:
                print("âš ï¸  æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†æ‰§è¡Œå¤±è´¥")
                guidance_result = None  # Treat as cancel
                
        except Exception as e:
            print(f"âŒ æ–‡ä»¶é€‰æ‹©è¿‡ç¨‹å‡ºé”™: {e}")
            guidance_result = None  # Treat as cancel
    
    # If file selection was cancelled or failed, ask for URL or description
    if guidance_result is None or guidance_result is False:
        print("\nğŸ“ è¯·æä¾›è®ºæ–‡ä¿¡æ¯ï¼š")
        
        choice = interactive_select(
            "è®ºæ–‡æ¥æº:", 
            ["è®ºæ–‡URLé“¾æ¥", "è®ºæ–‡æè¿°/æ ‡é¢˜ (å°†è‡ªåŠ¨æœç´¢)"]
        )
        
        if choice is None:
            return None
        
        if choice == 0:  # URL
            paper_url = input("è¯·è¾“å…¥è®ºæ–‡URL: ").strip()
            if not paper_url:
                print("âŒ æœªè¾“å…¥æœ‰æ•ˆçš„URL")
                return None
            print(f"è®ºæ–‡URL: {paper_url}")
            input_type = 2
            
        elif choice == 1:  # Description
            paper_description = input("è¯·è¾“å…¥è®ºæ–‡æè¿°æˆ–æ ‡é¢˜: ").strip()
            if not paper_description:
                print("âŒ æœªè¾“å…¥æœ‰æ•ˆçš„æè¿°")
                return None
            print(f"è®ºæ–‡æè¿°: {paper_description}")
            input_type = 3
    
    if input_type is None:
        print("âŒ æœªé€‰æ‹©æœ‰æ•ˆçš„è®ºæ–‡è¾“å…¥æ–¹å¼")
        return None
    
    # Get image analysis option (only for PDF processing)
    read_images = False
    if input_type == 1 or (input_type == 2 and paper_url):  # PDF file or URL
        image_choice = interactive_select("æ˜¯å¦åˆ†æå›¾ç‰‡:", ["å¦", "æ˜¯"])
        if image_choice is None:
            return None
        read_images = image_choice == 1

    # Get learning mode and style
    mode_choice = interactive_select("å­¦ä¹ æ¨¡å¼:", ["Beginner (åˆå­¦è€…)", "Advanced (é«˜çº§)", "Practical (å®è·µå‹)"])
    if mode_choice is None:
        return None
    mode = ["Beginner", "Advanced", "Practical"][mode_choice]

    style_choice = interactive_select("è§£é‡Šé£æ ¼:", ["Rigorous (ä¸¥è°¨)", "Witty (å¹½é»˜)"])
    if style_choice is None:
        return None
    style = ["Rigorous", "Witty"][style_choice]

    # Get output directory
    output_dir = get_output_directory()
    if output_dir is None:
        return None

    return {
        "paper_path": paper_path,
        "paper_content": paper_content,
        "paper_url": paper_url,
        "paper_description": paper_description,
        "input_type": input_type,
        "read_images": read_images,
        "mode": mode,
        "style": style,
        "type": "paper",
        "output_dir": output_dir
    }


def run_interactive_mode():
    """Run interactive mode to collect parameters."""
    # Clear terminal
    clear_terminal()
    
    # Get topic type
    topic_type = get_topic_type()
    if topic_type is None:
        print("è®¾ç½®å·²å–æ¶ˆ")
        return None
    
    # Get parameters based on type
    if topic_type == "general":
        params = get_general_topic_params()
    else:
        params = get_paper_params()
    
    if params is None:
        print("è®¾ç½®å·²å–æ¶ˆ")
        return None
    
    return params


def parse_direct_command(args):
    """Parse direct command arguments."""
    parser = argparse.ArgumentParser(description="LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ")
    parser.add_argument("topic", help="å­¦ä¹ ä¸»é¢˜æˆ–PDFæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--type", choices=["general", "paper"], help="å­¦ä¹ ç±»å‹ (general: é€šç”¨ä¸»é¢˜, paper: å­¦æœ¯è®ºæ–‡)")
    parser.add_argument("--mode", choices=["Beginner", "Advanced", "Practical"], help="å­¦ä¹ æ¨¡å¼")
    parser.add_argument("--style", choices=["Rigorous", "Witty"], help="è§£é‡Šé£æ ¼")
    parser.add_argument("--output-dir", help="è¾“å‡ºç›®å½• (å¦‚æœæœªæä¾›ï¼Œå°†å¼¹å‡ºé€‰æ‹©å¯¹è¯æ¡†)")
    parser.add_argument("--read-images", action="store_true", help="åˆ†æPDFä¸­çš„å›¾ç‰‡")
    parser.add_argument("--no-auto-create", action="store_true", help="ä¸è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶ï¼Œåªè·å–ç»“æ„å»ºè®®")
    parser.add_argument("--not-default", action="store_true", help="ä¸ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼Œå¯ç”¨äº¤äº’å¼é€‰æ‹©")
    
    parsed_args = parser.parse_args(args)
    
    # å¤„ç†è¾“å‡ºç›®å½•é€»è¾‘
    if not parsed_args.output_dir:
        if parsed_args.not_default:
            # ä½¿ç”¨äº¤äº’å¼é€‰æ‹©
            print("ğŸ“ æœªæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œè¯·é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹...")
            parsed_args.output_dir = get_output_directory()
            if not parsed_args.output_dir:
                print("âŒ æœªé€‰æ‹©è¾“å‡ºç›®å½•ï¼Œé€€å‡ºç¨‹åº")
                return None
        else:
            # ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼šå½“å‰ç›®å½•
            parsed_args.output_dir = os.getcwd()
            print(f"ğŸ“ ä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•ï¼š{parsed_args.output_dir}")
    
    # å¤„ç†modeå’Œstyleçš„é»˜è®¤å€¼
    if not parsed_args.mode:
        if parsed_args.not_default:
            # ä½¿ç”¨äº¤äº’å¼é€‰æ‹©ï¼ˆè¿™é‡Œåº”è¯¥è°ƒç”¨äº¤äº’å¼é€‰æ‹©å‡½æ•°ï¼‰
            parsed_args.mode = "Beginner"  # ä¸´æ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼Œåç»­å¯ä»¥æ”¹ä¸ºäº¤äº’å¼
        else:
            # ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼šç¬¬ä¸€é¡¹
            parsed_args.mode = "Beginner"
            print(f"ğŸ“š ä½¿ç”¨é»˜è®¤å­¦ä¹ æ¨¡å¼ï¼š{parsed_args.mode}")
    
    if not parsed_args.style:
        if parsed_args.not_default:
            # ä½¿ç”¨äº¤äº’å¼é€‰æ‹©ï¼ˆè¿™é‡Œåº”è¯¥è°ƒç”¨äº¤äº’å¼é€‰æ‹©å‡½æ•°ï¼‰
            parsed_args.style = "Rigorous"  # ä¸´æ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼Œåç»­å¯ä»¥æ”¹ä¸ºäº¤äº’å¼
        else:
            # ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼šç¬¬ä¸€é¡¹
            parsed_args.style = "Rigorous"
            print(f"ğŸ¨ ä½¿ç”¨é»˜è®¤è§£é‡Šé£æ ¼ï¼š{parsed_args.style}")
    
    # æ£€æŸ¥æ–‡ä»¶è¦†ç›–ï¼ˆä»…åœ¨é--not-defaultæ¨¡å¼ä¸‹ï¼‰
    if not parsed_args.not_default and not parsed_args.no_auto_create:
        if check_and_confirm_overwrite(parsed_args.output_dir):
            print("âœ… ç¡®è®¤ç»§ç»­")
        else:
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return None
    
    # Determine if it's a paper or general topic
    # Check if type is explicitly specified
    if parsed_args.type:
        if parsed_args.type == "paper":
            # Force paper type regardless of topic content
            if parsed_args.topic.endswith('.pdf'):
                return {
                    "paper_path": parsed_args.topic,
                    "input_type": 1,  # PDF file
                    "read_images": parsed_args.read_images,
                    "mode": parsed_args.mode,
                    "style": parsed_args.style,
                    "type": "paper",
                    "output_dir": parsed_args.output_dir,
                    "no_auto_create": parsed_args.no_auto_create,
                    "not_default": parsed_args.not_default
                }
            elif parsed_args.topic.endswith('.md'):
                try:
                    with open(parsed_args.topic, 'r', encoding='utf-8') as f:
                        paper_content = f.read()
                except FileNotFoundError:
                    print(f"âŒ æ‰¾ä¸åˆ°Markdownæ–‡ä»¶: {parsed_args.topic}")
                    return None
                except Exception as e:
                    print(f"âŒ è¯»å–Markdownæ–‡ä»¶å¤±è´¥: {e}")
                    return None
                    
                return {
                    "paper_path": parsed_args.topic,
                    "paper_content": paper_content,
                    "input_type": 0,  # Markdown file
                    "read_images": False,
                    "mode": parsed_args.mode,
                    "style": parsed_args.style,
                    "type": "paper",
                    "output_dir": parsed_args.output_dir,
                    "no_auto_create": parsed_args.no_auto_create,
                    "not_default": parsed_args.not_default
                }
            elif parsed_args.topic.startswith('http://') or parsed_args.topic.startswith('https://'):
                return {
                    "paper_url": parsed_args.topic,
                    "input_type": 2,  # URL
                    "read_images": parsed_args.read_images,
                    "mode": parsed_args.mode,
                    "style": parsed_args.style,
                    "type": "paper",
                    "output_dir": parsed_args.output_dir,
                    "no_auto_create": parsed_args.no_auto_create,
                    "not_default": parsed_args.not_default
                }
            else:
                # Treat as paper description
                return {
                    "paper_description": parsed_args.topic,
                    "input_type": 3,  # Description/Search
                    "read_images": parsed_args.read_images,
                    "mode": parsed_args.mode,
                    "style": parsed_args.style,
                    "type": "paper",
                    "output_dir": parsed_args.output_dir,
                    "no_auto_create": parsed_args.no_auto_create,
                    "not_default": parsed_args.not_default
                }
        else:  # general
            # Force general type
            return {
                "topic": parsed_args.topic,
                "mode": parsed_args.mode,
                "style": parsed_args.style,
                "type": "general",
                "output_dir": parsed_args.output_dir,
                "no_auto_create": parsed_args.no_auto_create,
                "not_default": parsed_args.not_default
            }
    
    # Auto-detect type if not specified
    if parsed_args.topic.endswith('.pdf'):
        return {
            "paper_path": parsed_args.topic,
            "input_type": 1,  # PDF file
            "read_images": parsed_args.read_images,
            "mode": parsed_args.mode,
            "style": parsed_args.style,
            "type": "paper",
            "output_dir": parsed_args.output_dir,
            "no_auto_create": parsed_args.no_auto_create,
            "not_default": parsed_args.not_default
        }
    elif parsed_args.topic.endswith('.md'):
        # Markdown file
        try:
            with open(parsed_args.topic, 'r', encoding='utf-8') as f:
                paper_content = f.read()
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°Markdownæ–‡ä»¶: {parsed_args.topic}")
            return None
        except Exception as e:
            print(f"âŒ è¯»å–Markdownæ–‡ä»¶å¤±è´¥: {e}")
            return None
            
        return {
            "paper_path": parsed_args.topic,
            "paper_content": paper_content,
            "input_type": 0,  # Markdown file
            "read_images": False,  # Not applicable for MD files
            "mode": parsed_args.mode,
            "style": parsed_args.style,
            "type": "paper",
            "output_dir": parsed_args.output_dir,
            "no_auto_create": parsed_args.no_auto_create,
            "not_default": parsed_args.not_default
        }
    elif parsed_args.topic.startswith('http://') or parsed_args.topic.startswith('https://'):
        # URL
        return {
            "paper_url": parsed_args.topic,
            "input_type": 2,  # URL
            "read_images": parsed_args.read_images,
            "mode": parsed_args.mode,
            "style": parsed_args.style,
            "type": "paper",
            "output_dir": parsed_args.output_dir,
            "no_auto_create": parsed_args.no_auto_create,
            "not_default": parsed_args.not_default
        }
    else:
        # Check if it's a file path that exists
        if os.path.exists(parsed_args.topic):
            if parsed_args.topic.endswith('.pdf'):
                return {
                    "paper_path": parsed_args.topic,
                    "input_type": 1,  # PDF file
                    "read_images": parsed_args.read_images,
                    "mode": parsed_args.mode,
                    "style": parsed_args.style,
                    "type": "paper",
                    "output_dir": parsed_args.output_dir,
                    "no_auto_create": parsed_args.no_auto_create,
                    "not_default": parsed_args.not_default
                }
            elif parsed_args.topic.endswith('.md'):
                try:
                    with open(parsed_args.topic, 'r', encoding='utf-8') as f:
                        paper_content = f.read()
                except Exception as e:
                    print(f"âŒ è¯»å–Markdownæ–‡ä»¶å¤±è´¥: {e}")
                    return None
                    
                return {
                    "paper_path": parsed_args.topic,
                    "paper_content": paper_content,
                    "input_type": 0,  # Markdown file
                    "read_images": False,
                    "mode": parsed_args.mode,
                    "style": parsed_args.style,
                    "type": "paper",
                    "output_dir": parsed_args.output_dir,
                    "no_auto_create": parsed_args.no_auto_create,
                    "not_default": parsed_args.not_default
                }
        
        # Treat as general topic or paper description
        # If it looks like a paper description (contains academic keywords), treat as paper search
        academic_keywords = ['paper', 'research', 'study', 'analysis', 'algorithm', 'model', 'neural', 'learning', 'deep', 'machine']
        if any(keyword in parsed_args.topic.lower() for keyword in academic_keywords):
            return {
                "paper_description": parsed_args.topic,
                "input_type": 3,  # Description/Search
                "read_images": parsed_args.read_images,
                "mode": parsed_args.mode,
                "style": parsed_args.style,
                "type": "paper",
                "output_dir": parsed_args.output_dir,
                "no_auto_create": parsed_args.no_auto_create,
                "not_default": parsed_args.not_default
            }
        else:
            # General topic
            return {
                "topic": parsed_args.topic,
                "mode": parsed_args.mode,
                "style": parsed_args.style,
                "type": "general",
                "output_dir": parsed_args.output_dir,
                "no_auto_create": parsed_args.no_auto_create,
                "not_default": parsed_args.not_default
            }


def generate_content_structure_prompt(params):
    """Generate a detailed prompt for content structure planning."""
    if params["type"] == "general":
        # General topic prompt
        topic = params["topic"]
        mode = params["mode"]
        style = params["style"]
        
        prompt = f"""è¯·å¯¹"{topic}"è¿™ä¸ªä¸»é¢˜è¿›è¡Œå…¨é¢çš„å¤´è„‘é£æš´ï¼ˆbrainstormingï¼‰ï¼Œä¸ºåˆ›å»ºæ•™ç¨‹æä¾›ä¸°å¯Œçš„æƒ³æ³•å’Œå»ºè®®ã€‚

å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

è¯·ä»ä»¥ä¸‹è§’åº¦æä¾›å°½å¯èƒ½å¤šçš„å»ºè®®ï¼š

1. **æ ¸å¿ƒæ¦‚å¿µå’ŒçŸ¥è¯†ç‚¹**
   - è¿™ä¸ªä¸»é¢˜åŒ…å«å“ªäº›æ ¸å¿ƒæ¦‚å¿µï¼Ÿ
   - å“ªäº›æ˜¯{mode}æ°´å¹³å­¦ä¹ è€…å¿…é¡»æŒæ¡çš„ï¼Ÿ
   - å“ªäº›æ¦‚å¿µä¹‹é—´æœ‰ä¾èµ–å…³ç³»ï¼Ÿ

2. **å­¦ä¹ è·¯å¾„å’Œç« èŠ‚ç»“æ„**
   - å»ºè®®çš„å­¦ä¹ é¡ºåºæ˜¯ä»€ä¹ˆï¼Ÿ
   - å¦‚ä½•ä»åŸºç¡€åˆ°è¿›é˜¶å¾ªåºæ¸è¿›ï¼Ÿ
   - æ¯ä¸ªé˜¶æ®µçš„é‡ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ

3. **å®è·µå’Œç»ƒä¹ **
   - æœ‰å“ªäº›ç»å…¸çš„ç»ƒä¹ é¢˜ç›®ï¼Ÿ
   - å“ªäº›å®é™…é¡¹ç›®é€‚åˆç»ƒä¹ ï¼Ÿ
   - å¦‚ä½•è®¾è®¡ä»ç®€å•åˆ°å¤æ‚çš„ç»ƒä¹ åºåˆ—ï¼Ÿ

4. **å¸¸è§é—®é¢˜å’Œéš¾ç‚¹**
   - å­¦ä¹ è€…é€šå¸¸åœ¨å“ªäº›åœ°æ–¹é‡åˆ°å›°éš¾ï¼Ÿ
   - æœ‰å“ªäº›å¸¸è§çš„è¯¯è§£éœ€è¦æ¾„æ¸…ï¼Ÿ
   - å¦‚ä½•å¸®åŠ©å­¦ä¹ è€…å…‹æœè¿™äº›éš¾ç‚¹ï¼Ÿ

5. **èµ„æºå’Œå·¥å…·**
   - éœ€è¦å“ªäº›å·¥å…·æˆ–è½¯ä»¶ï¼Ÿ
   - æœ‰å“ªäº›æœ‰ç”¨çš„å‚è€ƒèµ„æ–™ï¼Ÿ
   - æ¨èå“ªäº›åœ¨çº¿èµ„æºï¼Ÿ

6. **åº”ç”¨åœºæ™¯**
   - è¿™ä¸ªä¸»é¢˜åœ¨å®é™…ä¸­æœ‰å“ªäº›åº”ç”¨ï¼Ÿ
   - æœ‰å“ªäº›å…·ä½“çš„åº”ç”¨æ¡ˆä¾‹ï¼Ÿ
   - å¦‚ä½•å°†ç†è®ºä¸å®è·µç»“åˆï¼Ÿ

è¯·æä¾›è¯¦ç»†ã€å…¨é¢çš„å»ºè®®ï¼Œè¶Šå¤šè¶Šå¥½ï¼è¿™äº›å»ºè®®å°†ç”¨äºæ„å»ºä¸€ä¸ªå®Œæ•´çš„å­¦ä¹ æ•™ç¨‹ã€‚"""

        return prompt

    else:
        # Paper-based prompt - need to prepare paper content first
        print("\nğŸ“„ å‡†å¤‡è®ºæ–‡å†…å®¹...")
        
        # Prepare paper content based on input type
        paper_result = prepare_paper_content(params)
        if paper_result is None:
            return None
            
        paper_content, paper_path, token_count = paper_result
        
        # Store paper content in params for later use
        params["paper_content"] = paper_content
        params["paper_path"] = paper_path
        params["token_count"] = token_count
        
        # Ask user about brainstorming
        print(f"\nğŸ§  è®ºæ–‡å†…å®¹å·²å‡†å¤‡å®Œæ¯• (é¢„ä¼° {token_count:,} tokens)")
        
        # Auto-proceed with brainstorming if:
        # 1. Not using --not-default (default mode), OR
        # 2. Using free model and content fits within context
        should_auto_proceed = False
        
        if not params.get('not_default', False):
            # Default mode - auto proceed
            should_auto_proceed = True
            print("ğŸš€ é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨å¼€å§‹AIå¤´è„‘é£æš´åˆ†æ...")
        else:
            # Check if using free model and content fits
            models, model_details = get_openrouter_models()
            if models and params.get("selected_model"):
                selected_model = params["selected_model"]
                details = model_details.get(selected_model, {})
                is_free_model = details.get('input_cost_per_1m', 0) == 0
                context_length = details.get('context_length', 0)
                
                if is_free_model and context_length and token_count < context_length * 0.8:  # Use 80% of context as safe limit
                    should_auto_proceed = True
                    print("ğŸš€ å…è´¹æ¨¡å‹ä¸”å†…å®¹é€‚é‡ï¼šè‡ªåŠ¨å¼€å§‹AIå¤´è„‘é£æš´åˆ†æ...")
        
        if not should_auto_proceed:
            while True:
                try:
                    choice = input("æ˜¯å¦è¦è¿›è¡ŒAIå¤´è„‘é£æš´åˆ†æï¼Ÿ (Y/n): ").strip().lower()
                    if choice in ['y', 'yes', '']:
                        break
                    elif choice in ['n', 'no']:
                        print("è·³è¿‡å¤´è„‘é£æš´ï¼Œç›´æ¥è¿›å…¥æ•™ç¨‹ç”Ÿæˆ...")
                        return None  # Skip brainstorming
                    else:
                        print("è¯·è¾“å…¥ y æˆ– n")
                except KeyboardInterrupt:
                    print("\næ“ä½œå·²å–æ¶ˆ")
                    return None
        
        # Get OpenRouter models and check token limits
        print("\nğŸ¤– æ£€æŸ¥æ¨¡å‹tokené™åˆ¶...")
        models, model_details = get_openrouter_models()
        if not models:
            print("âŒ æ— æ³•è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨")
            return None
        
        # Use already selected model from params if available
        if params.get("selected_model") and params.get("max_tokens") is not None:
            selected_model = params["selected_model"]
            max_tokens = params["max_tokens"]
            print(f"âœ… ä½¿ç”¨å·²é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
        else:
            # This shouldn't happen in normal flow, but as fallback
            selected_model, max_tokens = select_openrouter_model(params)
            if not selected_model:
                print("âŒ æœªé€‰æ‹©æ¨¡å‹")
                return None
        
        # Check if content will be truncated
        estimated_prompt_tokens = count_tokens("åŸºäºè®ºæ–‡è¿›è¡Œå¤´è„‘é£æš´åˆ†æ...") + token_count
        
        if max_tokens and estimated_prompt_tokens > max_tokens:
            print(f"\nâš ï¸  è­¦å‘Šï¼šè¾“å…¥å†…å®¹å¯èƒ½ä¼šè¢«æˆªæ–­")
            print(f"   è®ºæ–‡å†…å®¹: {token_count:,} tokens")
            print(f"   æ¨¡å‹é™åˆ¶: {max_tokens:,} tokens") 
            print(f"   é¢„ä¼°æ€»è¾“å…¥: {estimated_prompt_tokens:,} tokens")
            
            # Calculate truncation point
            available_tokens = max_tokens - 1000  # Reserve 1000 tokens for prompt structure
            if available_tokens > 0:
                truncation_chars = available_tokens * 4  # Approximate characters
                print(f"   å†…å®¹å°†è¢«æˆªæ–­åˆ°çº¦ {available_tokens:,} tokens ({truncation_chars:,} å­—ç¬¦)")
                
                while True:
                    try:
                        choice = input("\nç»§ç»­å¤„ç† (ä½¿ç”¨æˆªæ–­çš„å†…å®¹) è¿˜æ˜¯å–æ¶ˆï¼Ÿ (c/Q): ").strip().lower()
                        if choice in ['c', 'continue']:
                            # Truncate content
                            paper_content = paper_content[:truncation_chars]
                            params["paper_content"] = paper_content
                            params["token_count"] = count_tokens(paper_content)
                            print(f"âœ‚ï¸  å†…å®¹å·²æˆªæ–­åˆ° {params['token_count']:,} tokens")
                            break
                        elif choice in ['q', 'quit', '']:
                            print("æ“ä½œå·²å–æ¶ˆ")
                            return None
                        else:
                            print("è¯·è¾“å…¥ c (ç»§ç»­) æˆ– q (é€€å‡º)")
                    except KeyboardInterrupt:
                        print("\næ“ä½œå·²å–æ¶ˆ")
                        return None
            else:
                print("âŒ å†…å®¹è¿‡é•¿ï¼Œæ— æ³•å¤„ç†")
                return None
        elif max_tokens is None:
            print(f"âœ… ä½¿ç”¨å…è´¹æ¨¡å‹ï¼Œæ— tokené™åˆ¶ (è®ºæ–‡å†…å®¹: {token_count:,} tokens)")
        else:
            print(f"âœ… å†…å®¹å¤§å°åˆé€‚ (è®ºæ–‡: {token_count:,} tokens, é™åˆ¶: {max_tokens:,} tokens)")
        
        # Store selected model info
        params["selected_model"] = selected_model
        params["max_tokens"] = max_tokens
        
        mode = params["mode"]
        style = params["style"]
        read_images = params.get("read_images", False)
        
        # Generate prompt with paper content
        prompt = f"""è¯·åŸºäºä»¥ä¸‹å­¦æœ¯è®ºæ–‡å†…å®¹è¿›è¡Œå…¨é¢çš„å¤´è„‘é£æš´åˆ†æï¼Œä¸ºåˆ›å»ºå­¦ä¹ æ•™ç¨‹æä¾›è¯¦ç»†å»ºè®®ã€‚

**è®ºæ–‡å†…å®¹ï¼š**
{paper_content}

**æ•™ç¨‹è¦æ±‚ï¼š**
- å­¦ä¹ æ¨¡å¼ï¼š{mode}
- è§£é‡Šé£æ ¼ï¼š{style}
- å›¾ç‰‡åˆ†æï¼š{"å·²å¯ç”¨" if read_images else "æœªå¯ç”¨"}

è¯·ä»ä»¥ä¸‹è§’åº¦æä¾›è¯¦ç»†çš„æ•™ç¨‹è®¾è®¡å»ºè®®ï¼š

1. **è®ºæ–‡æ ¸å¿ƒå†…å®¹åˆ†æ**
   - è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ
   - å…³é”®æ¦‚å¿µå’ŒæŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ
   - è®ºæ–‡è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ

2. **æ•™ç¨‹ç« èŠ‚ç»“æ„å»ºè®®**
   - å¦‚ä½•å°†è®ºæ–‡å†…å®¹è½¬åŒ–ä¸º{mode}æ°´å¹³çš„æ•™ç¨‹ç« èŠ‚ï¼Ÿ
   - å»ºè®®çš„å­¦ä¹ é¡ºåºå’Œç« èŠ‚åˆ’åˆ†ï¼Ÿ
   - æ¯ä¸ªç« èŠ‚åº”è¯¥é‡ç‚¹è®²è§£ä»€ä¹ˆå†…å®¹ï¼Ÿ

3. **æ¦‚å¿µè§£é‡Šç­–ç•¥**
   - å“ªäº›æ¦‚å¿µéœ€è¦è¯¦ç»†è§£é‡Šï¼Ÿ
   - å¦‚ä½•ç”¨{style}çš„é£æ ¼è§£é‡Šå¤æ‚æ¦‚å¿µï¼Ÿ
   - éœ€è¦å“ªäº›èƒŒæ™¯çŸ¥è¯†é“ºå«ï¼Ÿ

4. **å®è·µç»ƒä¹ è®¾è®¡**
   - åŸºäºè®ºæ–‡å†…å®¹å¯ä»¥è®¾è®¡å“ªäº›ç†è§£é¢˜ï¼Ÿ
   - æœ‰å“ªäº›å®é™…åº”ç”¨ç»ƒä¹ ï¼Ÿ
   - å¦‚ä½•è®¾è®¡æ‰¹åˆ¤æ€§æ€è€ƒé¢˜ï¼Ÿ

5. **æ•™å­¦é‡ç‚¹å’Œéš¾ç‚¹**
   - å­¦ä¹ è€…å¯èƒ½åœ¨å“ªäº›åœ°æ–¹é‡åˆ°å›°éš¾ï¼Ÿ
   - å¦‚ä½•å¸®åŠ©ç†è§£è®ºæ–‡ä¸­çš„åˆ›æ–°ç‚¹ï¼Ÿ
   - éœ€è¦ç‰¹åˆ«å¼ºè°ƒå“ªäº›å†…å®¹ï¼Ÿ

è¯·æä¾›è¯¦ç»†ã€å…·ä½“çš„å»ºè®®ï¼Œè¿™å°†ç”¨äºç”Ÿæˆå®Œæ•´çš„å­¦ä¹ æ•™ç¨‹ï¼"""

        return prompt


def get_openrouter_models():
    """Get available OpenRouter models with details (only useable ones)."""
    try:
        # ç›´æ¥è°ƒç”¨OPENROUTER --listï¼Œè®¾ç½®RUN_DATA_FILEç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['RUN_DATA_FILE'] = '/tmp/dummy_run_data.json'
        
        script_dir = Path(__file__).parent
        openrouter_path = script_dir / "OPENROUTER.py"
        
        result = subprocess.run([
            sys.executable, str(openrouter_path), "--list"
        ], capture_output=True, text=True, timeout=30, env=env)
        
        if result.returncode == 0:
            try:
                import json
                import re
                
                # æ¸…ç†ANSIè½¬ä¹‰åºåˆ—
                clean_output = re.sub(r'\x1b\[[0-9;]*[mJHK]', '', result.stdout)
                
                response_data = json.loads(clean_output)
                
                if response_data.get('success'):
                    # ä»JSONä¸­ç›´æ¥è·å–æ¨¡å‹åˆ—è¡¨å’Œè¯¦ç»†ä¿¡æ¯
                    models = response_data.get('models', [])
                    model_details = response_data.get('model_details', {})
                    
                    if models:
                        return models, model_details
                    else:
                        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„OpenRouteræ¨¡å‹", file=sys.stderr)
                        return [], {}
                else:
                    print(f"âš ï¸  è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response_data.get('message', 'Unknown error')}", file=sys.stderr)
                    return [], {}
                    
            except json.JSONDecodeError:
                print("âš ï¸  è§£ææ¨¡å‹åˆ—è¡¨JSONå¤±è´¥", file=sys.stderr)
                return [], {}
        else:
            print(f"âš ï¸  è°ƒç”¨OPENROUTER --listå¤±è´¥: {result.stderr}", file=sys.stderr)
            return [], {}
            
    except Exception as e:
        print(f"âš ï¸  è·å–OpenRouteræ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {e}", file=sys.stderr)
        return [], {}


def select_openrouter_model(params=None):
    """Let user select OpenRouter model."""
    print("\nğŸ¤– é€‰æ‹©AIæ¨¡å‹...")
    
    # è·å–å¯ç”¨æ¨¡å‹å’Œè¯¦ç»†ä¿¡æ¯
    models, model_details = get_openrouter_models()
    
    if not models:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„OpenRouteræ¨¡å‹", file=sys.stderr)
        models, model_details = get_openrouter_models()  # é‡è¯•ä¸€æ¬¡
        if not models:
            print("âŒ é‡è¯•åä»ç„¶æ²¡æœ‰å¯ç”¨çš„OpenRouteræ¨¡å‹", file=sys.stderr)
            return None, None
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨é»˜è®¤è®¾ç½®
    if params and not params.get('not_default', False):
        selected_model = models[0]
        print(f"ğŸ¤– ä½¿ç”¨é»˜è®¤æ¨¡å‹: {selected_model}")
    else:
        # äº¤äº’å¼é€‰æ‹©
        print("å¯ç”¨æ¨¡å‹:")
        for i, model in enumerate(models):
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯åŒ…æ‹¬context length
            details = model_details.get(model, {})
            context_length = details.get('context_length', 'Unknown')
            cost_info = ""
            if details.get('input_cost_per_1m', 0) == 0:
                cost_info = " (å…è´¹)"
            else:
                cost_info = f" (${details.get('input_cost_per_1m', 0):.1f}/$M)"
            print(f"  {i+1}. {model} [Context: {context_length:,}]{cost_info}")
        
        while True:
            try:
                choice = input(f"é€‰æ‹©æ¨¡å‹ (1-{len(models)}, é»˜è®¤: 1): ").strip()
                if not choice:
                    selected_model = models[0]
                    break
                
                choice_num = int(choice) - 1
                if 0 <= choice_num < len(models):
                    selected_model = models[choice_num]
                    break
                else:
                    print(f"è¯·è¾“å…¥ 1 åˆ° {len(models)} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print(f"è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\nå–æ¶ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                # è·å–ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
                models, model_details = get_openrouter_models()
                if models:
                    return models[0], None
                return None, None
        
        print(f"é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
    
    # è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯
    details = model_details.get(selected_model, {})
    context_length = details.get('context_length')
    
    # è®¡ç®—max_tokensä¸ºcontext_lengthçš„1/4
    max_tokens = None
    if context_length:
        max_tokens = context_length // 4
        print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯: Context Length: {context_length:,}, Max Tokens: {max_tokens:,}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå…è´¹æ¨¡å‹
    is_free_model = details.get('input_cost_per_1m', 0) == 0
    
    if not is_free_model and max_tokens:
        # æ£€æŸ¥æ˜¯å¦æ˜¯é»˜è®¤æ¨¡å‹ï¼ˆç¬¬ä¸€ä¸ªæ¨¡å‹ï¼‰
        is_default_model = selected_model == models[0]
        
        # åªæœ‰éé»˜è®¤æ¨¡å‹æ‰æ˜¾ç¤ºä»˜è´¹æç¤º
        if not is_default_model:
            print(f"\nğŸ’° è¿™æ˜¯ä»˜è´¹æ¨¡å‹ï¼Œå½“å‰max_tokensè®¾ç½®ä¸º: {max_tokens:,}")
            while True:
                try:
                    choice = input(f"æ˜¯å¦è¦ä¿®æ”¹max_tokensè®¾ç½®ï¼Ÿ (y/N): ").strip().lower()
                    if choice in ['y', 'yes']:
                        while True:
                            try:
                                new_max_tokens = input(f"è¯·è¾“å…¥max_tokens (å½“å‰: {max_tokens:,}, æœ€å¤§: {context_length:,}): ").strip()
                                if not new_max_tokens:
                                    break  # ä½¿ç”¨é»˜è®¤å€¼
                                
                                new_max_tokens = int(new_max_tokens)
                                if 1 <= new_max_tokens <= context_length:
                                    max_tokens = new_max_tokens
                                    print(f"âœ… Max tokensè®¾ç½®ä¸º: {max_tokens:,}")
                                    break
                                else:
                                    print(f"è¯·è¾“å…¥ 1 åˆ° {context_length:,} ä¹‹é—´çš„æ•°å­—")
                            except ValueError:
                                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                        break
                    elif choice in ['n', 'no', '']:
                        break
                    else:
                        print("è¯·è¾“å…¥ y æˆ– n")
                except KeyboardInterrupt:
                    print("\nä½¿ç”¨é»˜è®¤è®¾ç½®")
                    break
    
    return selected_model, max_tokens


def call_openrouter_for_structure(prompt, model=None, max_tokens=None, retry_count=0):
    """Call OpenRouter API to get content structure suggestions with retry mechanism."""
    import time
    
    try:
        script_dir = Path(__file__).parent
        run_path = script_dir / "RUN.py"
        
        if retry_count == 0:
            print("ğŸ”„ æ­£åœ¨è¿æ¥OpenRouter API...", file=sys.stderr)
        else:
            print(f"ğŸ”„ é‡è¯•APIè°ƒç”¨ (ç¬¬{retry_count}æ¬¡)...", file=sys.stderr)
            
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
        if not model:
            print("ğŸ”„ æ­£åœ¨è¿æ¥OpenRouter API...", file=sys.stderr)
            models = get_openrouter_models()
            if not models:
                return None, {"error": "No useable models available"}
            model = models[0]
        
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}", file=sys.stderr)
        if max_tokens:
            print(f"ğŸ”¢ æœ€å¤§tokens: {max_tokens}", file=sys.stderr)
        print("â³ è¿™å¯èƒ½éœ€è¦ä¸€ä¼šï¼Œè¯·è€å¿ƒç­‰å¾…...", file=sys.stderr)
        
        # æ„å»ºå‘½ä»¤ - ä½¿ç”¨RUN --showè°ƒç”¨OPENROUTERå·¥å…·
        cmd = [sys.executable, str(run_path), "--show", "OPENROUTER", prompt]
        
        if model:
            cmd.extend(["--model", model])
        
        # ä¼ å…¥max-tokenså‚æ•°ï¼ˆOPENROUTERå·¥å…·ä¼šè‡ªåŠ¨å¤„ç†åŠ¨æ€è°ƒæ•´ï¼‰
        if max_tokens:
            cmd.extend(["--max-tokens", str(max_tokens)])
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # ä½¿ç”¨RUN --showæ¨¡å¼è°ƒç”¨OPENROUTERå·¥å…·ï¼Œé¿å…å“åº”è¢«æˆªæ–­
        try:
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            try:
                stdout, stderr = process.communicate(timeout=60)
                
                # åˆ›å»ºä¸€ä¸ªresultå¯¹è±¡æ¥æ¨¡æ‹Ÿsubprocess.runçš„è¿”å›å€¼
                class Result:
                    def __init__(self, returncode, stdout, stderr):
                        self.returncode = returncode
                        self.stdout = stdout
                        self.stderr = stderr
                
                result = Result(process.returncode, stdout, stderr)
            except subprocess.TimeoutExpired:
                end_time = time.time()
                api_duration = end_time - start_time
                print(f"â° OpenRouter APIè°ƒç”¨è¶…æ—¶ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                process.kill()
                return None, None
        except KeyboardInterrupt:
            end_time = time.time()
            api_duration = end_time - start_time
            print(f"ğŸš« ç”¨æˆ·ä¸­æ–­APIè°ƒç”¨ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
            try:
                process.terminate()
                process.wait(timeout=5)
            except:
                process.kill()
            return None, None
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        api_duration = end_time - start_time
        
        if result.returncode == 0:
            print(f"âœ… OpenRouter APIè°ƒç”¨æˆåŠŸ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
            
            # è§£æJSONå“åº”
            try:
                import json
                import re
                
                # æ¸…ç†ANSIè½¬ä¹‰åºåˆ—
                clean_output = re.sub(r'\x1b\[[0-9;]*[mJKH]', '', result.stdout)
                
                response_data = json.loads(clean_output)
                
                if response_data.get('success'):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯RUN --showçš„åŒ…è£…æ ¼å¼
                    if 'output' in response_data:
                        # å°è¯•è§£æoutputå­—æ®µä¸­çš„JSON
                        try:
                            output_content = response_data['output']
                            if output_content.strip().startswith('{'):
                                # outputæ˜¯JSONæ ¼å¼
                                inner_data = json.loads(output_content)
                                if inner_data.get('success'):
                                    response_content = inner_data.get('content', '')
                                    usage = inner_data.get('usage', {})
                                    prompt_tokens = usage.get('input_tokens', 0)
                                    completion_tokens = usage.get('output_tokens', 0)
                                    total_tokens = usage.get('total_tokens', 0)
                                    cost = inner_data.get('cost', 0)
                                else:
                                    response_content = output_content
                                    prompt_tokens = completion_tokens = total_tokens = cost = 0
                            else:
                                # outputæ˜¯çº¯æ–‡æœ¬ï¼Œä½†æ£€æŸ¥æ˜¯å¦æœ‰RUN_DATA_FILE
                                response_content = output_content
                                prompt_tokens = completion_tokens = total_tokens = cost = 0
                                # å°è¯•ä»RUN_DATA_FILEä¸­è¯»å–tokenä¿¡æ¯
                                if '_RUN_DATA_file' in response_data:
                                    try:
                                        with open(response_data['_RUN_DATA_file'], 'r', encoding='utf-8') as f:
                                            run_data = json.load(f)
                                            if 'usage' in run_data:
                                                usage = run_data['usage']
                                                prompt_tokens = usage.get('input_tokens', 0)
                                                completion_tokens = usage.get('output_tokens', 0)
                                                total_tokens = usage.get('total_tokens', 0)
                                            # è¯»å–costä¿¡æ¯
                                            cost = run_data.get('cost', 0)
                                    except (FileNotFoundError, json.JSONDecodeError, KeyError):
                                        pass
                        except json.JSONDecodeError:
                            # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨outputå†…å®¹
                            response_content = response_data['output']
                            prompt_tokens = completion_tokens = total_tokens = cost = 0
                    else:
                        # ç›´æ¥ä»response_dataä¸­æå–
                        response_content = response_data.get('content', response_data.get('response', response_data.get('message', '')))
                        usage = response_data.get('usage', {})
                        prompt_tokens = usage.get('input_tokens', 0)
                        completion_tokens = usage.get('output_tokens', 0)
                        total_tokens = usage.get('total_tokens', 0)
                        cost = response_data.get('cost', 0)
                    
                    # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦
                    if not response_content or response_content.strip() == '':
                        print(f"âš ï¸  OpenRouter APIè¿”å›ç©ºå†…å®¹ (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                        return None, None
                    
                    # å¤„ç†å¯èƒ½çš„markdownä»£ç å—åŒ…è£…
                    if '```markdown' in response_content:
                        # ä½¿ç”¨```markdownåˆ†å‰²å†…å®¹
                        parts = response_content.split('```markdown')
                        if len(parts) >= 2:
                            # å–ç¬¬äºŒéƒ¨åˆ†ï¼ˆ```markdownä¹‹åçš„å†…å®¹ï¼‰
                            markdown_content = parts[1]
                            # ç§»é™¤æœ€åçš„```ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            if '```' in markdown_content:
                                markdown_content = markdown_content.split('```')[0]
                            response_content = markdown_content.strip()
                    
                    # è¿”å›å“åº”å†…å®¹å’Œtokenä¿¡æ¯
                    token_info = {
                        'prompt_tokens': prompt_tokens,
                        'completion_tokens': completion_tokens,
                        'total_tokens': total_tokens,
                        'cost': cost,
                        'api_duration': api_duration,
                        'model': model  # æ·»åŠ æ¨¡å‹ä¿¡æ¯
                    }
                    
                    return response_content, token_info
                else:
                    error_msg = response_data.get('error', 'Unknown error')
                    print(f"âŒ OpenRouter APIè¿”å›é”™è¯¯: {error_msg} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                    return f"ERROR: {error_msg}", None
                    
            except json.JSONDecodeError as e:
                print(f"âŒ è§£æJSONå“åº”å¤±è´¥: {e} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
                print(f"åŸå§‹è¾“å‡º: {result.stdout[:200]}...", file=sys.stderr)
                return None, None
                
        else:
            print(f"âŒ RUN --show OPENROUTERæ‰§è¡Œå¤±è´¥: {result.stderr} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
            return None, None
            
    except Exception as e:
        end_time = time.time()
        api_duration = end_time - start_time
        print(f"âŒ è°ƒç”¨OpenRouter APIæ—¶å‡ºé”™: {e} (è€—æ—¶: {api_duration:.2f}ç§’)", file=sys.stderr)
        return None, None


def generate_tutorial_prompt(params, brainstorming_response):
    """Generate prompt for tutorial.md creation."""
    if params["type"] == "general":
        # General topic
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        brainstorming_summary = brainstorming_response
        
        prompt = f"""è¯·ä¸º"{topic}"åˆ›å»ºä¸€ä¸ªç®€æ´çš„tutorial.mdæ–‡ä»¶ã€‚

å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹è¦ç‚¹åˆ›å»ºæ•™ç¨‹ï¼š
{brainstorming_summary}

è¯·åˆ›å»ºä¸€ä¸ªç»“æ„ç®€æ´çš„tutorial.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š
1. æ ‡é¢˜å’Œç›®å½•
2. 3-4ä¸ªæ ¸å¿ƒæ¦‚å¿µçš„è¯¦ç»†è§£é‡Šï¼ˆåŒ…å«ä»£ç ç¤ºä¾‹ï¼Œä¾‹é¢˜ç­‰ï¼Œif applicableï¼‰
3. ç®€æ˜çš„å­¦ä¹ è·¯å¾„æŒ‡å¯¼
4. 2-3ä¸ªå®è·µç»ƒä¹ å»ºè®®
5. ç²¾é€‰èµ„æºæ¨è

è¯·ç¡®ä¿å†…å®¹é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œå¹¶é‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚
è¯·ç›´æ¥æä¾›markdownæ ¼å¼çš„å†…å®¹ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•åˆ†éš”ç¬¦ã€‚"""
        
    else:
        # Paper-based
        paper_path = params.get('paper_path', 'è®ºæ–‡')
        paper_content = params.get('paper_content', '')
        mode = params['mode']
        style = params['style']
        
        # Use brainstorming response if available, otherwise use paper content directly
        if brainstorming_response:
            content_base = f"""å¤´è„‘é£æš´åˆ†æç»“æœï¼š
{brainstorming_response}

åŸè®ºæ–‡å†…å®¹ï¼ˆå‚è€ƒï¼‰ï¼š
{paper_content[:5000]}{'...' if len(paper_content) > 5000 else ''}"""
        else:
            content_base = f"""è®ºæ–‡å†…å®¹ï¼š
{paper_content}"""
        
        prompt = f"""è¯·åŸºäºå­¦æœ¯è®ºæ–‡å†…å®¹åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„tutorial.mdæ•™ç¨‹æ–‡ä»¶ã€‚

è®ºæ–‡ï¼š{paper_path}
å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹å†…å®¹åˆ›å»ºæ•™ç¨‹ï¼š
{content_base}

è¯·åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„tutorial.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š

1. **è®ºæ–‡æ¦‚è§ˆ**
   - è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å‘è¡¨ä¿¡æ¯
   - ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœº
   - ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

2. **æ ¸å¿ƒæ¦‚å¿µè¯¦è§£**
   - å…³é”®æ¦‚å¿µçš„å®šä¹‰å’Œè§£é‡Š
   - æŠ€æœ¯æ–¹æ³•çš„è¯¦ç»†è¯´æ˜
   - ç®—æ³•æˆ–æ¨¡å‹çš„å·¥ä½œåŸç†

3. **æŠ€æœ¯ç»†èŠ‚**
   - å®ç°æ–¹æ³•å’ŒæŠ€æœ¯è·¯çº¿
   - å®éªŒè®¾è®¡å’Œè¯„ä¼°æ–¹æ³•
   - ç»“æœåˆ†æå’Œè®¨è®º

4. **å­¦ä¹ è¦ç‚¹**
   - é‡ç‚¹çŸ¥è¯†ç‚¹æ€»ç»“
   - ä¸ç°æœ‰æ–¹æ³•çš„æ¯”è¾ƒ
   - ä¼˜åŠ¿å’Œå±€é™æ€§åˆ†æ

5. **æ‰©å±•é˜…è¯»**
   - ç›¸å…³è®ºæ–‡æ¨è
   - è¿›ä¸€æ­¥å­¦ä¹ èµ„æº

è¯·ç¡®ä¿å†…å®¹é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚
è¯·ç›´æ¥æä¾›markdownæ ¼å¼çš„å†…å®¹ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•åˆ†éš”ç¬¦ã€‚"""
    
    return prompt


def generate_question_prompt(params, tutorial_content):
    """Generate prompt for question.md creation."""
    if params["type"] == "general":
        # General topic
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        tutorial_summary = tutorial_content
        
        prompt = f"""è¯·ä¸º"{topic}"åˆ›å»ºç®€æ´çš„ç»ƒä¹ é¢˜æ–‡ä»¶question.mdã€‚

å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹æ•™ç¨‹å†…å®¹åˆ›å»ºç»ƒä¹ é¢˜ï¼š
{tutorial_summary}

è¯·åˆ›å»ºä¸€ä¸ªç®€æ´çš„question.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š
1. åŸºç¡€çŸ¥è¯†æµ‹è¯•é¢˜ï¼ˆ3é¢˜ï¼‰
2. ç†è§£åº”ç”¨é¢˜ï¼ˆ3é¢˜ï¼‰
3. å®è·µç»ƒä¹ é¢˜ï¼ˆ2é¢˜ï¼‰
4. æ€è€ƒé¢˜ï¼ˆ2é¢˜ï¼‰
5. æ¯ä¸ªé—®é¢˜éƒ½è¦æœ‰ç®€æ´æ˜ç¡®çš„ç­”æ¡ˆ

è¯·ä½¿ç”¨HTMLçš„details/summaryæ ‡ç­¾æ¥åˆ›å»ºå¯å±•å¼€çš„ç­”æ¡ˆåŒºåŸŸã€‚
è¯·ç¡®ä¿é—®é¢˜é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ã€‚
è¯·æ§åˆ¶å†…å®¹é•¿åº¦ï¼Œä¿æŒç®€æ´ã€‚"""
        
    else:
        # Paper-based
        paper_path = params.get('paper_path', 'è®ºæ–‡')
        mode = params['mode']
        style = params['style']
        
        tutorial_summary = tutorial_content
        
        prompt = f"""è¯·åŸºäºå­¦æœ¯è®ºæ–‡æ•™ç¨‹åˆ›å»ºcomprehensiveçš„ç»ƒä¹ é¢˜æ–‡ä»¶question.mdã€‚

è®ºæ–‡ï¼š{paper_path}
å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

åŸºäºä»¥ä¸‹æ•™ç¨‹å†…å®¹åˆ›å»ºç»ƒä¹ é¢˜ï¼š
{tutorial_summary}

è¯·åˆ›å»ºä¸€ä¸ªå…¨é¢çš„question.mdæ–‡ä»¶ï¼ŒåŒ…å«ï¼š

1. **è®ºæ–‡ç†è§£é¢˜ï¼ˆ4é¢˜ï¼‰**
   - ç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœºç†è§£
   - ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹
   - æŠ€æœ¯æ–¹æ³•å’ŒåŸç†
   - å®éªŒç»“æœå’Œç»“è®º

2. **æ¦‚å¿µè§£é‡Šé¢˜ï¼ˆ3é¢˜ï¼‰**
   - å…³é”®æ¦‚å¿µå®šä¹‰
   - æŠ€æœ¯æœ¯è¯­è§£é‡Š
   - æ–¹æ³•æ¯”è¾ƒåˆ†æ

3. **æ‰¹åˆ¤æ€§æ€è€ƒé¢˜ï¼ˆ3é¢˜ï¼‰**
   - æ–¹æ³•ä¼˜ç¼ºç‚¹åˆ†æ
   - æ”¹è¿›å»ºè®®å’Œæ‰©å±•
   - åº”ç”¨åœºæ™¯è®¨è®º

4. **å®è·µåº”ç”¨é¢˜ï¼ˆ2é¢˜ï¼‰**
   - å®é™…åº”ç”¨è®¾è®¡
   - å®ç°æ€è·¯åˆ†æ

æ¯ä¸ªé—®é¢˜éƒ½å¿…é¡»ï¼š
- åŸºäºæ•™ç¨‹ä¸­çš„å…·ä½“å†…å®¹
- æœ‰è¯¦ç»†å‡†ç¡®çš„ç­”æ¡ˆ
- ä½¿ç”¨HTMLçš„<details>å’Œ<summary>æ ‡ç­¾å®ç°ç­”æ¡ˆæŠ˜å 

æ ¼å¼ç¤ºä¾‹ï¼š
### é—®é¢˜1ï¼šè¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

[è¯¦ç»†ç­”æ¡ˆå†…å®¹...]

</details>

è¯·ç¡®ä¿é—®é¢˜é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œé‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚"""
    
    return prompt


def generate_file_creation_prompt(params, structure_response):
    """Generate prompt for file creation instructions."""
    topic = params['topic']
    mode = params['mode']
    style = params['style']
    
    prompt = f"""æ ¹æ®ä»¥ä¸‹å­¦ä¹ å†…å®¹ç»“æ„å»ºè®®ï¼Œè¯·æä¾›å…·ä½“çš„æ–‡ä»¶åˆ›å»ºæŒ‡ä»¤å’Œå†…å®¹ï¼š

å­¦ä¹ ä¸»é¢˜ï¼š{topic}
å­¦ä¹ æ¨¡å¼ï¼š{mode}
è§£é‡Šé£æ ¼ï¼š{style}

ç»“æ„å»ºè®®ï¼š
{structure_response}

è¯·æä¾›ï¼š
1. tutorial.md çš„å®Œæ•´å†…å®¹ï¼ˆä½¿ç”¨markdownæ ¼å¼ï¼‰
2. question.md çš„å®Œæ•´å†…å®¹ï¼ˆåŒ…å«ç»ƒä¹ é¢˜å’Œç­”æ¡ˆï¼‰
3. å¦‚æœéœ€è¦ï¼Œæä¾›å…¶ä»–ç›¸å…³æ–‡ä»¶çš„å†…å®¹

è¯·ç¡®ä¿å†…å®¹é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œå¹¶é‡‡ç”¨{style}çš„è§£é‡Šé£æ ¼ã€‚
æ¯ä¸ªæ–‡ä»¶çš„å†…å®¹åº”è¯¥ç”¨æ˜ç¡®çš„æ ‡è®°åˆ†éš”ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

===== tutorial.md =====
[tutorial.mdçš„å®Œæ•´å†…å®¹]
===== END tutorial.md =====

===== question.md =====
[question.mdçš„å®Œæ•´å†…å®¹]
===== END question.md =====

å¦‚æœæœ‰å…¶ä»–æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ç›¸åŒçš„æ ¼å¼ã€‚"""
    
    return prompt


def create_learning_files_from_responses(params, tutorial_response, question_response, prompts_and_responses=None):
    """Create learning files from separate tutorial and question responses."""
    output_dir = params['output_dir']
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    try:
        # åˆ›å»ºtutorial.md
        tutorial_path = Path(output_dir) / "tutorial.md"
        with open(tutorial_path, 'w', encoding='utf-8') as f:
            f.write(tutorial_response)
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {tutorial_path}")
        
        # åˆ›å»ºquestion.md
        question_path = Path(output_dir) / "question.md"
        with open(question_path, 'w', encoding='utf-8') as f:
            f.write(question_response)
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {question_path}")
        
        # åˆ›å»ºOPENROUTER_promptsæ–‡ä»¶å¤¹å¹¶ä¿å­˜promptså’Œresponses
        if prompts_and_responses:
            prompts_dir = Path(output_dir) / "OPENROUTER_prompts"
            prompts_dir.mkdir(exist_ok=True)
            
            for i, (prompt, response, token_info) in enumerate(prompts_and_responses, 1):
                # ä¿å­˜prompt
                prompt_path = prompts_dir / f"prompt_{i}.txt"
                with open(prompt_path, 'w', encoding='utf-8') as f:
                    f.write(prompt)
                    f.write(f"\n\n--- Openrouter API Call Info ---\n")
                    f.write(f"model: {token_info.get('model', 'unknown')}\n")
                    f.write(f"prompt_tokens: {token_info.get('prompt_tokens', 0)}\n")
                    f.write(f"completion_tokens: {token_info.get('completion_tokens', 0)}\n")
                    f.write(f"total_tokens: {token_info.get('total_tokens', 0)}\n")
                    f.write(f"cost: ${token_info.get('cost', 0):.6f}\n")
                    f.write(f"api_duration: {token_info.get('api_duration', 0):.2f} seconds\n")
                
                # ä¿å­˜response
                response_path = prompts_dir / f"response_{i}.txt"
                with open(response_path, 'w', encoding='utf-8') as f:
                    f.write(response)
                    f.write(f"\n\n--- Openrouter API Call Info ---\n")
                    f.write(f"model: {token_info.get('model', 'unknown')}\n")
                    f.write(f"prompt_tokens: {token_info.get('prompt_tokens', 0)}\n")
                    f.write(f"completion_tokens: {token_info.get('completion_tokens', 0)}\n")
                    f.write(f"total_tokens: {token_info.get('total_tokens', 0)}\n")
                    f.write(f"cost: ${token_info.get('cost', 0):.6f}\n")
                    f.write(f"api_duration: {token_info.get('api_duration', 0):.2f} seconds\n")
                
                print(f"âœ… ä¿å­˜promptå’Œresponse: {prompt_path.name}, {response_path.name}")
                model_used = token_info.get('model', 'unknown')
                cost = token_info.get('cost', 0)
                print(f"ğŸ“Š Tokenä½¿ç”¨: {token_info.get('total_tokens', 0)} tokens (è¾“å…¥: {token_info.get('prompt_tokens', 0)}, è¾“å‡º: {token_info.get('completion_tokens', 0)}) - æ¨¡å‹: {model_used} - è´¹ç”¨: ${cost:.6f} - ç”¨æ—¶: {token_info.get('api_duration', 0):.2f}ç§’")
        
        file_count = 2 + (len(prompts_and_responses) * 2 if prompts_and_responses else 0)
        print(f"\nğŸ“ åˆ›å»ºäº† {file_count} ä¸ªæ–‡ä»¶:")
        print(f"  - {tutorial_path}")
        print(f"  - {question_path}")
        if prompts_and_responses:
            print(f"  - OPENROUTER_prompts/ æ–‡ä»¶å¤¹åŒ…å« {len(prompts_and_responses)} ç»„promptå’Œresponse")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False


def create_learning_files(params, creation_response):
    """Create learning files based on AI response."""
    try:
        output_dir = Path(params['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è§£æAIå“åº”ä¸­çš„æ–‡ä»¶å†…å®¹
        files_content = parse_file_content(creation_response)
        
        if not files_content:
            print("âŒ æ— æ³•ä»AIå“åº”ä¸­è§£ææ–‡ä»¶å†…å®¹")
            return False
        
        # åˆ›å»ºæ–‡ä»¶
        created_files = []
        for filename, content in files_content.items():
            file_path = output_dir / filename
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                created_files.append(str(file_path))
                print(f"âœ… åˆ›å»ºæ–‡ä»¶: {file_path}")
            except Exception as e:
                print(f"âŒ åˆ›å»ºæ–‡ä»¶ {filename} å¤±è´¥: {e}")
                return False
        
        print(f"\nğŸ“ åˆ›å»ºäº† {len(created_files)} ä¸ªæ–‡ä»¶:")
        for file_path in created_files:
            print(f"  - {file_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False


def parse_file_content(response):
    """Parse file content from AI response."""
    import re
    
    files_content = {}
    
    # é¦–å…ˆå°è¯•åŒ¹é…æ ‡å‡†æ ¼å¼
    pattern = r'===== (.+?) =====\n(.*?)\n===== END \1 ====='
    matches = re.findall(pattern, response, re.DOTALL)
    
    if matches:
        for filename, content in matches:
            files_content[filename] = content.strip()
    else:
        # å¦‚æœæ ‡å‡†æ ¼å¼ä¸åŒ¹é…ï¼Œå°è¯•ä»å“åº”ä¸­æå–å†…å®¹å¹¶åˆ›å»ºé»˜è®¤æ–‡ä»¶
        print("âš ï¸  AIå“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œå°è¯•ä»å“åº”ä¸­æå–å†…å®¹...")
        
        # æ¸…ç†å“åº”å†…å®¹
        clean_response = re.sub(r'\x1b\[[0-9;]*[mJHK]', '', response)
        
        # å¦‚æœå“åº”åŒ…å«æ•™ç¨‹å†…å®¹ï¼Œåˆ›å»ºé»˜è®¤æ–‡ä»¶
        if len(clean_response.strip()) > 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å®¹
            # åˆ›å»º tutorial.md
            tutorial_content = f"""# PythonåŸºç¡€æ•™ç¨‹

## åŸºäºAIç”Ÿæˆçš„å­¦ä¹ å†…å®¹

{clean_response}

## æ³¨æ„
è¿™æ˜¯åŸºäºAIå“åº”è‡ªåŠ¨ç”Ÿæˆçš„å†…å®¹ï¼Œå»ºè®®è¿›ä¸€æ­¥æ•´ç†å’Œå®Œå–„ã€‚
"""
            files_content['tutorial.md'] = tutorial_content
            
            # åˆ›å»º question.md
            question_content = f"""# PythonåŸºç¡€ç»ƒä¹ é¢˜

## åŸºç¡€ç»ƒä¹ 

### é—®é¢˜1ï¼šä»€ä¹ˆæ˜¯Pythonï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚

</details>

### é—®é¢˜2ï¼šPythonçš„ä¸»è¦ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

Pythonçš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š
- ç®€æ´æ˜“è¯»çš„è¯­æ³•
- å¼ºå¤§çš„æ ‡å‡†åº“
- è·¨å¹³å°å…¼å®¹æ€§
- é¢å‘å¯¹è±¡ç¼–ç¨‹æ”¯æŒ

</details>

### é—®é¢˜3ï¼šå¦‚ä½•åœ¨Pythonä¸­åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

```python
my_list = [1, 2, 3, 4, 5]
```

</details>

## æ³¨æ„
è¿™æ˜¯åŸºäºAIå“åº”è‡ªåŠ¨ç”Ÿæˆçš„ç»ƒä¹ é¢˜ï¼Œå»ºè®®æ ¹æ®å®é™…æ•™ç¨‹å†…å®¹è¿›è¡Œè°ƒæ•´ã€‚
"""
            files_content['question.md'] = question_content
    
    return files_content


def create_files_from_brainstorming(params, brainstorming_response):
    """Create tutorial and question files based on brainstorming response."""
    try:
        output_dir = Path(params['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)
        
        topic = params['topic']
        mode = params['mode']
        style = params['style']
        
        # æ¸…ç†brainstormingå“åº”
        import re
        clean_response = re.sub(r'\x1b\[[0-9;]*[mJHK]', '', brainstorming_response)
        
        # åˆ›å»ºtutorial.md
        tutorial_content = create_tutorial_content(topic, mode, style, clean_response)
        tutorial_path = output_dir / "tutorial.md"
        with open(tutorial_path, 'w', encoding='utf-8') as f:
            f.write(tutorial_content)
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {tutorial_path}")
        
        # åˆ›å»ºquestion.md
        question_content = create_question_content(topic, mode, style, clean_response)
        question_path = output_dir / "question.md"
        with open(question_path, 'w', encoding='utf-8') as f:
            f.write(question_content)
        print(f"âœ… åˆ›å»ºæ–‡ä»¶: {question_path}")
        
        print(f"\nğŸ“ åˆ›å»ºäº† 2 ä¸ªæ–‡ä»¶:")
        print(f"  - {tutorial_path}")
        print(f"  - {question_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False


def create_tutorial_content(topic, mode, style, brainstorming_response):
    """Create tutorial.md content based on brainstorming."""
    content = f"""# {topic} æ•™ç¨‹

**å­¦ä¹ æ¨¡å¼**: {mode}  
**è§£é‡Šé£æ ¼**: {style}

## ç®€ä»‹

æ¬¢è¿å­¦ä¹ {topic}ï¼è¿™ä¸ªæ•™ç¨‹å°†ä¸ºæ‚¨æä¾›ç³»ç»Ÿçš„å­¦ä¹ è·¯å¾„å’Œå®è·µæŒ‡å¯¼ã€‚

## ç›®å½•

1. [åŸºç¡€æ¦‚å¿µ](#åŸºç¡€æ¦‚å¿µ)
2. [æ ¸å¿ƒçŸ¥è¯†ç‚¹](#æ ¸å¿ƒçŸ¥è¯†ç‚¹)
3. [å®è·µç»ƒä¹ ](#å®è·µç»ƒä¹ )
4. [è¿›é˜¶åº”ç”¨](#è¿›é˜¶åº”ç”¨)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
6. [èµ„æºæ¨è](#èµ„æºæ¨è)

## åŸºç¡€æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯{topic}ï¼Ÿ

{topic}æ˜¯ä¸€ä¸ªé‡è¦çš„å­¦ä¹ ä¸»é¢˜ã€‚æ ¹æ®AIçš„å»ºè®®ï¼Œå­¦ä¹ {topic}å¯¹äº{mode}æ°´å¹³çš„å­¦ä¹ è€…æ¥è¯´å…·æœ‰é‡è¦æ„ä¹‰ã€‚

### æ ¸å¿ƒæ¦‚å¿µ

åŸºäºbrainstormingçš„ç»“æœï¼Œä»¥ä¸‹æ˜¯{topic}çš„æ ¸å¿ƒæ¦‚å¿µï¼š

"""

    # å°è¯•ä»brainstormingå“åº”ä¸­æå–æœ‰ç”¨ä¿¡æ¯
    if "æ ¸å¿ƒæ¦‚å¿µ" in brainstorming_response or "æ¦‚å¿µ" in brainstorming_response:
        content += f"""
**ä»AIå»ºè®®ä¸­æå–çš„æ ¸å¿ƒæ¦‚å¿µï¼š**

{brainstorming_response[:1000]}...

*ï¼ˆå®Œæ•´çš„AIå»ºè®®è¯·å‚è€ƒåŸå§‹å“åº”ï¼‰*

"""

    content += f"""
## æ ¸å¿ƒçŸ¥è¯†ç‚¹

### å¿…é¡»æŒæ¡çš„çŸ¥è¯†ç‚¹

é’ˆå¯¹{mode}æ°´å¹³çš„å­¦ä¹ è€…ï¼Œä»¥ä¸‹æ˜¯å¿…é¡»æŒæ¡çš„çŸ¥è¯†ç‚¹ï¼š

1. **åŸºç¡€ç†è®º** - ç†è§£{topic}çš„åŸºæœ¬åŸç†
2. **å®è·µæŠ€èƒ½** - æŒæ¡åŸºæœ¬çš„æ“ä½œå’Œåº”ç”¨
3. **é—®é¢˜è§£å†³** - èƒ½å¤Ÿåˆ†æå’Œè§£å†³å¸¸è§é—®é¢˜

### å­¦ä¹ è·¯å¾„

å»ºè®®æŒ‰ç…§ä»¥ä¸‹é¡ºåºå­¦ä¹ ï¼š

1. åŸºç¡€æ¦‚å¿µç†è§£
2. æ ¸å¿ƒæŠ€èƒ½ç»ƒä¹ 
3. å®é™…é¡¹ç›®åº”ç”¨
4. é«˜çº§ç‰¹æ€§æ¢ç´¢

## å®è·µç»ƒä¹ 

### åŸºç¡€ç»ƒä¹ 

1. **å…¥é—¨ç»ƒä¹ ** - ç†Ÿæ‚‰åŸºæœ¬æ¦‚å¿µ
2. **æŠ€èƒ½ç»ƒä¹ ** - æŒæ¡æ ¸å¿ƒæŠ€èƒ½
3. **ç»¼åˆç»ƒä¹ ** - æ•´åˆæ‰€å­¦çŸ¥è¯†

### é¡¹ç›®å®è·µ

å»ºè®®å®Œæˆä»¥ä¸‹é¡¹ç›®æ¥å·©å›ºå­¦ä¹ ï¼š

1. **åŸºç¡€é¡¹ç›®** - åº”ç”¨åŸºæœ¬æ¦‚å¿µ
2. **è¿›é˜¶é¡¹ç›®** - ç»“åˆå¤šä¸ªçŸ¥è¯†ç‚¹
3. **å®æˆ˜é¡¹ç›®** - è§£å†³å®é™…é—®é¢˜

## è¿›é˜¶åº”ç”¨

### é«˜çº§ç‰¹æ€§

å½“æ‚¨æŒæ¡äº†åŸºç¡€çŸ¥è¯†åï¼Œå¯ä»¥æ¢ç´¢ï¼š

1. **é«˜çº§æŠ€æœ¯** - æ·±å…¥ç†è§£åŸç†
2. **æœ€ä½³å®è·µ** - å­¦ä¹ è¡Œä¸šæ ‡å‡†
3. **åˆ›æ–°åº”ç”¨** - æ¢ç´¢æ–°çš„å¯èƒ½æ€§

## å¸¸è§é—®é¢˜

### å­¦ä¹ éš¾ç‚¹

åŸºäºç»éªŒï¼Œå­¦ä¹ è€…é€šå¸¸åœ¨ä»¥ä¸‹æ–¹é¢é‡åˆ°å›°éš¾ï¼š

1. **æ¦‚å¿µç†è§£** - æŠ½è±¡æ¦‚å¿µçš„ç†è§£
2. **å®è·µåº”ç”¨** - ç†è®ºåˆ°å®è·µçš„è½¬æ¢
3. **é—®é¢˜è°ƒè¯•** - é‡åˆ°é—®é¢˜æ—¶çš„è§£å†³æ–¹æ³•

### è§£å†³æ–¹æ¡ˆ

é’ˆå¯¹è¿™äº›éš¾ç‚¹ï¼Œå»ºè®®ï¼š

1. **å¤šç»ƒä¹ ** - é€šè¿‡å¤§é‡ç»ƒä¹ åŠ æ·±ç†è§£
2. **å¯»æ±‚å¸®åŠ©** - åŠæ—¶å‘è€å¸ˆæˆ–åŒå­¦æ±‚åŠ©
3. **æŒç»­å­¦ä¹ ** - ä¿æŒå­¦ä¹ çš„è¿ç»­æ€§

## èµ„æºæ¨è

### å­¦ä¹ èµ„æº

1. **å®˜æ–¹æ–‡æ¡£** - æœ€æƒå¨çš„å­¦ä¹ èµ„æ–™
2. **åœ¨çº¿æ•™ç¨‹** - ä¸°å¯Œçš„å­¦ä¹ å†…å®¹
3. **å®è·µé¡¹ç›®** - åŠ¨æ‰‹ç»ƒä¹ çš„æœºä¼š

### å·¥å…·æ¨è

æ ¹æ®å­¦ä¹ éœ€è¦ï¼Œæ¨èä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š

1. **å¼€å‘ç¯å¢ƒ** - æä¾›è‰¯å¥½çš„å­¦ä¹ ç¯å¢ƒ
2. **è°ƒè¯•å·¥å…·** - å¸®åŠ©è§£å†³é—®é¢˜
3. **å‚è€ƒèµ„æ–™** - éšæ—¶æŸ¥é˜…çš„æ‰‹å†Œ

## æ€»ç»“

{topic}æ˜¯ä¸€ä¸ªå€¼å¾—æ·±å…¥å­¦ä¹ çš„ä¸»é¢˜ã€‚é€šè¿‡ç³»ç»Ÿçš„å­¦ä¹ å’Œå¤§é‡çš„å®è·µï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

1. æŒæ¡æ ¸å¿ƒæ¦‚å¿µå’ŒæŠ€èƒ½
2. è§£å†³å®é™…é—®é¢˜
3. ä¸ºè¿›ä¸€æ­¥å­¦ä¹ æ‰“ä¸‹åšå®åŸºç¡€

ç¥æ‚¨å­¦ä¹ æ„‰å¿«ï¼

---

**æ³¨æ„**: è¿™ä»½æ•™ç¨‹åŸºäºAIåŠ©æ‰‹çš„brainstormingç»“æœåˆ›å»ºï¼Œå»ºè®®ç»“åˆå…¶ä»–å­¦ä¹ èµ„æºä¸€èµ·ä½¿ç”¨ã€‚
"""

    return content


def create_question_content(topic, mode, style, brainstorming_response):
    """Create question.md content based on brainstorming."""
    content = f"""# {topic} ç»ƒä¹ é¢˜

**å­¦ä¹ æ¨¡å¼**: {mode}  
**è§£é‡Šé£æ ¼**: {style}

## åŸºç¡€çŸ¥è¯†é¢˜

### é—®é¢˜1ï¼šä»€ä¹ˆæ˜¯{topic}ï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

{topic}æ˜¯ä¸€ä¸ªé‡è¦çš„å­¦ä¹ é¢†åŸŸï¼Œæ¶‰åŠå¤šä¸ªæ ¸å¿ƒæ¦‚å¿µå’Œå®è·µæŠ€èƒ½ã€‚å¯¹äº{mode}æ°´å¹³çš„å­¦ä¹ è€…æ¥è¯´ï¼Œç†è§£{topic}çš„åŸºæœ¬åŸç†å’Œåº”ç”¨æ˜¯å¿…è¦çš„ã€‚

</details>

### é—®é¢˜2ï¼šå­¦ä¹ {topic}éœ€è¦ä»€ä¹ˆå‰ç½®çŸ¥è¯†ï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

å­¦ä¹ {topic}é€šå¸¸éœ€è¦ï¼š
- åŸºç¡€çš„ç†è®ºçŸ¥è¯†
- ä¸€å®šçš„é€»è¾‘æ€ç»´èƒ½åŠ›
- åŠ¨æ‰‹å®è·µçš„æ„æ„¿
- æŒç»­å­¦ä¹ çš„æ€åº¦

</details>

### é—®é¢˜3ï¼š{topic}çš„æ ¸å¿ƒæ¦‚å¿µæœ‰å“ªäº›ï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

åŸºäºAIçš„brainstormingå»ºè®®ï¼Œ{topic}çš„æ ¸å¿ƒæ¦‚å¿µåŒ…æ‹¬å¤šä¸ªæ–¹é¢ã€‚å…·ä½“å†…å®¹è¯·å‚è€ƒtutorial.mdä¸­çš„è¯¦ç»†ä»‹ç»ã€‚

</details>

## ç†è§£é¢˜

### é—®é¢˜4ï¼šè¯·è§£é‡Š{topic}çš„åŸºæœ¬åŸç†
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

{topic}çš„åŸºæœ¬åŸç†æ¶‰åŠå¤šä¸ªå±‚é¢çš„ç†è§£ã€‚å»ºè®®ä»åŸºç¡€æ¦‚å¿µå¼€å§‹ï¼Œé€æ­¥æ·±å…¥ç†è§£å…¶å·¥ä½œæœºåˆ¶å’Œåº”ç”¨åœºæ™¯ã€‚

</details>

### é—®é¢˜5ï¼š{topic}æœ‰å“ªäº›å®é™…åº”ç”¨ï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

{topic}åœ¨å®é™…ä¸­æœ‰å¹¿æ³›çš„åº”ç”¨ï¼ŒåŒ…æ‹¬ï¼š
- ç†è®ºç ”ç©¶
- å®é™…é¡¹ç›®
- é—®é¢˜è§£å†³
- åˆ›æ–°åº”ç”¨

</details>

## å®è·µé¢˜

### é—®é¢˜6ï¼šè®¾è®¡ä¸€ä¸ª{topic}çš„å…¥é—¨ç»ƒä¹ 
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

å»ºè®®çš„å…¥é—¨ç»ƒä¹ åº”è¯¥ï¼š
1. ä»æœ€åŸºç¡€çš„æ¦‚å¿µå¼€å§‹
2. æä¾›æ˜ç¡®çš„æ­¥éª¤æŒ‡å¯¼
3. åŒ…å«å®è·µæ“ä½œ
4. æœ‰æ˜ç¡®çš„é¢„æœŸç»“æœ

</details>

### é—®é¢˜7ï¼šå¦‚ä½•è§£å†³{topic}å­¦ä¹ ä¸­çš„å¸¸è§é—®é¢˜ï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

è§£å†³å­¦ä¹ é—®é¢˜çš„æ–¹æ³•ï¼š
1. ä»”ç»†é˜…è¯»æ•™ç¨‹å’Œæ–‡æ¡£
2. å¯»æ±‚è€å¸ˆæˆ–åŒå­¦çš„å¸®åŠ©
3. åœ¨çº¿æœç´¢ç›¸å…³èµ„æº
4. é€šè¿‡å®è·µéªŒè¯ç†è§£

</details>

## åº”ç”¨é¢˜

### é—®é¢˜8ï¼šè®¾è®¡ä¸€ä¸ª{topic}çš„å®é™…é¡¹ç›®
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

å®é™…é¡¹ç›®åº”è¯¥ï¼š
- æœ‰æ˜ç¡®çš„ç›®æ ‡
- ä½“ç°{topic}çš„æ ¸å¿ƒæ¦‚å¿µ
- é€‚åˆ{mode}æ°´å¹³çš„å­¦ä¹ è€…
- æä¾›å­¦ä¹ å’Œå®è·µçš„æœºä¼š

</details>

### é—®é¢˜9ï¼šå¦‚ä½•è¯„ä¼°{topic}çš„å­¦ä¹ æ•ˆæœï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

è¯„ä¼°å­¦ä¹ æ•ˆæœå¯ä»¥é€šè¿‡ï¼š
1. ç†è®ºçŸ¥è¯†æµ‹è¯•
2. å®è·µæŠ€èƒ½å±•ç¤º
3. é¡¹ç›®å®Œæˆæƒ…å†µ
4. é—®é¢˜è§£å†³èƒ½åŠ›

</details>

## æ€è€ƒé¢˜

### é—®é¢˜10ï¼š{topic}çš„æœªæ¥å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ
<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

{topic}çš„å‘å±•è¶‹åŠ¿å¯èƒ½åŒ…æ‹¬ï¼š
- æŠ€æœ¯è¿›æ­¥å¸¦æ¥çš„æ–°æœºä¼š
- åº”ç”¨é¢†åŸŸçš„æ‰©å±•
- å­¦ä¹ æ–¹æ³•çš„æ”¹è¿›
- å·¥å…·å’Œèµ„æºçš„ä¸°å¯Œ

è¿™éœ€è¦å­¦ä¹ è€…ä¿æŒæŒç»­å­¦ä¹ å’Œå…³æ³¨è¡Œä¸šåŠ¨æ€ã€‚

</details>

---

**ç­”é¢˜è¯´æ˜**:
- æ¯ä¸ªé—®é¢˜éƒ½å¯¹åº”tutorial.mdä¸­çš„ç›¸å…³çŸ¥è¯†ç‚¹
- ä½¿ç”¨HTMLçš„`<details>`å’Œ`<summary>`æ ‡ç­¾å®ç°ç­”æ¡ˆçš„æ˜¾ç¤º/éšè—
- å»ºè®®å…ˆç‹¬ç«‹æ€è€ƒå†æŸ¥çœ‹ç­”æ¡ˆ
- å¯ä»¥ç»“åˆå®è·µæ¥éªŒè¯ç†è§£

**å­¦ä¹ å»ºè®®**:
1. æŒ‰é¡ºåºå®Œæˆç»ƒä¹ é¢˜
2. æ¯å®Œæˆä¸€ç»„é¢˜ç›®åå›é¡¾ç›¸å…³æ•™ç¨‹å†…å®¹
3. é‡åˆ°ä¸ç†è§£çš„åœ°æ–¹åŠæ—¶æŸ¥é˜…èµ„æ–™
4. é€šè¿‡å®è·µé¡¹ç›®å·©å›ºæ‰€å­¦çŸ¥è¯†

---

**æ³¨æ„**: è¿™ä»½ç»ƒä¹ é¢˜åŸºäºAIåŠ©æ‰‹çš„brainstormingç»“æœåˆ›å»ºï¼Œå»ºè®®ç»“åˆå®é™…å­¦ä¹ è¿›åº¦è°ƒæ•´éš¾åº¦å’Œå†…å®¹ã€‚
"""

    return content


def call_openrouter_with_retry(prompt, model, max_tokens, step_name, max_retries=3, params=None):
    """Call OpenRouter API with retry mechanism and model switching."""
    current_model = model
    
    for attempt in range(max_retries):
        response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, attempt)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸï¼ˆä¸æ˜¯Noneä¸”ä¸æ˜¯é”™è¯¯ï¼‰
        if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
            return response, token_info, current_model
        
        print(f"âŒ {step_name}å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•)", file=sys.stderr)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯429é”™è¯¯ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰
        if response and isinstance(response, str) and ("429" in response or "rate-limited" in response):
            print("âš ï¸  æ£€æµ‹åˆ°é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç«‹å³åˆ‡æ¢æ¨¡å‹", file=sys.stderr)
            # ç«‹å³åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹
            if attempt == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡å¤±è´¥æ—¶åˆ‡æ¢
                # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
                all_models = get_openrouter_models()
                if not all_models:
                    print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨", file=sys.stderr)
                    break
                
                # ç§»é™¤å½“å‰å¤±è´¥çš„æ¨¡å‹
                available_models = [m for m in all_models if m != current_model]
                
                if not available_models:
                    print("âŒ æ²¡æœ‰å…¶ä»–å¯ç”¨æ¨¡å‹", file=sys.stderr)
                    break
                
                # åˆ†ç±»æ¨¡å‹
                free_models = [m for m in available_models if ":free" in m]
                paid_models = [m for m in available_models if ":free" not in m]
                
                # å¦‚æœä½¿ç”¨äº†--not-defaultï¼Œè®©ç”¨æˆ·é€‰æ‹©
                if params and not params.get('not_default', False):
                    # é»˜è®¤æ¨¡å¼ï¼šå¦‚æœå½“å‰æ˜¯å…è´¹æ¨¡å‹ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå…è´¹æ¨¡å‹
                    if current_model and ":free" in current_model and free_models:
                        current_model = free_models[0]
                        print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå…è´¹æ¨¡å‹: {current_model}", file=sys.stderr)
                        continue
                    elif paid_models:
                        current_model = paid_models[0]
                        print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä»˜è´¹æ¨¡å‹: {current_model}", file=sys.stderr)
                        continue
                else:
                    # äº¤äº’æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å‹è®©ç”¨æˆ·é€‰æ‹©
                    print(f"\nâš ï¸  æ¨¡å‹ '{current_model}' è°ƒç”¨å¤±è´¥", file=sys.stderr)
                    print("å¯ç”¨çš„æ›¿ä»£æ¨¡å‹ï¼š", file=sys.stderr)
                    
                    all_available = []
                    if free_models:
                        print("å…è´¹æ¨¡å‹ï¼š", file=sys.stderr)
                        for i, model_name in enumerate(free_models):
                            print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
                            all_available.append(model_name)
                    
                    if paid_models:
                        print("ä»˜è´¹æ¨¡å‹ï¼š", file=sys.stderr)
                        for i, model_name in enumerate(paid_models):
                            print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
                            all_available.append(model_name)
                    
                    try:
                        choice = input(f"\né€‰æ‹©æ¨¡å‹ (1-{len(all_available)}) æˆ–æŒ‰å›è½¦è·³è¿‡: ").strip()
                        if choice and choice.isdigit():
                            choice_idx = int(choice) - 1
                            if 0 <= choice_idx < len(all_available):
                                current_model = all_available[choice_idx]
                                print(f"âœ… åˆ‡æ¢åˆ°æ¨¡å‹: {current_model}", file=sys.stderr)
                                # é‡æ–°å°è¯•ä¸€æ¬¡
                                response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, 0)
                                if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
                                    return response, token_info, current_model
                    except (KeyboardInterrupt, EOFError):
                        print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ", file=sys.stderr)
                        break
            
            # å¦‚æœåˆ°è¿™é‡Œè¯´æ˜429é”™è¯¯å¤„ç†å¤±è´¥
            break
        
        # å¯¹äºå…¶ä»–é”™è¯¯ï¼Œåœ¨æœ€åä¸€æ¬¡é‡è¯•åæ‰è¿›è¡Œæ¨¡å‹åˆ‡æ¢
        if attempt == max_retries - 1:
            # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
            all_models = get_openrouter_models()
            if not all_models:
                print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨", file=sys.stderr)
                break
            
            # ç§»é™¤å½“å‰å¤±è´¥çš„æ¨¡å‹
            available_models = [m for m in all_models if m != current_model]
            
            if not available_models:
                print("âŒ æ²¡æœ‰å…¶ä»–å¯ç”¨æ¨¡å‹", file=sys.stderr)
                break
            
            # åˆ†ç±»æ¨¡å‹
            free_models = [m for m in available_models if ":free" in m]
            paid_models = [m for m in available_models if ":free" not in m]
            
            # å¦‚æœä½¿ç”¨äº†--not-defaultï¼Œè®©ç”¨æˆ·é€‰æ‹©
            if params and not params.get('not_default', False):
                # é»˜è®¤æ¨¡å¼ï¼šå¦‚æœå½“å‰æ˜¯å…è´¹æ¨¡å‹ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå…è´¹æ¨¡å‹
                if current_model and ":free" in current_model and free_models:
                    current_model = free_models[0]
                    print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå…è´¹æ¨¡å‹: {current_model}", file=sys.stderr)
                    # é‡æ–°å°è¯•ä¸€æ¬¡
                    response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, 0)
                    if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
                        return response, token_info, current_model
                elif paid_models:
                    current_model = paid_models[0]
                    print(f"ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ä»˜è´¹æ¨¡å‹: {current_model}", file=sys.stderr)
                    # é‡æ–°å°è¯•ä¸€æ¬¡
                    response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, 0)
                    if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
                        return response, token_info, current_model
            else:
                # äº¤äº’æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡å‹è®©ç”¨æˆ·é€‰æ‹©
                print(f"\nâš ï¸  æ¨¡å‹ '{current_model}' è°ƒç”¨å¤±è´¥", file=sys.stderr)
                print("å¯ç”¨çš„æ›¿ä»£æ¨¡å‹ï¼š", file=sys.stderr)
                
                all_available = []
                if free_models:
                    print("å…è´¹æ¨¡å‹ï¼š", file=sys.stderr)
                    for i, model_name in enumerate(free_models):
                        print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
                        all_available.append(model_name)
                
                if paid_models:
                    print("ä»˜è´¹æ¨¡å‹ï¼š", file=sys.stderr)
                    for i, model_name in enumerate(paid_models):
                        print(f"  {len(all_available) + 1}. {model_name}", file=sys.stderr)
                        all_available.append(model_name)
                
                try:
                    choice = input(f"\né€‰æ‹©æ¨¡å‹ (1-{len(all_available)}) æˆ–æŒ‰å›è½¦è·³è¿‡: ").strip()
                    if choice and choice.isdigit():
                        choice_idx = int(choice) - 1
                        if 0 <= choice_idx < len(all_available):
                            current_model = all_available[choice_idx]
                            print(f"âœ… åˆ‡æ¢åˆ°æ¨¡å‹: {current_model}", file=sys.stderr)
                            # é‡æ–°å°è¯•ä¸€æ¬¡
                            response, token_info = call_openrouter_for_structure(prompt, current_model, max_tokens, 0)
                            if response is not None and not (isinstance(response, str) and response.startswith("ERROR:")):
                                return response, token_info, current_model
                except (KeyboardInterrupt, EOFError):
                    print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ", file=sys.stderr)
                    break
            
            # å¦‚æœåˆ°è¿™é‡Œè¯´æ˜æ¨¡å‹åˆ‡æ¢ä¹Ÿå¤±è´¥äº†
            break
    
    return None, None, current_model


def get_non_free_models():
    """Get list of non-free models from OpenRouter."""
    try:
        models = get_openrouter_models()
        return [model for model in models if ":free" not in model]
    except:
        return []


def generate_learning_content(params):
    """Generate learning content based on collected parameters."""
    print("\nğŸ¤– æ­£åœ¨ç”Ÿæˆå­¦ä¹ å†…å®¹ç»“æ„...")
    
    # ç”¨äºä¿å­˜æ‰€æœ‰çš„promptså’Œresponsesï¼Œç°åœ¨åŒ…å«tokenä¿¡æ¯
    prompts_and_responses = []
    
    # For paper type, model selection might already be done in generate_content_structure_prompt
    if params["type"] == "paper" and params.get("selected_model"):
        selected_model = params["selected_model"]
        max_tokens = params["max_tokens"]
        print(f"âœ… ä½¿ç”¨å·²é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
    else:
        # è®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹
        selected_model, max_tokens = select_openrouter_model(params)
        if not selected_model:
            print("âŒ æœªé€‰æ‹©æ¨¡å‹")
            return None
        
        # Store selected model info in params for later use
        params["selected_model"] = selected_model
        params["max_tokens"] = max_tokens
    
    # Step 1: Brainstorming (optional for papers)
    brainstorming_response = None
    brainstorming_token_info = None
    
    print("\nğŸ“ ç¬¬1æ­¥ï¼šè¯¢é—®AIè¿›è¡Œå¤´è„‘é£æš´...")
    structure_prompt = generate_content_structure_prompt(params)
    
    if structure_prompt:  # Brainstorming was requested
        print("æŸ¥è¯¢å†…å®¹:")
        print("-" * 40)
        print(structure_prompt[:500] + "..." if len(structure_prompt) > 500 else structure_prompt)
        print("-" * 40)
        
        # Call OpenRouter API for brainstorming with retry
        brainstorming_response, brainstorming_token_info, current_model = call_openrouter_with_retry(
            structure_prompt, selected_model, max_tokens, "å¤´è„‘é£æš´", params=params
        )
        
        if brainstorming_response is None:
            print("âŒ å¤´è„‘é£æš´å¤±è´¥")
            return None
        
        # ä¿å­˜ç¬¬ä¸€ç»„promptå’Œresponse
        prompts_and_responses.append((structure_prompt, brainstorming_response, brainstorming_token_info))
        
        # å¦‚æœæ˜¯no_auto_createæ¨¡å¼ï¼Œåªè¿”å›brainstormingç»“æœ
        if params.get("no_auto_create", False):
            print("\nğŸ“‹ å¤´è„‘é£æš´å®Œæˆï¼ä»¥ä¸‹æ˜¯ç”Ÿæˆçš„ç»“æ„å»ºè®®ï¼š")
            print("=" * 60)
            print(brainstorming_response)
            print("=" * 60)
            print("\nğŸ’¡ ä½ å¯ä»¥åŸºäºä»¥ä¸Šå»ºè®®æ‰‹åŠ¨åˆ›å»ºtutorial.mdå’Œquestion.mdæ–‡ä»¶")
            return {
                'brainstorming_response': brainstorming_response,
                'prompts_and_responses': prompts_and_responses
            }
    else:
        print("â­ï¸  è·³è¿‡å¤´è„‘é£æš´ï¼Œç›´æ¥ç”Ÿæˆæ•™ç¨‹")
        
        # For paper type without brainstorming, check if we should continue
        if params["type"] == "paper":
            # Auto-proceed in default mode or with free models
            should_auto_proceed = False
            
            if not params.get('not_default', False):
                # Default mode - auto proceed with automatic creation
                should_auto_proceed = True
                print("ğŸš€ é»˜è®¤æ¨¡å¼ï¼šè‡ªåŠ¨é€‰æ‹©åˆ›å»ºæ¨¡å¼...")
                # Don't set no_auto_create, proceed with full auto creation
            else:
                # Check if using free model
                if selected_model and max_tokens:
                    models, model_details = get_openrouter_models()
                    if models:
                        details = model_details.get(selected_model, {})
                        is_free_model = details.get('input_cost_per_1m', 0) == 0
                        if is_free_model:
                            should_auto_proceed = True
                            print("ğŸš€ å…è´¹æ¨¡å‹ï¼šè‡ªåŠ¨é€‰æ‹©åˆ›å»ºæ¨¡å¼...")
            
            if not should_auto_proceed:
                # Ask user about creation mode
                print("\nğŸ¯ é€‰æ‹©åˆ›å»ºæ¨¡å¼:")
                creation_choice = interactive_select(
                    "åˆ›å»ºæ¨¡å¼:", 
                    ["è‡ªåŠ¨åˆ›å»º (AIç”Ÿæˆ3æ¬¡)", "æ‰‹åŠ¨åˆ›å»º (AIç”Ÿæˆ1æ¬¡ï¼Œä½ æ¥åˆ›å»ºæ–‡ä»¶)"]
                )
                if creation_choice is None:
                    return None
                
                if creation_choice == 1:  # Manual creation
                    params["no_auto_create"] = True
    
    # Step 2: Generate tutorial.md
    print("\nğŸ“ ç¬¬2æ­¥ï¼šåŸºäºå†…å®¹ç”Ÿæˆtutorial.md...")
    tutorial_prompt = generate_tutorial_prompt(params, brainstorming_response)
    
    print("æŸ¥è¯¢å†…å®¹:")
    print("-" * 40)
    print(tutorial_prompt[:500] + "..." if len(tutorial_prompt) > 500 else tutorial_prompt)
    print("-" * 40)
    
    tutorial_response, tutorial_token_info, current_model = call_openrouter_with_retry(
        tutorial_prompt, selected_model, max_tokens, "tutorial.mdç”Ÿæˆ", params=params
    )
    
    if tutorial_response is None:
        print("âŒ tutorial.mdç”Ÿæˆå¤±è´¥")
        return None
    
    # ä¿å­˜ç¬¬äºŒç»„promptå’Œresponse
    prompts_and_responses.append((tutorial_prompt, tutorial_response, tutorial_token_info))
    
    # Check if manual creation mode after tutorial generation
    if params.get("no_auto_create", False):
        print("\nğŸ“‹ Tutorialç”Ÿæˆå®Œæˆï¼")
        print("ğŸ’¡ ä½ å¯ä»¥åŸºäºä»¥ä¸‹å†…å®¹æ‰‹åŠ¨åˆ›å»ºquestion.mdæ–‡ä»¶")
        return {
            'tutorial_response': tutorial_response,
            'brainstorming_response': brainstorming_response,
            'prompts_and_responses': prompts_and_responses
        }
    
    # Step 3: Generate question.md
    print("\nğŸ“ ç¬¬3æ­¥ï¼šåŸºäºtutorial.mdç”Ÿæˆquestion.md...")
    question_prompt = generate_question_prompt(params, tutorial_response)
    
    print("æŸ¥è¯¢å†…å®¹:")
    print("-" * 40)
    print(question_prompt[:500] + "..." if len(question_prompt) > 500 else question_prompt)
    print("-" * 40)
    
    question_response, question_token_info, current_model = call_openrouter_with_retry(
        question_prompt, selected_model, max_tokens, "question.mdç”Ÿæˆ", params=params
    )
    
    if question_response is None:
        print("âŒ question.mdç”Ÿæˆå¤±è´¥")
        return None
    
    # ä¿å­˜ç¬¬ä¸‰ç»„promptå’Œresponse
    prompts_and_responses.append((question_prompt, question_response, question_token_info))
    
    # è¿”å›æ‰€æœ‰ç”Ÿæˆçš„å†…å®¹
    return {
        'tutorial_response': tutorial_response,
        'question_response': question_response,
        'brainstorming_response': brainstorming_response,
        'prompts_and_responses': prompts_and_responses
    }


def main():
    """Main function."""
    # Check if running in interactive mode (no arguments)
    if len(sys.argv) == 1:
        print("LEARN - æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ")
        print("å¯åŠ¨äº¤äº’æ¨¡å¼...")
        print()
        
        params = run_interactive_mode()
        if params is None:
            return 1
        
        # Generate learning content
        result = generate_learning_content(params)
        if result is None:
            return 1
        
        # å¦‚æœæ˜¯no_auto_createæ¨¡å¼ï¼Œä¸åˆ›å»ºæ–‡ä»¶
        if params.get("no_auto_create", False):
            print("âœ… å¤´è„‘é£æš´å®Œæˆï¼")
            return 0
        
        # åˆ›å»ºæ–‡ä»¶
        print("\nğŸ“ åˆ›å»ºæ•™ç¨‹æ–‡ä»¶...")
        success = create_learning_files_from_responses(
            params, 
            result['tutorial_response'], 
            result['question_response'], 
            result['prompts_and_responses']
        )
        
        if success:
            print("âœ… æ–‡ä»¶åˆ›å»ºå®Œæˆï¼")
            return 0
        else:
            print("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return 1
    
    # Parse direct command
    try:
        params = parse_direct_command(sys.argv[1:])
        
        # æ£€æŸ¥å‚æ•°æ”¶é›†æ˜¯å¦æˆåŠŸ
        if not params:
            return 1
        
        # Generate learning content
        result = generate_learning_content(params)
        if result is None:
            return 1
        
        # å¦‚æœæ˜¯no_auto_createæ¨¡å¼ï¼Œä¸åˆ›å»ºæ–‡ä»¶
        if params.get("no_auto_create", False):
            print("âœ… å¤´è„‘é£æš´å®Œæˆï¼")
            return 0
        
        # åˆ›å»ºæ–‡ä»¶
        print("\nğŸ“ åˆ›å»ºæ•™ç¨‹æ–‡ä»¶...")
        success = create_learning_files_from_responses(
            params, 
            result['tutorial_response'], 
            result['question_response'], 
            result['prompts_and_responses']
        )
        
        if success:
            print("âœ… æ–‡ä»¶åˆ›å»ºå®Œæˆï¼")
            return 0
        else:
            print("âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return 1
        
    except SystemExit:
        # argparse calls sys.exit on error
        return 1
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return 1


def search_and_download_paper(paper_description):
    """Search for paper and download if found."""
    print(f"\nğŸ” æœç´¢è®ºæ–‡: {paper_description}")
    
    try:
        script_dir = Path(__file__).parent
        search_paper_path = script_dir / "SEARCH_PAPER"
        
        # Search for papers
        result = subprocess.run([
            str(search_paper_path), paper_description, "--max-results", "5"
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ æœç´¢å¤±è´¥: {result.stderr}")
            return None, None
            
        print("âœ… æœç´¢å®Œæˆï¼Œæ­£åœ¨è§£æç»“æœ...")
        
        # Parse search results to find download URLs
        import json
        import re
        
        # Try to find the search results file
        search_data_dir = script_dir / "SEARCH_PAPER_DATA" / "results"
        if search_data_dir.exists():
            # Get the most recent search results file
            result_files = list(search_data_dir.glob("search_results_*.json"))
            if result_files:
                latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
                
                with open(latest_file, 'r', encoding='utf-8') as f:
                    search_results = json.load(f)
                
                # Show papers to user
                if search_results and len(search_results) > 0:
                    print(f"\næ‰¾åˆ° {len(search_results)} ç¯‡ç›¸å…³è®ºæ–‡:")
                    for i, paper in enumerate(search_results[:5]):  # Show first 5
                        title = paper.get('title', 'Unknown')
                        authors = paper.get('authors', [])
                        author_str = ', '.join(authors[:3]) + ('...' if len(authors) > 3 else '')
                        print(f"  {i+1}. {title}")
                        print(f"     ä½œè€…: {author_str}")
                    
                    # Let user select
                    while True:
                        try:
                            choice = input(f"\né€‰æ‹©è®ºæ–‡ (1-{min(5, len(search_results))}, æˆ–è¾“å…¥ 'q' é€€å‡º): ").strip()
                            if choice.lower() == 'q':
                                return None, None
                            
                            choice_idx = int(choice) - 1
                            if 0 <= choice_idx < min(5, len(search_results)):
                                selected_paper = search_results[choice_idx]
                                break
                            else:
                                print(f"è¯·è¾“å…¥ 1-{min(5, len(search_results))} ä¹‹é—´çš„æ•°å­—")
                        except ValueError:
                            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    
                    # Try to download the paper
                    pdf_url = selected_paper.get('pdf_url')
                    if pdf_url:
                        print(f"\nğŸ“¥ å°è¯•ä¸‹è½½è®ºæ–‡: {selected_paper.get('title', 'Unknown')}")
                        return download_paper(pdf_url, selected_paper.get('title', 'paper'))
                    else:
                        print("âŒ æœªæ‰¾åˆ°PDFä¸‹è½½é“¾æ¥")
                        return None, None
                else:
                    print("âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                    return None, None
            else:
                print("âŒ æœªæ‰¾åˆ°æœç´¢ç»“æœæ–‡ä»¶")
                return None, None
        else:
            print("âŒ æœç´¢ç»“æœç›®å½•ä¸å­˜åœ¨")
            return None, None
            
    except Exception as e:
        print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None


def download_paper(pdf_url, paper_title):
    """Download paper from URL."""
    try:
        script_dir = Path(__file__).parent
        download_path = script_dir / "DOWNLOAD"
        
        # Create a safe filename
        import re
        safe_title = re.sub(r'[^\w\s-]', '', paper_title)
        safe_title = re.sub(r'[-\s]+', '-', safe_title)
        filename = f"{safe_title}.pdf"
        
        # Try to download
        print(f"ğŸ“¥ ä¸‹è½½ä¸­: {pdf_url}")
        result = subprocess.run([
            str(download_path), pdf_url, filename
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            downloaded_path = Path.cwd() / filename
            if downloaded_path.exists():
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {downloaded_path}")
                return str(downloaded_path), paper_title
            else:
                print("âŒ ä¸‹è½½çš„æ–‡ä»¶ä¸å­˜åœ¨")
                return None, None
        else:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {result.stderr}")
            
            # Try alternative download methods if available
            # This could include trying different PDF URLs from the paper metadata
            print("ğŸ”„ å°è¯•å…¶ä»–ä¸‹è½½é“¾æ¥...")
            return None, None
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None


def process_paper_with_extract_pdf(paper_path, read_images=False):
    """Process PDF with EXTRACT_PDF tool."""
    print(f"\nğŸ“„ å¤„ç†PDFæ–‡ä»¶: {paper_path}")
    
    try:
        script_dir = Path(__file__).parent
        extract_pdf_path = script_dir / "EXTRACT_PDF_PROJ" / "pdf_extractor.py"
        
        # Build command
        cmd = ["python", str(extract_pdf_path), paper_path]
        if read_images:
            cmd.append("--post")
        else:
            cmd.append("--no-image-api")
        
        print(f"ğŸ”„ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(script_dir))
        
        if result.returncode == 0:
            print("âœ… PDFå¤„ç†å®Œæˆ")
            
            # Find the generated markdown file
            paper_name = Path(paper_path).stem
            possible_md_files = [
                Path(paper_path).parent / f"{paper_name}.md",
                Path.cwd() / f"{paper_name}.md",
                script_dir / f"{paper_name}.md"
            ]
            
            for md_file in possible_md_files:
                if md_file.exists():
                    print(f"ğŸ“ æ‰¾åˆ°ç”Ÿæˆçš„Markdownæ–‡ä»¶: {md_file}")
                    with open(md_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    return content, str(md_file)
            
            print("âš ï¸  PDFå¤„ç†å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç”Ÿæˆçš„Markdownæ–‡ä»¶")
            return None, None
        else:
            print(f"âŒ PDFå¤„ç†å¤±è´¥: {result.stderr}")
            return None, None
            
    except Exception as e:
        print(f"âŒ PDFå¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None


def count_tokens(text):
    """Simple token counting approximation."""
    # Rough approximation: 1 token â‰ˆ 4 characters for Chinese/English mixed text
    return len(text) // 4


def prepare_paper_content(params):
    """Prepare paper content based on input type."""
    input_type = params.get("input_type", 1)
    paper_content = None
    paper_path = None
    
    if input_type == 0:  # Markdown file
        paper_content = params.get("paper_content")
        paper_path = params.get("paper_path")
        print("âœ… ä½¿ç”¨å·²æä¾›çš„Markdownå†…å®¹")
        
    elif input_type == 1:  # PDF file
        paper_path = params.get("paper_path")
        read_images = params.get("read_images", False)
        paper_content, processed_path = process_paper_with_extract_pdf(paper_path, read_images)
        if processed_path:
            paper_path = processed_path
            
    elif input_type == 2:  # URL
        paper_url = params.get("paper_url")
        print(f"ğŸ“¥ ä¸‹è½½è®ºæ–‡: {paper_url}")
        
        # Extract filename from URL or use generic name
        import urllib.parse
        parsed_url = urllib.parse.urlparse(paper_url)
        filename = Path(parsed_url.path).name or "downloaded_paper.pdf"
        
        downloaded_path, title = download_paper(paper_url, filename.replace('.pdf', ''))
        if downloaded_path:
            read_images = params.get("read_images", False)
            paper_content, processed_path = process_paper_with_extract_pdf(downloaded_path, read_images)
            if processed_path:
                paper_path = processed_path
        else:
            print("âŒ æ— æ³•ä¸‹è½½è®ºæ–‡")
            return None, None
            
    elif input_type == 3:  # Description/Search
        paper_description = params.get("paper_description")
        downloaded_path, title = search_and_download_paper(paper_description)
        if downloaded_path:
            read_images = params.get("read_images", False)
            paper_content, processed_path = process_paper_with_extract_pdf(downloaded_path, read_images)
            if processed_path:
                paper_path = processed_path
        else:
            print("âŒ æ— æ³•æ‰¾åˆ°æˆ–ä¸‹è½½è®ºæ–‡")
            return None, None
    
    if not paper_content:
        print("âŒ æ— æ³•è·å–è®ºæ–‡å†…å®¹")
        return None, None
    
    # Count tokens
    token_count = count_tokens(paper_content)
    print(f"\nğŸ“Š è®ºæ–‡å†…å®¹ç»Ÿè®¡:")
    print(f"   å­—ç¬¦æ•°: {len(paper_content):,}")
    print(f"   é¢„ä¼°tokenæ•°: {token_count:,}")
    
    return paper_content, paper_path, token_count


if __name__ == "__main__":
    sys.exit(main()) 