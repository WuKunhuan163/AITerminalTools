{
  "success": true,
  "query": "neural networks",
  "max_results": 1,
  "total_papers_found": 1,
  "source_results": {
    "arxiv": 1
  },
  "papers": [
    {
      "title": "$Ï€^3$: Scalable Permutation-Equivariant Visual Geometry Learning",
      "authors": [
        "Yifan Wang",
        "Jianjun Zhou",
        "Haoyi Zhu",
        "Wenzheng Chang",
        "Yang Zhou",
        "Zizun Li",
        "Junyi Chen",
        "Jiangmiao Pang",
        "Chunhua Shen",
        "Tong He"
      ],
      "abstract": "We introduce $\\pi^3$, a feed-forward neural network that offers a novel\napproach to visual geometry reconstruction, breaking the reliance on a\nconventional fixed reference view. Previous methods often anchor their\nreconstructions to a designated viewpoint, an inductive bias that can lead to\ninstability and failures if the reference is suboptimal. In contrast, $\\pi^3$\nemploys a fully permutation-equivariant architecture to predict\naffine-invariant camera poses and scale-invariant local point maps without any\nreference frames. This design makes our model inherently robust to input\nordering and highly scalable. These advantages enable our simple and bias-free\napproach to achieve state-of-the-art performance on a wide range of tasks,\nincluding camera pose estimation, monocular/video depth estimation, and dense\npoint map reconstruction. Code and models are publicly available.",
      "url": "http://arxiv.org/abs/2507.13347v1",
      "pdf_url": "http://arxiv.org/pdf/2507.13347v1.pdf",
      "publication_date": "2025-07-17",
      "venue": "arXiv preprint",
      "citation_count": null,
      "source": "arxiv"
    }
  ],
  "timestamp": "2025-07-18T13:45:41.531548"
}