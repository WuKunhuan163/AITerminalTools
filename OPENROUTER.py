#!/usr/bin/env python3
"""
OPENROUTER.py - OpenRouter API è°ƒç”¨å·¥å…·
æ”¯æŒæŒ‡å®šæŸ¥è¯¢ã€æ¨¡å‹ã€APIå¯†é’¥ç­‰å‚æ•°ï¼Œè·å–AIå›å¤
ä¿®æ”¹ç‰ˆæœ¬ï¼šæ”¯æŒæ–°çš„æ¨¡å‹æ•°æ®ç»“æ„ï¼ŒåŒ…å«è´¹ç‡å’Œcontext lengthä¿¡æ¯
"""

import os
import sys
import json
import argparse
import requests
from pathlib import Path
from typing import Dict, Any, Optional, List, Union

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

def is_run_environment(command_identifier=None):
    """Check if running in RUN environment by checking environment variables"""
    if command_identifier:
        return os.environ.get(f'RUN_IDENTIFIER_{command_identifier}') == 'True'
    # æ£€æŸ¥é€šç”¨çš„RUNç¯å¢ƒå˜é‡
    return bool(os.environ.get('RUN_DATA_FILE') or os.environ.get('RUN_IDENTIFIER'))

# æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
MODELS_CONFIG_FILE = Path(__file__).parent / "OPENROUTER_PROJ" / "openrouter_models.json"


def get_default_models() -> Dict[str, Dict[str, Any]]:
    """è·å–é»˜è®¤æ¨¡å‹åˆ—è¡¨ï¼ˆä»é…ç½®æ–‡ä»¶æˆ–ç¡¬ç¼–ç ï¼‰"""
    # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½
    if MODELS_CONFIG_FILE.exists():
        try:
            with open(MODELS_CONFIG_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                models = data.get('models', {})
                if models:
                    return models
        except Exception:
            pass
    
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè¿”å›ç¡¬ç¼–ç çš„é»˜è®¤æ¨¡å‹
    return {
        "deepseek/deepseek-v3-base:free": {
            "input_cost_per_1m": 0,
            "output_cost_per_1m": 0,
            "context_length": 163840,
            "useable": True
        },
        "deepseek/deepseek-r1:free": {
            "input_cost_per_1m": 0,
            "output_cost_per_1m": 0,
            "context_length": 163840,
            "useable": True
        },
        "meta-llama/llama-3.2-3b-instruct:free": {
            "input_cost_per_1m": 0,
            "output_cost_per_1m": 0,
            "context_length": 131072,
            "useable": True
        }
    }


def test_connection(api_key=None, model=None):
    """æµ‹è¯•OpenRouter APIè¿æ¥çŠ¶æ€"""
    # è·å–APIå¯†é’¥
    if api_key:
        test_api_key = api_key
    else:
        test_api_key = os.getenv("OPENROUTER_API_KEY")
    
    if not test_api_key:
        return {
            "success": False,
            "message": "âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼šæœªè®¾ç½®APIå¯†é’¥",
            "results": [{
                "test": "APIå¯†é’¥æ£€æŸ¥",
                "status": "error",
                "message": "âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼šæœªè®¾ç½®APIå¯†é’¥"
            }],
            "summary": {
                "total_tests": 1,
                "successful": 0,
                "warnings": 0,
                "errors": 1
            },
            "details": "è¯·è®¾ç½®ç¯å¢ƒå˜é‡OPENROUTER_API_KEYæˆ–ä½¿ç”¨--keyå‚æ•°"
        }
    
    results = []
    
    # å‡†å¤‡APIè¯·æ±‚å¤´
    headers = {
        "Authorization": f"Bearer {test_api_key}",
        "HTTP-Referer": "https://github.com/your-app",
        "X-Title": "OPENROUTER Test Connection"
    }
    
    # æµ‹è¯•APIè¿æ¥å’Œæ¨¡å‹åˆ—è¡¨è·å–
    try:
        # æµ‹è¯•åŸºæœ¬è¿æ¥ï¼šè·å–æ¨¡å‹åˆ—è¡¨
        response = requests.get("https://openrouter.ai/api/v1/models", headers=headers, timeout=10)
        
        if response.status_code == 200:
            models_data = response.json()
            model_count = len(models_data.get('data', []))
            results.append({
                "test": "æ¨¡å‹åˆ—è¡¨è·å–",
                "status": "success",
                "message": f"âœ… æˆåŠŸè·å– {model_count} ä¸ªå¯ç”¨æ¨¡å‹"
            })
            
            # å¦‚æœæŒ‡å®šäº†ç‰¹å®šæ¨¡å‹ï¼Œæ£€æŸ¥å…¶å¯ç”¨æ€§
            if model:
                available_models = [m['id'] for m in models_data.get('data', [])]
                if model in available_models:
                    results.append({
                        "test": f"æ¨¡å‹ {model} å¯ç”¨æ€§",
                        "status": "success", 
                        "message": f"âœ… æ¨¡å‹ {model} å¯ç”¨"
                    })
                else:
                    results.append({
                        "test": f"æ¨¡å‹ {model} å¯ç”¨æ€§",
                        "status": "warning",
                        "message": f"âš ï¸  æ¨¡å‹ {model} ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­"
                    })
                    
        elif response.status_code == 401:
            results.append({
                "test": "APIè®¤è¯",
                "status": "error",
                "message": "âŒ APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ"
            })
        elif response.status_code == 429:
            results.append({
                "test": "APIé™åˆ¶",
                "status": "warning",
                "message": "âš ï¸  è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
            })
        else:
            results.append({
                "test": "APIè¿æ¥",
                "status": "error",
                "message": f"âŒ APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}"
            })
            
    except requests.exceptions.Timeout:
        results.append({
            "test": "ç½‘ç»œè¿æ¥",
            "status": "error", 
            "message": "âŒ è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        })
    except requests.exceptions.ConnectionError:
        results.append({
            "test": "ç½‘ç»œè¿æ¥",
            "status": "error",
            "message": "âŒ æ— æ³•è¿æ¥åˆ°OpenRouteræœåŠ¡å™¨"
        })
    except Exception as e:
        results.append({
            "test": "æœªçŸ¥é”™è¯¯",
            "status": "error",
            "message": f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
        })
    
    # å¦‚æœè¿æ¥æˆåŠŸï¼Œå¯ä»¥æµ‹è¯•ä¸€ä¸ªç®€å•çš„APIè°ƒç”¨
    if results and results[0]["status"] == "success":
        try:
            test_model = model if model else "deepseek/deepseek-chat:free"
            test_payload = {
                "model": test_model,
                "messages": [{"role": "user", "content": "Hello"}],
                "max_tokens": 5
            }
            
            api_response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=test_payload,
                timeout=15
            )
            
            if api_response.status_code == 200:
                results.append({
                    "test": "APIè°ƒç”¨æµ‹è¯•",
                    "status": "success",
                    "message": f"âœ… æˆåŠŸè°ƒç”¨æ¨¡å‹ {test_model}"
                })
            elif api_response.status_code == 402:
                results.append({
                    "test": "APIè°ƒç”¨æµ‹è¯•",
                    "status": "warning",
                    "message": "âš ï¸  è´¦æˆ·ä½™é¢ä¸è¶³æˆ–éœ€è¦ä»˜è´¹"
                })
            else:
                error_data = api_response.json() if api_response.headers.get('content-type', '').startswith('application/json') else {}
                error_msg = error_data.get('error', {}).get('message', f"HTTP {api_response.status_code}")
                results.append({
                    "test": "APIè°ƒç”¨æµ‹è¯•",
                    "status": "error",
                    "message": f"âŒ APIè°ƒç”¨å¤±è´¥: {error_msg}"
                })
                
        except Exception as e:
            results.append({
                "test": "APIè°ƒç”¨æµ‹è¯•",
                "status": "error",
                "message": f"âŒ APIè°ƒç”¨æµ‹è¯•å¤±è´¥: {str(e)}"
            })
    
    # ç”Ÿæˆæ€»ç»“
    success_count = sum(1 for r in results if r["status"] == "success")
    total_count = len(results)
    overall_success = success_count > 0 and not any(r["status"] == "error" for r in results)
    
    return {
        "success": overall_success,
        "message": f"è¿æ¥æµ‹è¯•å®Œæˆ: {success_count}/{total_count} é¡¹æˆåŠŸ",
        "results": results,
        "summary": {
            "total_tests": total_count,
            "successful": success_count,
            "warnings": sum(1 for r in results if r["status"] == "warning"),
            "errors": sum(1 for r in results if r["status"] == "error")
        }
    }


def load_models() -> Dict[str, Dict[str, Any]]:
    """åŠ è½½æ¨¡å‹åˆ—è¡¨ï¼ˆæ–°æ ¼å¼ï¼‰"""
    if MODELS_CONFIG_FILE.exists():
        try:
            with open(MODELS_CONFIG_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                models = data.get('models', {})
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ—§æ ¼å¼ï¼ˆåˆ—è¡¨ï¼‰
                if isinstance(models, list):
                    # è½¬æ¢æ—§æ ¼å¼åˆ°æ–°æ ¼å¼
                    new_models = {}
                    for model_id in models:
                        new_models[model_id] = {
                            "input_cost_per_1m": 0,
                            "output_cost_per_1m": 0,
                            "context_length": 0,
                            "useable": False
                        }
                    return new_models
                
                return models
        except Exception as e:
            print(f"âš ï¸  Loading model configuration failed: {e}", file=sys.stderr)
    
    return get_default_models()


def save_models(models: Dict[str, Dict[str, Any]]) -> bool:
    """ä¿å­˜æ¨¡å‹åˆ—è¡¨ï¼ˆæ–°æ ¼å¼ï¼‰"""
    try:
        MODELS_CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(MODELS_CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump({'models': models}, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"Saving model list failed: {e}", file=sys.stderr)
        return False


def set_default_model(model_ids_str: str) -> bool:
    """è®¾ç½®é»˜è®¤æ¨¡å‹ï¼ˆæ”¯æŒå¤šä¸ªæ¨¡å‹IDï¼Œå°†æŒ‡å®šæ¨¡å‹æŒ‰é¡ºåºç§»åˆ°åˆ—è¡¨æœ€å‰é¢ï¼‰"""
    models = load_models()
    
    # è§£ææ¨¡å‹IDåˆ—è¡¨ï¼ˆæ”¯æŒé€—å·æˆ–ç©ºæ ¼åˆ†éš”ï¼‰
    import re
    model_ids = re.split(r'[,\s]+', model_ids_str.strip())
    model_ids = [mid.strip() for mid in model_ids if mid.strip()]
    
    if not model_ids:
        print(f"âŒ No valid model ID provided", file=sys.stderr)
        return False
    
    # æ£€æŸ¥æ¯ä¸ªæ¨¡å‹æ˜¯å¦å­˜åœ¨
    existing_models = []
    missing_models = []
    
    for model_id in model_ids:
        if model_id in models:
            existing_models.append(model_id)
        else:
            missing_models.append(model_id)
    
    # è­¦å‘Šä¸å­˜åœ¨çš„æ¨¡å‹
    if missing_models:
        print(f"âš ï¸  The following models do not exist in the list: {', '.join(missing_models)}")
    
    if not existing_models:
        print(f"âŒ No valid models found", file=sys.stderr)
        return False
    
    # åˆ›å»ºæ–°çš„æœ‰åºå­—å…¸
    new_models = {}
    
    # 1. å…ˆæŒ‰æŒ‡å®šé¡ºåºæ·»åŠ å­˜åœ¨çš„æ¨¡å‹
    for model_id in existing_models:
        new_models[model_id] = models[model_id]
    
    # 2. ç„¶åæ·»åŠ å…¶ä»–æœªæŒ‡å®šçš„æ¨¡å‹ï¼Œä¿æŒå®ƒä»¬çš„åŸæœ‰ç›¸å¯¹é¡ºåº
    for model_id, info in models.items():
        if model_id not in existing_models:
            new_models[model_id] = info
    
    if save_models(new_models):
        if len(existing_models) == 1:
            print(f"âœ… '{existing_models[0]}' set as default model")
        else:
            print(f"âœ… Set priority models in order: {' -> '.join(existing_models)}")
            print(f"ğŸ“‹ New default model: {existing_models[0]}")
        return True
    else:
        print(f"âŒ Setting default model failed", file=sys.stderr)
        return False


def test_model_availability(model_id: str, api_key: str = None) -> Dict[str, Any]:
    """æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ç”¨"""
    # è·å–APIå¯†é’¥
    test_api_key = api_key or os.getenv("OPENROUTER_API_KEY")
    
    if not test_api_key:
        return {
            "success": False,
            "message": "âŒ API key is required to test models",
            "error": "missing_api_key"
        }
    
    headers = {
        "Authorization": f"Bearer {test_api_key}",
        "HTTP-Referer": "https://github.com/openrouter-test",
        "X-Title": "OPENROUTER Model Test"
    }
    
    # æµ‹è¯•æ¨¡å‹è°ƒç”¨
    test_payload = {
        "model": model_id,
        "messages": [{"role": "user", "content": "Hello, please respond with 'OK'"}],
        "max_tokens": 10
    }
    
    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=test_payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                return {
                    "success": True,
                    "message": f"âœ… Model {model_id} test successful",
                    "response": result['choices'][0]['message']['content'].strip()
                }
            else:
                return {
                    "success": False,
                    "message": f"âŒ Model {model_id} returned an abnormal format",
                    "error": "invalid_response_format"
                }
        elif response.status_code == 404:
            return {
                "success": False,
                "message": f"âŒ Model {model_id} does not exist",
                "error": "model_not_found"
            }
        elif response.status_code == 402:
            return {
                "success": False,
                "message": f"âŒ Account balance insufficient or model requires payment",
                "error": "payment_required"
            }
        else:
            error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}
            error_msg = error_data.get('error', {}).get('message', f"HTTP {response.status_code}")
            return {
                "success": False,
                "message": f"âŒ Model {model_id} test failed: {error_msg}",
                "error": "api_error"
            }
            
    except requests.exceptions.Timeout:
        return {
            "success": False,
            "message": f"âŒ Model {model_id} test timeout",
            "error": "timeout"
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ Model {model_id} test error: {str(e)}",
            "error": "unknown_error"
        }


def add_model(model_id: str, api_key: str = None) -> bool:
    """æ·»åŠ æ–°æ¨¡å‹åˆ°åˆ—è¡¨ï¼ˆå…ˆæµ‹è¯•å¯ç”¨æ€§ï¼‰"""
    models = load_models()
    
    if model_id in models:
        print(f"âš ï¸  Model '{model_id}' already exists in the list")
        return False
    
    print(f"ğŸ” Testing the availability of model '{model_id}'...")
    
    # æµ‹è¯•æ¨¡å‹
    test_result = test_model_availability(model_id, api_key)
    
    if not test_result["success"]:
        print(test_result["message"])
        return False
    
    print(test_result["message"])
    
    # å°è¯•è·å–æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
    try:
        # è·å–æ¨¡å‹åˆ—è¡¨ä»¥è·å–è¯¦ç»†ä¿¡æ¯
        test_api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        headers = {
            "Authorization": f"Bearer {test_api_key}",
            "HTTP-Referer": "https://github.com/openrouter-test",
            "X-Title": "OPENROUTER Model Info"
        }
        
        response = requests.get("https://openrouter.ai/api/v1/models", headers=headers, timeout=15)
        
        model_info = {
            "input_cost_per_1m": 0.0,
            "output_cost_per_1m": 0.0,
            "context_length": 4000,
            "useable": True
        }
        
        if response.status_code == 200:
            models_data = response.json()
            for model_data in models_data.get('data', []):
                if model_data.get('id') == model_id:
                    pricing = model_data.get('pricing', {})
                    model_info.update({
                        "input_cost_per_1m": float(pricing.get('prompt', '0')) * 1000000,
                        "output_cost_per_1m": float(pricing.get('completion', '0')) * 1000000,
                        "context_length": model_data.get('context_length', 4000),
                        "useable": True
                    })
                    break
    
    except Exception as e:
        print(f"âš ï¸  Unable to get model details, using default values: {e}")
    
    # æ·»åŠ åˆ°æ¨¡å‹åˆ—è¡¨
    models[model_id] = model_info
    
    if save_models(models):
        print(f"âœ… Successfully added model '{model_id}' to the list")
        print(f"ğŸ“Š Rate: input ${model_info['input_cost_per_1m']:.2f}/1M, output ${model_info['output_cost_per_1m']:.2f}/1M")
        print(f"ğŸ“ Context length: {model_info['context_length']:,} tokens")
        return True
    else:
        print(f"âŒ Adding model failed")
        return False


def remove_model(model_id: str) -> bool:
    """ä»åˆ—è¡¨ä¸­ç§»é™¤æ¨¡å‹"""
    models = load_models()
    
    if model_id not in models:
        print(f"âŒ Model '{model_id}' does not exist in the list")
        return False
    
    # åˆ é™¤æ¨¡å‹
    del models[model_id]
    
    if save_models(models):
        print(f"âœ… Removed model '{model_id}' from the list")
        return True
    else:
        print(f"âŒ Removing model failed")
        return False


def get_useable_models() -> List[str]:
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    models = load_models()
    return [model_id for model_id, info in models.items() if info.get('useable', False)]


def get_model_info(model_id: str) -> Optional[Dict[str, Any]]:
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    models = load_models()
    return models.get(model_id)


def get_suggested_max_tokens(model_id: str, user_max_tokens: Optional[int] = None) -> int:
    """æ ¹æ®æ¨¡å‹çš„context lengthå»ºè®®åˆé€‚çš„max tokensï¼ˆ1/4å®‰å…¨å€¼ï¼‰"""
    """Suggest appropriate max tokens based on the model's context length (1/4 safety value)"""
    model_info = get_model_info(model_id)
    if not model_info:
        return user_max_tokens or 1000
    
    context_length = model_info.get('context_length', 4000)
    
    # è®¡ç®—å»ºè®®çš„max tokensï¼ˆä¸Šä¸‹æ–‡é•¿åº¦çš„1/4ï¼Œä¸ºè¾“å…¥å’Œè¾“å‡ºå„ç•™1/4ç©ºé—´ï¼‰
    suggested_tokens = max(100, context_length // 4)
    
    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†max_tokensï¼Œä½¿ç”¨è¾ƒå°çš„å€¼
    if user_max_tokens:
        return min(user_max_tokens, suggested_tokens)
    
    return suggested_tokens

def write_to_json_output(data, command_identifier=None):
    """å°†ç»“æœå†™å…¥åˆ°æŒ‡å®šçš„ JSON è¾“å‡ºæ–‡ä»¶ä¸­"""
    if not is_run_environment(command_identifier):
        return False
    
    # Get the specific output file for this command identifier
    if command_identifier:
        output_file = os.environ.get(f'RUN_DATA_FILE_{command_identifier}')
    else:
        output_file = os.environ.get('RUN_DATA_FILE')
    
    if not output_file:
        return False
    
    try:
        from pathlib import Path
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"Error writing to JSON output file: {e}")
        return False


def create_json_output(success: bool, message: str, **kwargs) -> Dict[str, Any]:
    """åˆ›å»ºæ ‡å‡†JSONè¾“å‡ºæ ¼å¼"""
    return {
        "success": success,
        "message": message,
        "timestamp": __import__('datetime').datetime.now().isoformat(),
        **kwargs
    }


def list_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
    models = load_models()
    useable_models = get_useable_models()
    
    if is_run_environment():
        # åœ¨RUNç¯å¢ƒä¸‹è¿”å›JSONæ ¼å¼çš„æ¨¡å‹åˆ—è¡¨ï¼ˆåªè¿”å›å¯ç”¨æ¨¡å‹ï¼‰
        model_data = create_json_output(
            True, 
            "Command executed successfully", 
            models=useable_models,
            total_count=len(useable_models),
            default_model=useable_models[0] if useable_models else None,
            model_details={model_id: models[model_id] for model_id in useable_models}
        )
        
        if 'RUN_DATA_FILE' in os.environ:
            with open(os.environ['RUN_DATA_FILE'], 'w', encoding='utf-8') as f:
                json.dump(model_data, f, ensure_ascii=False, indent=2)
        
        print(json.dumps(model_data, ensure_ascii=False, indent=2))
    else:
        # åœ¨æ™®é€šç¯å¢ƒä¸‹æ˜¾ç¤ºæ ¼å¼åŒ–çš„æ¨¡å‹åˆ—è¡¨ï¼ˆåªæ˜¾ç¤ºå¯ç”¨æ¨¡å‹ï¼‰
        print("ğŸ“‹ Available models list:")
        print("=" * 40)
        for i, model_id in enumerate(useable_models, 1):
            info = models[model_id]
            input_cost = info.get('input_cost_per_1m', 0)
            output_cost = info.get('output_cost_per_1m', 0)
            context_length = info.get('context_length', 0)
            
            print(f"{i:2d}. {model_id}")
            print(f"    ğŸ“Š Rate: input ${input_cost:.2f}/1M, output ${output_cost:.2f}/1M")
            print(f"    ğŸ“ Context length: {context_length:,} tokens")
            print()
        
        print(f"Total: {len(useable_models)} available models")
        print(f"Default model: {useable_models[0] if useable_models else 'None'}")


def calculate_cost(input_tokens: int, output_tokens: int, model_id: str) -> float:
    """è®¡ç®—APIè°ƒç”¨è´¹ç”¨"""
    model_info = get_model_info(model_id)
    if not model_info:
        return 0.0
    
    input_cost = (input_tokens / 1000000) * model_info.get('input_cost_per_1m', 0)
    output_cost = (output_tokens / 1000000) * model_info.get('output_cost_per_1m', 0)
    
    return input_cost + output_cost


def call_openrouter_api(query: str, model: str = None, api_key: str = None, max_tokens: int = None, temperature: float = 0.7, output_dir: str = None, command_identifier: str = None) -> Union[str, Dict[str, Any]]:
    """
    è°ƒç”¨OpenRouter APIè·å–å›å¤
    
    Args:
        query: æŸ¥è¯¢å†…å®¹
        model: æ¨¡å‹åç§°
        api_key: APIå¯†é’¥
        max_tokens: æœ€å¤§tokenæ•°ï¼ˆNoneæ—¶è‡ªåŠ¨æ ¹æ®æ¨¡å‹context lengthè°ƒæ•´ï¼‰
        temperature: æ¸©åº¦å‚æ•°
        
    Returns:
        åŒ…å«å›å¤å†…å®¹å’Œå…ƒæ•°æ®çš„å­—å…¸
    """
    # è·å–APIå¯†é’¥
    if not api_key:
        api_key = os.getenv("OPENROUTER_API_KEY")
    
    if not api_key:
        return {
            "success": False,
            "error": "No API key provided. Use --update-key to set API key, set OPENROUTER_API_KEY environment variable, or use --key parameter"
        }
    
    # è·å–æ¨¡å‹
    if not model:
        useable_models = get_useable_models()
        if not useable_models:
            return {
                "success": False,
                "error": "No useable models available. Please run update_openrouter_models.py to update model information."
            }
        model = useable_models[0]
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
    model_info = get_model_info(model)
    if not model_info or not model_info.get('useable', False):
        return {
            "success": False,
            "error": f"Model '{model}' is not available or not useable"
        }
    
    # åŠ¨æ€è°ƒæ•´max_tokens
    suggested_max_tokens = get_suggested_max_tokens(model, max_tokens)
    if max_tokens is None:
        max_tokens = suggested_max_tokens
    elif max_tokens > suggested_max_tokens:
        print(f"âš ï¸  Specified max_tokens ({max_tokens}) exceeds the recommended value ({suggested_max_tokens}), adjusted", file=sys.stderr)
        max_tokens = suggested_max_tokens
    
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": [{"role": "user", "content": query}],
        "max_tokens": max_tokens,
        "temperature": temperature
    }
    
    try:
        print(f"ğŸ¤– Calling OpenRouter API...", file=sys.stderr)
        print(f"ğŸ“ Model: {model}, max tokens: {max_tokens}, temperature: {temperature}", file=sys.stderr)
        
        response = requests.post(url, headers=headers, json=data, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        
        if 'choices' in result and len(result['choices']) > 0:
            content = result['choices'][0]['message']['content']
            
            # è·å–tokenä½¿ç”¨ä¿¡æ¯
            usage = result.get('usage', {})
            input_tokens = usage.get('prompt_tokens', 0)
            output_tokens = usage.get('completion_tokens', 0)
            total_tokens = usage.get('total_tokens', 0)
            
            # è®¡ç®—è´¹ç”¨
            cost = calculate_cost(input_tokens, output_tokens, model)
            
            print(f"âœ… API call successful", file=sys.stderr)
            print(f"ğŸ“Š Token usage: input {input_tokens}, output {output_tokens}, total {total_tokens}", file=sys.stderr)
            print(f"ğŸ’° Cost: ${cost:.6f}", file=sys.stderr)
            
            return {
                "success": True,
                "content": content,
                "model": model,
                "usage": {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": total_tokens
                },
                "cost": cost,
                "model_info": model_info
            }
        else:
            return {
                "success": False,
                "error": "No response content received"
            }
            
    except requests.exceptions.RequestException as e:
        return {
            "success": False,
            "error": f"API request failed: {str(e)}"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Unexpected error: {str(e)}"
        }


def main():
    """ä¸»å‡½æ•°"""
    help_text = f"""OPENROUTER - OpenRouter API calling tool

Usage: OPENROUTER <query> [options]
       OPENROUTER --list
       OPENROUTER --default <model1> [model2] [model3] ...
       OPENROUTER --add <model> [--temp-key <api_key>]
       OPENROUTER --remove <model>
       OPENROUTER --test-connection

Options:
  <query>                æŸ¥è¯¢å†…å®¹
  --model <model>        æŒ‡å®šæ¨¡å‹ (é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹)
  --key <api_key>        æŒ‡å®šAPIå¯†é’¥ (ä¸´æ—¶ä½¿ç”¨)
  --max-tokens <num>     æœ€å¤§tokenæ•° (é»˜è®¤: æ ¹æ®æ¨¡å‹è‡ªåŠ¨è°ƒæ•´ä¸ºä¸Šä¸‹æ–‡é•¿åº¦çš„1/4)
  --temperature <float>  æ¸©åº¦å‚æ•° (é»˜è®¤: 0.7)
  --output-dir <dir>     è¾“å‡ºç›®å½•ï¼Œä¿å­˜æ¨¡å‹å›å¤åˆ°æŒ‡å®šç›®å½•
  --list                 åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
  --default <models>     è®¾ç½®é»˜è®¤æ¨¡å‹ä¼˜å…ˆçº§ï¼ˆæ”¯æŒå¤šä¸ªæ¨¡å‹ï¼Œç”¨é€—å·æˆ–ç©ºæ ¼åˆ†éš”ï¼‰
  --add <model>          æ·»åŠ æ–°æ¨¡å‹åˆ°åˆ—è¡¨ï¼ˆå…ˆæµ‹è¯•è¿æ¥ï¼‰
  --remove <model>       ä»åˆ—è¡¨ä¸­ç§»é™¤æ¨¡å‹
  --temp-key <api_key>   ä¸´æ—¶APIå¯†é’¥ï¼ˆç”¨äºæµ‹è¯•æ–°æ¨¡å‹ï¼‰
  --test-connection      æµ‹è¯•APIè¿æ¥çŠ¶æ€ï¼Œä¸å‘é€æŸ¥è¯¢
  --help                 æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

Examples:
  OPENROUTER "What is machine learning?"
  OPENROUTER "è§£é‡Šé‡å­è®¡ç®—" --model "deepseek/deepseek-r1:free"
  OPENROUTER "Write a Python function" --key "sk-or-v1-..." --max-tokens 2000
  OPENROUTER "åˆ›å»ºä¸€ä¸ªå­¦ä¹ è®¡åˆ’" --temperature 0.9

  OPENROUTER --list
  OPENROUTER --default "qwen/qwen3-235b-a22b-07-25:free"
  OPENROUTER --default "qwen/qwen3-235b-a22b-07-25:free,google/gemini-2.5-flash-lite-preview-06-17"
  OPENROUTER --default "model1 model2 model3"
  OPENROUTER --add "qwen/qwen3-235b-a22b-07-25:free"
  OPENROUTER --add "moonshotai/kimi-k2:free" --temp-key "sk-or-v1-..."
  OPENROUTER --remove "old-model"
  OPENROUTER --test-connection

Environment Variables:
  OPENROUTER_API_KEY    é»˜è®¤APIå¯†é’¥

Note: åªæœ‰æ ‡è®°ä¸ºå¯ç”¨(useable=true)çš„æ¨¡å‹æ‰ä¼šæ˜¾ç¤ºåœ¨åˆ—è¡¨ä¸­ã€‚
      è¿è¡Œ fetch_openrouter_models.py æ¥æ›´æ–°æ¨¡å‹ä¿¡æ¯å’Œè´¹ç‡ã€‚
"""

    parser = argparse.ArgumentParser(description="OpenRouter API è°ƒç”¨å·¥å…·", add_help=False)
    parser.add_argument('query', nargs='?', help='æŸ¥è¯¢å†…å®¹')
    parser.add_argument('--model', help='æŒ‡å®šæ¨¡å‹')
    parser.add_argument('--key', help='æŒ‡å®šAPIå¯†é’¥')
    parser.add_argument('--max-tokens', type=int, default=None, help='æœ€å¤§tokenæ•°ï¼ˆé»˜è®¤æ ¹æ®æ¨¡å‹è‡ªåŠ¨è°ƒæ•´ï¼‰')
    parser.add_argument('--temperature', type=float, default=0.7, help='æ¸©åº¦å‚æ•°')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹')
    parser.add_argument('--default', help='è®¾ç½®é»˜è®¤æ¨¡å‹')
    parser.add_argument('--add', help='æ·»åŠ æ–°æ¨¡å‹åˆ°åˆ—è¡¨ï¼ˆå…ˆæµ‹è¯•è¿æ¥ï¼‰')
    parser.add_argument('--remove', help='ä»åˆ—è¡¨ä¸­ç§»é™¤æ¨¡å‹')
    parser.add_argument('--temp-key', help='ä¸´æ—¶APIå¯†é’¥ï¼ˆç”¨äºæµ‹è¯•æ–°æ¨¡å‹ï¼‰')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•ï¼Œä¿å­˜æ¨¡å‹å›å¤åˆ°æŒ‡å®šç›®å½•')
    parser.add_argument('--test-connection', action='store_true', help='æµ‹è¯•APIè¿æ¥çŠ¶æ€ï¼Œä¸å‘é€æŸ¥è¯¢')
    parser.add_argument('--help', action='store_true', help='æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if args.help or (not args.query and not args.list and not args.default and not args.add and not args.remove and not args.test_connection):
        print(help_text)
        return
    
    # åˆ—å‡ºæ¨¡å‹
    if args.list:
        list_models()
        return
    
    # è®¾ç½®é»˜è®¤æ¨¡å‹
    if args.default:
        success = set_default_model(args.default)
        sys.exit(0 if success else 1)
    
    # æ·»åŠ æ¨¡å‹
    if args.add:
        success = add_model(args.add, args.temp_key)
        sys.exit(0 if success else 1)
    
    # ç§»é™¤æ¨¡å‹
    if args.remove:
        success = remove_model(args.remove)
        sys.exit(0 if success else 1)
    
    # æµ‹è¯•è¿æ¥
    if args.test_connection:
        result = test_connection(args.key, args.model)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨RUNç¯å¢ƒä¸­
        if is_run_environment():
            # RUNæ¨¡å¼ï¼šè¾“å‡ºJSON
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            # æ™®é€šæ¨¡å¼ï¼šè¾“å‡ºæ ¼å¼åŒ–æ–‡æœ¬
            print("ğŸ” OpenRouter API connection test results:")
            print()
            
            for test_result in result["results"]:
                print(f"ğŸ“Š {test_result['test']}: {test_result['message']}")
            
            print()
            summary = result["summary"]
            if result["success"]:
                print(f"âœ… Summary: connection test successful - {summary['successful']}/{summary['total_tests']} passed")
                if summary['warnings'] > 0:
                    print(f"âš ï¸  Warning: {summary['warnings']} items need attention")
            else:
                print(f"âŒ Summary: connection test failed - {summary['errors']} errors, {summary['warnings']} warnings")
                
        return
    
    # è°ƒç”¨API
    if args.query:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶è·¯å¾„ï¼ˆä»¥@å¼€å¤´ï¼‰
        if args.query.startswith('@'):
            file_path = args.query[1:]  # ç§»é™¤@å‰ç¼€
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    query_content = f.read()
            except Exception as e:
                print(f"âŒ Unable to read file {file_path}: {e}", file=sys.stderr)
                sys.exit(1)
        else:
            query_content = args.query
    else:
        # å¦‚æœæ²¡æœ‰æä¾›queryå‚æ•°ï¼Œå°è¯•ä»stdinè¯»å–
        if not sys.stdin.isatty():
            try:
                query_content = sys.stdin.read().strip()
                if not query_content:
                    print("âŒ Content read from stdin is empty", file=sys.stderr)
                    sys.exit(1)
            except Exception as e:
                print(f"âŒ Failed to read content from stdin: {e}", file=sys.stderr)
                sys.exit(1)
        else:
            print("âŒ No query content provided", file=sys.stderr)
            sys.exit(1)
    
    result = call_openrouter_api(
        query_content,
        args.model,
        args.key,
        args.max_tokens,
        args.temperature
    )
    
    # å¤„ç†--output-diråŠŸèƒ½
    if result['success'] and args.output_dir:
        try:
            from pathlib import Path
            import datetime
            
            output_path = Path(args.output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼šopenrouter_YYYYMMDD_HHMMSS.txt
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = output_path / f"openrouter_{timestamp}.txt"
            
            # å†™å…¥å›å¤å†…å®¹å’Œå…ƒæ•°æ®
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"Query: {query_content}\n")
                f.write(f"Model: {result.get('model', 'unknown')}\n")
                f.write(f"Timestamp: {datetime.datetime.now().isoformat()}\n")
                f.write(f"Cost: ${result.get('cost', 0):.6f}\n")
                f.write(f"Tokens: {result.get('usage', {}).get('total_tokens', 0)}\n")
                f.write("-" * 50 + "\n\n")
                f.write(result['content'])
            
            result['output_file'] = str(output_file)
            print(f"ğŸ’¾ Reply saved to: {output_file}", file=sys.stderr)
            
        except Exception as e:
            print(f"âš ï¸  Saving to output directory failed: {e}", file=sys.stderr)
    
    if is_run_environment():
        # åœ¨RUNç¯å¢ƒä¸‹è¾“å‡ºJSONæ ¼å¼
        if 'RUN_DATA_FILE' in os.environ:
            with open(os.environ['RUN_DATA_FILE'], 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        # åœ¨æ™®é€šç¯å¢ƒä¸‹è¾“å‡ºæ ¼å¼åŒ–ç»“æœ
        if result['success']:
            print(result['content'])
        else:
            print(f"âŒ Error: {result['error']}", file=sys.stderr)
            sys.exit(1)


if __name__ == "__main__":
    main() 