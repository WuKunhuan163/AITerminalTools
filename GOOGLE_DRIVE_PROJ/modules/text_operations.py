
class TextOperations:
    """
    Text file editing and content operations
    """
    
    def __init__(self, drive_service, main_instance):
        self.drive_service = drive_service
        self.main_instance = main_instance
    
    def cmd_download(self, *args, **kwargs):
        """Delegate to file_core for download operations"""
        # Import FileCore for download operations
        from .file_core import FileCore
        file_core = FileCore(self.drive_service, self.main_instance)
        return file_core.cmd_download(*args, **kwargs)
    
    def cmd_upload(self, *args, **kwargs):
        """Delegate to file_core for upload operations"""
        # Import FileCore for upload operations
        from .file_core import FileCore
        file_core = FileCore(self.drive_service, self.main_instance)
        return file_core.cmd_upload(*args, **kwargs)

    def _find_folder(self, folder_name, parent_id):
        """åœ¨æŒ‡å®šçˆ¶ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶å¤¹"""
        try:
            files_result = self.drive_service.list_files(folder_id=parent_id, max_results=100)
            if not files_result['success']:
                return None
            
            for file in files_result['files']:
                if (file['name'] == folder_name and 
                    file['mimeType'] == 'application/vnd.google-apps.folder'):
                    return file
            
            return None
            
        except Exception:
            return None

    def _create_text_file(self, filename, content):
        """é€šè¿‡è¿œç¨‹å‘½ä»¤åˆ›å»ºæ–‡æœ¬æ–‡ä»¶"""
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            # æ„å»ºè¿œç¨‹echoå‘½ä»¤
            remote_absolute_path = self.main_instance.resolve_remote_absolute_path(filename, current_shell)
            
            # ä½¿ç”¨base64ç¼–ç æ¥å®Œå…¨é¿å…å¼•å·å’Œç‰¹æ®Šå­—ç¬¦é—®é¢˜
            import base64
            content_bytes = content.encode('utf-8')
            content_base64 = base64.b64encode(content_bytes).decode('ascii')
            
            # æ„å»ºè¿œç¨‹å‘½ä»¤ - ä½¿ç”¨base64è§£ç é¿å…æ‰€æœ‰å¼•å·é—®é¢˜
            remote_command = f'echo "{content_base64}" | base64 -d > "{remote_absolute_path}"'
            
            # ä½¿ç”¨è¿œç¨‹å‘½ä»¤æ‰§è¡Œæ¥å£
            result = self.main_instance.execute_generic_remote_command("bash", ["-c", remote_command])
            
            if result.get("success"):
                # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«åˆ›å»ºäº†
                verification_result = self.main_instance.verify_creation_with_ls(
                    filename, current_shell, creation_type="file", max_attempts=60
                )
                
                if verification_result.get("success", False):
                    return {
                        "success": True,
                        "filename": filename,
                        "message": f"âœ… æ–‡ä»¶å·²åˆ›å»º: {filename}"
                    }
                else:
                    return {
                        "success": False,
                        "error": f"æ–‡ä»¶åˆ›å»ºå‘½ä»¤æˆåŠŸä½†éªŒè¯å¤±è´¥: {verification_result.get('error', 'Unknown verification error')}"
                    }
            else:
                # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„é”™è¯¯ä¿¡æ¯
                error_msg = result.get('error_info') or result.get('error') or 'Unknown error'
                return {
                    "success": False,
                    "error": f"åˆ›å»ºæ–‡ä»¶å¤±è´¥: {error_msg}"
                }
                
        except Exception as e:
            return {"success": False, "error": f"åˆ›å»ºæ–‡ä»¶æ—¶å‡ºé”™: {e}"}

    def cmd_cat(self, filename):
        """catå‘½ä»¤ - æ˜¾ç¤ºæ–‡ä»¶å†…å®¹"""
        try:
            if not self.drive_service:
                return {"success": False, "error": "Google Drive APIæœåŠ¡æœªåˆå§‹åŒ–"}
                
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shellï¼Œè¯·å…ˆåˆ›å»ºæˆ–åˆ‡æ¢åˆ°ä¸€ä¸ªshell"}
            
            if not filename:
                return {"success": False, "error": "è¯·æŒ‡å®šè¦æŸ¥çœ‹çš„æ–‡ä»¶"}
            
            # æŸ¥æ‰¾æ–‡ä»¶
            file_info = self._find_file(filename, current_shell)
            if not file_info:
                return {"success": False, "error": f"File or directory does not exist"}
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
            if file_info['mimeType'] == 'application/vnd.google-apps.folder':
                return {"success": False, "error": f"cat: {filename}: Is a directory"}
            
            # ä¸‹è½½å¹¶è¯»å–æ–‡ä»¶å†…å®¹
            try:
                import io
                from googleapiclient.http import MediaIoBaseDownload
                
                request = self.drive_service.service.files().get_media(fileId=file_info['id'])
                fh = io.BytesIO()
                downloader = MediaIoBaseDownload(fh, request)
                
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
                
                content = fh.getvalue().decode('utf-8', errors='replace')
                return {"success": True, "output": content, "filename": filename}
                
            except Exception as e:
                return {"success": False, "error": f"æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {e}"}
                
        except Exception as e:
            return {"success": False, "error": f"æ‰§è¡Œcatå‘½ä»¤æ—¶å‡ºé”™: {e}"}

    def cmd_grep(self, pattern, *filenames):
        """grepå‘½ä»¤ - åœ¨æ–‡ä»¶ä¸­æœç´¢æ¨¡å¼ï¼Œæ”¯æŒå¤šæ–‡ä»¶å’Œregex"""
        import re
        
        try:
            if not pattern:
                return {"success": False, "error": "è¯·æŒ‡å®šæœç´¢æ¨¡å¼"}
            
            if not filenames:
                return {"success": False, "error": "è¯·æŒ‡å®šè¦æœç´¢çš„æ–‡ä»¶"}
            
            # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
            try:
                regex = re.compile(pattern)
            except re.error as e:
                return {"success": False, "error": f"æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼: {e}"}
            
            result = {}
            
            for filename in filenames:
                # è·å–æ–‡ä»¶å†…å®¹
                cat_result = self.cmd_cat(filename)
                if not cat_result["success"]:
                    result[filename] = {
                        "local_file": None,
                        "occurrences": [],
                        "error": cat_result["error"]
                    }
                    continue
                
                content = cat_result["output"]
                lines = content.split('\n')
                
                # æœç´¢åŒ¹é…çš„ä½ç½®
                occurrences = {}
                for line_num, line in enumerate(lines, 1):
                    line_matches = []
                    for match in regex.finditer(line):
                        line_matches.append(match.start())
                    if line_matches:
                        occurrences[line_num] = line_matches
                
                # è½¬æ¢ä¸ºæ‰€éœ€æ ¼å¼: {line_num: [positions]}
                formatted_occurrences = occurrences
                
                # è·å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶è·¯å¾„
                local_file = self.main_instance.cache_manager._get_local_cache_path(filename)
                
                result[filename] = {
                    "local_file": local_file,
                    "occurrences": formatted_occurrences
                }
            
            return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": f"Grep command failed: {str(e)}"}

    def _find_file(self, filepath, current_shell):
        """æŸ¥æ‰¾æ–‡ä»¶ï¼Œæ”¯æŒè·¯å¾„è§£æ"""
        try:
            # å¦‚æœåŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼Œéœ€è¦è§£æè·¯å¾„
            if '/' in filepath:
                # åˆ†ç¦»ç›®å½•å’Œæ–‡ä»¶å
                dir_path, filename = filepath.rsplit('/', 1)
                
                # è§£æç›®å½•è·¯å¾„
                target_folder_id, _ = self.main_instance.resolve_path(dir_path, current_shell)
                if not target_folder_id:
                    return None
            else:
                # åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾
                filename = filepath
                target_folder_id = current_shell.get("current_folder_id", self.main_instance.REMOTE_ROOT_FOLDER_ID)
            
            # åˆ—å‡ºç›®æ ‡ç›®å½•å†…å®¹
            files_result = self.drive_service.list_files(folder_id=target_folder_id, max_results=100)
            if not files_result['success']:
                return None
            
            # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
            for file in files_result['files']:
                if file['name'] == filename:
                    return file
            
            return None
            
        except Exception:
            return None

    def _download_and_get_content(self, filename, remote_absolute_path, force=False):
        """
        ä¸‹è½½æ–‡ä»¶å¹¶è·å–å†…å®¹ï¼ˆç”¨äºreadå‘½ä»¤ï¼‰
        
        Args:
            filename (str): æ–‡ä»¶å
            remote_absolute_path (str): è¿œç¨‹ç»å¯¹è·¯å¾„
            force (bool): æ˜¯å¦å¼ºåˆ¶ä¸‹è½½å¹¶æ›´æ–°ç¼“å­˜
        """
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            # è§£æè·¯å¾„ä»¥è·å–ç›®æ ‡æ–‡ä»¶å¤¹å’Œæ–‡ä»¶å
            path_parts = remote_absolute_path.strip('/').split('/')
            actual_filename = path_parts[-1]
            
            # å¯¹äºç»å¯¹è·¯å¾„ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if remote_absolute_path.startswith('/content/drive/MyDrive/REMOTE_ROOT/'):
                # ç§»é™¤å‰ç¼€ï¼Œè·å–ç›¸å¯¹äºREMOTE_ROOTçš„è·¯å¾„
                relative_path = remote_absolute_path.replace('/content/drive/MyDrive/REMOTE_ROOT/', '')
                relative_parts = relative_path.split('/')
                actual_filename = relative_parts[-1]
                parent_relative_path = '/'.join(relative_parts[:-1]) if len(relative_parts) > 1 else ''
                
                if parent_relative_path:
                    # è½¬æ¢ä¸º~è·¯å¾„æ ¼å¼
                    parent_logical_path = '~/' + parent_relative_path
                    resolve_result = self.main_instance.path_resolver.resolve_path(parent_logical_path, current_shell)
                    if isinstance(resolve_result, tuple) and len(resolve_result) >= 2:
                        target_folder_id, _ = resolve_result
                        if not target_folder_id:
                            return {"success": False, "error": f"æ— æ³•è§£æç›®æ ‡è·¯å¾„: {parent_logical_path}"}
                    else:
                        return {"success": False, "error": f"è·¯å¾„è§£æè¿”å›æ ¼å¼é”™è¯¯: {parent_logical_path}"}
                else:
                    # æ–‡ä»¶åœ¨REMOTE_ROOTæ ¹ç›®å½•
                    target_folder_id = self.main_instance.REMOTE_ROOT_FOLDER_ID
            else:
                # ä½¿ç”¨å½“å‰shellçš„æ–‡ä»¶å¤¹ID
                target_folder_id = current_shell.get("current_folder_id", self.main_instance.REMOTE_ROOT_FOLDER_ID)
            
            # åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾æ–‡ä»¶
            result = self.drive_service.list_files(folder_id=target_folder_id, max_results=100)
            if not result['success']:
                return {"success": False, "error": f"æ— æ³•åˆ—å‡ºæ–‡ä»¶å¤¹å†…å®¹: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"}
            
            file_info = None
            files = result['files']
            for file in files:
                if file['name'] == actual_filename:
                    file_info = file
                    break
            
            if not file_info:
                return {"success": False, "error": f"File does not exist: {actual_filename}"}
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆä¸æ˜¯æ–‡ä»¶å¤¹ï¼‰
            if file_info['mimeType'] == 'application/vnd.google-apps.folder':
                return {"success": False, "error": f"{actual_filename} æ˜¯ä¸€ä¸ªç›®å½•ï¼Œæ— æ³•è¯»å–"}
            
            # ä½¿ç”¨Google Drive APIä¸‹è½½æ–‡ä»¶å†…å®¹
            try:
                file_id = file_info['id']
                request = self.drive_service.service.files().get_media(fileId=file_id)
                content = request.execute()
                
                # å°†å­—èŠ‚å†…å®¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if isinstance(content, bytes):
                    try:
                        content_str = content.decode('utf-8')
                    except UnicodeDecodeError:
                        try:
                            content_str = content.decode('gbk')
                        except UnicodeDecodeError:
                            content_str = content.decode('utf-8', errors='replace')
                else:
                    content_str = str(content)
                

                
                return {
                    "success": True,
                    "content": content_str,
                    "file_info": file_info
                }
                
            except Exception as e:
                return {"success": False, "error": f"ä¸‹è½½æ–‡ä»¶å†…å®¹å¤±è´¥: {e}"}
                
        except Exception as e:
            return {"success": False, "error": f"ä¸‹è½½å’Œè·å–å†…å®¹æ—¶å‡ºé”™: {e}"}

    def _format_read_output(self, selected_lines):
        """
        æ ¼å¼åŒ–è¯»å–è¾“å‡º
        
        Args:
            selected_lines: åŒ…å«(line_number, line_content)å…ƒç»„çš„åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–åçš„è¾“å‡ºå­—ç¬¦ä¸²
        """
        if not selected_lines:
            return ""
        
        # æ ¼å¼åŒ–æ¯è¡Œï¼Œæ˜¾ç¤ºè¡Œå·å’Œå†…å®¹
        formatted_lines = ["line_num: line_content"]
        for line_num, line_content in selected_lines:
            # è¡Œå·ä»0å¼€å§‹, 0-indexed
            formatted_lines.append(f"{line_num:4d}: {line_content}")
        
        return "\n".join(formatted_lines)

    def _parse_find_args(self, args):
        """è§£æfindå‘½ä»¤å‚æ•°"""
        try:
            args_list = list(args)
            
            # é»˜è®¤å€¼
            path = "."
            pattern = "*"
            case_sensitive = True
            file_type = None  # None=both, "f"=files, "d"=directories
            
            i = 0
            while i < len(args_list):
                arg = args_list[i]
                
                if arg == "-name" and i + 1 < len(args_list):
                    pattern = args_list[i + 1]
                    case_sensitive = True
                    i += 2
                elif arg == "-iname" and i + 1 < len(args_list):
                    pattern = args_list[i + 1]
                    case_sensitive = False
                    i += 2
                elif arg == "-type" and i + 1 < len(args_list):
                    file_type = args_list[i + 1]
                    if file_type not in ["f", "d"]:
                        return {"success": False, "error": "æ— æ•ˆçš„æ–‡ä»¶ç±»å‹ï¼Œä½¿ç”¨ 'f' (æ–‡ä»¶) æˆ– 'd' (ç›®å½•)"}
                    i += 2
                elif not arg.startswith("-"):
                    # è¿™æ˜¯è·¯å¾„å‚æ•°
                    path = arg
                    i += 1
                else:
                    i += 1
            
            return {
                "success": True,
                "path": path,
                "pattern": pattern,
                "case_sensitive": case_sensitive,
                "file_type": file_type
            }
            
        except Exception as e:
            return {"success": False, "error": f"å‚æ•°è§£æé”™è¯¯: {e}"}

    def _recursive_find(self, search_path, pattern, case_sensitive=True, file_type=None):
        """
        é€’å½’æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å’Œç›®å½•
        
        Args:
            search_path: æœç´¢è·¯å¾„
            pattern: æœç´¢æ¨¡å¼ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
            case_sensitive: æ˜¯å¦å¤§å°å†™æ•æ„Ÿ
            file_type: æ–‡ä»¶ç±»å‹è¿‡æ»¤ ("f" for files, "d" for directories, None for both)
        
        Returns:
            dict: {"success": bool, "files": list, "error": str}
        """
        try:
            import fnmatch
            
            # è§£ææœç´¢è·¯å¾„
            if search_path == ".":
                # ä½¿ç”¨å½“å‰shellè·¯å¾„
                current_shell = self.main_instance.get_current_shell()
                if current_shell:
                    search_path = current_shell.get("current_path", "~")
            
            # å°†~è½¬æ¢ä¸ºå®é™…çš„REMOTE_ROOTè·¯å¾„
            if search_path.startswith("~"):
                search_path = search_path.replace("~", "/content/drive/MyDrive/REMOTE_ROOT", 1)
            
            # ç”Ÿæˆè¿œç¨‹findå‘½ä»¤
            find_cmd_parts = ["find", f'"{search_path}"']
            
            # æ·»åŠ æ–‡ä»¶ç±»å‹è¿‡æ»¤
            if file_type == "f":
                find_cmd_parts.append("-type f")
            elif file_type == "d":
                find_cmd_parts.append("-type d")
            
            # æ·»åŠ åç§°æ¨¡å¼
            if case_sensitive:
                find_cmd_parts.append(f'-name "{pattern}"')
            else:
                find_cmd_parts.append(f'-iname "{pattern}"')
            
            find_command = " ".join(find_cmd_parts)
            
            # æ‰§è¡Œè¿œç¨‹findå‘½ä»¤
            result = self.main_instance.execute_generic_remote_command("bash", ["-c", find_command])
            
            if result.get("success"):
                stdout = result.get("stdout", "").strip()
                if stdout:
                    # åˆ†å‰²è¾“å‡ºä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨
                    files = [line.strip() for line in stdout.split("\n") if line.strip()]
                    return {
                        "success": True,
                        "files": files
                    }
                else:
                    return {
                        "success": True,
                        "files": []
                    }
            else:
                return {
                    "success": False,
                    "error": f"Remote find command failed: {result.get('error', 'Unknown error')}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"Error executing find: {e}"
            }

    def cmd_find(self, *args):
        """
        GDS findå‘½ä»¤å®ç°ï¼Œç±»ä¼¼bash find
        
        ç”¨æ³•:
            find [path] -name [pattern]
            find [path] -iname [pattern]  # å¤§å°å†™ä¸æ•æ„Ÿ
            find [path] -type f -name [pattern]  # åªæŸ¥æ‰¾æ–‡ä»¶
            find [path] -type d -name [pattern]  # åªæŸ¥æ‰¾ç›®å½•
        
        Args:
            *args: å‘½ä»¤å‚æ•°
            
        Returns:
            dict: æŸ¥æ‰¾ç»“æœ
        """
        try:
            if not args:
                return {
                    "success": False,
                    "error": "ç”¨æ³•: find [path] -name [pattern] æˆ– find [path] -type [f|d] -name [pattern]"
                }
            
            # è§£æå‚æ•°
            parsed_args = self._parse_find_args(args)
            if not parsed_args["success"]:
                return parsed_args
            
            search_path = parsed_args["path"]
            pattern = parsed_args["pattern"]
            case_sensitive = parsed_args["case_sensitive"]
            file_type = parsed_args["file_type"]  # "f" for files, "d" for directories, None for both
            
            # é€’å½’æœç´¢æ–‡ä»¶
            results = self._recursive_find(search_path, pattern, case_sensitive, file_type)
            
            if results["success"]:
                found_files = results["files"]
                
                # æ ¼å¼åŒ–è¾“å‡º
                output_lines = []
                for file_path in sorted(found_files):
                    output_lines.append(file_path)
                
                return {
                    "success": True,
                    "files": found_files,
                    "count": len(found_files),
                    "output": "\n".join(output_lines) if output_lines else "No files found matching the pattern."
                }
            else:
                return results
                
        except Exception as e:
            return {
                "success": False,
                "error": f"Find command error: {e}"
            }

    def _generate_edit_diff(self, original_lines, modified_lines, parsed_replacements):
        """
        ç”Ÿæˆç¼–è¾‘å·®å¼‚ä¿¡æ¯
        
        Args:
            original_lines: åŸå§‹æ–‡ä»¶è¡Œåˆ—è¡¨
            modified_lines: ä¿®æ”¹åæ–‡ä»¶è¡Œåˆ—è¡¨
            parsed_replacements: è§£æåçš„æ›¿æ¢æ“ä½œåˆ—è¡¨
            
        Returns:
            dict: å·®å¼‚ä¿¡æ¯
        """
        try:
            import difflib
            
            # ç”Ÿæˆunified diff
            diff = list(difflib.unified_diff(
                original_lines,
                modified_lines,
                fromfile='original',
                tofile='modified',
                lineterm=''
            ))
            
            # ç»Ÿè®¡å˜æ›´ä¿¡æ¯
            lines_added = len(modified_lines) - len(original_lines)
            changes_count = len(parsed_replacements)
            
            # ç”Ÿæˆç®€åŒ–çš„å˜æ›´æ‘˜è¦
            changes_summary = []
            for replacement in parsed_replacements:
                if replacement["type"] == "line_range":
                    changes_summary.append(f"Lines {replacement['start_line']}-{replacement['end_line']}: range replacement")
                elif replacement["type"] == "line_insert":
                    changes_summary.append(f"Line {replacement['insert_line']}: content insertion")
                elif replacement["type"] == "text_search":
                    changes_summary.append(f"Text search: '{replacement['old_text'][:50]}...' -> '{replacement['new_text'][:50]}...'")
            
            return {
                "diff_lines": diff,
                "lines_added": lines_added,
                "changes_count": changes_count,
                "changes_summary": changes_summary,
                "original_line_count": len(original_lines),
                "modified_line_count": len(modified_lines)
            }
            
        except Exception as e:
            return {
                "error": f"Failed to generate diff: {e}",
                "diff_lines": [],
                "lines_added": 0,
                "changes_count": 0,
                "changes_summary": []
            }

    def _generate_local_diff_preview(self, filename, original_lines, modified_lines, parsed_replacements):
        """
        ç”Ÿæˆæœ¬åœ°diffé¢„è§ˆï¼Œåªæ˜¾ç¤ºä¿®æ”¹çš„éƒ¨åˆ†
        
        Args:
            filename (str): æ–‡ä»¶å
            original_lines (list): åŸå§‹æ–‡ä»¶è¡Œ
            modified_lines (list): ä¿®æ”¹åæ–‡ä»¶è¡Œ
            parsed_replacements (list): è§£æåçš„æ›¿æ¢æ“ä½œ
            
        Returns:
            dict: åŒ…å«diffè¾“å‡ºå’Œå˜æ›´æ‘˜è¦
        """
        try:
            import tempfile
            import os
            import subprocess
            import hashlib
            import time
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_base_dir = os.path.join(os.path.expanduser("~"), ".local", "bin", "GOOGLE_DRIVE_DATA", "tmp")
            os.makedirs(temp_base_dir, exist_ok=True)
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å“ˆå¸Œæ–‡ä»¶å
            timestamp = str(int(time.time() * 1000))
            content_hash = hashlib.md5(filename.encode()).hexdigest()[:8]
            
            original_filename = f"{content_hash}_{timestamp}_original.tmp"
            modified_filename = f"{content_hash}_{timestamp}_modified.tmp"
            
            original_path = os.path.join(temp_base_dir, original_filename)
            modified_path = os.path.join(temp_base_dir, modified_filename)
            
            try:
                # å†™å…¥åŸå§‹æ–‡ä»¶
                with open(original_path, 'w', encoding='utf-8') as f:
                    f.writelines(original_lines)
                
                # å†™å…¥ä¿®æ”¹åæ–‡ä»¶
                with open(modified_path, 'w', encoding='utf-8') as f:
                    f.writelines(modified_lines)
                
                # æ‰§è¡Œdiffå‘½ä»¤
                diff_cmd = ['diff', '-u', original_path, modified_path]
                result = subprocess.run(diff_cmd, capture_output=True, text=True, encoding='utf-8')
                
                # diffå‘½ä»¤è¿”å›ç ï¼š0=æ— å·®å¼‚ï¼Œ1=æœ‰å·®å¼‚ï¼Œ2=é”™è¯¯
                if result.returncode == 0:
                    diff_output = "No changes detected"
                elif result.returncode == 1:
                    # æœ‰å·®å¼‚ï¼Œå¤„ç†è¾“å‡º
                    diff_lines = result.stdout.splitlines()
                    # ç§»é™¤æ–‡ä»¶è·¯å¾„è¡Œï¼Œåªä¿ç•™å·®å¼‚å†…å®¹
                    filtered_lines = []
                    for line in diff_lines:
                        if line.startswith('---') or line.startswith('+++'):
                            # æ›¿æ¢ä¸´æ—¶æ–‡ä»¶è·¯å¾„ä¸ºå®é™…æ–‡ä»¶å
                            if line.startswith('---'):
                                filtered_lines.append(f"--- {filename} (original)")
                            elif line.startswith('+++'):
                                filtered_lines.append(f"+++ {filename} (modified)")
                        else:
                            filtered_lines.append(line)
                    diff_output = '\n'.join(filtered_lines)
                else:
                    diff_output = f"Diff command error: {result.stderr}"
                
                # ç”Ÿæˆå˜æ›´æ‘˜è¦
                changes_summary = []
                for replacement in parsed_replacements:
                    if replacement["type"] == "line_range":
                        changes_summary.append(f"Lines {replacement['start_line']}-{replacement['end_line']}: range replacement")
                    elif replacement["type"] == "line_insert":
                        changes_summary.append(f"Line {replacement['insert_line']}: content insertion")
                    elif replacement["type"] == "text_search":
                        changes_summary.append(f"Text search: '{replacement['old_text'][:50]}...' -> '{replacement['new_text'][:50]}...'")
                
                return {
                    "diff_output": diff_output,
                    "changes_summary": changes_summary,
                    "temp_files_created": [original_path, modified_path]
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if os.path.exists(original_path):
                        os.unlink(original_path)
                    if os.path.exists(modified_path):
                        os.unlink(modified_path)
                except Exception as cleanup_error:
                    # æ¸…ç†å¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½
                    pass
                    
        except Exception as e:
            return {
                "diff_output": f"Failed to generate diff preview: {str(e)}",
                "changes_summary": [],
                "temp_files_created": []
            }

    def cmd_edit(self, filename, replacement_spec, preview=False, backup=False):
        """
        GDS editå‘½ä»¤ - æ”¯æŒå¤šæ®µæ–‡æœ¬åŒæ­¥æ›¿æ¢çš„æ–‡ä»¶ç¼–è¾‘åŠŸèƒ½
        
        Args:
            filename (str): è¦ç¼–è¾‘çš„æ–‡ä»¶å
            replacement_spec (str): æ›¿æ¢è§„èŒƒï¼Œæ”¯æŒå¤šç§æ ¼å¼
            preview (bool): é¢„è§ˆæ¨¡å¼ï¼Œåªæ˜¾ç¤ºä¿®æ”¹ç»“æœä¸å®é™…ä¿å­˜
            backup (bool): æ˜¯å¦åˆ›å»ºå¤‡ä»½æ–‡ä»¶
            
        Returns:
            dict: ç¼–è¾‘ç»“æœ
            
        æ”¯æŒçš„æ›¿æ¢æ ¼å¼:
        1. è¡Œå·æ›¿æ¢: '[[[1, 2], "new content"], [[5, 7], "another content"]]'
        2. è¡Œå·æ’å…¥: '[[[1, null], "content to insert"], [[5, null], "another insert"]]'
        3. æ–‡æœ¬æœç´¢æ›¿æ¢: '[["old text", "new text"], ["another old", "another new"]]'
        4. æ··åˆæ¨¡å¼: '[[[1, 1], "line replacement"], [[3, null], "insertion"], ["text", "replace"]]'
        """
        # Debugä¿¡æ¯æ”¶é›†å™¨
        debug_info = []
        # åˆå§‹åŒ–å˜é‡ä»¥é¿å…ä½œç”¨åŸŸé—®é¢˜
        files_to_upload = []
        
        def debug_log(message):
            debug_info.append(message)
        
        try:
            
            import json
            import re
            import tempfile
            import shutil
            import os
            from datetime import datetime
            
            # å¯¼å…¥ç¼“å­˜ç®¡ç†å™¨
            import sys
            from pathlib import Path
            cache_manager_path = Path(__file__).parent.parent / "cache_manager.py"
            if cache_manager_path.exists():
                sys.path.insert(0, str(Path(__file__).parent.parent))
                from cache_manager import GDSCacheManager
                cache_manager = GDSCacheManager()
            else:
                return {"success": False, "error": "Cache manager not found"}
            
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "No active remote shell"}
            
            # 1. è§£ææ›¿æ¢è§„èŒƒ
            try:
                replacements = json.loads(replacement_spec)
                if not isinstance(replacements, list):
                    return {"success": False, "error": "Replacement specification must be an array"}
            except json.JSONDecodeError as e:
                # æä¾›æ›´æœ‰å»ºè®¾æ€§çš„é”™è¯¯ä¿¡æ¯
                error_msg = f"JSON parsing failed: {e}\n\n"
                error_msg += "Common issues:\n"
                error_msg += "1. Missing quotes around strings\n"
                error_msg += "2. Unescaped quotes inside strings (use \\\" instead of \")\n" 
                error_msg += "3. Missing commas between array elements\n"
                error_msg += "4. Shell quote conflicts. Try using single quotes around JSON\n\n"
                error_msg += f"Your input: {repr(replacement_spec)}\n"
                error_msg += "Correct format examples:\n"
                error_msg += "  Text replacement: '[[\"old\", \"new\"]]'\n"
                error_msg += "  Line replacement: '[[[1, 3], \"new content\"]]'\n"
                error_msg += "  Mixed: '[[[1, 2], \"line\"], [\"old\", \"new\"]]'"
                return {"success": False, "error": error_msg}
            
            # 2. ä¸‹è½½æ–‡ä»¶åˆ°ç¼“å­˜
            download_result = self.cmd_download(filename, force=True)  # å¼ºåˆ¶é‡æ–°ä¸‹è½½ç¡®ä¿æœ€æ–°å†…å®¹
            if not download_result["success"]:
                return {"success": False, "error": f"{download_result.get('error')}"}  #TODO
            
            cache_file_path = download_result.get("cache_path") or download_result.get("cached_path")
            if not cache_file_path or not os.path.exists(cache_file_path):
                return {"success": False, "error": "Failed to get cache file path"}
            
            # 3. è¯»å–æ–‡ä»¶å†…å®¹
            try:
                with open(cache_file_path, 'r', encoding='utf-8') as f:
                    original_lines = f.readlines()
            except UnicodeDecodeError:
                # å°è¯•å…¶ä»–ç¼–ç 
                try:
                    with open(cache_file_path, 'r', encoding='gbk') as f:
                        original_lines = f.readlines()
                except:
                    return {"success": False, "error": "Unsupported file encoding, please ensure the file is UTF-8 or GBK encoded"}
            except Exception as e:
                return {"success": False, "error": f"Failed to read file: {e}"}
            
            # 4. è§£æå’ŒéªŒè¯æ›¿æ¢æ“ä½œ
            parsed_replacements = []
            for i, replacement in enumerate(replacements):
                if not isinstance(replacement, list) or len(replacement) != 2:
                    return {"success": False, "error": f"Replacement specification item {i+1} has incorrect format, should be [source, target] format"}
                
                source, target = replacement
                
                if isinstance(source, list) and len(source) == 2:
                    start_line, end_line = source
                    
                    # æ£€æŸ¥æ’å…¥æ¨¡å¼ï¼š[a, null] æˆ– [a, ""] æˆ– [a, None]
                    if end_line is None or end_line == "" or end_line == "null":
                        # æ’å…¥æ¨¡å¼: [[line_number, null], "content_to_insert"]
                        if not isinstance(start_line, int):
                            return {"success": False, "error": f"Insert mode requires integer line number, got: {start_line}"}
                        
                        if start_line < 0 or start_line > len(original_lines):
                            return {"success": False, "error": f"Insert line number error: {start_line} (valid range: 0-{len(original_lines)}, 0-based index)"}
                        
                        parsed_replacements.append({
                            "type": "line_insert",
                            "insert_after_idx": start_line,
                            "insert_line": start_line,
                            "new_content": target,
                            "original_content": ""  # æ’å…¥æ¨¡å¼æ²¡æœ‰åŸå§‹å†…å®¹
                        })
                        
                    elif isinstance(start_line, int) and isinstance(end_line, int):
                        # æ›¿æ¢æ¨¡å¼: [[start_line, end_line], "new_content"] (0-based, [a, b] åŒ…å«è¯­æ³•)
                        # ä½¿ç”¨0-basedç´¢å¼•ï¼Œ[a, b] åŒ…å«è¯­æ³•ï¼Œä¸readå‘½ä»¤ä¿æŒä¸€è‡´
                        start_idx = start_line
                        end_idx = end_line  # end_lineæ˜¯inclusiveçš„
                        
                        if start_idx < 0 or start_idx >= len(original_lines) or end_line >= len(original_lines) or start_idx > end_idx:
                            return {"success": False, "error": f"Line number range error: [{start_line}, {end_line}] in file with {len(original_lines)} lines (0-based index)"}
                        
                        parsed_replacements.append({
                            "type": "line_range",
                            "start_idx": start_idx,
                            "end_idx": end_idx,
                            "start_line": start_line,
                            "end_line": end_line,
                            "new_content": target,
                            "original_content": "".join(original_lines[start_idx:end_line + 1]).rstrip()
                        })
                    else:
                        return {"success": False, "error": f"Invalid line specification: [{start_line}, {end_line}]. Use [start, end] for replacement or [line, null] for insertion."}
                    
                elif isinstance(source, str):
                    # æ–‡æœ¬æœç´¢æ›¿æ¢æ¨¡å¼: ["old_text", "new_text"]
                    if source not in "".join(original_lines):
                        return {"success": False, "error": f"Text not found to replace: {source[:50]}..."}
                    
                    parsed_replacements.append({
                        "type": "text_search",
                        "old_text": source,
                        "new_text": target
                    })
                else:
                    return {"success": False, "error": f"Source format for replacement specification item {i+1} is not supported, should be line number array [start, end] or text string"}
            
            # 5. æ‰§è¡Œæ›¿æ¢å’Œæ’å…¥æ“ä½œ
            modified_lines = original_lines.copy()
            
            # å…ˆå¤„ç†æ’å…¥æ“ä½œï¼ˆæŒ‰è¡Œå·å€’åºï¼Œé¿å…è¡Œå·å˜åŒ–å½±å“åç»­æ’å…¥ï¼‰
            line_insertions = [r for r in parsed_replacements if r["type"] == "line_insert"]
            line_insertions.sort(key=lambda x: x["insert_after_idx"], reverse=True)
            
            for insertion in line_insertions:
                insert_after_idx = insertion["insert_after_idx"]
                new_content = insertion["new_content"]
                
                # å°†æ–°å†…å®¹æŒ‰æ¢è¡Œç¬¦æ‹†åˆ†æˆè¡Œåˆ—è¡¨ï¼Œæ­£ç¡®å¤„ç†\n
                if new_content:
                    # å¤„ç†æ¢è¡Œç¬¦ï¼Œå°†\nè½¬æ¢ä¸ºå®é™…æ¢è¡Œ
                    processed_content = new_content.replace('\\n', '\n')
                    # å¤„ç†ç©ºæ ¼å ä½ç¬¦ï¼Œæ”¯æŒå¤šç§æ ¼å¼
                    processed_content = processed_content.replace('_SPACE_', ' ')  # å•ä¸ªç©ºæ ¼
                    processed_content = processed_content.replace('_SP_', ' ')     # ç®€å†™å½¢å¼
                    processed_content = processed_content.replace('_4SP_', '    ') # 4ä¸ªç©ºæ ¼ï¼ˆå¸¸ç”¨ç¼©è¿›ï¼‰
                    processed_content = processed_content.replace('_TAB_', '\t')   # åˆ¶è¡¨ç¬¦
                    new_lines = processed_content.split('\n')
                    
                    # ç¡®ä¿æ¯è¡Œéƒ½ä»¥æ¢è¡Œç¬¦ç»“å°¾
                    formatted_new_lines = []
                    for i, line in enumerate(new_lines):
                        if i < len(new_lines) - 1:  # ä¸æ˜¯æœ€åä¸€è¡Œ
                            formatted_new_lines.append(line + '\n')
                        else:  # æœ€åä¸€è¡Œ
                            formatted_new_lines.append(line + '\n')  # æ’å…¥çš„å†…å®¹æ€»æ˜¯æ·»åŠ æ¢è¡Œç¬¦
                    
                    # åœ¨æŒ‡å®šè¡Œä¹‹åæ’å…¥å†…å®¹
                    # insert_after_idx = 0 è¡¨ç¤ºåœ¨ç¬¬0è¡Œåæ’å…¥ï¼ˆå³ç¬¬1è¡Œä¹‹å‰ï¼‰
                    # insert_after_idx = len(lines) è¡¨ç¤ºåœ¨æ–‡ä»¶æœ«å°¾æ’å…¥
                    insert_position = insert_after_idx + 1 if insert_after_idx < len(modified_lines) else len(modified_lines)
                    modified_lines[insert_position:insert_position] = formatted_new_lines
            
            # ç„¶åæŒ‰è¡Œå·å€’åºå¤„ç†è¡Œæ›¿æ¢ï¼Œé¿å…è¡Œå·å˜åŒ–å½±å“åç»­æ›¿æ¢
            line_replacements = [r for r in parsed_replacements if r["type"] == "line_range"]
            line_replacements.sort(key=lambda x: x["start_idx"], reverse=True)
            
            for replacement in line_replacements:
                start_idx = replacement["start_idx"]
                end_idx = replacement["end_idx"]
                new_content = replacement["new_content"]
                
                # å°†æ–°å†…å®¹æŒ‰æ¢è¡Œç¬¦æ‹†åˆ†æˆè¡Œåˆ—è¡¨ï¼Œæ­£ç¡®å¤„ç†\n
                if new_content:
                    # å¤„ç†æ¢è¡Œç¬¦ï¼Œå°†\nè½¬æ¢ä¸ºå®é™…æ¢è¡Œ
                    processed_content = new_content.replace('\\n', '\n')
                    # å¤„ç†ç©ºæ ¼å ä½ç¬¦ï¼Œæ”¯æŒå¤šç§æ ¼å¼
                    processed_content = processed_content.replace('_SPACE_', ' ')  # å•ä¸ªç©ºæ ¼
                    processed_content = processed_content.replace('_SP_', ' ')     # ç®€å†™å½¢å¼
                    processed_content = processed_content.replace('_4SP_', '    ') # 4ä¸ªç©ºæ ¼ï¼ˆå¸¸ç”¨ç¼©è¿›ï¼‰
                    processed_content = processed_content.replace('_TAB_', '\t')   # åˆ¶è¡¨ç¬¦
                    new_lines = processed_content.split('\n')
                    
                    # ç¡®ä¿æ¯è¡Œéƒ½ä»¥æ¢è¡Œç¬¦ç»“å°¾ï¼ˆé™¤äº†æœ€åä¸€è¡Œï¼‰
                    formatted_new_lines = []
                    for i, line in enumerate(new_lines):
                        if i < len(new_lines) - 1:  # ä¸æ˜¯æœ€åä¸€è¡Œ
                            formatted_new_lines.append(line + '\n')
                        else:  # æœ€åä¸€è¡Œ
                            # æ ¹æ®åŸæ–‡ä»¶çš„æœ€åä¸€è¡Œæ˜¯å¦æœ‰æ¢è¡Œç¬¦æ¥å†³å®š
                            if end_idx == len(original_lines) and original_lines and not original_lines[-1].endswith('\n'):
                                formatted_new_lines.append(line)  # ä¸æ·»åŠ æ¢è¡Œç¬¦
                            else:
                                formatted_new_lines.append(line + '\n')  # æ·»åŠ æ¢è¡Œç¬¦
                    
                    # æ›¿æ¢è¡ŒèŒƒå›´ (ä½¿ç”¨[a, b]åŒ…å«è¯­æ³•)
                    modified_lines[start_idx:end_idx + 1] = formatted_new_lines
                else:
                    # ç©ºå†…å®¹ï¼Œåˆ é™¤è¡ŒèŒƒå›´
                    modified_lines[start_idx:end_idx + 1] = []
            
            # å¤„ç†æ–‡æœ¬æœç´¢æ›¿æ¢
            text_replacements = [r for r in parsed_replacements if r["type"] == "text_search"]
            if text_replacements:
                file_content = "".join(modified_lines)
                for replacement in text_replacements:
                    file_content = file_content.replace(replacement["old_text"], replacement["new_text"])
                modified_lines = file_content.splitlines(keepends=True)
            
            # 6. ç”Ÿæˆç»“æœé¢„è§ˆ
            diff_info = self._generate_edit_diff(original_lines, modified_lines, parsed_replacements)
            
            if preview:
                # é¢„è§ˆæ¨¡å¼ï¼šä½¿ç”¨diffæ˜¾ç¤ºä¿®æ”¹å†…å®¹ï¼Œä¸ä¿å­˜æ–‡ä»¶
                diff_result = self._generate_local_diff_preview(filename, original_lines, modified_lines, parsed_replacements)
                return {
                    "success": True,
                    "mode": "preview",
                    "filename": filename,
                    "original_lines": len(original_lines),
                    "modified_lines": len(modified_lines),
                    "replacements_applied": len(parsed_replacements),
                    "diff_output": diff_result.get("diff_output", ""),
                    "changes_summary": diff_result.get("changes_summary", []),
                    "message": f"ğŸ“ é¢„è§ˆæ¨¡å¼ - æ–‡ä»¶: {filename}\nåŸå§‹è¡Œæ•°: {len(original_lines)}, ä¿®æ”¹åè¡Œæ•°: {len(modified_lines)}\nåº”ç”¨æ›¿æ¢: {len(parsed_replacements)} ä¸ª"
                }
            
            # 7. å‡†å¤‡ä¸´æ—¶ç›®å½•å’Œæ–‡ä»¶ä¸Šä¼ åˆ—è¡¨
            import tempfile
            import os
            temp_dir = tempfile.gettempdir()
            
            # ä»å®Œæ•´è·¯å¾„ä¸­æå–æ–‡ä»¶åï¼Œä¿æŒåŸå§‹æ–‡ä»¶åç”¨äºæ›¿æ¢
            actual_filename = os.path.basename(filename)
            # ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œä¸æ·»åŠ æ—¶é—´æˆ³ï¼Œè¿™æ ·uploadæ—¶ä¼šç›´æ¥æ›¿æ¢
            temp_file_path = os.path.join(temp_dir, actual_filename)
            
            files_to_upload = []
            backup_info = {}
            
            if backup:
                # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³é¿å…å†²çªï¼ŒåŒ…å«æ¯«ç§’
                import time
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') + f"_{int(time.time() * 1000) % 10000:04d}"
                backup_filename = f"{filename}.backup.{timestamp}"
                
                debug_log("Creating backup file for batch upload...")
                # ä¸‹è½½åŸæ–‡ä»¶åˆ°ç¼“å­˜
                download_result = self.cmd_download(filename, force=True)
                if download_result["success"]:
                    cache_file_path = download_result.get("cache_path") or download_result.get("cached_path")
                    if cache_file_path and os.path.exists(cache_file_path):
                        # åˆ›å»ºä¸´æ—¶å¤‡ä»½æ–‡ä»¶
                        temp_backup_path = os.path.join(temp_dir, backup_filename)
                        import shutil
                        shutil.copy2(cache_file_path, temp_backup_path)
                        files_to_upload.append(temp_backup_path)
                        debug_log(f"Backup file prepared: {temp_backup_path}")
                        
                        backup_info = {
                            "backup_created": True,
                            "backup_filename": backup_filename,
                            "backup_temp_path": temp_backup_path
                        }
                    else:
                        backup_info = {
                            "backup_created": False,
                            "backup_error": "Failed to get cache file for backup"
                        }
                else:
                    backup_info = {
                        "backup_created": False,
                        "backup_error": f"Failed to download original file for backup: {download_result.get('error')}"
                    }
            
            # æ·»åŠ ä¿®æ”¹åçš„æ–‡ä»¶åˆ°ä¸Šä¼ åˆ—è¡¨
            files_to_upload.append(temp_file_path)
            debug_log(f"Files to upload: {files_to_upload}")
            
            # 8. ä¿å­˜ä¿®æ”¹åçš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å
            debug_log(f"Using temp_file_path='{temp_file_path}' for original filename='{actual_filename}'")
            
            with open(temp_file_path, 'w', encoding='utf-8') as temp_file:
                temp_file.writelines(modified_lines)
            
            try:
                # 9. æ›´æ–°ç¼“å­˜
                remote_absolute_path = self.main_instance.resolve_remote_absolute_path(filename, current_shell)
                cache_result = cache_manager.cache_file(remote_absolute_path, temp_file_path)
                
                if not cache_result["success"]:
                    return {"success": False, "error": f"Failed to update cache: {cache_result.get('error')}"}
                
                # 10. ä¸Šä¼ ä¿®æ”¹åçš„æ–‡ä»¶ï¼Œç¡®ä¿ç¼“å­˜çŠ¶æ€æ­£ç¡®æ›´æ–°
                debug_log(f"About to upload edited file - temp_file_path='{temp_file_path}', filename='{filename}'")
                debug_log(f"temp_file exists: {os.path.exists(temp_file_path)}")
                if os.path.exists(temp_file_path):
                    with open(temp_file_path, 'r', encoding='utf-8') as f:
                        content_preview = f.read()[:200]
                    debug_log(f"temp_file content preview: {content_preview}...")
                
                # æ‰¹é‡ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶ï¼ˆå¤‡ä»½æ–‡ä»¶+ä¿®æ”¹åçš„æ–‡ä»¶ï¼‰
                debug_log("Starting batch upload...")
                upload_result = self.cmd_upload(files_to_upload, force=True)
                debug_log(f"Batch upload result: {upload_result}")
                
                if upload_result["success"]:
                    # ç”Ÿæˆdiffé¢„è§ˆç”¨äºæ˜¾ç¤º
                    diff_result = self._generate_local_diff_preview(filename, original_lines, modified_lines, parsed_replacements)
                    
                    result = {
                        "success": True,
                        "filename": filename,
                        "original_lines": len(original_lines),
                        "modified_lines": len(modified_lines),
                        "replacements_applied": len(parsed_replacements),
                        "diff": diff_info,
                        "diff_output": diff_result.get("diff_output", ""),
                        "cache_updated": True,
                        "uploaded": True,
                        "message": f"File {filename} edited successfully, applied {len(parsed_replacements)} replacements"
                    }
                    result.update(backup_info)
                    
                    # å¦‚æœæœ‰å¤‡ä»½æ–‡ä»¶ï¼Œæ·»åŠ æˆåŠŸä¿¡æ¯
                    if backup_info.get("backup_created"):
                        result["message"] += f"\nğŸ“‹ Backup created: {backup_info['backup_filename']}"
                    
                    # åœ¨ç¼–è¾‘å®Œæˆåè¿è¡Œlinteræ£€æŸ¥
                    try:
                        linter_result = self._run_linter_on_content(''.join(modified_lines), filename)
                        if linter_result.get("has_issues"):
                            result["linter_output"] = linter_result.get("formatted_output", "")
                            result["has_linter_issues"] = True
                        else:
                            result["has_linter_issues"] = False
                    except Exception as e:
                        # Linter failure shouldn't break the edit operation
                        result["linter_error"] = f"Linter check failed: {str(e)}"
                    
                    return result
                else:
                    return {
                        "success": False,
                        "error": f"Failed to upload files: {upload_result.get('error')}",
                        "cache_updated": True,
                        "diff": diff_info,
                        "backup_info": backup_info
                    }
                    
            finally:
                # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                for temp_path in files_to_upload:
                    try:
                        if os.path.exists(temp_path):
                            os.unlink(temp_path)
                            debug_log(f"Cleaned up temp file: {temp_path}")
                    except Exception as cleanup_error:
                        debug_log(f"Failed to cleanup temp file {temp_path}: {cleanup_error}")
            
        except KeyboardInterrupt:
            # ç”¨æˆ·ä¸­æ–­ï¼Œè¾“å‡ºdebugä¿¡æ¯
            if debug_info:
                print("\nğŸ”§ DEBUG INFO (due to KeyboardInterrupt):")
                for i, info in enumerate(debug_info, 1):
                    print(f"  {i}. {info}")
            raise  # é‡æ–°æŠ›å‡ºKeyboardInterrupt
        except Exception as e:
            # è¾“å‡ºdebugä¿¡æ¯ç”¨äºå¼‚å¸¸è¯Šæ–­
            if debug_info:
                print("ğŸ”§ DEBUG INFO (due to exception):")
                for i, info in enumerate(debug_info, 1):
                    print(f"  {i}. {info}")
            return {"success": False, "error": f"Edit operation failed: {str(e)}"}

    def _create_backup(self, filename, backup_filename):
        """
        åˆ›å»ºæ–‡ä»¶çš„å¤‡ä»½å‰¯æœ¬
        
        Args:
            filename (str): åŸæ–‡ä»¶å
            backup_filename (str): å¤‡ä»½æ–‡ä»¶å
            
        Returns:
            dict: å¤‡ä»½ç»“æœ
        """
        # å¤‡ä»½debugä¿¡æ¯æ”¶é›†å™¨
        backup_debug = []
        
        def backup_debug_log(message):
            backup_debug.append(message)
        
        try:
            backup_debug_log(f"Starting backup: {filename} -> {backup_filename}")
            
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                backup_debug_log("ERROR: No active remote shell")
                return {"success": False, "error": "No active remote shell"}
            
            backup_debug_log(f"Current shell: {current_shell.get('id', 'unknown')}")
            
            # ä¸‹è½½åŸæ–‡ä»¶åˆ°ç¼“å­˜
            backup_debug_log("Step 1: Downloading original file to cache...")
            download_result = self.cmd_download(filename, force=True)
            backup_debug_log(f"Download result: success={download_result.get('success')}, error={download_result.get('error')}")
            
            if not download_result["success"]:
                if backup_debug:
                    print("ğŸ”§ BACKUP DEBUG INFO (download failed):")
                    for i, info in enumerate(backup_debug, 1):
                        print(f"  {i}. {info}")
                return {"success": False, "error": f"Failed to download original file for backup: {download_result.get('error')}"}
            
            import os
            cache_file_path = download_result.get("cache_path") or download_result.get("cached_path")
            backup_debug_log(f"Cache file path: {cache_file_path}")
            backup_debug_log(f"Cache file exists: {os.path.exists(cache_file_path) if cache_file_path else False}")
            
            if not cache_file_path or not os.path.exists(cache_file_path):
                if backup_debug:
                    print("ğŸ”§ BACKUP DEBUG INFO (cache file not found):")
                    for i, info in enumerate(backup_debug, 1):
                        print(f"  {i}. {info}")
                return {"success": False, "error": "Failed to get cache file path for backup"}
            
            # ä¸Šä¼ ç¼“å­˜æ–‡ä»¶ä½œä¸ºå¤‡ä»½
            backup_debug_log("Step 2: Creating backup file with correct name...")
            backup_debug_log(f"Cache file path: {cache_file_path}")
            backup_debug_log(f"Backup filename: {backup_filename}")
            
            # åˆ›å»ºä¸´æ—¶å¤‡ä»½æ–‡ä»¶ï¼Œä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶å
            import tempfile
            temp_dir = tempfile.gettempdir()
            temp_backup_path = os.path.join(temp_dir, backup_filename)
            backup_debug_log(f"Temp backup path: {temp_backup_path}")
            
            # å¤åˆ¶ç¼“å­˜æ–‡ä»¶åˆ°ä¸´æ—¶å¤‡ä»½æ–‡ä»¶
            import shutil
            shutil.copy2(cache_file_path, temp_backup_path)
            backup_debug_log(f"Copied cache to temp backup: {cache_file_path} -> {temp_backup_path}")
            
            try:
                # ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
                backup_debug_log("Step 3: Uploading backup file...")
                upload_result = self.cmd_upload([temp_backup_path], force=True)
                backup_debug_log(f"Upload result: success={upload_result.get('success')}, error={upload_result.get('error')}")
                backup_debug_log(f"Upload file_moves: {upload_result.get('file_moves', [])}")
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if os.path.exists(temp_backup_path):
                        os.unlink(temp_backup_path)
                        backup_debug_log(f"Cleaned up temp backup file: {temp_backup_path}")
                except Exception as cleanup_error:
                    backup_debug_log(f"Failed to cleanup temp backup file: {cleanup_error}")
            
            if upload_result.get("success", False):
                backup_debug_log("Backup creation completed successfully")
                return {"success": True, "message": f"Backup created: {backup_filename}"}
            else:
                if backup_debug:
                    print("ğŸ”§ BACKUP DEBUG INFO (upload failed):")
                    for i, info in enumerate(backup_debug, 1):
                        print(f"  {i}. {info}")
                return {"success": False, "error": f"Failed to create backup: {upload_result.get('error')}"}
                
        except KeyboardInterrupt:
            # ç”¨æˆ·ä¸­æ–­å¤‡ä»½è¿‡ç¨‹
            if backup_debug:
                print("\nğŸ”§ BACKUP DEBUG INFO (due to KeyboardInterrupt):")
                for i, info in enumerate(backup_debug, 1):
                    print(f"  {i}. {info}")
            raise
        except Exception as e:
            return {"success": False, "error": f"Backup creation failed: {str(e)}"}

