
class DependencyAnalysis:
    """
    Package dependency analysis and visualization
    """
    
    def __init__(self, drive_service, main_instance):
        self.drive_service = drive_service
        self.main_instance = main_instance
        self._pypi_client = None
    
    def cmd_deps(self, *args, **kwargs):
        """ç‹¬ç«‹çš„ä¾èµ–åˆ†æå‘½ä»¤"""
        try:
            if not args:
                return {"success": False, "error": "Usage: GDS deps <package1> [package2] [...] [--depth=N] [--analysis-type=smart|depth]"}
            
            # è§£æå‚æ•°
            packages = []
            max_depth = 2
            
            i = 0
            while i < len(args):
                arg = args[i]
                if arg.startswith('--depth='):
                    max_depth = int(arg.split('=')[1])
                elif arg == '--depth' and i + 1 < len(args):
                    max_depth = int(args[i + 1])
                    i += 1
                elif arg.startswith('--analysis-type='):
                    analysis_type = arg.split('=')[1]
                elif arg == '--analysis-type' and i + 1 < len(args):
                    analysis_type = args[i + 1]
                    i += 1
                elif arg == '-r' or arg == '--requirement':
                    # å¤„ç†requirements.txtæ–‡ä»¶
                    if i + 1 < len(args):
                        requirements_file = args[i + 1]
                        packages_from_file = self._parse_requirements_file(requirements_file)
                        packages.extend(packages_from_file)
                        i += 1
                elif arg.startswith('-r'):
                    # å¤„ç† -rrequirements.txt æ ¼å¼
                    requirements_file = arg[2:]
                    packages_from_file = self._parse_requirements_file(requirements_file)
                    packages.extend(packages_from_file)
                elif arg.endswith('.txt') and ('requirements' in arg.lower() or 'req' in arg.lower()):
                    # ç›´æ¥æŒ‡å®šrequirementsæ–‡ä»¶
                    packages_from_file = self._parse_requirements_file(arg)
                    packages.extend(packages_from_file)
                elif not arg.startswith('-'):
                    packages.append(arg)
                i += 1
            
            if not packages:
                return {"success": False, "error": "No packages specified for dependency analysis"}
            
            print(f"Analyzing dependencies for: {', '.join(packages)}")
            print(f"Analysis depth: {max_depth}")
            
            # è·å–å½“å‰ç¯å¢ƒçš„å·²å®‰è£…åŒ…ä¿¡æ¯
            installed_packages = self._detect_current_environment_packages()
            
            # æ ¹æ®åˆ†æç±»å‹é€‰æ‹©ä¸åŒçš„åˆ†ææ–¹æ³•
            if analysis_type == "smart":
                analysis_result = self._smart_dependency_analysis(
                    packages, 
                    max_calls=10, 
                    interface_mode=False, 
                    installed_packages=installed_packages
                )
            elif analysis_type == "depth":
                analysis_result = self._depth_based_dependency_analysis(
                    packages, 
                    max_depth=max_depth, 
                    interface_mode=False, 
                    installed_packages=installed_packages
                )
            else:
                return {"success": False, "error": f"Unknown analysis type: {analysis_type}. Use 'smart' or 'depth'"}
            
            # æ˜¾ç¤ºåˆ†æç»“æœ
            total_calls = analysis_result.get('total_calls', 0)
            analyzed_packages = analysis_result.get('analyzed_packages', 0)
            total_time = analysis_result.get('total_time', 0)
            
            if total_time:
                print(f"Analysis completed: {total_calls} API calls, {analyzed_packages} packages analyzed in {total_time:.2f}s\n")
            else:
                print(f"Analysis completed: {total_calls} API calls, {analyzed_packages} packages analyzed\n")
            
            # æ˜¾ç¤ºä¾èµ–æ ‘
            self._display_smart_dependency_tree(analysis_result, installed_packages)
            
            return {
                "success": True,
                "message": f"Dependency analysis completed for {len(packages)} package(s)",
                "analysis_result": analysis_result
            }
            
        except Exception as e:
            return {"success": False, "error": f"Dependency analysis failed: {str(e)}"}
    
    def _parse_requirements_file(self, requirements_file):
        """è§£ærequirements.txtæ–‡ä»¶"""
        packages = []
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ è¿œç¨‹æ–‡ä»¶è¯»å–é€»è¾‘
            # ç›®å‰ç®€åŒ–å¤„ç†ï¼Œè¿”å›ç©ºåˆ—è¡¨
            print(f"Note: Requirements file parsing not yet implemented for remote files: {requirements_file}")
            return packages
        except Exception as e:
            print(f"Error parsing requirements file: {e}")
            return packages
    
    def _detect_current_environment_packages(self):
        """æ£€æµ‹å½“å‰ç¯å¢ƒçš„å·²å®‰è£…åŒ…"""
        try:
            # è·å–å½“å‰shellä¿¡æ¯
            current_shell = self.main_instance.get_current_shell()
            shell_id = current_shell.get("id", "default_shell") if current_shell else "default_shell"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒ
            try:
                from .venv_operations import VenvOperations
                venv_ops = VenvOperations(self.drive_service, self.main_instance)
                all_states = venv_ops._load_all_venv_states()
                
                current_venv = None
                if shell_id in all_states and all_states[shell_id].get("current_venv"):
                    current_venv = all_states[shell_id]["current_venv"]
                
                if current_venv:
                    # ä»JSONè·å–è™šæ‹Ÿç¯å¢ƒçš„åŒ…ä¿¡æ¯
                    if 'environments' in all_states and current_venv in all_states['environments']:
                        env_data = all_states['environments'][current_venv]
                        return env_data.get('packages', {})
                else:
                    # ç³»ç»Ÿç¯å¢ƒçš„åŸºç¡€åŒ…
                    return {
                        'pip': '23.0.0',
                        'setuptools': '65.0.0'
                    }
            except Exception:
                # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›åŸºç¡€åŒ…
                return {
                    'pip': '23.0.0',
                    'setuptools': '65.0.0'
                }
            
            return {}
        except Exception as e:
            return {}
        
    def _get_pypi_client(self):
        """Get or create PyPI client instance"""
        if self._pypi_client is None:
            try:
                import sys
                import os
                bin_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
                sys.path.insert(0, bin_path)
                from PYPI import PyPIClient
                self._pypi_client = PyPIClient()
            except ImportError:
                print("Warning: PYPI tool not available, falling back to direct API calls")
                self._pypi_client = None
        return self._pypi_client

    def _ensure_pipdeptree_available(self):
        """æ£€æŸ¥pipdeptreeå‘½ä»¤æ˜¯å¦å¯ç”¨"""
        try:
            # Checking if pipdeptree command is available
            import subprocess
            # ç›´æ¥æµ‹è¯•å‘½ä»¤æ˜¯å¦å¯ç”¨ï¼Œè€Œä¸æ˜¯import
            result = subprocess.run(['pipdeptree', '--version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                # pipdeptree command is available
                return True
            else:
                # pipdeptree command failed
                return False
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            # pipdeptree command not found
            print("ğŸ’¡ Please install pipdeptree with: pip install pipdeptree")
            return False

    def _get_package_dependencies_with_pipdeptree(self, package_name, installed_packages=None):
        """ä½¿ç”¨pipdeptreeè·å–å•ä¸ªåŒ…çš„ä¾èµ–ä¿¡æ¯"""
        try:
            # Getting dependencies for package
            
            # é¦–å…ˆæ£€æŸ¥åŒ…æ˜¯å¦åœ¨å·²å®‰è£…åŒ…åˆ—è¡¨ä¸­
            if installed_packages:
                # æ ‡å‡†åŒ–åŒ…åè¿›è¡Œæ¯”è¾ƒ
                pkg_variants = [package_name, package_name.replace('-', '_'), package_name.replace('_', '-')]
                found_in_installed = False
                actual_pkg_name = package_name
                
                for variant in pkg_variants:
                    if variant.lower() in [pkg.lower() for pkg in installed_packages.keys()]:
                        found_in_installed = True
                        # æ‰¾åˆ°å®é™…çš„åŒ…åï¼ˆä¿æŒåŸå§‹å¤§å°å†™ï¼‰
                        for installed_pkg in installed_packages.keys():
                            if installed_pkg.lower() == variant.lower():
                                actual_pkg_name = installed_pkg
                                break
                        break
                
                if not found_in_installed:
                    # Package not found in installed packages
                    return None
                
                # Package found in installed packages
            
            # æ–¹æ³•1ï¼šå°è¯•æœ¬åœ°pipdeptree (å¯èƒ½ä¸ä¼šæ‰¾åˆ°è¿œç¨‹åŒ…ï¼Œä½†å€¼å¾—ä¸€è¯•)
            try:
                import subprocess
                import json
                
                cmd = ['pipdeptree', '-p', package_name, '--json', '--warn', 'silence']
                # Running local command
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                # Local command completed
                
                if result.returncode == 0 and result.stdout.strip():
                    dep_data = json.loads(result.stdout)
                    # Local pipdeptree found packages
                    
                    for pkg_info in dep_data:
                        pkg_name_in_data = pkg_info['package']['package_name']
                        if pkg_name_in_data.lower() == package_name.lower():
                            # Found matching package locally
                            dependencies = []
                            for dep in pkg_info.get('dependencies', []):
                                dependencies.append(dep['package_name'])
                            # Local dependencies found
                            return dependencies
                
                # Package not found in local pipdeptree, trying fallback
                
            except Exception as e:
                # Local pipdeptree failed
                
                # æ–¹æ³•2ï¼šä½¿ç”¨è¿œç¨‹pip showå‘½ä»¤è·å–ä¾èµ–ä¿¡æ¯
                return self._get_dependencies_via_remote_pip_show(package_name)
                
        except Exception as e:
            # Error getting dependencies
            import traceback
            traceback.print_exc()
            return None

    def _get_dependencies_via_remote_pip_show(self, package_name):
        """é€šè¿‡è¿œç¨‹pip showå‘½ä»¤è·å–åŒ…ä¾èµ–ä¿¡æ¯"""
        try:
            # Using remote pip show for package
            
            # æ„å»ºè¿œç¨‹pip showå‘½ä»¤
            pip_show_cmd = f"pip show {package_name}"
            result = self.main_instance.execute_generic_remote_command("bash", ["-c", pip_show_cmd])
            
            if not result.get("success"):
                # Remote pip show failed
                return []
            
            output = result.get("stdout", "")
            # pip show output received
            
            # è§£æpip showè¾“å‡ºä¸­çš„Requireså­—æ®µ
            dependencies = []
            for line in output.split('\n'):
                if line.startswith('Requires:'):
                    requires_text = line.replace('Requires:', '').strip()
                    if requires_text and requires_text != 'None':
                        # è§£æä¾èµ–ï¼Œå¤„ç†ç‰ˆæœ¬çº¦æŸ
                        for dep in requires_text.split(','):
                            dep = dep.strip()
                            if dep:
                                # ç§»é™¤ç‰ˆæœ¬çº¦æŸï¼Œåªä¿ç•™åŒ…å
                                dep_name = dep.split('>=')[0].split('<=')[0].split('==')[0].split('>')[0].split('<')[0].split('!=')[0].split('~=')[0].strip()
                                if dep_name:
                                    dependencies.append(dep_name)
                    break
            
            # Remote pip show dependencies found
            return dependencies
            
        except Exception as e:
            # Remote pip show error
            return []

    def _get_pypi_dependencies_with_all_sizes(self, package_name):
        """
        ä»PyPI JSON APIè·å–åŒ…çš„ç›´æ¥ä¾èµ–ä¿¡æ¯ï¼ŒåŒæ—¶è·å–æ¯ä¸ªä¾èµ–çš„å¤§å°
        è¿™ç®—ä½œä¸€æ¬¡å®Œæ•´çš„APIè°ƒç”¨
        
        Args:
            package_name: åŒ…å
            
        Returns:
            tuple: (ä¾èµ–åˆ—è¡¨, åŒ…å¤§å°, ä¾èµ–å¤§å°å­—å…¸)
                   å¦‚æœå¤±è´¥è¿”å›(None, 0, {})
        """
        try:
            pypi_client = self._get_pypi_client()
            if pypi_client:
                # Use PYPI tool
                dependencies, package_size = pypi_client.get_package_dependencies_with_size(package_name)
                return dependencies, package_size, {}  # è¿”å›ç©ºçš„dependency_sizes
            else:
                # Fallback to direct API calls
                import requests
                
                # é¦–å…ˆè·å–ä¸»åŒ…ä¿¡æ¯
                api_url = f"https://pypi.org/pypi/{package_name}/json"
                response = requests.get(api_url, timeout=10)
                response.raise_for_status()
                
                data = response.json()
                
                # Get package size from latest release
                package_size = 0
                releases = data.get("releases", {})
                info = data.get("info", {})
                
                # Try to get size from the latest version
                latest_version = info.get("version", "")
                if latest_version and latest_version in releases:
                    files = releases[latest_version]
                    if files:
                        package_size = max((f.get("size", 0) for f in files), default=0)
                
                # Get dependencies
                requires_dist = data.get("info", {}).get("requires_dist")
                
                if requires_dist is None:
                    return [], package_size, {}
                
                # è§£æä¾èµ–è§„æ ¼ï¼Œæå–åŒ…å
                dependencies = []
                for dep_spec in requires_dist:
                    dep_spec = dep_spec.split(';')[0].strip()
                    import re
                    match = re.match(r'^([a-zA-Z0-9_-]+)', dep_spec)
                    if match:
                        dep_name = match.group(1)
                        dependencies.append(dep_name)
                
                # ä¸è·å–ä¾èµ–çš„å¤§å°ï¼Œåªè¿”å›ä¾èµ–åˆ—è¡¨å’Œä¸»åŒ…å¤§å°
                # ä¾èµ–çš„å¤§å°å°†åœ¨åç»­åˆ†ææ—¶è·å–
                return dependencies, package_size, {}
            
        except Exception as e:
            return None, 0, {}

    def _get_pypi_dependencies_with_size(self, package_name):
        """
        ä»PyPI JSON APIè·å–åŒ…çš„ç›´æ¥ä¾èµ–ä¿¡æ¯å’ŒåŒ…å¤§å°
        
        Args:
            package_name: åŒ…å
            
        Returns:
            tuple: (ä¾èµ–åŒ…ååˆ—è¡¨, åŒ…å¤§å°(bytes))ï¼Œå¦‚æœå¤±è´¥è¿”å›(None, 0)
        """
        try:
            pypi_client = self._get_pypi_client()
            if pypi_client:
                # Use PYPI tool
                return pypi_client.get_package_dependencies_with_size(package_name)
            else:
                # Fallback to direct API calls
                import requests
                
                # Getting PyPI dependencies and size
                api_url = f"https://pypi.org/pypi/{package_name}/json"
                
                response = requests.get(api_url, timeout=10)
                response.raise_for_status()
                
                data = response.json()
                
                # Get package size from latest release
                package_size = 0
                releases = data.get("releases", {})
                info = data.get("info", {})
                
                # Try to get size from the latest version
                latest_version = info.get("version", "")
                if latest_version and latest_version in releases:
                    files = releases[latest_version]
                    if files:
                        # Get the largest file size (usually the wheel or tar.gz)
                        package_size = max((f.get("size", 0) for f in files), default=0)
                
                # Get dependencies
                requires_dist = data.get("info", {}).get("requires_dist")
                
                if requires_dist is None:
                    # No requires_dist found
                    return [], package_size
                
                # è§£æä¾èµ–è§„æ ¼ï¼Œæå–åŒ…å
                dependencies = []
                for dep_spec in requires_dist:
                    # å¤„ç†ä¾èµ–è§„æ ¼ï¼Œå¦‚ "numpy>=1.0.0" -> "numpy"
                    # ä¹Ÿå¤„ç†æ¡ä»¶ä¾èµ–ï¼Œå¦‚ "pytest; extra == 'test'" -> "pytest"
                    dep_spec = dep_spec.split(';')[0].strip()  # ç§»é™¤æ¡ä»¶éƒ¨åˆ†
                    
                    # æå–åŒ…åï¼ˆç§»é™¤ç‰ˆæœ¬çº¦æŸï¼‰
                    import re
                    match = re.match(r'^([a-zA-Z0-9_-]+)', dep_spec)
                    if match:
                        dep_name = match.group(1)
                        dependencies.append(dep_name)
                
                # PyPI dependencies and size found
                return dependencies, package_size
            
        except Exception as e:
            # Error getting PyPI data
            return None, 0

    def _smart_dependency_analysis(self, packages, max_calls=10, interface_mode=False, installed_packages=None):
        """
        æ™ºèƒ½ä¾èµ–åˆ†æç­–ç•¥ï¼Œé™åˆ¶APIè°ƒç”¨æ¬¡æ•°ï¼ŒåŸºäºåŒ…å¤§å°ä¼˜åŒ–é˜Ÿåˆ—
        
        Args:
            packages: è¦åˆ†æçš„åŒ…åˆ—è¡¨
            max_calls: æœ€å¤§APIè°ƒç”¨æ¬¡æ•° (n)
            interface_mode: æ¥å£æ¨¡å¼ï¼Œè¿”å›æ¯å±‚éœ€è¦ä¸‹è½½çš„åŒ…
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
            
        Returns:
            dict: åˆ†æç»“æœï¼ŒåŒ…å«ä¾èµ–æ ‘å’Œå±‚çº§ä¿¡æ¯
        """
        try:
            import heapq
            from collections import defaultdict
            
            # åˆå§‹åŒ–æ•°æ®ç»“æ„
            D = {}  # package name -> dependencies mapping  
            Q = []  # priority queue: (-size, package_name) for max-heap behavior
            package_sizes = {}  # package -> size mapping
            layers = defaultdict(set)  # layer -> set of packages
            
            # å°†åˆå§‹åŒ…åŠ å…¥Layer 0
            current_packages = [pkg.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0] for pkg in packages]
            layers[0].update(current_packages)
            
            # å°†åˆå§‹åŒ…åŠ å…¥é˜Ÿåˆ—ï¼Œä¼˜å…ˆçº§æœ€é«˜
            for pkg in current_packages:
                heapq.heappush(Q, (-float('inf'), pkg))
                
            i = 0  # å½“å‰APIè°ƒç”¨æ¬¡æ•°
            
            while Q and i < max_calls:
                l = max_calls - i  # é˜Ÿåˆ—å‰©ä½™å®¹é‡
                
                # å–å‡ºä¼˜å…ˆçº§æœ€é«˜çš„åŒ…
                neg_size, current_pkg = heapq.heappop(Q)
                
                if current_pkg in D:
                    continue  # å·²ç»åˆ†æè¿‡äº†
                    
                # è°ƒç”¨æ–°çš„APIè·å–ä¾èµ–å’Œæ‰€æœ‰å¤§å°ä¿¡æ¯
                deps, pkg_size, dep_sizes = self._get_pypi_dependencies_with_all_sizes(current_pkg)
                i += 1
                
                # æ›´æ–°æ•°æ®ç»“æ„
                package_sizes[current_pkg] = pkg_size
                package_sizes.update(dep_sizes)  # æ›´æ–°æ‰€æœ‰ä¾èµ–çš„å¤§å°
                
                if deps is not None:
                    D[current_pkg] = deps
                    
                    # å¤„ç†æ–°å‘ç°çš„ä¾èµ–S
                    S = deps
                    for dep in S:
                        if dep not in D and dep not in [item[1] for item in Q]:
                            # æ£€æŸ¥æ˜¯å¦åº”è¯¥åŠ å…¥é˜Ÿåˆ—Q
                            # è§„åˆ™ï¼š(1)ä¸å­˜åœ¨Dä¸­ (2)ä¸å­˜åœ¨Qä¸­ (3)æ¯”Qçš„ç¬¬lä¸ªå…ƒç´ å¤§
                            l = max_calls - i  # æ›´æ–°lå€¼
                            if l > 0:
                                dep_size = dep_sizes.get(dep, 0)
                                if len(Q) < l:
                                    # é˜Ÿåˆ—æœªæ»¡ï¼Œç›´æ¥åŠ å…¥
                                    heapq.heappush(Q, (-dep_size, dep))
                                elif Q:
                                    # é˜Ÿåˆ—å·²æ»¡ï¼Œæ£€æŸ¥æ˜¯å¦æ¯”æœ€å°çš„å¤§
                                    min_size = -Q[0][0] if Q else 0
                                    if dep_size > min_size:
                                        heapq.heappop(Q)  # ç§»é™¤æœ€å°çš„
                                        heapq.heappush(Q, (-dep_size, dep))
                                
                                # ç»´æŠ¤é˜Ÿåˆ—å¤§å°ä¸ºl
                                while len(Q) > l:
                                    heapq.heappop(Q)
                else:
                    # APIå¤±è´¥ï¼Œå°è¯•fallback
                    fallback_deps = self._get_package_dependencies_with_pipdeptree(current_pkg, installed_packages)
                    if fallback_deps:
                        D[current_pkg] = fallback_deps
                    else:
                        D[current_pkg] = []
            
            # ç”Ÿæˆä¾èµ–æ ‘å’Œå±‚çº§ä¿¡æ¯
            decomposed = set()
            
            def build_tree_and_layers(pkg, current_layer=0, visited=None):
                if visited is None:
                    visited = set()
                    
                if pkg in visited:
                    return {}  # é¿å…å¾ªç¯ä¾èµ–
                    
                visited.add(pkg)
                
                if pkg in D and pkg not in decomposed:
                    decomposed.add(pkg)
                    deps = D[pkg]
                    
                    # å°†ä¾èµ–æ·»åŠ åˆ°ä¸‹ä¸€å±‚
                    if deps:
                        next_layer = current_layer + 1
                        layers[next_layer].update(deps)
                        
                    result = {
                        'dependencies': deps,
                        'size': package_sizes.get(pkg, 0),
                        'children': {}
                    }
                    
                    for dep in deps:
                        result['children'][dep] = build_tree_and_layers(dep, current_layer + 1, visited.copy())
                    
                    return result
                else:
                    return {
                        'dependencies': [],
                        'size': package_sizes.get(pkg, 0),
                        'children': {}
                    }
            
            # ä¸ºæ¯ä¸ªåˆå§‹åŒ…æ„å»ºæ ‘
            result = {
                'trees': {},
                'layers': {},
                'package_sizes': package_sizes,
                'total_calls': i,
                'analyzed_packages': len(D),
                'D': D,  # è°ƒè¯•ç”¨
                'Q': [(size, pkg) for size, pkg in Q]  # è°ƒè¯•ç”¨
            }
            
            for pkg in current_packages:
                result['trees'][pkg] = build_tree_and_layers(pkg)
            
            # è½¬æ¢layersä¸ºlistå¹¶å»é‡
            for layer_num in layers:
                result['layers'][layer_num] = list(layers[layer_num])
            
            if interface_mode:
                # æ¥å£æ¨¡å¼ï¼šè¿”å›æ¯å±‚éœ€è¦ä¸‹è½½çš„åŒ…
                result['download_layers'] = result['layers'].copy()
                    
            return result
            
        except Exception as e:
            # Smart analysis failed, fallback to simple analysis
            return {
                'trees': {},
                'layers': {0: current_packages},
                'package_sizes': {},
                'total_calls': 0,
                'analyzed_packages': 0,
                'error': str(e)
            }

    def _depth_based_dependency_analysis(self, packages, max_depth=1, interface_mode=False, installed_packages=None):
        """
        åŸºäºæ·±åº¦å’ŒåŒ…æ•°é‡é™åˆ¶çš„ä¾èµ–åˆ†æç­–ç•¥
        
        Args:
            packages: è¦åˆ†æçš„åŒ…åˆ—è¡¨
            max_depth: æœ€å¤§åˆ†ææ·±åº¦
            interface_mode: æ¥å£æ¨¡å¼ï¼Œè¿”å›æ¯å±‚éœ€è¦ä¸‹è½½çš„åŒ…
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
            
        Returns:
            dict: åˆ†æç»“æœï¼ŒåŒ…å«ä¾èµ–æ ‘å’Œå±‚çº§ä¿¡æ¯
        """
        try:
            import concurrent.futures
            from collections import defaultdict
            import time
            
            # åˆå§‹åŒ–æ•°æ®ç»“æ„
            # Q: {package_name: {'physical_size': int, 'logical_size': None, 'dependencies': []}}
            Q = {}
            R = []  # å¾…åˆ†æçš„åŒ…åˆ—è¡¨
            layers = defaultdict(set)  # layer -> set of packages
            
            # æ¸…ç†åŒ…åå¹¶åˆå§‹åŒ–
            current_packages = [pkg.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0] for pkg in packages]
            layers[0].update(current_packages)
            
            # åˆå§‹åŒ–Qå’ŒR
            for pkg in current_packages:
                Q[pkg] = {
                    'physical_size': None,
                    'logical_size': None, 
                    'dependencies': []
                }
                R.append(pkg)
            
            total_calls = 0
            current_depth = 0
            analysis_start_time = time.time()
            
            # ä¸»åˆ†æå¾ªç¯
            while R and len(Q) < 1000 and current_depth <= max_depth:
                # print(f"Analyzing depth {current_depth}: {len(R)} packages to analyze...")
                
                # å‡†å¤‡è¿™ä¸€è½®è¦åˆ†æçš„åŒ…ï¼ˆæœ€å¤š40ä¸ªï¼‰
                batch_size = min(40, len(R))
                current_batch = R[:batch_size]
                R = R[batch_size:]  # ç§»é™¤å·²å¤„ç†çš„åŒ…
                
                # è¿‡æ»¤æ‰å·²ç»åˆ†æè¿‡ä¾èµ–çš„åŒ…ï¼ˆdependenciesä¸ä¸ºç©ºçš„åŒ…ï¼‰
                packages_to_analyze = []
                for pkg in current_batch:
                    if pkg not in Q:
                        packages_to_analyze.append(pkg)
                    elif len(Q[pkg]['dependencies']) == 0:  # dependenciesä¸ºç©ºï¼Œè¡¨ç¤ºå°šæœªåˆ†æä¾èµ–
                        packages_to_analyze.append(pkg)
                
                if not packages_to_analyze:
                    if not R:  # Rç©ºäº†ï¼Œè¿›å…¥ä¸‹ä¸€å±‚
                        current_depth += 1
                        if current_depth <= max_depth:
                            # æ”¶é›†ä¸‹ä¸€å±‚çš„åŒ…
                            R_prime = []
                            for pkg_name, pkg_data in Q.items():
                                if pkg_data['dependencies']:
                                    for dep in pkg_data['dependencies']:
                                        if dep not in Q and dep not in R_prime:
                                            R_prime.append(dep)
                            
                            R = R_prime
                            if R:
                                layers[current_depth].update(R)
                    continue
                
                # å¹¶è¡Œåˆ†æå½“å‰æ‰¹æ¬¡
                batch_start_time = time.time()
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=min(40, len(packages_to_analyze))) as executor:
                    future_to_package = {
                        executor.submit(self._get_pypi_dependencies_with_all_sizes, pkg): pkg 
                        for pkg in packages_to_analyze
                    }
                    
                    for future in concurrent.futures.as_completed(future_to_package):
                        package_name = future_to_package[future]
                        try:
                            deps, pkg_size, dep_sizes = future.result()
                            total_calls += 1
                            
                            # æ›´æ–°Q
                            if package_name not in Q:
                                Q[package_name] = {
                                    'physical_size': pkg_size,
                                    'logical_size': None,
                                    'dependencies': deps or []
                                }
                            else:
                                Q[package_name]['physical_size'] = pkg_size
                                Q[package_name]['dependencies'] = deps or []
                            
                            # å°†æ–°å‘ç°çš„ä¾èµ–åŠ å…¥Qï¼ˆå¦‚æœè¿˜æœ‰ç©ºé—´ï¼‰ï¼Œä½†ä¸è®¾ç½®dependencies
                            # è¿™æ ·å®ƒä»¬åœ¨ä¸‹ä¸€å±‚ä»ç„¶å¯ä»¥è¢«åˆ†æ
                            if deps:
                                for dep in deps:
                                    if dep not in Q and len(Q) < 1000:
                                        Q[dep] = {
                                            'physical_size': None,  # ä¾èµ–çš„å¤§å°æœªçŸ¥ï¼Œéœ€è¦åç»­åˆ†æ
                                            'logical_size': None,
                                            'dependencies': []  # ç©ºåˆ—è¡¨ï¼Œè¡¨ç¤ºå°šæœªåˆ†æä¾èµ–
                                        }
                            
                        except Exception as e:
                            print(f"Error analyzing {package_name}: {e}")
                            if package_name not in Q:
                                Q[package_name] = {
                                    'physical_size': 0,
                                    'logical_size': None,
                                    'dependencies': []
                                }
                
                batch_duration = time.time() - batch_start_time
                print(f"    Processed {len(packages_to_analyze)} packages in {batch_duration:.2f}s")
                
                # å¦‚æœè¿™æ‰¹å¤„ç†æ—¶é—´å°‘äº1ç§’ï¼Œç­‰å¾…åˆ°1ç§’
                if batch_duration < 1.0:
                    time.sleep(1.0 - batch_duration)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›å…¥ä¸‹ä¸€å±‚
                if not R and current_depth < max_depth:
                    current_depth += 1
                    # æ”¶é›†ä¸‹ä¸€å±‚çš„åŒ…ï¼šä»å½“å‰å±‚çš„åŒ…ä¸­æ‰¾å‡ºå®ƒä»¬çš„ä¾èµ–
                    R_prime = []
                    current_layer_packages = layers.get(current_depth - 1, [])
                    
                    for pkg_name in current_layer_packages:
                        if pkg_name in Q and Q[pkg_name]['dependencies']:
                            for dep in Q[pkg_name]['dependencies']:
                                # åªæ·»åŠ å°šæœªåˆ†æè¿‡ä¾èµ–çš„åŒ…ï¼ˆdependenciesä¸ºç©ºä¸”ä¸åœ¨R_primeä¸­ï¼‰
                                if dep in Q and len(Q[dep]['dependencies']) == 0 and dep not in R_prime:
                                    R_prime.append(dep)
                                elif dep not in Q:
                                    R_prime.append(dep)
                                    # ç¡®ä¿åœ¨Qä¸­æœ‰æ¡ç›®
                                    Q[dep] = {
                                        'physical_size': None,
                                        'logical_size': None,
                                        'dependencies': []
                                    }
                    
                    R = R_prime
                    if R:
                        layers[current_depth].update(R)
                        print(f"Moving to depth {current_depth} with {len(R)} new packages: {R[:5]}{'...' if len(R) > 5 else ''}")
            
            analysis_end_time = time.time()
            total_analysis_time = analysis_end_time - analysis_start_time
            
            # è®¡ç®—é€»è¾‘å¤§å°
            def calculate_logical_size(pkg_name, visited=None):
                if visited is None:
                    visited = set()
                
                if pkg_name in visited or pkg_name not in Q:
                    return 0
                
                visited.add(pkg_name)
                pkg_data = Q[pkg_name]
                
                if pkg_data['logical_size'] is not None:
                    return pkg_data['logical_size']
                
                # è®¡ç®—é€»è¾‘å¤§å° = ç‰©ç†å¤§å° + æ‰€æœ‰å­åŒ…çš„é€»è¾‘å¤§å°
                logical_size = pkg_data['physical_size'] if pkg_data['physical_size'] is not None else 0
                
                for dep in pkg_data['dependencies']:
                    if dep in Q:
                        logical_size += calculate_logical_size(dep, visited.copy())
                    # å¦‚æœä¾èµ–ä¸åœ¨Qä¸­ï¼ˆç”±äºé™åˆ¶ï¼‰ï¼Œä½¿ç”¨å…¶ç‰©ç†å¤§å°
                
                pkg_data['logical_size'] = logical_size
                return logical_size
            
            # ä¸ºæ‰€æœ‰åŒ…è®¡ç®—é€»è¾‘å¤§å°
            for pkg_name in current_packages:
                calculate_logical_size(pkg_name)
            
            # æ„å»ºç»“æœ
            result = {
                'trees': {},
                'layers': {},
                'package_sizes': {pkg: (data['physical_size'] if data['physical_size'] is not None else 0) for pkg, data in Q.items()},
                'logical_sizes': {pkg: (data['logical_size'] if data['logical_size'] is not None else 0) for pkg, data in Q.items()},
                'total_calls': total_calls,
                'analyzed_packages': len(Q),
                'total_time': total_analysis_time,
                'Q': Q  # è°ƒè¯•ç”¨
            }
            
            # æ„å»ºä¾èµ–æ ‘
            def build_tree(pkg_name, visited=None, max_tree_depth=3):
                if visited is None:
                    visited = set()
                
                if pkg_name in visited or pkg_name not in Q:
                    return {}
                
                visited.add(pkg_name)
                pkg_data = Q[pkg_name]
                
                result_tree = {
                    'dependencies': pkg_data['dependencies'],
                    'size': pkg_data['physical_size'] if pkg_data['physical_size'] is not None else 0,
                    'logical_size': pkg_data['logical_size'] if pkg_data['logical_size'] is not None else 0,
                    'children': {}
                }
                
                if len(visited) < max_tree_depth:
                    for dep in pkg_data['dependencies']:
                        result_tree['children'][dep] = build_tree(dep, visited.copy(), max_tree_depth)
                
                return result_tree
            
            for pkg in current_packages:
                result['trees'][pkg] = build_tree(pkg)
            
            # è½¬æ¢layersä¸ºlist
            for layer_num in layers:
                result['layers'][layer_num] = list(layers[layer_num])
            
            if interface_mode:
                result['download_layers'] = result['layers'].copy()
                    
            return result
            
        except Exception as e:
            # Analysis failed, fallback to simple analysis
            return {
                'trees': {},
                'layers': {0: current_packages},
                'package_sizes': {},
                'logical_sizes': {},
                'total_calls': 0,
                'analyzed_packages': 0,
                'error': str(e)
            }

    def _get_pypi_dependencies(self, package_name):
        """
        ä»PyPI JSON APIè·å–åŒ…çš„ç›´æ¥ä¾èµ–ä¿¡æ¯
        
        Args:
            package_name: åŒ…å
            
        Returns:
            list: ä¾èµ–åŒ…ååˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            import requests
            
            # Getting PyPI dependencies
            api_url = f"https://pypi.org/pypi/{package_name}/json"
            
            response = requests.get(api_url, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            requires_dist = data.get("info", {}).get("requires_dist")
            
            if requires_dist is None:
                # No requires_dist found
                return []
            
            # è§£æä¾èµ–è§„æ ¼ï¼Œæå–åŒ…å
            dependencies = []
            for dep_spec in requires_dist:
                # å¤„ç†ä¾èµ–è§„æ ¼ï¼Œå¦‚ "numpy>=1.0.0" -> "numpy"
                # ä¹Ÿå¤„ç†æ¡ä»¶ä¾èµ–ï¼Œå¦‚ "pytest; extra == 'test'" -> "pytest"
                dep_spec = dep_spec.split(';')[0].strip()  # ç§»é™¤æ¡ä»¶éƒ¨åˆ†
                
                # æå–åŒ…åï¼ˆç§»é™¤ç‰ˆæœ¬çº¦æŸï¼‰
                import re
                match = re.match(r'^([a-zA-Z0-9_-]+)', dep_spec)
                if match:
                    dep_name = match.group(1)
                    dependencies.append(dep_name)
            
            # PyPI dependencies found
            return dependencies
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                # Package not found on PyPI
                return None
            else:
                # HTTP error for package
                return None
        except Exception as e:
            # Error getting PyPI dependencies
            return None

    def _analyze_dependencies_recursive(self, packages, max_depth=2, installed_packages=None):
        """
        é€’å½’åˆ†æåŒ…ä¾èµ–å…³ç³»ï¼ˆä½¿ç”¨PyPI API + å¹¶è¡Œå¤„ç†ï¼‰
        
        Args:
            packages: è¦åˆ†æçš„åŒ…åˆ—è¡¨
            max_depth: æœ€å¤§é€’å½’æ·±åº¦
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
            
        Returns:
            dict: é€’å½’ä¾èµ–åˆ†æç»“æœ
        """
        try:
            import concurrent.futures
            import threading
            from collections import defaultdict, deque
            
            # Starting recursive dependency analysis
            
            # ç”¨äºå­˜å‚¨æ‰€æœ‰ä¾èµ–å…³ç³»
            all_dependencies = {}  # {package: [direct_deps]}
            dependencies_by_level = defaultdict(lambda: defaultdict(list))  # {package: {level: [deps]}}
            processed_packages = set()
            lock = threading.Lock()
            
            def process_package_batch(package_list, current_level):
                """å¹¶è¡Œå¤„ç†ä¸€æ‰¹åŒ…"""
                if current_level > max_depth:
                    return []
                
                # Processing dependency level
                
                next_level_packages = []
                
                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–ä¾èµ–
                with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_package = {
                        executor.submit(self._get_pypi_dependencies, pkg): pkg 
                        for pkg in package_list
                    }
                    
                    # æ”¶é›†ç»“æœ
                    for future in concurrent.futures.as_completed(future_to_package):
                        pkg = future_to_package[future]
                        try:
                            deps = future.result()
                            
                            with lock:
                                if deps is not None:
                                    all_dependencies[pkg] = deps
                                    dependencies_by_level[pkg][current_level] = deps
                                    
                                    # æ·»åŠ åˆ°ä¸‹ä¸€å±‚å¤„ç†é˜Ÿåˆ—
                                    for dep in deps:
                                        if dep not in processed_packages:
                                            next_level_packages.append(dep)
                                            processed_packages.add(dep)
                                else:
                                    # PyPIæŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•fallbackæ–¹æ³•
                                    # PyPI failed, trying fallback
                                    fallback_deps = self._get_package_dependencies_with_pipdeptree(pkg, installed_packages)
                                    if fallback_deps:
                                        all_dependencies[pkg] = fallback_deps
                                        dependencies_by_level[pkg][current_level] = fallback_deps
                                        for dep in fallback_deps:
                                            if dep not in processed_packages:
                                                next_level_packages.append(dep)
                                                processed_packages.add(dep)
                                    else:
                                        all_dependencies[pkg] = []
                                        dependencies_by_level[pkg][current_level] = []
                                
                                processed_packages.add(pkg)
                                
                        except Exception as e:
                            # Error processing package
                            with lock:
                                all_dependencies[pkg] = []
                                dependencies_by_level[pkg][current_level] = []
                
                return next_level_packages
            
            # å¼€å§‹é€’å½’å¤„ç†
            current_level = 0
            current_packages = [pkg.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0] for pkg in packages]
            
            while current_packages and current_level <= max_depth:
                current_packages = process_package_batch(current_packages, current_level)
                current_level += 1
            
            # ç»Ÿè®¡ç»“æœ
            all_deps = set()
            dependency_count = defaultdict(int)
            
            for pkg_deps in all_dependencies.values():
                for dep in pkg_deps:
                    all_deps.add(dep)
                    dependency_count[dep] += 1
            
            # è®¡ç®—å…±äº«ä¾èµ–
            shared_deps = [(dep, count) for dep, count in dependency_count.items() if count > 1]
            shared_deps.sort(key=lambda x: x[1], reverse=True)
            
            result = {
                "dependencies": all_dependencies,
                "dependencies_by_level": dict(dependencies_by_level),
                "total_unique_deps": len(all_deps),
                "shared_dependencies": shared_deps,
                "dependency_count": dict(dependency_count)
            }
            
            # Recursive analysis complete
            
            return result
            
        except Exception as e:
            # Recursive dependency analysis failed
            import traceback
            traceback.print_exc()
            return self._fallback_dependency_analysis(packages)

    def _analyze_package_dependencies(self, packages, max_depth=2, installed_packages=None):
        """
        åˆ†æåŒ…ä¾èµ–å…³ç³»ï¼ˆä¼˜å…ˆä½¿ç”¨PyPI APIï¼Œpipdeptreeä½œä¸ºfallbackï¼‰
        
        Args:
            packages: è¦åˆ†æçš„åŒ…åˆ—è¡¨
            max_depth: åˆ†ææ·±åº¦
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
            
        Returns:
            dict: ä¾èµ–åˆ†æç»“æœ
        """
        try:
            # Dependency analysis starting (debug output removed)
            
            # ä½¿ç”¨æ–°çš„é€’å½’åˆ†ææ–¹æ³•
            return self._analyze_dependencies_recursive(packages, max_depth, installed_packages)
            
        except Exception as e:
            # Dependency analysis failed
            import traceback
            traceback.print_exc()
            return self._fallback_dependency_analysis(packages)

    def _fallback_dependency_analysis(self, packages):
        """å›é€€çš„ä¾èµ–åˆ†æï¼ˆå½“pipdeptreeä¸å¯ç”¨æ—¶ï¼‰"""
        print("Using fallback dependency analysis")
        dependencies = {}
        dependencies_by_level = {}
        
        for package in packages:
            dependencies[package] = []
            dependencies_by_level[package] = {0: []}
        
        return {
            "dependencies": dependencies,
            "dependencies_by_level": dependencies_by_level,
            "total_unique_deps": 0,
            "shared_dependencies": [],
            "dependency_count": {}
        }

    def _normalize_package_name(self, package_name):
        """
        æ ‡å‡†åŒ–åŒ…åè¿›è¡Œæ¯”è¾ƒ
        å°†ä¸‹åˆ’çº¿è½¬æ¢ä¸ºè¿å­—ç¬¦ï¼Œå¹¶è½¬æ¢ä¸ºå°å†™
        """
        if not package_name:
            return ""
        # ç§»é™¤ç‰ˆæœ¬ä¿¡æ¯
        base_name = package_name.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
        # å°†ä¸‹åˆ’çº¿è½¬æ¢ä¸ºè¿å­—ç¬¦ï¼Œè½¬æ¢ä¸ºå°å†™
        normalized = base_name.replace('_', '-').lower().strip()
        return normalized

    def _show_dependency_tree(self, packages_args, installed_packages=None):
        """
        æ˜¾ç¤ºåŒ…çš„ä¾èµ–æ ‘ç»“æ„
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆåŒ…æ‹¬--show-depsé€‰é¡¹ï¼‰
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ï¼Œå¦‚æœæä¾›åˆ™ä¸é‡æ–°æ‰«æ
            
        Returns:
            dict: ä¾èµ–æ ‘æ˜¾ç¤ºç»“æœ
        """
        try:
            # è¿‡æ»¤å‡ºå®é™…çš„åŒ…åï¼ˆæ’é™¤é€‰é¡¹ï¼‰æˆ–å¤„ç†requirements.txt
            packages = []
            max_depth = 2  # é»˜è®¤æ˜¾ç¤º2å±‚
            
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg == '--show-deps':
                    i += 1
                    continue
                elif arg.startswith('--depth='):
                    max_depth = int(arg.split('=')[1])
                    i += 1
                    continue
                elif arg == '-r' or arg == '--requirement':
                    # å¤„ç†requirements.txtæ–‡ä»¶
                    if i + 1 < len(packages_args):
                        requirements_file = packages_args[i + 1]
                        packages_from_file = self._parse_requirements_file(requirements_file)
                        packages.extend(packages_from_file)
                        i += 2
                    else:
                        i += 1
                elif arg.startswith('-r'):
                    # å¤„ç† -rrequirements.txt æ ¼å¼
                    requirements_file = arg[2:]  # å»æ‰-r
                    packages_from_file = self._parse_requirements_file(requirements_file)
                    packages.extend(packages_from_file)
                    i += 1
                elif arg.endswith('.txt') and ('requirements' in arg.lower() or 'req' in arg.lower()):
                    # ç›´æ¥æŒ‡å®šrequirementsæ–‡ä»¶
                    packages_from_file = self._parse_requirements_file(arg)
                    packages.extend(packages_from_file)
                    i += 1
                elif arg.startswith('-'):
                    # è·³è¿‡å…¶ä»–é€‰é¡¹
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        i += 2
                    else:
                        i += 1
                else:
                    packages.append(arg)
                    i += 1
            
            if not packages:
                return {
                    "success": False,
                    "error": "No packages specified for dependency tree analysis"
                }
            
            # è§£æ--depthé€‰é¡¹ï¼Œé»˜è®¤ä¸º1
            max_depth = 1  # é»˜è®¤å€¼
            for i, arg in enumerate(packages_args):
                if arg.startswith('--depth='):
                    max_depth = int(arg.split('=')[1])
                    packages_args.pop(i)
                    break
                elif arg == '--depth' and i + 1 < len(packages_args):
                    max_depth = int(packages_args[i + 1])
                    packages_args.pop(i + 1)
                    packages_args.pop(i)
                    break
            
            # é‡æ–°è§£æåŒ…åˆ—è¡¨ï¼ˆç§»é™¤äº†--depthé€‰é¡¹åï¼‰
            packages = []
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg == '--show-deps':
                    i += 1
                    continue
                elif arg.startswith('--depth='):
                    i += 1
                    continue
                elif arg == '-r' or arg == '--requirement':
                    if i + 1 < len(packages_args):
                        requirements_file = packages_args[i + 1]
                        packages_from_file = self._parse_requirements_file(requirements_file)
                        packages.extend(packages_from_file)
                        i += 2
                    else:
                        i += 1
                elif arg.startswith('-r'):
                    requirements_file = arg[2:]
                    packages_from_file = self._parse_requirements_file(requirements_file)
                    packages.extend(packages_from_file)
                    i += 1
                elif arg.endswith('.txt') and ('requirements' in arg.lower() or 'req' in arg.lower()):
                    packages_from_file = self._parse_requirements_file(arg)
                    packages.extend(packages_from_file)
                    i += 1
                elif arg.startswith('-'):
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        i += 2
                    else:
                        i += 1
                else:
                    packages.append(arg)
                    i += 1
            
            print(f"Analyzing dependency tree (max depth {max_depth})...")
            
            # è·å–å·²å®‰è£…åŒ…çš„ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨æä¾›çš„åŒ…ä¿¡æ¯ï¼Œé¿å…é‡å¤æ‰«æï¼‰
            if installed_packages is None:
                installed_packages = self._detect_current_environment_packages(None)
            
            # ä½¿ç”¨åŸºäºæ·±åº¦çš„ä¾èµ–åˆ†æ
            smart_analysis = self._depth_based_dependency_analysis(
                packages, 
                max_depth=max_depth, 
                interface_mode=False, 
                installed_packages=installed_packages
            )
            
            # æ˜¾ç¤ºåˆ†æç»Ÿè®¡
            total_calls = smart_analysis.get('total_calls', 0)
            analyzed_packages = smart_analysis.get('analyzed_packages', 0)
            total_time = smart_analysis.get('total_time', 0)
            print(f"Analysis completed: {total_calls} API calls, {analyzed_packages} packages analyzed in {total_time:.2f}s\n")
            
            # æ˜¾ç¤ºæ™ºèƒ½ä¾èµ–æ ‘
            self._display_smart_dependency_tree(smart_analysis, installed_packages)
            
            return {
                "success": True,
                "message": f"Smart dependency tree analysis completed for {len(packages)} package(s)",
                "smart_analysis": smart_analysis
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Dependency tree analysis failed: {str(e)}"
            }
    
    def _display_smart_dependency_tree(self, smart_analysis, installed_packages=None):
        """
        æ˜¾ç¤ºæ™ºèƒ½ä¾èµ–åˆ†æç»“æœï¼ŒåŒ…å«åŒ…å¤§å°å’Œå±‚çº§ä¿¡æ¯
        
        Args:
            smart_analysis: æ™ºèƒ½åˆ†æç»“æœ
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
        """
        def format_size(size_bytes):
            """æ ¼å¼åŒ–åŒ…å¤§å°æ˜¾ç¤º"""
            if size_bytes == 0:
                return ""
            elif size_bytes < 1024:
                return f" ({size_bytes}B)"
            elif size_bytes < 1024 * 1024:
                return f" ({size_bytes/1024:.1f}KB)"
            else:
                return f" ({size_bytes/(1024*1024):.1f}MB)"
        
        def format_logical_size(physical_size, logical_size):
            """æ ¼å¼åŒ–é€»è¾‘å¤§å°æ˜¾ç¤ºï¼ˆç‰©ç†å¤§å°â†’é€»è¾‘å¤§å°ï¼‰"""
            if logical_size and logical_size != physical_size and logical_size > physical_size:
                if logical_size < 1024*1024:
                    return f" ({physical_size/1024:.1f}KBâ†’{logical_size/1024:.1f}KB)"
                else:
                    return f" ({physical_size/(1024*1024):.1f}MBâ†’{logical_size/(1024*1024):.1f}MB)"
            else:
                return format_size(physical_size)
        
        def is_package_installed(pkg_name):
            """æ£€æŸ¥åŒ…æ˜¯å¦å·²å®‰è£…"""
            if not installed_packages:
                return False
            normalized_name = self._normalize_package_name(pkg_name)
            normalized_installed = {self._normalize_package_name(pkg): pkg for pkg in installed_packages.keys()}
            return normalized_name in normalized_installed
        
        trees = smart_analysis.get('trees', {})
        package_sizes = smart_analysis.get('package_sizes', {})
        logical_sizes = smart_analysis.get('logical_sizes', {})
        layers = smart_analysis.get('layers', {})
        
        # æ˜¾ç¤ºæ¯ä¸ªä¸»åŒ…çš„ä¾èµ–æ ‘
        for package, tree_data in trees.items():
            installed_mark = " [âˆš]" if is_package_installed(package) else ""
            physical_size = package_sizes.get(package, 0)
            logical_size = logical_sizes.get(package, 0)
            size_info = format_logical_size(physical_size, logical_size)
            print(f"{package}{installed_mark}{size_info}")
            
            # æ˜¾ç¤ºç›´æ¥ä¾èµ–
            deps = tree_data.get('dependencies', [])
            if deps:
                for i, dep in enumerate(deps):
                    is_last = (i == len(deps) - 1)
                    connector = "â””â”€" if is_last else "â”œâ”€"
                    dep_installed = " [âˆš]" if is_package_installed(dep) else ""
                    dep_physical = package_sizes.get(dep, 0)
                    dep_logical = logical_sizes.get(dep, 0)
                    dep_size = format_logical_size(dep_physical, dep_logical)
                    print(f"{connector} {dep}{dep_installed}{dep_size}")
                    
                    # æ˜¾ç¤ºäºŒçº§ä¾èµ– (Level 2) - 4ä¸ªç©ºæ ¼ç¼©è¿›
                    child_data = tree_data.get('children', {}).get(dep, {})
                    child_deps = child_data.get('dependencies', [])
                    if child_deps:
                        for j, child_dep in enumerate(child_deps):
                            is_last_child = (j == len(child_deps) - 1)
                            if is_last:
                                # çˆ¶çº§æ˜¯æœ€åä¸€ä¸ªï¼Œä½¿ç”¨ç©ºæ ¼
                                child_connector = "    â””â”€" if is_last_child else "    â”œâ”€"
                            else:
                                # çˆ¶çº§ä¸æ˜¯æœ€åä¸€ä¸ªï¼Œä½¿ç”¨ç«–çº¿è¿æ¥
                                child_connector = "â”‚   â””â”€" if is_last_child else "â”‚   â”œâ”€"
                            child_installed = " [âˆš]" if is_package_installed(child_dep) else ""
                            child_physical = package_sizes.get(child_dep, 0)
                            child_logical = logical_sizes.get(child_dep, 0)
                            child_size = format_logical_size(child_physical, child_logical)
                            print(f"{child_connector} {child_dep}{child_installed}{child_size}")
            
        # æ˜¾ç¤ºå±‚çº§æ±‡æ€»ï¼ˆä»Level 1å¼€å§‹ï¼‰
        print()
        for layer_num in sorted(layers.keys()):
            if layer_num == 0:
                continue  # è·³è¿‡ä¸»åŒ…å±‚
            pkgs = layers[layer_num]
            if pkgs:
                # å»é‡å¹¶æŒ‰å¤§å°æ’åº
                unique_pkgs = list(set(pkgs))
                pkg_with_sizes = [(pkg, package_sizes.get(pkg, 0)) for pkg in unique_pkgs]
                pkg_with_sizes.sort(key=lambda x: x[1], reverse=True)
                
                print(f"\nLevel {layer_num}: {', '.join([f'{pkg}{format_size(size)}' for pkg, size in pkg_with_sizes])}")
    
    def _get_package_sizes_for_layers(self, download_layers):
        """è·å–å„å±‚åŒ…çš„å¤§å°ä¿¡æ¯"""
        package_sizes = {}
        
        for layer_packages in download_layers.values():
            for package in layer_packages:
                if package not in package_sizes:
                    # å°è¯•è·å–åŒ…å¤§å°
                    try:
                        _, size = self._get_pypi_dependencies_with_size(package)
                        package_sizes[package] = size
                    except Exception:
                        package_sizes[package] = 0
        
        return package_sizes
    
    def _display_package_dependency_tree(self, package, dependency_analysis, max_depth, installed_packages=None):
        """
        æ˜¾ç¤ºå•ä¸ªåŒ…çš„2å±‚ä¾èµ–æ ‘
        
        Args:
            package: åŒ…å
            dependency_analysis: ä¾èµ–åˆ†æç»“æœ
            max_depth: æœ€å¤§æ·±åº¦
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
        """
        base_name = package.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
        
        # æ£€æŸ¥ä¸»åŒ…æ˜¯å¦å·²å®‰è£…
        normalized_base_name = self._normalize_package_name(base_name)
        is_installed = False
        if installed_packages:
            # åˆ›å»ºæ ‡å‡†åŒ–çš„å·²å®‰è£…åŒ…å­—å…¸
            normalized_installed = {self._normalize_package_name(pkg): pkg for pkg in installed_packages.keys()}
            is_installed = normalized_base_name in normalized_installed
        
        main_package_status = " [âˆš]" if is_installed else ""
        print(f"{package}{main_package_status}")
        
        # è·å–ä¾èµ–å…³ç³»
        dependencies = dependency_analysis.get("dependencies", {})
        dependencies_by_level = dependency_analysis.get("dependencies_by_level", {})
        
        if package in dependencies:
            all_deps = dependencies[package]
            if all_deps and package in dependencies_by_level:
                level_deps = dependencies_by_level[package]
                
                # è·å–ç›´æ¥ä¾èµ–ï¼ˆLevel 0ï¼‰
                direct_deps = level_deps.get(0, [])
                if direct_deps:
                    # æˆ‘ä»¬éœ€è¦ä»é€’å½’åˆ†æç»“æœä¸­è·å–æ¯ä¸ªä¾èµ–çš„å­ä¾èµ–
                    # ä½¿ç”¨åŸå§‹çš„dependencieså­—å…¸æ¥è·å–æ¯ä¸ªåŒ…çš„ä¾èµ–
                    for i, direct_dep in enumerate(direct_deps):
                        is_last_direct = (i == len(direct_deps) - 1)
                        direct_connector = "â””â”€" if is_last_direct else "â”œâ”€"
                        
                        # æ£€æŸ¥ç›´æ¥ä¾èµ–æ˜¯å¦å·²å®‰è£…
                        direct_dep_base = direct_dep.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
                        normalized_direct_name = self._normalize_package_name(direct_dep_base)
                        direct_is_installed = False
                        if installed_packages:
                            direct_is_installed = normalized_direct_name in normalized_installed
                        direct_status = " [âˆš]" if direct_is_installed else ""
                        
                        print(f"   {direct_connector} {direct_dep}{direct_status}")
                        
                        # è·å–è¿™ä¸ªç›´æ¥ä¾èµ–çš„å­ä¾èµ–
                        sub_deps = dependencies.get(direct_dep_base, [])
                        if sub_deps:
                            prefix = "              " if is_last_direct else "   â”‚          "
                            
                            # é™åˆ¶æ˜¾ç¤ºæ•°é‡ï¼Œé¿å…è¿‡é•¿
                            display_sub_deps = sub_deps[:4]  # æœ€å¤šæ˜¾ç¤º4ä¸ªå­ä¾èµ–
                            
                            for j, sub_dep in enumerate(display_sub_deps):
                                sub_is_last = (j == len(display_sub_deps) - 1) and len(sub_deps) <= 4
                                sub_connector = "â””â”€" if sub_is_last else "â”œâ”€"
                                
                                # æ£€æŸ¥å­ä¾èµ–æ˜¯å¦å·²å®‰è£…
                                sub_dep_base = sub_dep.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
                                normalized_sub_name = self._normalize_package_name(sub_dep_base)
                                sub_is_installed = False
                                if installed_packages:
                                    sub_is_installed = normalized_sub_name in normalized_installed
                                sub_status = " [âˆš]" if sub_is_installed else ""
                                
                                print(f"{prefix}{sub_connector} {sub_dep}{sub_status}")
                            
                            # å¦‚æœæœ‰æ›´å¤šå­ä¾èµ–ï¼Œæ˜¾ç¤ºçœç•¥å·
                            if len(sub_deps) > 4:
                                ellipsis_prefix = "              " if is_last_direct else "   â”‚          "
                                print(f"{ellipsis_prefix}â””â”€ ... ({len(sub_deps) - 4} more)")
            else:
                print("   â””â”€ No dependencies")
        else:
            print("   â””â”€ Package not in known dependencies database")
