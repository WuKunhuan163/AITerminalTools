#!/usr/bin/env python3
"""
Google Drive Shell - File Operations Module
ä»google_drive_shell.pyé‡æ„è€Œæ¥çš„file_operationsæ¨¡å—
"""

import os
import time
import subprocess
from pathlib import Path
import platform
from typing import Dict
from .linter import GDSLinter

try:
    from ..google_drive_api import GoogleDriveService
except ImportError:
    from GOOGLE_DRIVE_PROJ.google_drive_api import GoogleDriveService

# å¯¼å…¥debugæ•è·ç³»ç»Ÿ
from .remote_commands import debug_capture, debug_print


class VenvApiManager:
    """è™šæ‹Ÿç¯å¢ƒAPIç®¡ç†å™¨ - ç»Ÿä¸€å¤„ç†æ‰€æœ‰è™šæ‹Ÿç¯å¢ƒç›¸å…³çš„APIæ“ä½œ"""
    
    def __init__(self, drive_service, main_instance):
        self.drive_service = drive_service
        self.main_instance = main_instance
    
    def get_venv_base_path(self):
        """è·å–è™šæ‹Ÿç¯å¢ƒåŸºç¡€è·¯å¾„"""
        return f"{self.main_instance.REMOTE_ENV}/venv"
    
    def get_venv_state_file_path(self):
        """è·å–è™šæ‹Ÿç¯å¢ƒçŠ¶æ€æ–‡ä»¶è·¯å¾„"""
        return f"{self.get_venv_base_path()}/venv_states.json"
    
    def read_venv_states(self):
        """è¯»å–è™šæ‹Ÿç¯å¢ƒçŠ¶æ€æ–‡ä»¶"""
        try:
            import json
            
            if not self.drive_service:
                return {"success": False, "error": "Google Drive APIæœåŠ¡æœªåˆå§‹åŒ–"}
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„ï¼šREMOTE_ENV/venv/venv_states.json
            venv_states_filename = "venv_states.json"
            
            # é¦–å…ˆéœ€è¦æ‰¾åˆ°REMOTE_ENV/venvæ–‡ä»¶å¤¹
            try:
                # åˆ—å‡ºREMOTE_ENVæ–‡ä»¶å¤¹çš„å†…å®¹ï¼Œå¯»æ‰¾venvå­æ–‡ä»¶å¤¹
                env_files_result = self.drive_service.list_files(
                    folder_id=self.main_instance.REMOTE_ENV_FOLDER_ID, 
                    max_results=100
                )
                
                if not env_files_result['success']:
                    return {"success": False, "error": "æ— æ³•åˆ—å‡ºREMOTE_ENVç›®å½•å†…å®¹"}
                
                # å¯»æ‰¾venvæ–‡ä»¶å¤¹
                venv_folder_id = None
                for file in env_files_result['files']:
                    if file['name'] == 'venv' and file['mimeType'] == 'application/vnd.google-apps.folder':
                        venv_folder_id = file['id']
                        break
                
                if not venv_folder_id:
                    # venvæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºçŠ¶æ€
                    return {"success": True, "data": {}, "note": "venvæ–‡ä»¶å¤¹ä¸å­˜åœ¨"}
                
                # åœ¨venvæ–‡ä»¶å¤¹ä¸­å¯»æ‰¾venv_states.jsonæ–‡ä»¶
                venv_files_result = self.drive_service.list_files(
                    folder_id=venv_folder_id, 
                    max_results=100
                )
                
                if not venv_files_result['success']:
                    return {"success": False, "error": "æ— æ³•åˆ—å‡ºvenvç›®å½•å†…å®¹"}
                
                # å¯»æ‰¾venv_states.jsonæ–‡ä»¶
                states_file_id = None
                for file in venv_files_result['files']:
                    if file['name'] == venv_states_filename:
                        states_file_id = file['id']
                        break
                
                if not states_file_id:
                    # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºçŠ¶æ€
                    return {"success": True, "data": {}, "note": "venv_states.jsonæ–‡ä»¶ä¸å­˜åœ¨"}
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                try:
                    import io
                    from googleapiclient.http import MediaIoBaseDownload
                    
                    request = self.drive_service.service.files().get_media(fileId=states_file_id)
                    fh = io.BytesIO()
                    downloader = MediaIoBaseDownload(fh, request)
                    
                    done = False
                    while done is False:
                        status, done = downloader.next_chunk()
                    
                    content = fh.getvalue().decode('utf-8', errors='replace')
                    
                    # è§£æJSONå†…å®¹
                    try:
                        states_data = json.loads(content)
                        return {"success": True, "data": states_data if isinstance(states_data, dict) else {}}
                    except json.JSONDecodeError as e:
                        return {"success": False, "error": f"JSONè§£æå¤±è´¥: {e}"}
                        
                except Exception as e:
                    return {"success": False, "error": f"è¯»å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}"}
                    
            except Exception as e:
                return {"success": False, "error": f"æŸ¥æ‰¾æ–‡ä»¶å¤±è´¥: {e}"}
                
        except Exception as e:
            return {"success": False, "error": f"APIè¯»å–venvçŠ¶æ€å¤±è´¥: {e}"}
    
    def list_venv_environments(self):
        """åˆ—å‡ºæ‰€æœ‰è™šæ‹Ÿç¯å¢ƒ"""
        try:
            if not self.drive_service:
                return []
            
            # é¦–å…ˆéœ€è¦æ‰¾åˆ°REMOTE_ENV/venvæ–‡ä»¶å¤¹
            try:
                # åˆ—å‡ºREMOTE_ENVæ–‡ä»¶å¤¹çš„å†…å®¹ï¼Œå¯»æ‰¾venvå­æ–‡ä»¶å¤¹
                env_files_result = self.drive_service.list_files(
                    folder_id=self.main_instance.REMOTE_ENV_FOLDER_ID, 
                    max_results=100
                )
                
                if not env_files_result['success']:
                    return []
                
                # å¯»æ‰¾venvæ–‡ä»¶å¤¹
                venv_folder_id = None
                for file in env_files_result['files']:
                    if file['name'] == 'venv' and file['mimeType'] == 'application/vnd.google-apps.folder':
                        venv_folder_id = file['id']
                        break
                
                if not venv_folder_id:
                    # venvæ–‡ä»¶å¤¹ä¸å­˜åœ¨
                    return []
                
                # åœ¨venvæ–‡ä»¶å¤¹ä¸­åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶å¤¹ï¼ˆè™šæ‹Ÿç¯å¢ƒï¼‰
                venv_files_result = self.drive_service.list_files(
                    folder_id=venv_folder_id, 
                    max_results=100
                )
                
                if not venv_files_result['success']:
                    return []
                
                # è¿‡æ»¤å‡ºæ–‡ä»¶å¤¹ï¼ˆè™šæ‹Ÿç¯å¢ƒï¼‰ï¼Œæ’é™¤venv_states.jsonç­‰æ–‡ä»¶
                env_names = []
                for file in venv_files_result['files']:
                    if (file['mimeType'] == 'application/vnd.google-apps.folder' and 
                        not file['name'].startswith('.') and 
                        file['name'] != 'venv_states.json'):
                        env_names.append(file['name'])
                
                return env_names
                    
            except Exception as e:
                return []
                
        except Exception as e:
            return []


class FileOperations:
    """Google Drive Shell File Operations"""

    def __init__(self, drive_service, main_instance=None):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        self.drive_service = drive_service
        self.main_instance = main_instance
    
    def check_network_connection(self):
        """å§”æ‰˜åˆ°sync_managerçš„ç½‘ç»œè¿æ¥æ£€æŸ¥"""
        return self.main_instance.sync_manager.check_network_connection()
    
    def _verify_files_available(self, file_moves):
        """å§”æ‰˜åˆ°file_utilsçš„æ–‡ä»¶å¯ç”¨æ€§éªŒè¯"""
        return self.main_instance.file_utils._verify_files_available(file_moves)
    
    def generate_commands(self, *args, **kwargs):
        """å§”æ‰˜åˆ°remote_commandsçš„è¿œç¨‹å‘½ä»¤ç”Ÿæˆ"""
        return self.main_instance.remote_commands.generate_commands(*args, **kwargs)
    
    def _cleanup_local_equivalent_files(self, file_moves):
        """å§”æ‰˜åˆ°cache_managerçš„æœ¬åœ°ç­‰æ•ˆæ–‡ä»¶æ¸…ç†"""
        return self.main_instance.cache_manager._cleanup_local_equivalent_files(file_moves)
    
    def ensure_google_drive_desktop_running(self):
        """ç¡®ä¿Google Drive Desktopæ­£åœ¨è¿è¡Œ"""
        try:
            # æ£€æŸ¥Google Drive Desktopæ˜¯å¦æ­£åœ¨è¿è¡Œ
            result = subprocess.run(['pgrep', '-f', 'Google Drive'], 
                                  capture_output=True, text=True)
            if result.returncode == 0 and bool(result.stdout.strip()):
                return True
            
            # å¦‚æœæ²¡æœ‰è¿è¡Œï¼Œå°è¯•å¯åŠ¨
            print(f"å¯åŠ¨Google Drive Desktop...")
            if platform.system() == "Darwin":  # macOS
                subprocess.run(['open', '-a', 'Google Drive'], check=False)
            elif platform.system() == "Linux":
                subprocess.run(['google-drive'], check=False)
            elif platform.system() == "Windows":
                subprocess.run(['start', 'GoogleDrive'], shell=True, check=False)
            
            # ç­‰å¾…å¯åŠ¨
            for i in range(10):
                time.sleep(1)
                result = subprocess.run(['pgrep', '-f', 'Google Drive'], 
                                      capture_output=True, text=True)
                if result.returncode == 0 and bool(result.stdout.strip()):
                    print(f"Google Drive Desktop started successfully")
                    return True
            
            print(f"Error:  Google Drive Desktop failed to start")
            return False
            
        except Exception as e:
            print(f"Error: Error checking/starting Google Drive Desktop: {e}")
            return False
    
    def _check_large_files(self, source_files):
        """æ£€æŸ¥å¤§æ–‡ä»¶å¹¶åˆ†ç¦»å¤„ç†ï¼ˆå¤§äº1Gçš„æ–‡ä»¶ï¼‰"""
        normal_files = []
        large_files = []
        
        for file_path in source_files:
            try:
                file_size = os.path.getsize(file_path)
                # 1G = 1024 * 1024 * 1024 bytes
                if file_size > 1024 * 1024 * 1024:
                    large_files.append({
                        "path": file_path,
                        "size": file_size,
                        "name": os.path.basename(file_path)
                    })
                else:
                    normal_files.append(file_path)
            except OSError:
                # æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ï¼ŒåŠ å…¥normal_filesè®©åç»­å¤„ç†æŠ¥é”™
                normal_files.append(file_path)
        
        return normal_files, large_files
    
    def _handle_large_files(self, large_files, target_path, current_shell):
        """å¤„ç†å¤§æ–‡ä»¶ä¸Šä¼ """
        print(f"\nDetected {len(large_files)} large files (>1GB):")
        for file_info in large_files:
            size_gb = file_info["size"] / (1024 * 1024 * 1024)
            print(f"  - {file_info['name']} ({size_gb:.1f} GB)")
        
        print(f"\nLarge files need to be manually uploaded to Google Drive:")
        print(f"  1. Open Google Drive web version")
        print(f"  2. Manually drag and drop these large files")
        print(f"  3. Wait for upload to complete")
        
        return {"success": True, "message": "Large files detected, manual upload required"}
    
    def wait_for_file_sync(self, file_names, file_moves):
        """ç­‰å¾…æ–‡ä»¶åŒæ­¥å®Œæˆ"""
        return self.main_instance.sync_manager.wait_for_file_sync(file_names, file_moves)
    

    
    def _check_target_file_conflicts_before_move(self, file_moves, force=False):
        """æ£€æŸ¥ç›®æ ‡æ–‡ä»¶å†²çª"""
        # ç®€åŒ–å®ç°ï¼Œå¦‚æœforce=Trueç›´æ¥è¿”å›æˆåŠŸ
        if force:
            return {"success": True, "conflicts": []}
        
        # å¦åˆ™æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        conflicts = []
        for move in file_moves:
            target_path = move.get("new_path", "")
            if os.path.exists(target_path):
                conflicts.append({
                    "file": move.get("source", ""),
                    "target": target_path,
                    "reason": "File already exists"
                })
        
        if conflicts:
            return {
                "success": False,
                "conflicts": conflicts,
                "error": f"Found {len(conflicts)} file conflicts"
            }
        
        return {"success": True, "conflicts": []}
    
    def _check_remote_file_conflicts(self, source_files, target_path):
        """æ£€æŸ¥è¿œç¨‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆç”¨äºéforceæ¨¡å¼ï¼‰"""
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "No active remote shell"}
            
            conflicts = []
            
            # è·å–ç›®æ ‡ç›®å½•ä¸­çš„æ–‡ä»¶åˆ—è¡¨
            ls_result = self.main_instance.cmd_ls(target_path, detailed=False, recursive=False)
            if not ls_result.get("success"):
                # å¦‚æœæ— æ³•åˆ—å‡ºæ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯ç›®å½•ä¸å­˜åœ¨ï¼‰ï¼Œåˆ™è®¤ä¸ºæ²¡æœ‰å†²çª
                return {"success": True, "conflicts": []}
            
            # è·å–è¿œç¨‹æ–‡ä»¶ååˆ—è¡¨
            remote_files = set()
            if ls_result.get("files"):
                for file_info in ls_result["files"]:
                    remote_files.add(file_info["name"])
            
            # æ£€æŸ¥æ¯ä¸ªæºæ–‡ä»¶æ˜¯å¦åœ¨è¿œç¨‹å·²å­˜åœ¨
            for source_file in source_files:
                if not os.path.exists(source_file):
                    continue
                
                filename = os.path.basename(source_file)
                if filename in remote_files:
                    conflicts.append({
                        "local_file": source_file,
                        "remote_file": filename,
                        "reason": "File already exists in remote directory"
                    })
            
            if conflicts:
                conflict_files = [c["remote_file"] for c in conflicts]
                return {
                    "success": False,
                    "conflicts": conflicts,
                    "error": f"\nFile exists: {', '.join(conflict_files)}. Use --force to override."
                }
            
            return {"success": True, "conflicts": []}
            
        except Exception as e:
            # å¦‚æœæ£€æŸ¥è¿‡ç¨‹å‡ºé”™ï¼Œå…è®¸ç»§ç»­ä¸Šä¼ ï¼ˆä¿å®ˆå¤„ç†ï¼‰
            debug_print(f"Remote file conflict check failed: {e}")
            return {"success": True, "conflicts": []}

    def cmd_upload_folder(self, folder_path, target_path=".", keep_zip=False, force=False):
        """
        ä¸Šä¼ æ–‡ä»¶å¤¹åˆ°Google Drive
        
        æµç¨‹ï¼šæ‰“åŒ… -> ä¸Šä¼ zipæ–‡ä»¶ï¼ˆä½œä¸ºæ™®é€šæ–‡ä»¶ï¼‰
        
        Args:
            folder_path (str): è¦ä¸Šä¼ çš„æ–‡ä»¶å¤¹è·¯å¾„
            target_path (str): ç›®æ ‡è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰shellè·¯å¾„ï¼‰
            keep_zip (bool): æ˜¯å¦ä¿ç•™æœ¬åœ°zipæ–‡ä»¶ï¼ˆè¿œç«¯æ€»æ˜¯ä¿ç•™zipæ–‡ä»¶ï¼‰
            force (bool): æ˜¯å¦å¼ºåˆ¶è¦†ç›–ç°æœ‰æ–‡ä»¶
            
        Returns:
            dict: ä¸Šä¼ ç»“æœ
        """
        try:
            folder_name = Path(folder_path).name
            print(f"Packing {folder_name} ...", end="", flush=True)
            
            # æ­¥éª¤1: æ‰“åŒ…æ–‡ä»¶å¤¹
            zip_result = self.main_instance.file_utils._zip_folder(folder_path)
            if not zip_result["success"]:
                print(f" âœ—")
                return {"success": False, "error": f"æ‰“åŒ…å¤±è´¥: {zip_result['error']}"}
            else: 
                print(f" âˆš")
            
            zip_path = zip_result["zip_path"]
            zip_filename = Path(zip_path).name
            
            try:
                # æ­¥éª¤2: ä¸Šä¼ zipæ–‡ä»¶å¹¶è‡ªåŠ¨è§£å‹
                # ä¼ é€’æ–‡ä»¶å¤¹ä¸Šä¼ çš„ç‰¹æ®Šå‚æ•°
                upload_result = self.cmd_upload([zip_path], target_path, force=force, 
                                              folder_upload_info={
                                                  "is_folder_upload": True,
                                                  "zip_filename": zip_filename,
                                                  "keep_zip": keep_zip
                                              })
                if not upload_result["success"]:
                    print(f" âœ—")
                    return {"success": False, "error": f"ä¸Šä¼ å¤±è´¥: {upload_result['error']}"}
                
                # æˆåŠŸå®Œæˆ
                print(f" âˆš")
                return {
                    "success": True,
                    "message": f"Uploaded folder: {folder_name}",
                    "original_folder": folder_path,
                    "zip_uploaded": zip_filename,
                    "zip_kept": keep_zip,
                    "target_path": target_path,
                    "zip_size": zip_result.get("zip_size", 0),
                    "method": "zip_upload_and_extract",
                    "upload_details": upload_result
                }
                
            finally:
                # æ ¹æ®keep_zipå‚æ•°å†³å®šæ˜¯å¦æ¸…ç†æœ¬åœ°ä¸´æ—¶zipæ–‡ä»¶
                if not keep_zip:
                    try:
                        if Path(zip_path).exists():
                            Path(zip_path).unlink()
                            print(f"Cleaned up local temporary file: {zip_filename}")
                    except Exception as e:
                        print(f"Warning: Failed to clean up temporary file: {e}")
                else:
                    print(f"Saved local zip file: {zip_path}")
                    
        except Exception as e:
            # å¦‚æœå‡ºé”™ï¼Œä¹Ÿè¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'zip_path' in locals() and Path(zip_path).exists():
                    Path(zip_path).unlink()
                    print(f"å·²æ¸…ç†æœ¬åœ°ä¸´æ—¶æ–‡ä»¶: {zip_path}")
            except:
                pass
            return {"success": False, "error": f"æ–‡ä»¶å¤¹ä¸Šä¼ è¿‡ç¨‹å‡ºé”™: {e}"}

    def cmd_upload(self, source_files, target_path=".", force=False, folder_upload_info=None, remove_local=False):
        """
        GDS UPLOAD å‘½ä»¤å®ç°
        
        Args:
            source_files (list): è¦ä¸Šä¼ çš„æºæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            target_path (str): ç›®æ ‡è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰ shell è·¯å¾„ï¼‰
            force (bool): æ˜¯å¦å¼ºåˆ¶è¦†ç›–ç°æœ‰æ–‡ä»¶
            
        Returns:
            dict: ä¸Šä¼ ç»“æœ
        """
        try:
            # ç«‹å³æ˜¾ç¤ºè¿›åº¦æ¶ˆæ¯
            print(f"Waiting for upload ...", end="", flush=True)
            debug_capture.start_capture()
            
            # å»¶è¿Ÿå¯åŠ¨debugä¿¡æ¯æ•è·ï¼Œè®©é‡å‘½åä¿¡æ¯èƒ½å¤Ÿæ˜¾ç¤º
            debug_print(f"cmd_upload called with source_files={source_files}, target_path='{target_path}', force={force}")
            
            # 0. æ£€æŸ¥Google Drive Desktopæ˜¯å¦è¿è¡Œ
            if not self.ensure_google_drive_desktop_running():
                return {"success": False, "error": "ç”¨æˆ·å–æ¶ˆä¸Šä¼ æ“ä½œ"}
            
            # 1. éªŒè¯è¾“å…¥å‚æ•°
            if not source_files:
                return {"success": False, "error": "è¯·æŒ‡å®šè¦ä¸Šä¼ çš„æ–‡ä»¶"}
            
            if isinstance(source_files, str):
                source_files = [source_files]
            
            # 1.5. æ£€æŸ¥å¤§æ–‡ä»¶å¹¶åˆ†ç¦»å¤„ç†
            normal_files, large_files = self._check_large_files(source_files)
            
            # å¤„ç†å¤§æ–‡ä»¶
            if large_files:
                large_file_result = self._handle_large_files(large_files, target_path, current_shell)
                if not large_file_result["success"]:
                    return large_file_result
            
            # å¦‚æœæ²¡æœ‰æ­£å¸¸å¤§å°çš„æ–‡ä»¶éœ€è¦å¤„ç†ï¼Œä½†æœ‰å¤§æ–‡ä»¶ï¼Œéœ€è¦ç­‰å¾…æ‰‹åŠ¨ä¸Šä¼ å®Œæˆ
            if not normal_files:
                if large_files:
                    # ç­‰å¾…å¤§æ–‡ä»¶æ‰‹åŠ¨ä¸Šä¼ å®Œæˆ
                    large_file_names = [Path(f["path"]).name for f in large_files]
                    print(f"\nâ³ Waiting for large files manual upload ...")
                    
                    # åˆ›å»ºè™šæ‹Ÿfile_movesç”¨äºè®¡ç®—è¶…æ—¶æ—¶é—´
                    virtual_file_moves = [{"new_path": f["path"]} for f in large_files]
                    sync_result = self.wait_for_file_sync(large_file_names, virtual_file_moves)
                    
                    if sync_result["success"]:
                        return {
                            "success": True,
                            "message": f"\nLarge files manual upload completed: {len(large_files)} files",
                            "large_files_handled": True,
                            "sync_time": sync_result.get("sync_time", 0)
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"Manual upload failed: {sync_result.get('error', 'Unknown error')}",
                            "large_files_handled": True
                        }
                else:
                    return {"success": False, "error": "Cannot find valid files"}
            
            # ç»§ç»­å¤„ç†æ­£å¸¸å¤§å°çš„æ–‡ä»¶
            source_files = normal_files
            
            # 2. è·å–å½“å‰ shell
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "No active remote shell, please create or switch to a shell"}
            
            # 3. è§£æç›®æ ‡è·¯å¾„
            debug_print(f"Before _resolve_target_path_for_upload - target_path='{target_path}'")
            debug_print(f"current_shell={current_shell}")
            target_folder_id, target_display_path = self.main_instance.path_resolver._resolve_target_path_for_upload(target_path, current_shell)
            debug_print(f"After _resolve_target_path_for_upload - target_folder_id='{target_folder_id}', target_display_path='{target_display_path}'")
            if target_folder_id is None and self.drive_service:
                # ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨ï¼Œä½†è¿™æ˜¯æ­£å¸¸çš„ï¼Œæˆ‘ä»¬ä¼šåœ¨è¿œç«¯åˆ›å»ºå®ƒ
                # é™é»˜å¤„ç†ç›®æ ‡è·¯å¾„åˆ›å»º
                target_folder_id = None  # æ ‡è®°ä¸ºéœ€è¦åˆ›å»º
                target_display_path = target_path
            elif not self.drive_service:
                print(f"è­¦å‘Š: Google Drive API æœåŠ¡æœªåˆå§‹åŒ–ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            
            # 3.5. æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…å†²çªï¼ˆé™¤éä½¿ç”¨--forceï¼‰
            overridden_files = []
            if not force:
                # æ£€æŸ¥è¿œç¨‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                conflict_check_result = self._check_remote_file_conflicts(source_files, target_path)
                if not conflict_check_result["success"]:
                    return conflict_check_result
            else:
                # Forceæ¨¡å¼ï¼šæ£€æŸ¥å“ªäº›æ–‡ä»¶ä¼šè¢«è¦†ç›–ï¼Œè®°å½•è­¦å‘Š
                override_check_result = self.main_instance.file_utils._check_files_to_override(source_files, target_path)
                if override_check_result["success"] and override_check_result.get("overridden_files"):
                    overridden_files = override_check_result["overridden_files"]
                    for file_path in overridden_files:
                        print(f"Warning: Overriding remote file {file_path}")
            
            # 4. æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶å¤¹ï¼Œæç¤ºæ­£ç¡®è¯­æ³•
            for source_file in source_files:
                if Path(source_file).is_dir():
                    print(f"\nError: '{source_file}' is a directory")
                    print(f"To upload folders, use: GDS upload-folder {source_file}")
                    print(f"   Options: --keep-zip to preserve local zip file")
                    return {"success": False, "error": f""}
            
            # 5. ç§»åŠ¨æ–‡ä»¶åˆ° LOCAL_EQUIVALENT
            file_moves = []
            failed_moves = []
            
            for source_file in source_files:
                debug_print(f"Processing file: {source_file}")
                move_result = self.main_instance.sync_manager.move_to_local_equivalent(source_file)
                debug_print(f"Move result: {move_result}")
                
                if move_result["success"]:
                    file_moves.append({
                        "original_path": move_result["original_path"],
                        "filename": move_result["filename"],
                        "original_filename": move_result["original_filename"],
                        "new_path": move_result["new_path"],
                        "renamed": move_result["renamed"]
                    })
                    
                    # è®°å½•é‡å‘½åä¿¡æ¯åˆ°debugï¼ˆä¸æ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰
                    if move_result["renamed"]:
                        debug_print(f"ğŸ·ï¸  File renamed: {move_result['original_filename']} -> {move_result['filename']}")
                    else:
                        debug_print(f"File processed without renaming: {move_result['filename']}")
                else:
                    failed_moves.append({
                        "file": source_file,
                        "error": move_result.get("error", "Unknown error")
                    })
                    print(f"\nâœ— {move_result['error']}")
            
            if not file_moves:
                return {
                    "success": False,
                    "error": "All file moves failed",
                    "failed_moves": failed_moves
                }
            
            # 5. æ£€æµ‹ç½‘ç»œè¿æ¥
            network_result = self.check_network_connection()
            if not network_result["success"]:
                print(f"Warning: Network connection check failed: {network_result['error']}")
                print(f"ğŸ“± Will continue to execute, but please ensure network connection is normal")
            else:
                # é™é»˜å¤„ç†ç½‘ç»œæ£€æŸ¥
                pass
            
            # 6. ç­‰å¾…æ–‡ä»¶åŒæ­¥åˆ° DRIVE_EQUIVALENT
            # å¯¹äºåŒæ­¥æ£€æµ‹ï¼Œä½¿ç”¨é‡å‘½ååçš„æ–‡ä»¶åï¼ˆåœ¨DRIVE_EQUIVALENTä¸­çš„å®é™…æ–‡ä»¶åï¼‰
            expected_filenames = [fm["filename"] for fm in file_moves]
            
            sync_result = self.wait_for_file_sync(expected_filenames, file_moves)
            
            if not sync_result["success"]:
                # åŒæ­¥æ£€æµ‹å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ
                print(f"Warning: File sync check failed: {sync_result.get('error', 'Unknown error')}")
                print(f"ğŸ“± Upload may have succeeded, please manually verify files have been uploaded")
                print(f"You can retry upload if needed")
                
                # è¿”å›å¤±è´¥ç»“æœï¼Œè®©ç”¨æˆ·å†³å®šæ˜¯å¦é‡è¯•
                return {
                    "success": False,
                    "error": f"Upload sync verification failed: {sync_result.get('error', 'Unknown error')}",
                    "file_moves": file_moves,
                    "sync_time": sync_result.get("sync_time", 0),
                    "suggestion": "Files may have been uploaded successfully. Please check manually and retry if needed."
                }
            else:
                base_time = sync_result.get("base_sync_time", sync_result.get("sync_time", 0))
                sync_result["sync_time"] = base_time
            
            # 7. é™é»˜éªŒè¯æ–‡ä»¶åŒæ­¥çŠ¶æ€
            self._verify_files_available(file_moves)
            
            # 8. é™é»˜ç”Ÿæˆè¿œç«¯å‘½ä»¤
            debug_print(f"Before generate_commands - file_moves={file_moves}")
            debug_print(f"Before generate_commands - target_path='{target_path}'")
            remote_command = self.generate_commands(file_moves, target_path, folder_upload_info)
            debug_print(f"After generate_commands - remote_command preview: {remote_command[:200]}...")
            
            # 7.5. è¿œç«¯ç›®å½•åˆ›å»ºå·²ç»é›†æˆåˆ°generate_commandsä¸­ï¼Œæ— éœ€é¢å¤–å¤„ç†
            
            # 8. ä½¿ç”¨ç»Ÿä¸€çš„è¿œç«¯å‘½ä»¤æ‰§è¡Œæ¥å£
            # å¯¹äºæ–‡ä»¶å¤¹ä¸Šä¼ ï¼Œè·³è¿‡æ–‡ä»¶éªŒè¯å› ä¸ºéªŒè¯çš„æ˜¯zipæ–‡ä»¶è€Œä¸æ˜¯è§£å‹åçš„å†…å®¹
            if folder_upload_info and folder_upload_info.get("is_folder_upload", False):
                # æ–‡ä»¶å¤¹ä¸Šä¼ ï¼šè·³è¿‡æ–‡ä»¶éªŒè¯ï¼Œä¿¡ä»»è¿œç¨‹å‘½ä»¤æ‰§è¡Œç»“æœ
                context_info = {
                    "expected_filenames": None,  # è·³è¿‡éªŒè¯
                    "sync_filenames": expected_filenames,
                    "target_folder_id": target_folder_id,
                    "target_path": target_path,
                    "file_moves": file_moves,
                    "is_folder_upload": True
                }
            else:
                # æ™®é€šæ–‡ä»¶ä¸Šä¼ ï¼šæ­£å¸¸éªŒè¯
                context_info = {
                    "expected_filenames": [fm.get("original_filename", fm["filename"]) for fm in file_moves],  # éªŒè¯é˜¶æ®µç”¨åŸå§‹æ–‡ä»¶å
                    "sync_filenames": expected_filenames,  # åŒæ­¥é˜¶æ®µç”¨é‡å‘½ååçš„æ–‡ä»¶å
                    "target_folder_id": target_folder_id,
                    "target_path": target_path,
                    "file_moves": file_moves
                }
            
            execution_result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯
            if not execution_result["success"]:
                return {
                    "success": False,
                    "error": execution_result.get("error", execution_result.get("data", {}).get("error", "Unknown error")),
                    "remote_command": remote_command,
                    "execution_result": execution_result
                }
            
            if folder_upload_info and folder_upload_info.get("is_folder_upload", False):
                # æ–‡ä»¶å¤¹ä¸Šä¼ ï¼šè·³è¿‡æ–‡ä»¶éªŒè¯ï¼Œä¿¡ä»»è¿œç¨‹å‘½ä»¤æ‰§è¡Œç»“æœ
                debug_print(f"Folder upload detected, skipping file verification")
                verify_result = {
                    "success": True,
                    "found_files": [],
                    "missing_files": [],
                    "total_expected": len(expected_filenames),
                    "total_found": 0,
                    "skip_verification": True
                }
            else:
                # æ™®é€šæ–‡ä»¶ä¸Šä¼ ï¼šä½¿ç”¨ls-basedéªŒè¯
                expected_for_verification = [fm.get("original_filename", fm["filename"]) for fm in file_moves]

                # ä½¿ç”¨å¸¦è¿›åº¦çš„éªŒè¯æœºåˆ¶
                verify_result = self.main_instance.remote_commands._verify_upload_with_progress(
                    expected_for_verification, 
                    target_path, 
                    current_shell
                )

                debug_capture.start_capture()
                debug_print(f"Verification completed: {verify_result}")
            
            # 9. ä¸Šä¼ å’Œè¿œç«¯å‘½ä»¤æ‰§è¡Œå®Œæˆåï¼Œæ¸…ç†LOCAL_EQUIVALENTä¸­çš„æ–‡ä»¶
            if verify_result["success"]:
                self._cleanup_local_equivalent_files(file_moves)
                
                # æ·»åŠ åˆ é™¤è®°å½•åˆ°ç¼“å­˜ï¼ˆè®°å½•åŸå§‹æ–‡ä»¶åå’Œä¸´æ—¶æ–‡ä»¶åçš„ä½¿ç”¨ï¼‰
                for file_info in file_moves:
                    original_filename = file_info["original_filename"]
                    temp_filename = file_info["filename"]
                    
                    # è®°å½•åŸå§‹æ–‡ä»¶åçš„ä½¿ç”¨
                    self.main_instance.cache_manager.add_deletion_record(original_filename)
                    debug_print(f"Added deletion record for original: {original_filename}")
                    
                    # å¦‚æœæ–‡ä»¶è¢«é‡å‘½åï¼Œä¹Ÿè®°å½•ä¸´æ—¶æ–‡ä»¶åçš„ä½¿ç”¨
                    if file_info["renamed"] and temp_filename != original_filename:
                        self.main_instance.cache_manager.add_deletion_record(temp_filename)
                        debug_print(f"Added deletion record for temp: {temp_filename}")
                
                # å¦‚æœæŒ‡å®šäº† --remove-local é€‰é¡¹ï¼Œåˆ é™¤æœ¬åœ°æºæ–‡ä»¶
                if remove_local:
                    removed_files = []
                    failed_removals = []
                    for source_file in source_files:
                        try:
                            if os.path.exists(source_file):
                                os.unlink(source_file)
                                removed_files.append(source_file)
                        except Exception as e:
                            failed_removals.append({"file": source_file, "error": str(e)})
            
            result = {
                "success": verify_result["success"],
                "uploaded_files": verify_result.get("found_files", []),
                "failed_files": verify_result.get("missing_files", []) + [fm["file"] for fm in failed_moves],
                "target_path": target_display_path,
                "target_folder_id": target_folder_id,
                "total_attempted": len(file_moves) + len(failed_moves),
                "total_succeeded": len(verify_result.get("found_files", [])),
                "remote_command": remote_command,
                "file_moves": file_moves,
                "failed_moves": failed_moves,
                "sync_time": sync_result.get("sync_time", 0),
                "message": f"Upload completed: {len(verify_result.get('found_files', []))}/{len(file_moves)} files" if verify_result["success"] else f" âœ—\nâš ï¸ Partially uploaded: {len(verify_result.get('found_files', []))}/{len(file_moves)} files",
                "api_available": self.drive_service is not None
            }
            
            # Add debug information for all uploads to diagnose verification issues
            used_direct_feedback = verify_result.get("source") == "direct_feedback"
            upload_failed = not verify_result["success"]
            
            # Always show debug information to diagnose verification problems
            if used_direct_feedback:
                debug_print(f"User used direct feedback, showing debug information:")
            elif upload_failed:
                debug_print(f"Upload failed, showing debug information:")
            else:
                debug_print(f"Upload completed, showing verification debug information:")
            
            debug_print(f"verify_result={verify_result}")
            debug_print(f"sync_result={sync_result}")
            debug_print(f"target_folder_id='{target_folder_id}'")
            debug_print(f"target_display_path='{target_display_path}'")
            
            # åœæ­¢debugä¿¡æ¯æ•è·
            debug_capture.stop_capture()
            
            # Always print debug capture buffer
            captured_debug = debug_capture.get_debug_info()
            if captured_debug:
                debug_print(f"Captured debug output:")
                debug_print(captured_debug)
            
            # æ·»åŠ æœ¬åœ°æ–‡ä»¶åˆ é™¤ä¿¡æ¯
            if remove_local and verify_result["success"]:
                result["removed_local_files"] = removed_files
                result["failed_local_removals"] = failed_removals
                if removed_files:
                    result["message"] += f" (removed {len(removed_files)} local files)"
                if failed_removals:
                    result["message"] += f" (failed to remove {len(failed_removals)} local files)"
            
            # åœæ­¢debugä¿¡æ¯æ•è·
            debug_capture.stop_capture()
            return result
            
        except Exception as e:
            # åœæ­¢debugä¿¡æ¯æ•è·
            debug_capture.stop_capture()
            return {
                "success": False,
                "error": f"Upload error: {str(e)}"
            }

    def cmd_pwd(self):
        """æ˜¾ç¤ºå½“å‰è·¯å¾„"""
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shellï¼Œè¯·å…ˆåˆ›å»ºæˆ–åˆ‡æ¢åˆ°ä¸€ä¸ªshell"}
            
            return {
                "success": True,
                "current_path": current_shell.get("current_path", "~"),
                "home_url": self.main_instance.HOME_URL,
                "shell_id": current_shell["id"],
                "shell_name": current_shell["name"]
            }
            
        except Exception as e:
            return {"success": False, "error": f"è·å–å½“å‰è·¯å¾„æ—¶å‡ºé”™: {e}"}

    def cmd_ls(self, path=None, detailed=False, recursive=False, show_hidden=False):
        """åˆ—å‡ºç›®å½•å†…å®¹ï¼Œæ”¯æŒé€’å½’ã€è¯¦ç»†æ¨¡å¼å’Œæ‰©å±•ä¿¡æ¯æ¨¡å¼ï¼Œæ”¯æŒæ–‡ä»¶è·¯å¾„"""
        try:
            if not self.drive_service:
                return {"success": False, "error": "Google Drive APIæœåŠ¡æœªåˆå§‹åŒ–"}
                
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shellï¼Œè¯·å…ˆåˆ›å»ºæˆ–åˆ‡æ¢åˆ°ä¸€ä¸ªshell"}
            
            if path is None or path == ".":
                # å½“å‰ç›®å½•
                target_folder_id = current_shell.get("current_folder_id", self.main_instance.REMOTE_ROOT_FOLDER_ID)
                display_path = current_shell.get("current_path", "~")
            elif path == "~":
                # æ ¹ç›®å½•
                target_folder_id = self.main_instance.REMOTE_ROOT_FOLDER_ID
                display_path = "~"
            else:
                # é¦–å…ˆå°è¯•ä½œä¸ºç›®å½•è§£æ
                target_folder_id, display_path = self.main_instance.resolve_path(path, current_shell)
                
                if not target_folder_id:
                    # å¦‚æœä½œä¸ºç›®å½•è§£æå¤±è´¥ï¼Œå°è¯•ä½œä¸ºæ–‡ä»¶è·¯å¾„è§£æ
                    file_result = self._resolve_file_path(path, current_shell)
                    if file_result:
                        # è¿™æ˜¯ä¸€ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œè¿”å›å•ä¸ªæ–‡ä»¶ä¿¡æ¯
                        return self._ls_single_file(file_result, path)
                    else:

                        return {"success": False, "error": f"Path not found: {path}"}
            
            if recursive:
                return self._ls_recursive(target_folder_id, display_path, detailed, show_hidden)
            else:
                return self._ls_single(target_folder_id, display_path, detailed, show_hidden)
                
        except Exception as e:

            return {"success": False, "error": f"æ‰§è¡Œlså‘½ä»¤æ—¶å‡ºé”™: {e}"}

    def _ls_recursive(self, root_folder_id, root_path, detailed, show_hidden=False, max_depth=5):
        """é€’å½’åˆ—å‡ºç›®å½•å†…å®¹"""
        try:
            all_items = []
            visited_folders = set()  # é˜²æ­¢å¾ªç¯å¼•ç”¨
            
            def scan_folder(folder_id, folder_path, depth=0):
                # æ·±åº¦é™åˆ¶
                if depth > max_depth:
                    return
                
                # å¾ªç¯æ£€æµ‹
                if folder_id in visited_folders:
                    return
                visited_folders.add(folder_id)
                
                result = self.drive_service.list_files(folder_id=folder_id, max_results=100)
                if not result['success']:
                    visited_folders.discard(folder_id)  # å¤±è´¥æ—¶ç§»é™¤ï¼Œå…è®¸é‡è¯•
                    return
                
                files = result['files']
                
                # æ·»åŠ ç½‘é¡µé“¾æ¥
                for file in files:
                    file['url'] = self._generate_web_url(file)
                    file['path'] = folder_path
                    file['depth'] = depth
                    all_items.append(file)
                    
                    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œé€’å½’æ‰«æ
                    if file['mimeType'] == 'application/vnd.google-apps.folder':
                        sub_path = f"{folder_path}/{file['name']}" if folder_path != "~" else f"~/{file['name']}"
                        scan_folder(file['id'], sub_path, depth + 1)
                
                visited_folders.discard(folder_id)  # æ‰«æå®Œæˆåç§»é™¤ï¼Œå…è®¸åœ¨å…¶ä»–è·¯å¾„ä¸­å†æ¬¡è®¿é—®
            
            # å¼€å§‹é€’å½’æ‰«æ
            scan_folder(root_folder_id, root_path)
            
            # æŒ‰è·¯å¾„å’Œåç§°æ’åº
            all_items.sort(key=lambda x: (x['path'], x['name'].lower()))
            
            # åˆ†ç¦»æ–‡ä»¶å¤¹å’Œæ–‡ä»¶
            folders = [f for f in all_items if f['mimeType'] == 'application/vnd.google-apps.folder']
            other_files = [f for f in all_items if f['mimeType'] != 'application/vnd.google-apps.folder']
            
            if detailed:
                # è¯¦ç»†æ¨¡å¼ï¼šè¿”å›åµŒå¥—çš„æ ‘å½¢ç»“æ„
                nested_structure = self._build_nested_structure(all_items, root_path)
                
                return {
                    "success": True,
                    "path": root_path,
                    "folder_id": root_folder_id,
                    "folder_url": self._generate_folder_url(root_folder_id),
                    "files": nested_structure["files"],
                    "folders": nested_structure["folders"],  # æ¯ä¸ªæ–‡ä»¶å¤¹åŒ…å«è‡ªå·±çš„fileså’Œfolders
                    "count": len(all_items),
                    "mode": "recursive_detailed"
                }
            else:
                # ç®€å•æ¨¡å¼ï¼šåªè¿”å›åŸºæœ¬ä¿¡æ¯
                return {
                    "success": True,
                    "path": root_path,
                    "folder_id": root_folder_id,
                    "files": other_files,
                    "folders": folders,
                    "all_items": all_items,
                    "count": len(all_items),
                    "mode": "recursive_bash"
                }
                
        except Exception as e:
            return {"success": False, "error": f"é€’å½’åˆ—å‡ºç›®å½•æ—¶å‡ºé”™: {e}"}

    def _build_nested_structure(self, all_items, root_path):
        """æ„å»ºåµŒå¥—çš„æ–‡ä»¶å¤¹ç»“æ„ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹åŒ…å«è‡ªå·±çš„fileså’Œfolders"""
        try:
            # æŒ‰è·¯å¾„åˆ†ç»„æ‰€æœ‰é¡¹ç›®
            path_groups = {}
            
            for item in all_items:
                path = item['path']
                if path not in path_groups:
                    path_groups[path] = {'files': [], 'folders': []}
                
                if item['mimeType'] == 'application/vnd.google-apps.folder':
                    path_groups[path]['folders'].append(item)
                else:
                    path_groups[path]['files'].append(item)
            
            # æ„å»ºåµŒå¥—ç»“æ„
            def build_folder_content(folder_path):
                content = path_groups.get(folder_path, {'files': [], 'folders': []})
                
                # ä¸ºæ¯ä¸ªå­æ–‡ä»¶å¤¹é€’å½’æ„å»ºå†…å®¹
                enriched_folders = []
                for folder in content['folders']:
                    folder_copy = folder.copy()
                    sub_path = f"{folder_path}/{folder['name']}" if folder_path != "~" else f"~/{folder['name']}"
                    sub_content = build_folder_content(sub_path)
                    
                    # å°†å­å†…å®¹æ·»åŠ åˆ°æ–‡ä»¶å¤¹ä¸­
                    folder_copy['files'] = sub_content['files']
                    folder_copy['folders'] = sub_content['folders']
                    enriched_folders.append(folder_copy)
                
                return {
                    'files': content['files'],
                    'folders': enriched_folders
                }
            
            # ä»æ ¹è·¯å¾„å¼€å§‹æ„å»º
            return build_folder_content(root_path)
            
        except Exception as e:
            return {'files': [], 'folders': [], 'error': str(e)}

    def _build_folder_tree(self, folders):
        """æ„å»ºæ–‡ä»¶å¤¹æ ‘ç»“æ„ï¼Œä¾¿äºæ˜¾ç¤ºå±‚æ¬¡å…³ç³»"""
        try:
            tree = {}
            
            for folder in folders:
                path_parts = folder['path'].split('/')
                current_level = tree
                
                for i, part in enumerate(path_parts):
                    if part not in current_level:
                        current_level[part] = {
                            'folders': {},
                            'info': None
                        }
                    current_level = current_level[part]['folders']
                
                # åœ¨æœ€ç»ˆä½ç½®æ·»åŠ å½“å‰æ–‡ä»¶å¤¹ä¿¡æ¯
                current_level[folder['name']] = {
                    'folders': {},
                    'info': {
                        'id': folder['id'],
                        'url': folder['url'],
                        'name': folder['name'],
                        'path': folder['path'],
                        'depth': folder['depth']
                    }
                }
            
            return tree
            
        except Exception as e:
            print(f"æ„å»ºæ–‡ä»¶å¤¹æ ‘æ—¶å‡ºé”™: {e}")
            return {}

    def _generate_folder_url(self, folder_id):
        """ç”Ÿæˆæ–‡ä»¶å¤¹çš„ç½‘é¡µé“¾æ¥"""
        return f"https://drive.google.com/drive/folders/{folder_id}"

    def _generate_web_url(self, file):
        """ä¸ºæ–‡ä»¶ç”Ÿæˆç½‘é¡µé“¾æ¥"""
        file_id = file['id']
        mime_type = file['mimeType']
        
        if mime_type == 'application/vnd.google.colaboratory':
            # Colabæ–‡ä»¶
            return f"https://colab.research.google.com/drive/{file_id}"
        elif mime_type == 'application/vnd.google-apps.document':
            # Googleæ–‡æ¡£
            return f"https://docs.google.com/document/d/{file_id}/edit"
        elif mime_type == 'application/vnd.google-apps.spreadsheet':
            # Googleè¡¨æ ¼
            return f"https://docs.google.com/spreadsheets/d/{file_id}/edit"
        elif mime_type == 'application/vnd.google-apps.presentation':
            # Googleå¹»ç¯ç‰‡
            return f"https://docs.google.com/presentation/d/{file_id}/edit"
        elif mime_type == 'application/vnd.google-apps.folder':
            # æ–‡ä»¶å¤¹
            return f"https://drive.google.com/drive/folders/{file_id}"
        else:
            # å…¶ä»–æ–‡ä»¶ï¼ˆé¢„è§ˆæˆ–ä¸‹è½½ï¼‰
            return f"https://drive.google.com/file/d/{file_id}/view"


    def cmd_mkdir(self, path, recursive=False):
        """åˆ›å»ºç›®å½•ï¼Œé€šè¿‡è¿œç¨‹å‘½ä»¤ç•Œé¢æ‰§è¡Œä»¥ç¡®ä¿ç”±ç”¨æˆ·è´¦æˆ·åˆ›å»º"""
        try:
            if not self.drive_service:
                return {"success": False, "error": "Google Drive APIæœåŠ¡æœªåˆå§‹åŒ–"}
                
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shellï¼Œè¯·å…ˆåˆ›å»ºæˆ–åˆ‡æ¢åˆ°ä¸€ä¸ªshell"}
            
            if not path:
                return {"success": False, "error": "è¯·æŒ‡å®šè¦åˆ›å»ºçš„ç›®å½•åç§°"}
            
            # è°ƒç”¨ç»Ÿä¸€çš„mkdir_remoteæ–¹æ³•
            return self.cmd_mkdir_remote(path, recursive)
                
        except Exception as e:
            return {"success": False, "error": f"æ‰§è¡Œmkdirå‘½ä»¤æ—¶å‡ºé”™: {e}"}

    def cmd_touch(self, filename):
        """åˆ›å»ºç©ºæ–‡ä»¶ï¼Œé€šè¿‡è¿œç¨‹å‘½ä»¤ç•Œé¢æ‰§è¡Œ"""
        try:
            if not self.drive_service:
                return {"success": False, "error": "Google Drive APIæœåŠ¡æœªåˆå§‹åŒ–"}
                
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shellï¼Œè¯·å…ˆåˆ›å»ºæˆ–åˆ‡æ¢åˆ°ä¸€ä¸ªshell"}
            
            if not filename:
                return {"success": False, "error": "è¯·æŒ‡å®šè¦åˆ›å»ºçš„æ–‡ä»¶å"}
            
            # è§£æç»å¯¹è·¯å¾„
            current_path = current_shell.get("current_path", "~")
            if filename.startswith("/"):
                # ç»å¯¹è·¯å¾„
                absolute_path = filename.replace("~", "/content/drive/MyDrive/REMOTE_ROOT", 1)
            else:
                # ç›¸å¯¹è·¯å¾„
                if current_path == "~":
                    current_path = "/content/drive/MyDrive/REMOTE_ROOT"
                else:
                    current_path = current_path.replace("~", "/content/drive/MyDrive/REMOTE_ROOT", 1)
                absolute_path = f"{current_path}/{filename}"
            
            # ç”Ÿæˆè¿œç«¯touchå‘½ä»¤ï¼ˆåˆ›å»ºç©ºæ–‡ä»¶ï¼‰
            remote_command = f'touch "{absolute_path}"'
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = {
                "filename": filename,
                "absolute_path": absolute_path
            }
            
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£æ‰§è¡Œè¿œç«¯å‘½ä»¤
            execution_result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if execution_result["success"]:
                # ç®€æ´è¿”å›ï¼Œåƒbash shellä¸€æ ·æˆåŠŸæ—¶ä¸æ˜¾ç¤ºä»»ä½•ä¿¡æ¯
                return {
                    "success": True,
                    "filename": filename,
                    "absolute_path": absolute_path,
                    "remote_command": remote_command,
                    "message": "",  # ç©ºæ¶ˆæ¯ï¼Œä¸æ˜¾ç¤ºä»»ä½•å†…å®¹
                    "verification": {"success": True}
                }
            else:
                return execution_result
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"è¿œç«¯touchå‘½ä»¤ç”Ÿæˆå¤±è´¥: {e}"
            }

    def _ls_single(self, target_folder_id, display_path, detailed, show_hidden=False):
        """åˆ—å‡ºå•ä¸ªç›®å½•å†…å®¹ï¼ˆç»Ÿä¸€å®ç°ï¼ŒåŒ…å«å»é‡å¤„ç†ï¼‰"""
        try:
            result = self.drive_service.list_files(folder_id=target_folder_id, max_results=50)
            
            if result['success']:
                files = result['files']
                
                # æ·»åŠ ç½‘é¡µé“¾æ¥åˆ°æ¯ä¸ªæ–‡ä»¶
                for file in files:
                    file['url'] = self._generate_web_url(file)
                
                # æŒ‰åç§°æ’åºï¼Œæ–‡ä»¶å¤¹ä¼˜å…ˆ
                folders = sorted([f for f in files if f['mimeType'] == 'application/vnd.google-apps.folder'], 
                               key=lambda x: x['name'].lower())
                other_files = sorted([f for f in files if f['mimeType'] != 'application/vnd.google-apps.folder'], 
                                   key=lambda x: x['name'].lower())
                
                # å»é‡å¤„ç†
                seen_names = set()
                clean_folders = []
                clean_files = []
                
                # å¤„ç†æ–‡ä»¶å¤¹
                for folder in folders:
                    if folder["name"] not in seen_names:
                        clean_folders.append(folder)
                        seen_names.add(folder["name"])
                
                # å¤„ç†æ–‡ä»¶
                for file in other_files:
                    if file["name"] not in seen_names:
                        clean_files.append(file)
                        seen_names.add(file["name"])
                
                if detailed:
                    # è¯¦ç»†æ¨¡å¼ï¼šè¿”å›å®Œæ•´JSON
                    return {
                        "success": True,
                        "path": display_path,
                        "folder_id": target_folder_id,
                        "folder_url": self._generate_folder_url(target_folder_id),
                        "files": clean_files,  # åªæœ‰éæ–‡ä»¶å¤¹æ–‡ä»¶
                        "folders": clean_folders,  # åªæœ‰æ–‡ä»¶å¤¹
                        "count": len(clean_folders) + len(clean_files),
                        "mode": "detailed"
                    }
                else:
                    # bashé£æ ¼ï¼šåªè¿”å›æ–‡ä»¶ååˆ—è¡¨
                    return {
                        "success": True,
                        "path": display_path,
                        "folder_id": target_folder_id,
                        "files": clean_files,  # åªæœ‰éæ–‡ä»¶å¤¹æ–‡ä»¶
                        "folders": clean_folders,  # åªæœ‰æ–‡ä»¶å¤¹
                        "count": len(clean_folders) + len(clean_files),
                        "mode": "bash"
                    }
            else:
                return {"success": False, "error": f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {result['error']}"}
                
        except Exception as e:
            return {"success": False, "error": f"åˆ—å‡ºå•ä¸ªç›®å½•æ—¶å‡ºé”™: {e}"}

    def _resolve_file_path(self, file_path, current_shell):
        """è§£ææ–‡ä»¶è·¯å¾„ï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
        try:
            # åˆ†ç¦»ç›®å½•å’Œæ–‡ä»¶å
            if "/" in file_path:
                dir_path = "/".join(file_path.split("/")[:-1])
                filename = file_path.split("/")[-1]
            else:
                # ç›¸å¯¹äºå½“å‰ç›®å½•
                dir_path = "."
                filename = file_path
            

            
            # è§£æç›®å½•è·¯å¾„
            if dir_path == ".":
                parent_folder_id = current_shell.get("current_folder_id", self.main_instance.REMOTE_ROOT_FOLDER_ID)
            else:
                parent_folder_id, _ = self.main_instance.resolve_path(dir_path, current_shell)
                if not parent_folder_id:

                    return None
            

            
            # åœ¨çˆ¶ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
            result = self.drive_service.list_files(folder_id=parent_folder_id, max_results=100)
            if not result['success']:

                return None
            
            for file in result['files']:
                if file['name'] == filename:

                    file['url'] = self._generate_web_url(file)
                    return file
            

            return None
            
        except Exception as e:

            return None

    def _ls_single_file(self, file_info, original_path):
        """è¿”å›å•ä¸ªæ–‡ä»¶çš„lsä¿¡æ¯"""
        try:
            # åˆ¤æ–­æ˜¯æ–‡ä»¶å¤¹è¿˜æ˜¯æ–‡ä»¶
            if file_info['mimeType'] == 'application/vnd.google-apps.folder':
                print(f"{file_info['name']}/")
            else:
                print(f"{file_info['name']}")
            
            return {
                "success": True,
                "path": original_path,
                "files": [file_info] if file_info['mimeType'] != 'application/vnd.google-apps.folder' else [],
                "folders": [file_info] if file_info['mimeType'] == 'application/vnd.google-apps.folder' else [],
                "count": 1,
                "mode": "single_file"
            }
            
        except Exception as e:

            return {"success": False, "error": f"æ˜¾ç¤ºå•ä¸ªæ–‡ä»¶æ—¶å‡ºé”™: {e}"}

    def _find_folder(self, folder_name, parent_id):
        """åœ¨æŒ‡å®šçˆ¶ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶å¤¹"""
        try:
            files_result = self.drive_service.list_files(folder_id=parent_id, max_results=100)
            if not files_result['success']:
                return None
            
            for file in files_result['files']:
                if (file['name'] == folder_name and 
                    file['mimeType'] == 'application/vnd.google-apps.folder'):
                    return file
            
            return None
            
        except Exception:
            return None

    def cmd_rm(self, path, recursive=False, force=False):
        """åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•ï¼Œé€šè¿‡è¿œç¨‹rmå‘½ä»¤æ‰§è¡Œ"""
        try:
            if not self.drive_service:
                return {"success": False, "error": "Google Drive API service not initialized"}
                
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "No active remote shell, please create or switch to a shell first"}
            
            if not path:
                return {"success": False, "error": "Please specify file or directory to delete"}
            
            # è§£æè¿œç¨‹ç»å¯¹è·¯å¾„
            absolute_path = self.main_instance.resolve_remote_absolute_path(path, current_shell)
            if not absolute_path:
                return {"success": False, "error": f"Cannot resolve path: {path}"}
            
            # æ„å»ºrmå‘½ä»¤
            rm_flags = ""
            if recursive:
                rm_flags += "r"
            if force:
                rm_flags += "f"
            
            if rm_flags:
                remote_command = f'rm -{rm_flags} "{absolute_path}"'
            else:
                remote_command = f'rm "{absolute_path}"'
            
            # æ‰§è¡Œè¿œç¨‹å‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if result["success"]:
                # ç®€åŒ–éªŒè¯é€»è¾‘ï¼šå¦‚æœè¿œç¨‹å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œå°±è®¤ä¸ºåˆ é™¤æˆåŠŸ
                # é¿å…å¤æ‚çš„éªŒè¯é€»è¾‘å¯¼è‡´è¯¯æŠ¥
                return {
                    "success": True,
                    "path": path,
                    "absolute_path": absolute_path,
                    "remote_command": remote_command,
                    "message": "",  # ç©ºæ¶ˆæ¯ï¼Œåƒbash shellä¸€æ ·
                }
            else:
                return result
                
        except Exception as e:
            return {"success": False, "error": f"Error executing rm command: {e}"}

    # cmd_echo å·²åˆ é™¤ - ç»Ÿä¸€ä½¿ç”¨ google_drive_shell.py ä¸­çš„ _handle_unified_echo_command

    def _create_text_file(self, filename, content):
        """é€šè¿‡è¿œç¨‹å‘½ä»¤åˆ›å»ºæ–‡æœ¬æ–‡ä»¶"""
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            # æ„å»ºè¿œç¨‹echoå‘½ä»¤
            remote_absolute_path = self.main_instance.resolve_remote_absolute_path(filename, current_shell)
            
            # ä½¿ç”¨base64ç¼–ç æ¥å®Œå…¨é¿å…å¼•å·å’Œç‰¹æ®Šå­—ç¬¦é—®é¢˜
            import base64
            content_bytes = content.encode('utf-8')
            content_base64 = base64.b64encode(content_bytes).decode('ascii')
            
            # æ„å»ºè¿œç¨‹å‘½ä»¤ - ä½¿ç”¨base64è§£ç é¿å…æ‰€æœ‰å¼•å·é—®é¢˜
            remote_command = f'echo "{content_base64}" | base64 -d > "{remote_absolute_path}"'
            
            # ä½¿ç”¨è¿œç¨‹å‘½ä»¤æ‰§è¡Œæ¥å£
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if result.get("success"):
                # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«åˆ›å»ºäº†
                verification_result = self.main_instance.verify_creation_with_ls(
                    filename, current_shell, creation_type="file", max_attempts=30
                )
                
                if verification_result.get("success", False):
                    return {
                        "success": True,
                        "filename": filename,
                        "message": f"Created: {filename}"
                    }
                else:
                    return {
                        "success": False,
                        "error": f"File create command succeeded but verification failed: {verification_result.get('error', 'Unknown verification error')}"
                    }
            else:
                # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„é”™è¯¯ä¿¡æ¯
                error_msg = result.get('error_info') or result.get('error') or 'Unknown error'
                return {
                    "success": False,
                    "error": f"Create file failed: {error_msg}"
                }
                
        except Exception as e:
            return {"success": False, "error": f"Create file failed: {e}"}

    def cmd_cat(self, filename):
        """catå‘½ä»¤ - æ˜¾ç¤ºæ–‡ä»¶å†…å®¹"""
        try:
            if not self.drive_service:
                return {"success": False, "error": "Google Drive API service not initialized"}
                
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "No active remote shell, please create or switch to a shell"}
            
            if not filename:
                return {"success": False, "error": "Please specify the file to view"}
            
            # æŸ¥æ‰¾æ–‡ä»¶
            file_info = self._find_file(filename, current_shell)
            if not file_info:
                return {"success": False, "error": f"File or directory does not exist"}
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
            if file_info['mimeType'] == 'application/vnd.google-apps.folder':
                return {"success": False, "error": f"cat: {filename}: Is a directory"}
            
            # ä¸‹è½½å¹¶è¯»å–æ–‡ä»¶å†…å®¹
            try:
                import io
                from googleapiclient.http import MediaIoBaseDownload
                
                request = self.drive_service.service.files().get_media(fileId=file_info['id'])
                fh = io.BytesIO()
                downloader = MediaIoBaseDownload(fh, request)
                
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
                
                content = fh.getvalue().decode('utf-8', errors='replace')
                return {"success": True, "output": content, "filename": filename}
                
            except Exception as e:
                return {"success": False, "error": f"Cannot read file content: {e}"}
                
        except Exception as e:
            return {"success": False, "error": f"Execute cat command failed: {e}"}

    def cmd_grep(self, pattern, *filenames):
        """grepå‘½ä»¤ - åœ¨æ–‡ä»¶ä¸­æœç´¢æ¨¡å¼ï¼Œæ”¯æŒå¤šæ–‡ä»¶å’Œregex"""
        import re
        
        try:
            if not pattern:
                return {"success": False, "error": "Please specify the search pattern"}
            
            if not filenames:
                return {"success": False, "error": "Please specify the file to search"}
            
            # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
            try:
                regex = re.compile(pattern)
            except re.error as e:
                return {"success": False, "error": f"Invalid regular expression: {e}"}
            
            result = {}
            
            for filename in filenames:
                # è·å–æ–‡ä»¶å†…å®¹
                cat_result = self.cmd_cat(filename)
                if not cat_result["success"]:
                    result[filename] = {
                        "local_file": None,
                        "occurrences": [],
                        "error": cat_result["error"]
                    }
                    continue
                
                content = cat_result["output"]
                lines = content.split('\n')
                
                # æœç´¢åŒ¹é…çš„ä½ç½®
                occurrences = {}
                for line_num, line in enumerate(lines, 1):
                    line_matches = []
                    for match in regex.finditer(line):
                        line_matches.append(match.start())
                    if line_matches:
                        occurrences[line_num] = line_matches
                
                # è½¬æ¢ä¸ºæ‰€éœ€æ ¼å¼: {line_num: [positions]}
                formatted_occurrences = occurrences
                
                # è·å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶è·¯å¾„
                local_file = self.main_instance.cache_manager._get_local_cache_path(filename)
                
                result[filename] = {
                    "local_file": local_file,
                    "occurrences": formatted_occurrences
                }
            
            return {"success": True, "result": result}
                
        except Exception as e:
            return {"success": False, "error": f"Grep command failed: {str(e)}"}

    def cmd_upload_multi(self, file_pairs, force=False, remove_local=False):
        """
        å¤šæ–‡ä»¶ä¸Šä¼ å‘½ä»¤ï¼Œæ”¯æŒ [[src1, dst1], [src2, dst2], ...] è¯­æ³•
        
        Args:
            file_pairs (list): æ–‡ä»¶å¯¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º [æºæ–‡ä»¶è·¯å¾„, è¿œç«¯ç›®æ ‡è·¯å¾„]
            
        Returns:
            dict: ä¸Šä¼ ç»“æœ
        """
        try:
            # 0. æ£€æŸ¥Google Drive Desktopæ˜¯å¦è¿è¡Œ
            if not self.ensure_google_drive_desktop_running():
                return {"success": False, "error": "User cancelled upload operation"}
            
            if not file_pairs:
                return {"success": False, "error": "Please specify file pairs to upload"}
            
            # éªŒè¯æ–‡ä»¶å¯¹æ ¼å¼å’Œæºæ–‡ä»¶å”¯ä¸€æ€§
            validated_pairs = []
            source_files = set()
            
            for pair in file_pairs:
                if not isinstance(pair, (list, tuple)) or len(pair) != 2:
                    return {"success": False, "error": "File pair format error, each element should be [source_file, remote_path]"}
                src_file, dst_path = pair
                if not os.path.exists(src_file):
                    return {"success": False, "error": f"Source file does not exist: {src_file}"}
                
                # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦é‡å¤
                abs_src_file = os.path.abspath(src_file)
                if abs_src_file in source_files:
                    return {
                        "success": False,
                        "error": f"Source file conflict: {src_file} cannot be uploaded to multiple locations"
                    }
                source_files.add(abs_src_file)
                
                validated_pairs.append([src_file, dst_path])
            
            # ç¬¬ä¸€é˜¶æ®µï¼šæ£€æŸ¥ç›®æ ‡ç›®å½•å†²çªå’Œæ–‡ä»¶å­˜åœ¨å†²çª
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "No active remote shell, please create or switch to a shell"}
            
            # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦æœ‰é‡å¤
            target_paths = set()
            for src_file, dst_path in validated_pairs:
                filename = Path(src_file).name
                
                # åˆ¤æ–­ dst_path æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
                # ä½¿ç”¨åŸæ¥çš„é€»è¾‘ï¼šæ£€æŸ¥è·¯å¾„æœ€åä¸€ä¸ªéƒ¨åˆ†æ˜¯å¦åŒ…å«ç‚¹å·
                last_part = dst_path.split('/')[-1]
                is_file = '.' in last_part and last_part != '.' and last_part != '..'
                
                # è®¡ç®—å®Œæ•´çš„è¿œç«¯ç›®æ ‡è·¯å¾„
                if is_file:
                    # dst_path æ˜¯æ–‡ä»¶åï¼Œéœ€è¦æ”¾åœ¨å½“å‰ç›®å½•ä¸­
                    if dst_path.startswith("/"):
                        # ç»å¯¹è·¯å¾„æ–‡ä»¶å
                        full_target_path = dst_path
                    else:
                        # ç›¸å¯¹è·¯å¾„æ–‡ä»¶åï¼Œæ”¾åœ¨å½“å‰shellç›®å½•ä¸­
                        current_path = current_shell.get("current_path", "~")
                        if current_path == "~":
                            full_target_path = f"~/{dst_path}"
                        else:
                            full_target_path = f"{current_path}/{dst_path}"
                else:
                    # dst_path æ˜¯æ–‡ä»¶å¤¹ï¼Œåœ¨åé¢æ·»åŠ æ–‡ä»¶å
                    if dst_path.startswith("/"):
                        full_target_path = f"{dst_path.rstrip('/')}/{filename}"
                    elif dst_path == "." or dst_path == "":
                        if current_shell.get("current_path") != "~":
                            current_path = current_shell.get("current_path", "~")
                            if current_path.startswith("~/"):
                                full_target_path = f"{current_path}/{filename}"
                            else:
                                full_target_path = f"~/{filename}"
                        else:
                            full_target_path = f"~/{filename}"
                    else:
                        if current_shell.get("current_path") != "~":
                            current_path = current_shell.get("current_path", "~")
                            if current_path.startswith("~/"):
                                base_path = current_path[2:] if len(current_path) > 2 else ""
                                if base_path:
                                    full_target_path = f"~/{base_path}/{dst_path.strip('/')}/{filename}"
                                else:
                                    full_target_path = f"~/{dst_path.strip('/')}/{filename}"
                            else:
                                full_target_path = f"~/{dst_path.strip('/')}/{filename}"
                        else:
                            full_target_path = f"~/{dst_path.strip('/')}/{filename}"
                
                if full_target_path in target_paths:
                    return {
                        "success": False,
                        "error": f"Target path conflict: {full_target_path} specified by multiple files"
                    }
                target_paths.add(full_target_path)
            
            # æ£€æŸ¥æ¯ä¸ªç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé™¤éä½¿ç”¨--forceï¼‰
            overridden_files = []
            if not force:
                for src_file, dst_path in validated_pairs:
                    filename = Path(src_file).name
                    
                    # è®¡ç®—è¿œç«¯ç»å¯¹è·¯å¾„
                    if dst_path.startswith("/"):
                        remote_file_path = f"{dst_path.rstrip('/')}/{filename}"
                    elif dst_path == "." or dst_path == "":
                        if current_shell.get("current_path") != "~":
                            current_path = current_shell.get("current_path", "~")
                            if current_path.startswith("~/"):
                                remote_file_path = f"{current_path}/{filename}"
                            else:
                                remote_file_path = f"~/{filename}"
                        else:
                            remote_file_path = f"~/{filename}"
                    else:
                        if current_shell.get("current_path") != "~":
                            current_path = current_shell.get("current_path", "~")
                            if current_path.startswith("~/"):
                                base_path = current_path[2:] if len(current_path) > 2 else ""
                                if base_path:
                                    remote_file_path = f"~/{base_path}/{dst_path.strip('/')}/{filename}"
                                else:
                                    remote_file_path = f"~/{dst_path.strip('/')}/{filename}"
                            else:
                                remote_file_path = f"~/{dst_path.strip('/')}/{filename}"
                        else:
                            remote_file_path = f"~/{dst_path.strip('/')}/{filename}"
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    dir_path = '/'.join(remote_file_path.split('/')[:-1]) if remote_file_path.count('/') > 0 else "~"
                    file_name = remote_file_path.split('/')[-1]
                    
                    ls_result = self.main_instance.cmd_ls(dir_path, detailed=False, recursive=False)
                    if ls_result["success"] and "files" in ls_result:
                        existing_files = [f["name"] for f in ls_result["files"]]
                        if file_name in existing_files:
                            return {
                                "success": False,
                                "error": f"File exists: {remote_file_path}"
                            }
            else:
                # Forceæ¨¡å¼ï¼šæ£€æŸ¥å“ªäº›æ–‡ä»¶ä¼šè¢«è¦†ç›–ï¼Œè®°å½•è­¦å‘Š
                for src_file, dst_path in validated_pairs:
                    filename = Path(src_file).name
                    
                    # è®¡ç®—è¿œç«¯ç»å¯¹è·¯å¾„
                    if dst_path.startswith("/"):
                        remote_file_path = f"{dst_path.rstrip('/')}/{filename}"
                    elif dst_path == "." or dst_path == "":
                        if current_shell.get("current_path") != "~":
                            current_path = current_shell.get("current_path", "~")
                            if current_path.startswith("~/"):
                                remote_file_path = f"{current_path}/{filename}"
                            else:
                                remote_file_path = f"~/{filename}"
                        else:
                            remote_file_path = f"~/{filename}"
                    else:
                        if current_shell.get("current_path") != "~":
                            current_path = current_shell.get("current_path", "~")
                            if current_path.startswith("~/"):
                                base_path = current_path[2:] if len(current_path) > 2 else ""
                                if base_path:
                                    remote_file_path = f"~/{base_path}/{dst_path.strip('/')}/{filename}"
                                else:
                                    remote_file_path = f"~/{dst_path.strip('/')}/{filename}"
                            else:
                                remote_file_path = f"~/{dst_path.strip('/')}/{filename}"
                        else:
                            remote_file_path = f"~/{dst_path.strip('/')}/{filename}"
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è®°å½•ä¸ºè¦†ç›–
                    dir_path = '/'.join(remote_file_path.split('/')[:-1]) if remote_file_path.count('/') > 0 else "~"
                    file_name = remote_file_path.split('/')[-1]
                    
                    ls_result = self.main_instance.cmd_ls(dir_path, detailed=False, recursive=False)
                    if ls_result["success"] and "files" in ls_result:
                        existing_files = [f["name"] for f in ls_result["files"]]
                        if file_name in existing_files:
                            overridden_files.append(remote_file_path)
                            print(f"Warning: Overriding remote file {remote_file_path}")
            
            # ç¬¬äºŒé˜¶æ®µï¼šæ‰§è¡Œå¤šæ–‡ä»¶ä¸Šä¼ 
            all_file_moves = []
            failed_moves = []
            
            # ç§»åŠ¨æ‰€æœ‰æ–‡ä»¶åˆ°LOCAL_EQUIVALENT
            for src_file, dst_path in validated_pairs:
                move_result = self.main_instance.move_to_local_equivalent(src_file)
                if move_result["success"]:
                    all_file_moves.append({
                        "original_path": move_result["original_path"],
                        "filename": move_result["filename"],
                        "new_path": move_result["new_path"],
                        "renamed": move_result["renamed"],
                        "target_path": dst_path
                    })
                else:
                    failed_moves.append({
                        "file": src_file,
                        "error": move_result["error_info"]
                    })
            
            if not all_file_moves:
                return {
                    "success": False,
                    "error": "æ‰€æœ‰æ–‡ä»¶ç§»åŠ¨å¤±è´¥",
                    "failed_moves": failed_moves
                }
            
            # ç­‰å¾…æ–‡ä»¶åŒæ­¥åˆ°DRIVE_EQUIVALENT
            expected_filenames = [fm["filename"] for fm in all_file_moves]
            sync_result = self.wait_for_file_sync(expected_filenames, all_file_moves)
            
            if not sync_result["success"]:
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶åŒæ­¥æ£€æµ‹å¤±è´¥: {sync_result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                    "file_moves": all_file_moves,
                    "sync_time": sync_result.get("sync_time", 0)
                }
            
            # ç”Ÿæˆå¼‚æ­¥è¿œç«¯å‘½ä»¤
            remote_command = self._generate_multi_file_commands(all_file_moves)
            
            # æ‰§è¡Œè¿œç«¯å‘½ä»¤
            context_info = {
                "file_moves": all_file_moves,
                "multi_file": True
            }
            
            execution_result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if not execution_result["success"]:
                return {
                    "success": False,
                    "error": execution_result.get("error", execution_result.get("data", {}).get("error", "Unknown error")),
                    "remote_command": remote_command,
                    "execution_result": execution_result
                }
            
            # å¦‚æœæŒ‡å®šäº† --remove-local é€‰é¡¹ï¼Œåˆ é™¤æœ¬åœ°æºæ–‡ä»¶
            removed_files = []
            failed_removals = []
            if remove_local and execution_result["success"]:
                for src_file, _ in validated_pairs:
                    try:
                        if os.path.exists(src_file):
                            os.unlink(src_file)
                            removed_files.append(src_file)
                    except Exception as e:
                        failed_removals.append({"file": src_file, "error": str(e)})
            
            result = {
                "success": True,
                "uploaded_files": [{"name": fm["filename"], "target_path": fm["target_path"]} for fm in all_file_moves],
                "failed_files": [fm["file"] for fm in failed_moves],
                "total_attempted": len(validated_pairs),
                "total_succeeded": len(all_file_moves),
                "message": f"å¤šæ–‡ä»¶ä¸Šä¼ å®Œæˆ: {len(all_file_moves)}/{len(validated_pairs)} ä¸ªæ–‡ä»¶æˆåŠŸ",
                "sync_time": sync_result.get("sync_time", 0),
                "remote_command": remote_command
            }
            
            # æ·»åŠ æœ¬åœ°æ–‡ä»¶åˆ é™¤ä¿¡æ¯
            if remove_local:
                result["removed_local_files"] = removed_files
                result["failed_local_removals"] = failed_removals
                if removed_files:
                    result["message"] += f" (removed {len(removed_files)} local files)"
                if failed_removals:
                    result["message"] += f" (failed to remove {len(failed_removals)} local files)"
            
            return result
            
        except Exception as e:
            return {"success": False, "error": f"å¤šæ–‡ä»¶ä¸Šä¼ æ—¶å‡ºé”™: {e}"}

    def cmd_download(self, filename, local_path=None, force=False):
        """
        downloadå‘½ä»¤ - ä»Google Driveä¸‹è½½æ–‡ä»¶å¹¶ç¼“å­˜
        ç”¨æ³•ï¼š
        - download A: ä¸‹è½½åˆ°ç¼“å­˜ç›®å½•ï¼Œæ˜¾ç¤ºå“ˆå¸Œæ–‡ä»¶å
        - download A B: ä¸‹è½½åˆ°ç¼“å­˜ç›®å½•ï¼Œç„¶åå¤åˆ¶åˆ°æŒ‡å®šä½ç½®ï¼ˆç±»ä¼¼cpæ“ä½œï¼‰
        - download --force A: å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼Œæ›¿æ¢ç¼“å­˜
        """
        try:
            # å¯¼å…¥ç¼“å­˜ç®¡ç†å™¨
            import sys
            from pathlib import Path
            cache_manager_path = Path(__file__).parent.parent / "cache_manager.py"
            if cache_manager_path.exists():
                sys.path.insert(0, str(Path(__file__).parent.parent))
                from cache_manager import GDSCacheManager
                cache_manager = GDSCacheManager()
            else:
                return {"success": False, "error": "ç¼“å­˜ç®¡ç†å™¨æœªæ‰¾åˆ°"}
            
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            # æ„å»ºè¿œç«¯ç»å¯¹è·¯å¾„
            remote_absolute_path = self.main_instance.resolve_remote_absolute_path(filename, current_shell)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ç¼“å­˜ï¼ˆå¦‚æœforce=Trueåˆ™è·³è¿‡ç¼“å­˜æ£€æŸ¥ï¼‰
            if not force and cache_manager.is_file_cached(remote_absolute_path):
                cached_info = cache_manager.get_cached_file(remote_absolute_path)
                cached_path = cache_manager.get_cached_file_path(remote_absolute_path)
                
                if local_path:
                    # å¦‚æœæŒ‡å®šäº†æœ¬åœ°ç›®æ ‡ï¼Œå¤åˆ¶ç¼“å­˜æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®ï¼ˆcpæ“ä½œï¼‰
                    import shutil
                    if os.path.isdir(local_path):
                        # ä»åŸå§‹filenameä¸­æå–å®é™…æ–‡ä»¶åï¼ˆä¸åŒ…å«è·¯å¾„éƒ¨åˆ†ï¼‰
                        actual_filename = os.path.basename(filename)
                        target_path = os.path.join(local_path, actual_filename)
                    else:
                        target_path = local_path
                    
                    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(os.path.abspath(target_path)), exist_ok=True)
                    shutil.copy2(cached_path, target_path)
                    
                    return {
                        "success": True,
                        "message": f"Using cached file: {target_path}",
                        "source": "cache",
                        "remote_path": remote_absolute_path,
                        "cache_file": cached_info["cache_file"],
                        "local_path": target_path,
                        "cache_status": cached_info["status"]
                    }
                else:
                    # åªæ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
                    return {
                        "success": True,
                        "message": f"Using cached file: {cached_info['cache_file']}",
                        "source": "cache",
                        "remote_path": remote_absolute_path,
                        "cache_file": cached_info["cache_file"],
                        "cached_path": cached_path,
                        "cache_status": cached_info["status"]
                    }
            
            # æ–‡ä»¶æœªç¼“å­˜æˆ–å¼ºåˆ¶é‡æ–°ä¸‹è½½
            # å¦‚æœæ˜¯å¼ºåˆ¶æ¨¡å¼ä¸”æ–‡ä»¶å·²ç¼“å­˜ï¼Œå…ˆåˆ é™¤æ—§ç¼“å­˜
            if force and cache_manager.is_file_cached(remote_absolute_path):
                old_cached_info = cache_manager.get_cached_file(remote_absolute_path)
                old_cache_file = old_cached_info.get("cache_file")
                
                # åˆ é™¤æ—§çš„ç¼“å­˜æ–‡ä»¶
                cleanup_result = cache_manager.cleanup_cache(remote_absolute_path)
                force_info = {
                    "force_mode": True,
                    "removed_old_cache": cleanup_result.get("success", False),
                    "old_cache_file": old_cache_file
                }
            else:
                force_info = {"force_mode": False}
            
            # è§£æè·¯å¾„ä»¥è·å–ç›®æ ‡æ–‡ä»¶å¤¹å’Œæ–‡ä»¶å
            file_info = None
            target_folder_id = None
            actual_filename = None
            
            # åˆ†æè·¯å¾„ï¼šåˆ†ç¦»ç›®å½•è·¯å¾„å’Œæ–‡ä»¶å
            if '/' in filename:
                # åŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼Œéœ€è¦è§£æè·¯å¾„
                path_parts = filename.rsplit('/', 1)  # ä»å³è¾¹åˆ†å‰²ï¼Œåªåˆ†å‰²ä¸€æ¬¡
                dir_path = path_parts[0] if path_parts[0] else '/'
                actual_filename = path_parts[1]
                
                # è§£æç›®å½•è·¯å¾„
                target_folder_id, resolved_path = self.main_instance.resolve_path(dir_path, current_shell)
                if not target_folder_id:
                    return {"success": False, "error": f"Download failed: directory not found: {dir_path}"}
            else:
                # æ²¡æœ‰è·¯å¾„åˆ†éš”ç¬¦ï¼Œåœ¨å½“å‰ç›®å½•æŸ¥æ‰¾
                target_folder_id = current_shell.get("current_folder_id")
                actual_filename = filename
            
            # åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾æ–‡ä»¶
            result = self.drive_service.list_files(folder_id=target_folder_id, max_results=100)
            if result['success']:
                files = result['files']
                for file in files:
                    if file['name'] == actual_filename:
                        file_info = file
                        break
            
            if not file_info:
                return {"success": False, "error": f"Download failed: file not found: {actual_filename}"}
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆä¸æ˜¯æ–‡ä»¶å¤¹ï¼‰
            if file_info['mimeType'] == 'application/vnd.google-apps.folder':
                return {"success": False, "error": f"download: {actual_filename}: æ˜¯ä¸€ä¸ªç›®å½•ï¼Œæ— æ³•ä¸‹è½½"}
            
            # ä½¿ç”¨Google Drive APIç›´æ¥ä¸‹è½½æ–‡ä»¶
            import tempfile
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{actual_filename}") as temp_file:
                temp_path = temp_file.name
            
            try:
                # ä½¿ç”¨Google Drive APIä¸‹è½½æ–‡ä»¶å†…å®¹
                file_id = file_info['id']
                request = self.drive_service.service.files().get_media(fileId=file_id)
                content = request.execute()
                
                # å°†å†…å®¹å†™å…¥ä¸´æ—¶æ–‡ä»¶
                with open(temp_path, 'wb') as f:
                    f.write(content)
                
                # ä¸‹è½½æˆåŠŸï¼Œç¼“å­˜æ–‡ä»¶
                cache_result = cache_manager.cache_file(
                    remote_path=remote_absolute_path,
                    temp_file_path=temp_path
                )
                
                if cache_result["success"]:
                    if local_path:
                        # å¦‚æœæŒ‡å®šäº†æœ¬åœ°ç›®æ ‡ï¼Œä¹Ÿå¤åˆ¶åˆ°ç›®æ ‡ä½ç½®ï¼ˆcpæ“ä½œï¼‰
                        import shutil
                        if os.path.isdir(local_path):
                            target_path = os.path.join(local_path, actual_filename)
                        else:
                            target_path = local_path
                        
                        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                        os.makedirs(os.path.dirname(os.path.abspath(target_path)), exist_ok=True)
                        shutil.copy2(temp_path, target_path)
                        
                        result = {
                            "success": True,
                            "message": f"Downloaded successfully to: {target_path}",
                            "source": "download",
                            "remote_path": remote_absolute_path,
                            "cache_file": cache_result["cache_file"],
                            "cache_path": cache_result["cache_path"],
                            "local_path": target_path
                        }
                        result.update(force_info)
                        return result
                    else:
                        # åªæ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
                        result = {
                            "success": True,
                            "message": f"Downloaded successfully to: {cache_result['cache_file']}",
                            "source": "download",
                            "remote_path": remote_absolute_path,
                            "cache_file": cache_result["cache_file"],
                            "cache_path": cache_result["cache_path"]
                        }
                        result.update(force_info)
                        return result
                else:
                    return {"success": False, "error": f"Download failed: {cache_result.get('error')}"}
                    
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
                    
        except Exception as e:
            return {"success": False, "error": f"ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}"}

    def cmd_mv_multi(self, file_pairs, force=False):
        """
        å¤šæ–‡ä»¶ç§»åŠ¨å‘½ä»¤ï¼Œæ”¯æŒ [[src1, dst1], [src2, dst2], ...] è¯­æ³•
        
        Args:
            file_pairs (list): æ–‡ä»¶å¯¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º [æºè¿œç«¯è·¯å¾„, ç›®æ ‡è¿œç«¯è·¯å¾„]
            
        Returns:
            dict: ç§»åŠ¨ç»“æœ
        """
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            if not file_pairs:
                return {"success": False, "error": "è¯·æŒ‡å®šè¦ç§»åŠ¨çš„æ–‡ä»¶å¯¹"}
            
            # éªŒè¯æ–‡ä»¶å¯¹æ ¼å¼å¹¶æ£€æŸ¥å†²çª
            validated_pairs = []
            target_destinations = set()
            source_files = set()
            
            for pair in file_pairs:
                if not isinstance(pair, (list, tuple)) or len(pair) != 2:
                    return {"success": False, "error": "æ–‡ä»¶å¯¹æ ¼å¼é”™è¯¯ï¼Œæ¯ä¸ªå…ƒç´ åº”ä¸º [æºè·¯å¾„, ç›®æ ‡è·¯å¾„]"}
                
                source, destination = pair
                if not source or not destination:
                    return {"success": False, "error": "Source and destination paths cannot be empty"}
                
                # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦é‡å¤
                abs_source_path = self.main_instance.resolve_remote_absolute_path(source, current_shell)
                if abs_source_path in source_files:
                    return {
                        "success": False,
                        "error": f"Source file conflict: {source} cannot be moved to multiple destinations"
                    }
                source_files.add(abs_source_path)
                
                # è®¡ç®—ç›®æ ‡çš„è¿œç«¯ç»å¯¹è·¯å¾„ç”¨äºé‡å¤æ£€æµ‹
                if destination.startswith("/"):
                    abs_destination = destination
                else:
                    if current_shell and current_shell.get("current_path") != "~":
                        current_path = current_shell.get("current_path", "~")
                        if current_path.startswith("~/"):
                            relative_path = current_path[2:] if len(current_path) > 2 else ""
                            if relative_path:
                                abs_destination = f"~/{relative_path}/{destination}"
                            else:
                                abs_destination = f"~/{destination}"
                        else:
                            abs_destination = f"~/{destination}"
                    else:
                        abs_destination = f"~/{destination}"
                
                # æ£€æŸ¥ç›®æ ‡è·¯å¾„æ˜¯å¦é‡å¤
                if abs_destination in target_destinations:
                    return {
                        "success": False,
                        "error": f"Destination path conflict: {abs_destination} specified by multiple files"
                    }
                target_destinations.add(abs_destination)
                
                # ç®€åŒ–ç‰ˆæœ¬ï¼šä¸è¿›è¡Œå¤æ‚çš„å†²çªæ£€æŸ¥
                
                validated_pairs.append([source, destination])
            
            # ç”Ÿæˆå¤šæ–‡ä»¶mvçš„è¿œç«¯å‘½ä»¤
            remote_command = self._generate_multi_mv_commands(validated_pairs, current_shell)
            
            # æ‰§è¡Œè¿œç«¯å‘½ä»¤
            context_info = {
                "file_pairs": validated_pairs,
                "multi_file": True
            }
            
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if result.get("success"):
                return {
                    "success": True,
                    "moved_files": [{"source": src, "destination": dst} for src, dst in validated_pairs],
                    "total_moved": len(validated_pairs),
                    "message": f"å¤šæ–‡ä»¶ç§»åŠ¨å®Œæˆ: {len(validated_pairs)} ä¸ªæ–‡ä»¶",
                    "verification": "success"
                }
            else:
                error_msg = result.get("message", result.get("error", "æœªçŸ¥é”™è¯¯"))
                return {
                    "success": False,
                    "error": f"å¤šæ–‡ä»¶ç§»åŠ¨å¤±è´¥: {error_msg}",
                    "verification": "failed"
                }
                
        except Exception as e:
            return {"success": False, "error": f"å¤šæ–‡ä»¶ç§»åŠ¨æ—¶å‡ºé”™: {e}"}

    def cmd_mv(self, source, destination, force=False):
        """mvå‘½ä»¤ - ç§»åŠ¨/é‡å‘½åæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼ˆä½¿ç”¨è¿œç«¯æŒ‡ä»¤æ‰§è¡Œï¼‰"""
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            if not source or not destination:
                return {"success": False, "error": "ç”¨æ³•: mv <source> <destination>"}
            
            # ç®€åŒ–ç‰ˆæœ¬ï¼šä¸è¿›è¡Œå¤æ‚çš„å†²çªæ£€æŸ¥
            
            # æ„å»ºè¿œç«¯mvå‘½ä»¤ - éœ€è¦è®¡ç®—ç»å¯¹è·¯å¾„
            source_absolute_path = self.main_instance.resolve_remote_absolute_path(source, current_shell)
            destination_absolute_path = self.main_instance.resolve_remote_absolute_path(destination, current_shell)
            
            # æ„å»ºå¢å¼ºçš„è¿œç«¯å‘½ä»¤ï¼ŒåŒ…å«æˆåŠŸ/å¤±è´¥æç¤º
            base_command = f"mv {source_absolute_path} {destination_absolute_path}"
            remote_command = f"({base_command})"
            
            # ä½¿ç”¨è¿œç«¯æŒ‡ä»¤æ‰§è¡Œæ¥å£
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if result.get("success"):
                # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«ç§»åŠ¨äº†
                verification_result = self.main_instance.verify_creation_with_ls(
                    destination, current_shell, creation_type="file", max_attempts=30
                )
                
                if verification_result.get("success", False):
                    return {
                        "success": True,
                        "source": source,
                        "destination": destination,
                        "message": f""
                    }
                else:
                    return {
                        "success": False,
                        "error": f"mvå‘½ä»¤æ‰§è¡ŒæˆåŠŸä½†éªŒè¯å¤±è´¥: {verification_result.get('error', 'Unknown verification error')}"
                    }
            else:
                # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„é”™è¯¯ä¿¡æ¯
                error_msg = result.get('error_info') or result.get('error') or 'Unknown error'
                return {
                    "success": False,
                    "error": f"è¿œç«¯mvå‘½ä»¤æ‰§è¡Œå¤±è´¥: {error_msg}"
                }
                
        except Exception as e:
            return {"success": False, "error": f"æ‰§è¡Œmvå‘½ä»¤æ—¶å‡ºé”™: {e}"}

    def _find_file(self, filepath, current_shell):
        """æŸ¥æ‰¾æ–‡ä»¶ï¼Œæ”¯æŒè·¯å¾„è§£æ"""
        try:
            # å¦‚æœåŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼Œéœ€è¦è§£æè·¯å¾„
            if '/' in filepath:
                # åˆ†ç¦»ç›®å½•å’Œæ–‡ä»¶å
                dir_path, filename = filepath.rsplit('/', 1)
                
                # è§£æç›®å½•è·¯å¾„
                target_folder_id, _ = self.main_instance.resolve_path(dir_path, current_shell)
                if not target_folder_id:
                    return None
            else:
                # åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾
                filename = filepath
                target_folder_id = current_shell.get("current_folder_id", self.main_instance.REMOTE_ROOT_FOLDER_ID)
            
            # åˆ—å‡ºç›®æ ‡ç›®å½•å†…å®¹
            files_result = self.drive_service.list_files(folder_id=target_folder_id, max_results=100)
            if not files_result['success']:
                return None
            
            # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
            for file in files_result['files']:
                if file['name'] == filename:
                    return file
            
            return None
            
        except Exception:
            return None

    def cmd_pip(self, *args, **kwargs):
        """æ‰§è¡Œpipå‘½ä»¤ï¼ˆå¢å¼ºç‰ˆ - è‡ªåŠ¨å¤„ç†è™šæ‹Ÿç¯å¢ƒã€æ™ºèƒ½ä¾èµ–åˆ†æã€åŒ…çŠ¶æ€æ˜¾ç¤ºï¼‰"""
        try:
            if not args:
                return {"success": False, "error": "pipå‘½ä»¤éœ€è¦å‚æ•°"}
            
            # æ„å»ºpipå‘½ä»¤
            pip_args = list(args)
            pip_command = " ".join(pip_args)
            
            # è·å–å½“å‰æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒ
            current_shell = self.main_instance.get_current_shell()
            shell_id = current_shell.get("id", "default") if current_shell else "default"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒ
            all_states = self._load_all_venv_states()
            current_venv = None
            env_path = None
            if shell_id in all_states and all_states[shell_id].get("current_venv"):
                current_venv = all_states[shell_id]["current_venv"]
                env_path = f"{self._get_venv_base_path()}/{current_venv}"
            
            # ç‰¹æ®Šå¤„ç†ä¸åŒçš„pipå‘½ä»¤
            if pip_args[0] == "--show-deps":
                # ç›´æ¥å¤„ç† --show-depsï¼Œä¸éœ€è¦è¿œç¨‹æ‰§è¡Œï¼Œé™é»˜è·å–åŒ…ä¿¡æ¯
                current_packages = self._get_packages_from_json(current_venv) if current_venv else {}
                return self._show_dependency_tree(pip_args, current_packages)
            
            # æ£€æµ‹å½“å‰ç¯å¢ƒä¸­çš„åŒ…ï¼ˆç”¨äºæ˜¾ç¤º[âˆš]æ ‡è®°ï¼‰
            current_packages = self._detect_current_environment_packages(current_venv)
            
            if pip_args[0] == "install":
                return self._handle_pip_install(pip_args[1:], current_venv, env_path, current_packages)
            elif pip_args[0] == "list":
                return self._handle_pip_list(pip_args[1:], current_venv, env_path, current_packages)
            elif pip_args[0] == "show":
                return self._handle_pip_show(pip_args[1:], current_venv, env_path, current_packages)
            else:
                # å…¶ä»–pipå‘½ä»¤ï¼Œä½¿ç”¨å¢å¼ºç‰ˆæ‰§è¡Œå™¨
                target_info = f"in {current_venv}" if current_venv else "in system environment"
                return self._execute_pip_command_enhanced(pip_command, current_venv, target_info)
                
        except Exception as e:
            return {"success": False, "error": f"æ‰§è¡Œpipå‘½ä»¤æ—¶å‡ºé”™: {str(e)}"}

    def _detect_current_environment_packages(self, current_venv=None):
        """æ£€æµ‹å½“å‰ç¯å¢ƒä¸­å·²å®‰è£…çš„åŒ…"""
        try:
            if current_venv:
                # å‘åå…¼å®¹ï¼šæ£€æŸ¥ç¯å¢ƒçŠ¶æ€æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
                self._ensure_environment_state_exists(current_venv)
                
                env_path = f"{self._get_venv_base_path()}/{current_venv}"
                current_packages = self._scan_environment_packages_real(env_path, current_venv)
            else:
                print(f"No active virtual environment, scanning system packages")
                # å¯¹äºç³»ç»Ÿç¯å¢ƒï¼Œæˆ‘ä»¬å‡è®¾æœ‰ä¸€äº›åŸºç¡€åŒ…
                current_packages = {
                    'pip': '23.0.0',
                    'setuptools': '65.0.0'
                }
            
            return current_packages
            
        except Exception as e:
            print(f"Warning: Package detection failed: {str(e)}")
            return {}



    def _handle_pip_install(self, packages_args, current_venv, env_path, current_packages):
        """å¤„ç†pip installå‘½ä»¤ - åŒ…å«æ™ºèƒ½ä¾èµ–åˆ†æå’Œå·²å®‰è£…åŒ…æ£€æµ‹"""
        try:
            if not packages_args:
                return {"success": False, "error": "pip installéœ€è¦æŒ‡å®šåŒ…å"}
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ --show-deps é€‰é¡¹
            if '--show-deps' in packages_args:
                return self._show_dependency_tree(packages_args, current_packages)
            
            # æ˜¾ç¤ºå½“å‰ç¯å¢ƒä¿¡æ¯
            env_info = f"ç¯å¢ƒ: {current_venv}" if current_venv else "ç¯å¢ƒ: system"
            print(f"{env_info} | å·²æœ‰ {len(current_packages)} ä¸ªåŒ…")
            
            # æ£€æŸ¥å“ªäº›åŒ…å·²ç»å®‰è£…
            installed_packages = []
            new_packages = []
            
            for package in packages_args:
                # ç®€å•çš„åŒ…åæå–ï¼ˆå»é™¤ç‰ˆæœ¬å·ï¼‰
                pkg_name = package.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
                
                if pkg_name in current_packages:
                    installed_packages.append(f"{pkg_name} [âˆš] v{current_packages[pkg_name]}")
                else:
                    new_packages.append(package)
            
            # æ˜¾ç¤ºå·²å®‰è£…çš„åŒ…
            if installed_packages:
                print(f"å·²å®‰è£…çš„åŒ…:")
                for pkg in installed_packages:
                    print(f"  {pkg}")
            
            # å¦‚æœæ²¡æœ‰æ–°åŒ…éœ€è¦å®‰è£…
            if not new_packages:
                return {
                    "success": True,
                    "message": "æ‰€æœ‰æŒ‡å®šçš„åŒ…éƒ½å·²å®‰è£…",
                    "installed_packages": installed_packages
                }
            
            print(f"éœ€è¦å®‰è£…çš„æ–°åŒ…: {', '.join(new_packages)}")
            
            # éªŒè¯åŒ…çš„å¯å®‰è£…æ€§
            validation_result = self._validate_pip_install_packages(new_packages)
            if not validation_result["success"]:
                return validation_result
            
            # æ£€æŸ¥ç‰ˆæœ¬å†²çª
            conflict_result = self._check_pip_version_conflicts(new_packages)
            if conflict_result.get("has_conflicts"):
                print(f"Warning:  {conflict_result['conflicts_summary']}")
                print(f"å»ºè®®: {conflict_result['suggestion']}")
            
            # å°è¯•æ™ºèƒ½å®‰è£…ï¼ˆç”¨äºå¤šåŒ…å®‰è£…ï¼‰
            if len(new_packages) >= 2:
                smart_result = self._smart_pip_install(new_packages)
                if smart_result.get("use_smart_install"):
                    return smart_result
            
            # æ ‡å‡†å®‰è£…æµç¨‹
            install_command = f"install {' '.join(new_packages)}"
            target_info = f"in {current_venv}" if current_venv else "in system environment"
            return self._execute_pip_command_enhanced(install_command, current_venv, target_info)
            
        except Exception as e:
            return {"success": False, "error": f"å¤„ç†pip installæ—¶å‡ºé”™: {str(e)}"}

    def _handle_pip_list(self, list_args, current_venv, env_path, current_packages):
        """å¤„ç†pip listå‘½ä»¤ - æ˜¾ç¤ºå¢å¼ºçš„åŒ…åˆ—è¡¨ä¿¡æ¯"""
        try:
            env_info = f"ç¯å¢ƒ: {current_venv}" if current_venv else "ç¯å¢ƒ: system"
            print(f"Total {len(current_packages)} packages: ")
            
            if current_packages:
                for pkg_name, version in sorted(current_packages.items()):
                    print(f"  {pkg_name} == {version}")
            else:
                print(f"\\næœªæ£€æµ‹åˆ°å·²å®‰è£…çš„åŒ…")
            
            # å¦‚æœæœ‰é¢å¤–çš„listå‚æ•°ï¼Œæ‰§è¡ŒåŸå§‹pip listå‘½ä»¤
            if list_args:
                list_command = f"list {' '.join(list_args)}"
                target_info = f"in {current_venv}" if current_venv else "in system environment"
                return self._execute_pip_command_enhanced(list_command, current_venv, target_info)
            
            return {
                "success": True,
                "packages": current_packages,
                "environment": current_venv or "system"
            }
            
        except Exception as e:
            return {"success": False, "error": f"å¤„ç†pip listæ—¶å‡ºé”™: {str(e)}"}

    def _handle_pip_show(self, show_args, current_venv, env_path, current_packages):
        """å¤„ç†pip showå‘½ä»¤ - æ˜¾ç¤ºåŒ…çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            if not show_args:
                return {"success": False, "error": "pip showéœ€è¦æŒ‡å®šåŒ…å"}
            
            package_name = show_args[0]
            
            # æ£€æŸ¥åŒ…æ˜¯å¦å·²å®‰è£…
            if package_name in current_packages:
                print(f"{package_name} [âˆš] v{current_packages[package_name]} (å·²å®‰è£…)")
            else:
                print(f"{package_name} [Ã—] (æœªå®‰è£…)")
            
            # æ‰§è¡ŒåŸå§‹pip showå‘½ä»¤è·å–è¯¦ç»†ä¿¡æ¯
            show_command = f"show {' '.join(show_args)}"
            target_info = f"in {current_venv}" if current_venv else "in system environment"
            return self._execute_pip_command_enhanced(show_command, current_venv, target_info)
            
        except Exception as e:
                        return {"success": False, "error": f"å¤„ç†pip showæ—¶å‡ºé”™: {str(e)}"}

    def _validate_pip_install_packages(self, packages_args):
        """
        ä¿®å¤é—®é¢˜#4: éªŒè¯pip installåŒ…çš„å¯å®‰è£…æ€§ï¼Œç‰¹åˆ«æ˜¯æœ¬åœ°è·¯å¾„åŒ…
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬'install'ï¼‰
            
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        try:
            # è¿‡æ»¤å‡ºå®é™…çš„åŒ…å/è·¯å¾„ï¼ˆæ’é™¤é€‰é¡¹å‚æ•°ï¼‰
            packages = []
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg.startswith('-'):
                    # è·³è¿‡é€‰é¡¹å‚æ•°
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        i += 2  # è·³è¿‡é€‰é¡¹å’Œå…¶å€¼
                    else:
                        i += 1  # è·³è¿‡å•ä¸ªé€‰é¡¹
                else:
                    packages.append(arg)
                    i += 1
            
            # æ£€æŸ¥æœ¬åœ°è·¯å¾„åŒ…
            local_path_issues = []
            for package in packages:
                if package.startswith('./') or package.startswith('/') or package.startswith('~/'):
                    # è¿™æ˜¯ä¸€ä¸ªæœ¬åœ°è·¯å¾„åŒ…ï¼Œéœ€è¦æ£€æŸ¥å…¶å­˜åœ¨æ€§å’Œå¯å®‰è£…æ€§
                    path_check_result = self._check_local_package_installability(package)
                    if not path_check_result["success"]:
                        local_path_issues.append({
                            "package": package,
                            "issue": path_check_result["error"],
                            "suggestion": path_check_result.get("suggestion", "")
                        })
            
            if local_path_issues:
                error_messages = ["âŒ Local package installation issues found:"]
                for issue in local_path_issues:
                    error_messages.append(f"  â€¢ {issue['package']}: {issue['issue']}")
                    if issue['suggestion']:
                        error_messages.append(f"    ğŸ’¡ Suggestion: {issue['suggestion']}")
                
                return {
                    "success": False,
                    "error": "\n".join(error_messages),
                    "local_path_issues": local_path_issues
                }
            
            return {"success": True}
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Package validation failed: {str(e)}"
            }

    def _check_local_package_installability(self, package_path):
        """æ£€æŸ¥æœ¬åœ°åŒ…è·¯å¾„çš„å¯å®‰è£…æ€§"""
        try:
            # ç®€åŒ–å®ç°ï¼Œåªæ£€æŸ¥åŸºæœ¬çš„è·¯å¾„æ ¼å¼
            if package_path.startswith('~/'):
                return {"success": True}  # è¿œç¨‹è·¯å¾„ï¼Œå‡è®¾å­˜åœ¨
            elif package_path.startswith('./') or package_path.startswith('/'):
                return {"success": True}  # ç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„ï¼Œå‡è®¾å­˜åœ¨
            else:
                return {"success": True}  # å…¶ä»–æ ¼å¼ï¼Œå‡è®¾æœ‰æ•ˆ
        except Exception as e:
            return {
                "success": False,
                "error": f"Path check failed: {str(e)}",
                "suggestion": "Verify the package path exists and is accessible"
            }

    def _check_pip_version_conflicts(self, packages_args):
        """
        ä¿®å¤é—®é¢˜#6: æ£€æµ‹pip installå¯èƒ½çš„ç‰ˆæœ¬å†²çª
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬'install'ï¼‰
            
        Returns:
            dict: å†²çªæ£€æµ‹ç»“æœ
        """
        try:
            # æå–åŒ…åï¼ˆæ’é™¤é€‰é¡¹ï¼‰
            packages = []
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg.startswith('-'):
                    # è·³è¿‡é€‰é¡¹å‚æ•°
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        i += 2
                    else:
                        i += 1
                else:
                    # è§£æåŒ…åå’Œç‰ˆæœ¬è¦æ±‚
                    if '==' in arg or '>=' in arg or '<=' in arg or '>' in arg or '<' in arg or '!=' in arg:
                        # åŒ…å«ç‰ˆæœ¬è¦æ±‚çš„åŒ…
                        packages.append(arg)
                    else:
                        # æ™®é€šåŒ…å
                        packages.append(arg)
                    i += 1
            
            # å·²çŸ¥çš„å¸¸è§ç‰ˆæœ¬å†²çªæ¨¡å¼
            conflict_patterns = {
                'pandas': {
                    'conflicting_packages': ['dask-cudf-cu12', 'cudf-cu12'],
                    'version_constraint': '<2.2.4',
                    'description': 'CUDA packages require pandas < 2.2.4'
                },
                'numpy': {
                    'conflicting_packages': ['numba'],
                    'version_constraint': '<2.1',
                    'description': 'numba requires numpy < 2.1'
                },
                'torch': {
                    'conflicting_packages': ['tensorflow'],
                    'version_constraint': 'varies',
                    'description': 'PyTorch and TensorFlow may have CUDA compatibility issues'
                }
            }
            
            # æ£€æµ‹å†²çª
            detected_conflicts = []
            for package in packages:
                pkg_name = package.split('==')[0].split('>=')[0].split('<=')[0]
                if pkg_name in conflict_patterns:
                    pattern = conflict_patterns[pkg_name]
                    for other_pkg in packages:
                        other_pkg_name = other_pkg.split('==')[0].split('>=')[0].split('<=')[0]
                        if other_pkg_name in pattern['conflicting_packages']:
                            detected_conflicts.append({
                                'package1': pkg_name,
                                'package2': other_pkg_name,
                                'description': pattern['description'],
                                'constraint': pattern['version_constraint']
                            })
            
            if detected_conflicts:
                conflict_summary = f"Found {len(detected_conflicts)} potential conflict(s)"
                suggestion = "Consider installing packages separately or check version compatibility"
                return {
                    "has_conflicts": True,
                    "conflicts": detected_conflicts,
                    "conflicts_summary": conflict_summary,
                    "suggestion": suggestion,
                    "checked_packages": packages
                }
            else:
                return {
                    "has_conflicts": False,
                    "conflicts_summary": "No known conflicts detected",
                    "suggestion": "Proceed with installation",
                    "checked_packages": packages
                }
            
        except Exception as e:
            # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä¸é˜»æ­¢å®‰è£…ï¼Œåªè®°å½•è­¦å‘Š
            return {
                "has_conflicts": False,
                "conflicts_summary": f"Conflict detection failed: {str(e)}",
                "suggestion": "Proceed with caution",
                "checked_packages": []
            }

    def _smart_pip_install(self, packages_args):
        """
        æ™ºèƒ½åŒ…ä¾èµ–ç®¡ç†ç³»ç»Ÿ
        
        åŠŸèƒ½ï¼š
        1. è·å–åŒ…çš„ä¾èµ–å…³ç³»
        2. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒé—´çš„åŒ…å…±äº«å¯èƒ½æ€§
        3. ç»„è£…é€’å½’çš„pipå®‰è£…å‘½ä»¤ï¼ˆæœ€å¤š2å±‚é€’å½’ï¼‰
        4. é¿å…é‡å¤ä¸‹è½½
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬'install'ï¼‰
            
        Returns:
            dict: æ™ºèƒ½å®‰è£…ç»“æœ
        """
        try:
            # æå–å®é™…çš„åŒ…åï¼ˆæ’é™¤é€‰é¡¹ï¼‰
            packages = []
            install_options = []
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg.startswith('-'):
                    # æ”¶é›†å®‰è£…é€‰é¡¹
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        install_options.extend([arg, packages_args[i + 1]])
                        i += 2
                    else:
                        install_options.append(arg)
                        i += 1
                else:
                    packages.append(arg)
                    i += 1
            
            # åªå¯¹å¤šåŒ…å®‰è£…æˆ–å¤æ‚ä¾èµ–å¯ç”¨æ™ºèƒ½å®‰è£…
            if len(packages) < 2:
                return {"use_smart_install": False}
            
            # æ’é™¤æœ¬åœ°è·¯å¾„åŒ…ï¼ˆå®ƒä»¬ä¸é€‚ç”¨äºä¾èµ–åˆ†æï¼‰
            remote_packages = [pkg for pkg in packages 
                             if not pkg.startswith('./') and not pkg.startswith('/') and not pkg.startswith('~/')]
            
            if len(remote_packages) < 2:
                return {"use_smart_install": False}
            
            print(f"Activating smart package management system...")
            print(f"Analyzing {len(remote_packages)} packages for dependency optimization")
            
            # æ£€æµ‹å½“å‰è™šæ‹Ÿç¯å¢ƒä¸­å·²æœ‰çš„åŒ…
            current_packages = self._detect_current_environment_packages(None)
            print(f"Current environment has {len(current_packages)} packages installed")
            
            # ç®€åŒ–çš„æ™ºèƒ½å®‰è£…é€»è¾‘ï¼ˆå®é™…çš„ä¾èµ–åˆ†ææ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œæä¾›åŸºç¡€æ¡†æ¶ï¼‰
            print(f"Smart install analysis completed")
            print(f"No significant optimizations found, using standard installation")
            return {"use_smart_install": False}
                
        except Exception as e:
            print(f"Smart install system error: {str(e)}")
            print(f"Falling back to standard pip install")
            return {"use_smart_install": False}

    def _execute_pip_command_enhanced(self, pip_command, current_env, target_info):
        """å¼ºåŒ–çš„pipå‘½ä»¤æ‰§è¡Œï¼Œæ”¯æŒé”™è¯¯å¤„ç†å’Œç»“æœéªŒè¯"""
        try:
            import time
            import random
            
            # ç”Ÿæˆå”¯ä¸€çš„ç»“æœæ–‡ä»¶å
            timestamp = int(time.time())
            random_id = f"{random.randint(1000, 9999):04x}"
            result_filename = f"pip_result_{timestamp}_{random_id}.json"
            result_file_path = f"/content/drive/MyDrive/REMOTE_ROOT/tmp/{result_filename}"
            
            # æ„å»ºç¯å¢ƒè®¾ç½®å‘½ä»¤
            env_setup = ""
            if current_env:
                env_path = f"{self._get_venv_base_path()}/{current_env}"
                env_setup = f'export PYTHONPATH="{env_path}"'
            
            # ä½¿ç”¨Python subprocessåŒ…è£…pipæ‰§è¡Œï¼Œç¡®ä¿æ­£ç¡®æ•è·æ‰€æœ‰è¾“å‡ºå’Œé”™è¯¯
            python_script = f'''
import subprocess
import json
import sys
from datetime import datetime

print(f"Starting pip {pip_command}...")

# æ‰§è¡Œpipå‘½ä»¤å¹¶æ•è·æ‰€æœ‰è¾“å‡º
try:
    result = subprocess.run(
        ["pip"] + "{pip_command}".split(),
        capture_output=True,
        text=True
    )
    
    # æ˜¾ç¤ºpipçš„å®Œæ•´è¾“å‡º
    if result.stdout:
        print(f"STDOUT:")
        print(result.stdout)
    if result.stderr:
        print(f"STDERR:")
        print(result.stderr)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡ERRORå…³é”®å­—ï¼ˆæ’é™¤ä¾èµ–å†²çªè­¦å‘Šï¼‰
    has_error = False
    if result.returncode != 0:  # åªæœ‰åœ¨é€€å‡ºç é0æ—¶æ‰æ£€æŸ¥é”™è¯¯
        has_error = "ERROR:" in result.stderr or "ERROR:" in result.stdout
    
    print(f"Pip command completed with exit code: {{result.returncode}}")
    if has_error:
        print(f" Detected ERROR messages in pip output")
    
    # ç”Ÿæˆç»“æœJSON
    result_data = {{
        "success": result.returncode == 0 and not has_error,
        "pip_command": "{pip_command}",
        "exit_code": result.returncode,
        "environment": "{current_env or 'system'}",
        "stdout": result.stdout,
        "stderr": result.stderr,
        "has_error": has_error,
        "timestamp": datetime.now().isoformat()
    }}
    
    with open("{result_file_path}", "w") as f:
        json.dump(result_data, f, indent=2)
    
    # æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
    if result.returncode == 0 and not has_error:
        print(f"pip command completed successfully")
    else:
        print(f"pip command failed (exit_code: {{result.returncode}}, has_error: {{has_error}})")

except subprocess.TimeoutExpired:
    print(f"Error:  Pip command timed out after 5 minutes")
    result_data = {{
        "success": False,
        "pip_command": "{pip_command}",
        "exit_code": -1,
        "environment": "{current_env or 'system'}",
        "error": "Command timed out",
        "timestamp": datetime.now().isoformat()
    }}
    with open("{result_file_path}", "w") as f:
        json.dump(result_data, f, indent=2)

except Exception as e:
    print(f"Error: Error executing pip command: {{e}}")
    result_data = {{
        "success": False,
        "pip_command": "{pip_command}",
        "exit_code": -1,
        "environment": "{current_env or 'system'}",
        "error": str(e),
        "timestamp": datetime.now().isoformat()
    }}
    with open("{result_file_path}", "w") as f:
        json.dump(result_data, f, indent=2)
'''
            
            # æ„å»ºå®Œæ•´çš„è¿œç¨‹å‘½ä»¤
            commands = [
                f'cd "{self.main_instance.REMOTE_ROOT}"',
                "mkdir -p tmp",  # ç¡®ä¿è¿œç¨‹tmpç›®å½•å­˜åœ¨
                env_setup,  # è®¾ç½®è™šæ‹Ÿç¯å¢ƒï¼ˆå¦‚æœéœ€è¦ï¼‰
                f"python3 -c '{python_script}'",
                "clear && echo 'âœ… æ‰§è¡Œå®Œæˆ'"  # æ¸…å±å¹¶æ˜¾ç¤ºå®Œæˆæç¤º
            ]
            
            # è¿‡æ»¤ç©ºå‘½ä»¤
            commands = [cmd for cmd in commands if cmd.strip()]
            full_command = " && ".join(commands)
            
            # æ‰§è¡Œè¿œç¨‹å‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", full_command])
            
            if result.get("success"):
                return {
                    "success": True,
                    "message": f"Pip {pip_command} completed successfully {target_info}",
                    "output": result.get("stdout", ""),
                    "environment": current_env or "system"
                }
            else:
                return {
                    "success": False,
                    "error": result.get("error", f"Pip {pip_command} execution failed"),
                    "stderr": result.get("stderr", "")
                }
                
        except Exception as e:
            return {"success": False, "error": f"Enhanced pip execution failed: {str(e)}"}

    def _get_packages_from_json(self, env_name):
        """ä»JSONæ–‡ä»¶ä¸­è·å–åŒ…ä¿¡æ¯"""
        try:
            # åŠ è½½æ‰€æœ‰è™šæ‹Ÿç¯å¢ƒçŠ¶æ€
            all_states = self._load_all_venv_states()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰environmentså­—æ®µ
            if 'environments' in all_states and env_name in all_states['environments']:
                env_data = all_states['environments'][env_name]
                packages = env_data.get('packages', {})
                return packages
            
            return {}
                
        except Exception as e:
            print(f"Error: Failed to get packages from JSON: {str(e)}")
            import traceback
            traceback.print_exc()
            return {}

    def _parse_improved_package_scan_output(self, stdout, env_name):
        """è§£ææ”¹è¿›çš„åŒ…æ‰«æè¾“å‡º"""
        try:
            detected_packages = {}
            
            if not stdout or stdout.strip() == "":
                print(f"Empty scan output")
                return detected_packages
            
            lines = stdout.strip().split('\n')
            current_section = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                if line.startswith('=== Package directories ==='):
                    current_section = 'packages'
                elif line.startswith('=== Dist-info directories ==='):
                    current_section = 'dist-info'
                elif line.startswith('=== Egg-info directories ==='):
                    current_section = 'egg-info'
                elif current_section == 'dist-info' and line.endswith('.dist-info'):
                    # ä».dist-infoç›®å½•åæå–åŒ…åå’Œç‰ˆæœ¬
                    pkg_info = line.replace('.dist-info', '')
                    if '-' in pkg_info:
                        parts = pkg_info.split('-')
                        if len(parts) >= 2:
                            pkg_name = parts[0]
                            version = '-'.join(parts[1:])
                            detected_packages[pkg_name] = version
                elif current_section == 'egg-info' and line.endswith('.egg-info'):
                    # ä».egg-infoç›®å½•åæå–åŒ…åå’Œç‰ˆæœ¬
                    pkg_info = line.replace('.egg-info', '')
                    if '-' in pkg_info:
                        parts = pkg_info.split('-')
                        if len(parts) >= 2:
                            pkg_name = parts[0]
                            version = '-'.join(parts[1:])
                            detected_packages[pkg_name] = version
                elif current_section == 'packages':
                    # å¤„ç†æ™®é€šåŒ…ç›®å½•
                    if line not in ['No package directories', 'Environment directory exists', 'No dist-info found', 'No egg-info found']:
                        # å‡è®¾è¿™æ˜¯ä¸€ä¸ªåŒ…åï¼Œç‰ˆæœ¬æœªçŸ¥
                        if not line.startswith('Environment directory') and not line.startswith('Scanning packages'):
                            detected_packages[line] = 'unknown'
            
            print(f"Parsed {len(detected_packages)} packages from scan output")
            return detected_packages
            
        except Exception as e:
            print(f"Failed to parse package scan output: {str(e)}")
            return {}

    def _initialize_venv_state(self, env_name):
        """ä¸ºæ–°åˆ›å»ºçš„è™šæ‹Ÿç¯å¢ƒåˆå§‹åŒ–çŠ¶æ€æ¡ç›®"""
        return self._initialize_venv_state_simple(env_name)

    def _initialize_venv_state_simple(self, env_name):
        """ç®€åŒ–çš„çŠ¶æ€åˆå§‹åŒ–æ–¹æ³•"""
        try:
            # è¯»å–æ‰€æœ‰çŠ¶æ€
            all_states = self._load_all_venv_states()
            
            # ç¡®ä¿environmentså­—æ®µå­˜åœ¨
            if 'environments' not in all_states:
                all_states['environments'] = {}
            
            # æ£€æŸ¥ç‰¹å®šç¯å¢ƒæ˜¯å¦å­˜åœ¨
            if env_name not in all_states['environments']:
                all_states['environments'][env_name] = {
                    'created_at': self._get_current_timestamp(),
                    'packages': {},
                    'last_updated': self._get_current_timestamp()
                }
                
                # ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
                self._save_all_venv_states(all_states)
                print(f"Initialized state for environment '{env_name}'")
                return True
            else:
                print(f"Environment '{env_name}' already has state entry")
                return True
                
        except Exception as e:
            print(f"Failed to initialize venv state for '{env_name}': {str(e)}")
            return False

    def _initialize_venv_states_batch(self, env_names):
        """æ‰¹é‡åˆå§‹åŒ–è™šæ‹Ÿç¯å¢ƒçŠ¶æ€æ¡ç›®ï¼ˆçŠ¶æ€å·²åœ¨è¿œç¨‹å‘½ä»¤ä¸­åˆå§‹åŒ–ï¼‰"""
        # çŠ¶æ€å·²ç»åœ¨è¿œç¨‹å‘½ä»¤ä¸­åˆå§‹åŒ–ï¼Œè¿™é‡Œåªéœ€è¦è®°å½•æ—¥å¿—
        print(f"Initialized state for {len(env_names)} environment(s): {', '.join(env_names)}")
        return True

    def _prepare_batch_state_init_command(self, env_names):
        """å‡†å¤‡æ‰¹é‡çŠ¶æ€åˆå§‹åŒ–çš„è¿œç¨‹å‘½ä»¤"""
        try:
            if not env_names:
                return None
                
            import json
            from datetime import datetime
            
            # æ„å»ºçŠ¶æ€åˆå§‹åŒ–å‘½ä»¤
            state_file_path = self._get_venv_state_file_path()
            current_time = datetime.now().isoformat()
            
            # æ„å»ºPythonè„šæœ¬æ¥æ›´æ–°çŠ¶æ€
            python_script = f'''
import json
import os
from datetime import datetime

# è¯»å–ç°æœ‰çŠ¶æ€
states = {{}}
state_file = "{state_file_path}"
if os.path.exists(state_file):
    try:
        with open(state_file, 'r') as f:
            states = json.load(f)
    except:
        states = {{}}

# ç¡®ä¿environmentså­—æ®µå­˜åœ¨
if \"environments\" not in states:
    states[\"environments\"] = {{}}

# ä¸ºæ¯ä¸ªæ–°ç¯å¢ƒæ·»åŠ çŠ¶æ€æ¡ç›®
env_names = {env_names}
new_envs_added = []
for env_name in env_names:
    if env_name not in states[\"environments\"]:
        states[\"environments\"][env_name] = {{
            \"created_at\": \"{current_time}\",
            \"packages\": {{}},
            \"last_updated\": \"{current_time}\"
        }}
        new_envs_added.append(env_name)

# ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
if new_envs_added:
    with open(state_file, 'w') as f:
        json.dump(states, f, indent=2, ensure_ascii=False)
    print(f"Initialized state for " + str(len(new_envs_added)) + " environment(s): " + ", ".join(new_envs_added))
else:
    print(f"All environments already have state entries")
'''
            
            # æ„å»ºå®Œæ•´çš„å‘½ä»¤
            command = f'''mkdir -p "{self._get_venv_base_path()}" && python3 -c '{python_script}' '''
            
            return command.strip()
                
        except Exception as e:
            print(f"Failed to prepare batch state init command: {str(e)}")
            return None

    def _ensure_environment_state_exists(self, env_name):
        """ç¡®ä¿ç¯å¢ƒçŠ¶æ€å­˜åœ¨ï¼ˆå‘åå…¼å®¹ï¼‰"""
        try:
            all_states = self._load_all_venv_states()
            
            # æ£€æŸ¥environmentså­—æ®µæ˜¯å¦å­˜åœ¨
            if 'environments' not in all_states:
                all_states['environments'] = {}
            
            # æ£€æŸ¥ç‰¹å®šç¯å¢ƒæ˜¯å¦å­˜åœ¨
            if env_name not in all_states['environments']:
                print(f"Environment '{env_name}' not found in state, creating entry...")
                all_states['environments'][env_name] = {
                    'created_at': self._get_current_timestamp(),
                    'packages': {},
                    'last_updated': self._get_current_timestamp()
                }
                
                # ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
                self._save_all_venv_states(all_states)
                print(f"Created state entry for environment '{env_name}'")
            
            return True
            
        except Exception as e:
            print(f"Failed to ensure environment state exists: {str(e)}")
            return False

    def _get_current_timestamp(self):
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        import datetime
        return datetime.datetime.now().isoformat()

    def _save_all_venv_states(self, all_states):
        """ä¿å­˜å®Œæ•´çš„è™šæ‹Ÿç¯å¢ƒçŠ¶æ€"""
        try:
            import json
            
            # æ„å»ºä¿å­˜çŠ¶æ€çš„è¿œç¨‹å‘½ä»¤
            state_file_path = self._get_venv_state_file_path()
            json_content = json.dumps(all_states, indent=2, ensure_ascii=False)
            
            # è½¬ä¹‰JSONå†…å®¹ä»¥ä¾¿åœ¨bashä¸­ä½¿ç”¨
            escaped_json = json_content.replace("'", "'\"'\"'")
            
            remote_command = f'''
mkdir -p "{self._get_venv_base_path()}" && {{
    echo '{escaped_json}' > "{state_file_path}"
    echo "State file updated: {state_file_path}"
}}
'''
            
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if result.get("success"):
                print(f"Venv states saved successfully")
                return True
            else:
                print(f"Failed to save venv states: {result.get('error', 'Unknown error')}")
                return False
                
        except Exception as e:
            print(f"Error saving venv states: {str(e)}")
            return False

    def _save_all_venv_states_inline(self, all_states):
        """å†…è”ä¿å­˜çŠ¶æ€ï¼ˆè¿”å›å‘½ä»¤å­—ç¬¦ä¸²è€Œä¸æ˜¯æ‰§è¡Œï¼‰"""
        try:
            import json
            
            # æ„å»ºä¿å­˜çŠ¶æ€çš„å‘½ä»¤å­—ç¬¦ä¸²
            state_file_path = self._get_venv_state_file_path()
            json_content = json.dumps(all_states, indent=2, ensure_ascii=False)
            
            # è½¬ä¹‰JSONå†…å®¹ä»¥ä¾¿åœ¨bashä¸­ä½¿ç”¨
            escaped_json = json_content.replace("'", "'\"'\"'")
            
            command_str = f'''
mkdir -p "{self._get_venv_base_path()}" && {{
    echo '{escaped_json}' > "{state_file_path}"
    echo "Venv states saved successfully"
}}
'''
            return command_str
                
        except Exception as e:
            print(f"Error preparing venv states save command: {str(e)}")
            return None



    def cmd_python(self, code=None, filename=None, python_args=None, save_output=False):
        """pythonå‘½ä»¤ - æ‰§è¡ŒPythonä»£ç """
        try:
            if filename:
                # æ‰§è¡ŒDriveä¸­çš„Pythonæ–‡ä»¶
                return self._execute_python_file(filename, save_output, python_args)
            elif code:
                # æ‰§è¡Œç›´æ¥æä¾›çš„Pythonä»£ç 
                return self._execute_python_code(code, save_output)
            else:
                return {"success": False, "error": "è¯·æä¾›Pythonä»£ç æˆ–æ–‡ä»¶å"}
                
        except Exception as e:
            return {"success": False, "error": f"æ‰§è¡ŒPythonå‘½ä»¤æ—¶å‡ºé”™: {e}"}

    def _execute_python_file(self, filename, save_output=False, python_args=None):
        """æ‰§è¡ŒGoogle Driveä¸­çš„Pythonæ–‡ä»¶"""
        try:
            # ç›´æ¥åœ¨è¿œç«¯æ‰§è¡ŒPythonæ–‡ä»¶ï¼Œä¸éœ€è¦å…ˆè¯»å–æ–‡ä»¶å†…å®¹
            return self._execute_python_file_remote(filename, save_output, python_args)
            
        except Exception as e:
            return {"success": False, "error": f"æ‰§è¡ŒPythonæ–‡ä»¶æ—¶å‡ºé”™: {e}"}
    
    def _execute_python_file_remote(self, filename, save_output=False, python_args=None):
        """è¿œç¨‹æ‰§è¡ŒPythonæ–‡ä»¶"""
        try:
            # è·å–ç¯å¢ƒæ–‡ä»¶è·¯å¾„
            current_shell = self.main_instance.get_current_shell()
            shell_id = current_shell.get("id", "default") if current_shell else "default"
            # Direct storage in REMOTE_ENV, no .tmp subdirectory needed
            env_file = f"{self.main_instance.REMOTE_ENV}/venv/venv_pythonpath.sh"
            
            # æ„å»ºPythonå‘½ä»¤ï¼ŒåŒ…å«æ–‡ä»¶åå’Œå‚æ•°
            python_cmd_parts = ['python3', filename]
            if python_args:
                python_cmd_parts.extend(python_args)
            python_cmd = ' '.join(python_cmd_parts)
            
            # æ„å»ºè¿œç¨‹å‘½ä»¤ï¼šæ£€æŸ¥å¹¶åº”ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œç„¶åæ‰§è¡ŒPythonæ–‡ä»¶
            commands = [
                # sourceç¯å¢ƒæ–‡ä»¶ï¼Œå¦‚æœå¤±è´¥åˆ™å¿½ç•¥ï¼ˆä¼šä½¿ç”¨é»˜è®¤çš„PYTHONPATHï¼‰
                f"source {env_file} 2>/dev/null || true",
                python_cmd
            ]
            command = " && ".join(commands)
            
            # æ‰§è¡Œè¿œç¨‹å‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", command])
            
            if result.get("success"):
                return {
                    "success": True,
                    "stdout": result.get("stdout", ""),
                    "stderr": result.get("stderr", ""),
                    "return_code": result.get("exit_code", 0)
                }
            else:
                return {
                    "success": False,
                    "error": f"Remote Python file execution failed: {result.get('error', '')}",
                    "stdout": result.get("stdout", ""),
                    "stderr": result.get("stderr", "")
                }
                
        except Exception as e:
            return {"success": False, "error": f"è¿œç¨‹Pythonæ–‡ä»¶æ‰§è¡Œæ—¶å‡ºé”™: {e}"}

    def _execute_python_code(self, code, save_output=False, filename=None):
        """æ‰§è¡ŒPythonä»£ç å¹¶è¿”å›ç»“æœ"""
        try:
            # ç›´æ¥å°è¯•è¿œç¨‹æ‰§è¡Œï¼Œåœ¨è¿œç¨‹å‘½ä»¤ä¸­æ£€æŸ¥å’Œåº”ç”¨è™šæ‹Ÿç¯å¢ƒ
            return self._execute_python_code_remote_unified(code, save_output, filename)
                
        except Exception as e:
            return {"success": False, "error": f"æ‰§è¡ŒPythonä»£ç æ—¶å‡ºé”™: {e}"}

    def _execute_python_code_remote_unified(self, code, save_output=False, filename=None):
        """ç»Ÿä¸€çš„è¿œç¨‹Pythonæ‰§è¡Œæ–¹æ³•ï¼Œåœ¨ä¸€ä¸ªå‘½ä»¤ä¸­æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒå¹¶æ‰§è¡Œä»£ç """
        try:
            import base64
            import time
            import random
            
            # ä½¿ç”¨base64ç¼–ç é¿å…æ‰€æœ‰bashè½¬ä¹‰é—®é¢˜
            code_bytes = code.encode('utf-8')
            code_base64 = base64.b64encode(code_bytes).decode('ascii')
            
            # ç”Ÿæˆå”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶å
            timestamp = int(time.time())
            random_id = f"{random.randint(1000, 9999):04x}"
            temp_filename = f"python_code_{timestamp}_{random_id}.b64"
            
            # è·å–ç¯å¢ƒæ–‡ä»¶è·¯å¾„
            current_shell = self.main_instance.get_current_shell()
            shell_id = current_shell.get("id", "default") if current_shell else "default"
            # Direct storage in REMOTE_ENV, no .tmp subdirectory needed
            env_file = f"{self.main_instance.REMOTE_ENV}/venv/venv_pythonpath.sh"
            temp_file_path = f"{self.main_instance.REMOTE_ROOT}/tmp/{temp_filename}"
            
            # æ„å»ºç»Ÿä¸€çš„è¿œç¨‹å‘½ä»¤ï¼š
            # 1. ç¡®ä¿tmpç›®å½•å­˜åœ¨
            # 2. å°†base64å­—ç¬¦ä¸²å†™å…¥ä¸´æ—¶æ–‡ä»¶
            # 3. sourceç¯å¢ƒæ–‡ä»¶
            # 4. ä»ä¸´æ—¶æ–‡ä»¶è¯»å–base64å¹¶è§£ç æ‰§è¡Œ
            # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            # æ„å»ºå‘½ä»¤ï¼Œç¡®ä¿Pythonè„šæœ¬çš„é€€å‡ºç è¢«æ­£ç¡®æ•è·
            command = f'''
            mkdir -p {self.main_instance.REMOTE_ROOT}/tmp && \\
            echo "{code_base64}" > "{temp_file_path}" && \\
            source {env_file} 2>/dev/null || true
            
            # æ‰§è¡ŒPythonä»£ç å¹¶æ•è·é€€å‡ºç 
            python3 -c "import base64; exec(base64.b64decode(open(\\"{temp_file_path}\\").read().strip()).decode(\\"utf-8\\"))"
            PYTHON_EXIT_CODE=$?
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            rm -f "{temp_file_path}"
            
            # è¿”å›Pythonè„šæœ¬çš„é€€å‡ºç 
            exit $PYTHON_EXIT_CODE
            '''.strip()
            
            # æ‰§è¡Œè¿œç¨‹å‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", command])
            
            if result.get("success"):
                return {
                    "success": True,
                    "stdout": result.get("stdout", ""),
                    "stderr": result.get("stderr", ""),
                    "return_code": result.get("exit_code", 0),
                    "source": result.get("source", "")
                }
            else:
                return {
                    "success": False,
                    "error": f"User direct feedback is as above. ",
                    "stdout": result.get("stdout", ""),
                    "stderr": result.get("stderr", "")
                }
                
        except Exception as e:
            return {"success": False, "error": f"è¿œç¨‹Pythonæ‰§è¡Œæ—¶å‡ºé”™: {e}"}

    def _execute_non_bash_safe_commands(self, commands, action_description, context_name=None, expected_pythonpath=None):
        """
        ç”Ÿæˆébash-safeå‘½ä»¤ä¾›ç”¨æˆ·åœ¨è¿œç«¯ä¸»shellä¸­æ‰§è¡Œï¼Œå¹¶è‡ªåŠ¨éªŒè¯ç»“æœ
        """
        try:
            import time
            import random
            import json
            import os
            
            # ç”Ÿæˆå”¯ä¸€çš„ç»“æœæ–‡ä»¶å
            timestamp = int(time.time())
            random_id = f"{random.randint(1000, 9999):04x}"
            result_filename = f"venv_result_{timestamp}_{random_id}.json"
            # ç”Ÿæˆè¿œç¨‹å’Œæœ¬åœ°æ–‡ä»¶è·¯å¾„
            import os
            bin_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
            local_result_file = f"{bin_dir}/GOOGLE_DRIVE_DATA/remote_files/{result_filename}"
            # ä½¿ç”¨è¿œç¨‹è·¯å¾„è€Œä¸æ˜¯æœ¬åœ°è·¯å¾„
            remote_result_file = f"/content/drive/MyDrive/REMOTE_ROOT/tmp/{result_filename}"
            
            # ç”ŸæˆåŒ…å«éªŒè¯çš„å®Œæ•´å‘½ä»¤
            original_command = " && ".join(commands)
            full_commands = [
                f"mkdir -p {self.main_instance.REMOTE_ROOT}/tmp",  # ç¡®ä¿è¿œç¨‹tmpç›®å½•å­˜åœ¨
                original_command,
                # éªŒè¯PYTHONPATHå¹¶è¾“å‡ºåˆ°è¿œç¨‹JSONæ–‡ä»¶
                f'echo "{{" > {remote_result_file}',
                f'echo "  \\"success\\": true," >> {remote_result_file}',
                f'echo "  \\"action\\": \\"{action_description}\\"," >> {remote_result_file}',
                f'echo "  \\"pythonpath\\": \\"$PYTHONPATH\\"," >> {remote_result_file}',
                f'echo "  \\"timestamp\\": \\"$(date)\\"" >> {remote_result_file}',
                f'echo "}}" >> {remote_result_file}'
            ]
            
            full_command_with_verification = " && ".join(full_commands)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„tkinterçª—å£ç•Œé¢
            context_str = f" '{context_name}'" if context_name else ""
            window_title = f"Execute command to {action_description}{context_str}"
            
            # è°ƒç”¨ç»Ÿä¸€çš„è¿œç¨‹å‘½ä»¤çª—å£
            try:
                result = self.main_instance.remote_commands._show_command_window(
                    action_description,  # cmd
                    [context_name] if context_name else [],  # args
                    full_command_with_verification,  # remote_command
                    window_title  # debug_info
                )
                
                if result.get("action") == "failed":
                    return {
                        "success": False, 
                        "error": result.get("message", "User reported execution failed"),
                        "source": "user_reported_failure"
                    }
                elif result.get("action") == "direct_feedback":
                    # ç”¨æˆ·æä¾›äº†ç›´æ¥åé¦ˆï¼Œè·³è¿‡æ–‡ä»¶æ£€æµ‹
                    print ()
                    return {
                        "success": True,
                        "message": result.get("message", "Command executed successfully"),
                        "source": "direct_feedback"
                    }
            except Exception as e:
                # å¦‚æœtkinterçª—å£å¤±è´¥ï¼Œå›é€€åˆ°ç»ˆç«¯æç¤º
                print(f"\nExecute the following command in remote main shell to {action_description}{context_str}:")
                print(f"Command: {full_command_with_verification}")
                print(f"Copy and execute the above command, then press Ctrl+D")
            
            # å¦‚æœä½¿ç”¨äº†tkinterçª—å£ï¼Œç­‰å¾…æ–‡ä»¶æ£€æµ‹
            remote_file_path = f"~/tmp/{result_filename}"
            
            # ç­‰å¾…å¹¶æ£€æµ‹ç»“æœæ–‡ä»¶
            print(f"â³ Validating results ...", end="", flush=True)
            max_attempts = 60
            
            for attempt in range(max_attempts):
                try:
                    # æ£€æŸ¥è¿œç¨‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    check_result = self.main_instance.remote_commands._check_remote_file_exists(remote_result_file)
                    
                    if check_result.get("exists"):
                        # æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å†…å®¹
                        print(f"âˆš")  # æˆåŠŸæ ‡è®°
                        read_result = self.main_instance.remote_commands._read_result_file_via_gds(result_filename)
                        
                        if read_result.get("success"):
                            result_data = read_result.get("data", {})
                            
                            # éªŒè¯ç»“æœï¼ˆPYTHONPATHéªŒè¯æˆ–å…¶ä»–éªŒè¯ï¼‰
                            if expected_pythonpath:
                                # PYTHONPATHéªŒè¯æ¨¡å¼ï¼ˆç”¨äºè™šæ‹Ÿç¯å¢ƒï¼‰
                                actual_pythonpath = result_data.get("pythonpath", "")
                                
                                if expected_pythonpath in actual_pythonpath:
                                    return {
                                        "success": True,
                                        "message": f"{action_description.capitalize()}{context_str} completed and verified",
                                        "pythonpath": actual_pythonpath,
                                        "result_data": result_data
                                    }
                                else:
                                    return {
                                        "success": False,
                                        "error": f"PYTHONPATH verification failed: expected {expected_pythonpath}, got {actual_pythonpath}",
                                        "result_data": result_data
                                    }
                            else:
                                # é€šç”¨éªŒè¯æ¨¡å¼ï¼ˆç”¨äºpipç­‰å‘½ä»¤ï¼‰
                                return {
                                    "success": True,
                                    "message": f"{action_description.capitalize()}{context_str} completed successfully",
                                    "result_data": result_data
                                }
                        else:
                            return {"success": False, "error": f"Error reading result: {read_result.get('error')}"}
                    
                    # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç­‰å¾…1ç§’å¹¶è¾“å‡ºè¿›åº¦ç‚¹
                    time.sleep(1)
                    print(f".", end="", flush=True)
                    
                except Exception as e:
                    print(f"\nError: Error checking result file: {str(e)[:100]}")
                    return {"success": False, "error": f"Error checking result: {e}"}
            
            print(f"\nError: Timeout: No result file found after {max_attempts} seconds")
            return {"success": False, "error": "Execution timeout - no result file found"}
            
        except Exception as e:
            print(f"Error: {e}")
            return {"success": False, "error": f"Error generating command: {e}"}

    def _get_venv_base_path(self):
        """è·å–è™šæ‹Ÿç¯å¢ƒåŸºç¡€è·¯å¾„"""
        return f"{self.main_instance.REMOTE_ENV}/venv"
    
    def _get_venv_api_manager(self):
        """è·å–è™šæ‹Ÿç¯å¢ƒAPIç®¡ç†å™¨"""
        if not hasattr(self, '_venv_api_manager'):
            self._venv_api_manager = VenvApiManager(self.drive_service, self.main_instance)
        return self._venv_api_manager
    
    def _read_venv_states_via_api(self):
        """é€šè¿‡Google Drive APIè¯»å–venv_states.jsonæ–‡ä»¶"""
        api_manager = self._get_venv_api_manager()
        return api_manager.read_venv_states()

    def _get_venv_environments_via_api(self):
        """é€šè¿‡Google Drive APIåˆ—å‡ºæ‰€æœ‰è™šæ‹Ÿç¯å¢ƒ"""
        try:
            api_manager = self._get_venv_api_manager()
            env_names = api_manager.list_venv_environments()
            
            if not env_names:
                print(f"APIæœªæ‰¾åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œå›é€€åˆ°è¿œç¨‹å‘½ä»¤")
                return self._get_venv_environments_via_remote()
            
            return env_names
                
        except Exception as e:
            print(f"Warning: APIåˆ—å‡ºè™šæ‹Ÿç¯å¢ƒå¼‚å¸¸: {e}ï¼Œå›é€€åˆ°è¿œç¨‹å‘½ä»¤")
            return self._get_venv_environments_via_remote()
    
    def _get_venv_environments_via_remote(self):
        """é€šè¿‡è¿œç¨‹å‘½ä»¤åˆ—å‡ºæ‰€æœ‰è™šæ‹Ÿç¯å¢ƒï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        try:
            remote_command = f'''
VENV_BASE_PATH="{self._get_venv_base_path()}"
if [ -d "$VENV_BASE_PATH" ]; then
    ls -la "$VENV_BASE_PATH" 2>/dev/null | grep "^d" | grep -v "^d.*\\.\\.*$" | awk "{{print \\$NF}}" | while read dir; do
        if [ -n "$dir" ] && [ "$dir" != "." ] && [ "$dir" != ".." ] && [[ ! "$dir" =~ ^\\. ]]; then
            echo "$dir"
        fi
    done
else
    echo ""
fi
'''
            
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if result.get("success"):
                output = result.get("stdout", "").strip()
                if output:
                    return [line.strip() for line in output.split('\n') if line.strip()]
                else:
                    return []
            else:
                return []
                
        except Exception as e:
            print(f"Warning: è¿œç¨‹å‘½ä»¤åˆ—å‡ºè™šæ‹Ÿç¯å¢ƒå¤±è´¥: {e}")
            return []

    
    def _load_all_venv_states(self):
        """ä»ç»Ÿä¸€çš„JSONæ–‡ä»¶åŠ è½½æ‰€æœ‰è™šæ‹Ÿç¯å¢ƒçŠ¶æ€ï¼ˆä¼˜å…ˆä½¿ç”¨APIï¼Œå›é€€åˆ°è¿œç¨‹å‘½ä»¤ï¼‰"""
        try:
            import json
            
            # é¦–å…ˆå°è¯•é€šè¿‡APIè¯»å–
            try:
                api_result = self._read_venv_states_via_api()
                if api_result.get("success"):
                    return api_result.get("data", {})
            except Exception as api_error:
                print(f"API call failed: {api_error}")
            
            # å›é€€åˆ°è¿œç¨‹å‘½ä»¤
            state_file = self._get_venv_state_file_path()
            check_command = f'cat "{state_file}" 2>/dev/null || echo "{{}}"'
            result = self.main_instance.execute_generic_command("bash", ["-c", check_command])
            if result.get("success") and result.get("stdout"):
                stdout_content = result["stdout"].strip()
                try:
                    state_data = json.loads(stdout_content)
                    return state_data if isinstance(state_data, dict) else {}
                except json.JSONDecodeError as e:
                    return {}
            else:
                self._create_initial_venv_states_file()
                return {}
            
        except Exception: 
            import traceback
            traceback.print_exc()
            return {}
    
    def _create_initial_venv_states_file(self):
        """åˆ›å»ºåˆå§‹çš„è™šæ‹Ÿç¯å¢ƒçŠ¶æ€æ–‡ä»¶"""
        try:
            import json
            state_file = self._get_venv_state_file_path()
            
            # åˆ›å»ºåŸºæœ¬çš„JSONç»“æ„
            initial_structure = {
                "environments": {},
                "created_at": self._get_current_timestamp(),
                "version": "1.0"
            }
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            venv_dir = f"{self._get_venv_base_path()}"
            mkdir_command = f'mkdir -p "{venv_dir}"'
            mkdir_result = self.main_instance.execute_generic_command("bash", ["-c", mkdir_command])
            print(f"åˆ›å»ºç›®å½•ç»“æœ: {mkdir_result}")
            
            # å†™å…¥åˆå§‹JSONæ–‡ä»¶
            json_content = json.dumps(initial_structure, indent=2, ensure_ascii=False)
            create_command = f'cat > "{state_file}" << \'EOF\'\n{json_content}\nEOF'
            create_result = self.main_instance.execute_generic_command("bash", ["-c", create_command])
            print(f"åˆ›å»ºJSONæ–‡ä»¶ç»“æœ: {create_result}")
            
            if create_result.get("success"):
                print(f"æˆåŠŸåˆ›å»ºåˆå§‹çŠ¶æ€æ–‡ä»¶: {state_file}")
                return True
            else:
                print(f"Error: åˆ›å»ºçŠ¶æ€æ–‡ä»¶å¤±è´¥: {create_result.get('error')}")
                return False
            
        except Exception as e:
            print(f"Error: åˆ›å»ºåˆå§‹çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def _packages_differ(self, json_packages, api_packages):
        """æ¯”è¾ƒä¸¤ä¸ªåŒ…å­—å…¸æ˜¯å¦ä¸åŒ"""
        if len(json_packages) != len(api_packages):
            return True
        
        for pkg_name, version in json_packages.items():
            if pkg_name not in api_packages or api_packages[pkg_name] != version:
                return True
        
        return False
    
    def _update_environment_packages_in_json(self, env_name, packages_dict):
        """æ›´æ–°JSONæ–‡ä»¶ä¸­æŒ‡å®šç¯å¢ƒçš„åŒ…ä¿¡æ¯"""
        try:
            import datetime
            
            # åŠ è½½ç°æœ‰çŠ¶æ€
            all_states = self._load_all_venv_states()
            
            # ç¡®ä¿ç¯å¢ƒå­˜åœ¨
            if "environments" not in all_states:
                all_states["environments"] = {}
            
            if env_name not in all_states["environments"]:
                all_states["environments"][env_name] = {
                    "created_at": datetime.datetime.now().isoformat(),
                    "packages": {},
                    "last_updated": datetime.datetime.now().isoformat()
                }
            
            # æ›´æ–°åŒ…ä¿¡æ¯
            all_states["environments"][env_name]["packages"] = packages_dict
            all_states["environments"][env_name]["last_updated"] = datetime.datetime.now().isoformat()
            
            # ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
            self._save_all_venv_states(all_states)
            
        except Exception as e:
            print(f"Error: æ›´æ–°ç¯å¢ƒåŒ…ä¿¡æ¯å¤±è´¥: {e}")
    
    def _load_venv_state(self, shell_id):
        """ä»ç»Ÿä¸€çš„JSONæ–‡ä»¶åŠ è½½æŒ‡å®šshellçš„è™šæ‹Ÿç¯å¢ƒçŠ¶æ€"""
        try:
            all_states = self._load_all_venv_states()
            return all_states.get(shell_id)
            
        except Exception as e:
            print(f"Warning: åŠ è½½è™šæ‹Ÿç¯å¢ƒçŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def _clear_venv_state(self, shell_id):
        """æ¸…é™¤æŒ‡å®šshellçš„è™šæ‹Ÿç¯å¢ƒçŠ¶æ€"""
        try:
            # è¯»å–ç°æœ‰çš„çŠ¶æ€æ–‡ä»¶
            existing_states = self._load_all_venv_states()
            
            # ç§»é™¤æŒ‡å®šshellçš„çŠ¶æ€
            if shell_id in existing_states:
                del existing_states[shell_id]
            
            # ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
            state_file = self._get_venv_state_file_path()
            import json
            json_content = json.dumps(existing_states, indent=2, ensure_ascii=False)
            
            commands = [
                f"mkdir -p '{self._get_venv_base_path()}'",
                f"cat > '{state_file}' << 'EOF'\n{json_content}\nEOF"
            ]
            
            command_script = " && ".join(commands)
            result = self.main_instance.execute_generic_command("bash", ["-c", command_script])
            
            return result.get("success", False)
            
        except Exception as e:
            print(f"Warning: æ¸…é™¤è™šæ‹Ÿç¯å¢ƒçŠ¶æ€å¤±è´¥: {e}")
            return False

    def _get_venv_state_file_path(self):
        """è·å–è™šæ‹Ÿç¯å¢ƒçŠ¶æ€æ–‡ä»¶è·¯å¾„ï¼ˆç»Ÿä¸€çš„JSONæ ¼å¼ï¼‰"""
        return f"{self._get_venv_base_path()}/venv_states.json"
    
    def _save_venv_state(self, venv_name, env_path, shell_id):
        """ä¿å­˜è™šæ‹Ÿç¯å¢ƒçŠ¶æ€åˆ°ç»Ÿä¸€çš„JSONæ–‡ä»¶"""
        try:
            import json
            from datetime import datetime
            
            # è¯»å–ç°æœ‰çš„çŠ¶æ€æ–‡ä»¶
            state_file = self._get_venv_state_file_path()
            existing_states = self._load_all_venv_states()
            
            # æ›´æ–°å½“å‰shellçš„çŠ¶æ€
            existing_states[shell_id] = {
                "current_venv": venv_name,
                "env_path": env_path or f"{self._get_venv_base_path()}/{venv_name}",
                "activated_at": datetime.now().isoformat(),
                "shell_id": shell_id
            }
            
            json_content = json.dumps(existing_states, indent=2, ensure_ascii=False)
            
            # ä½¿ç”¨echoå‘½ä»¤åˆ›å»ºJSONæ–‡ä»¶
            commands = [
                f"mkdir -p '{self._get_venv_base_path()}'",
                f"cat > '{state_file}' << 'EOF'\n{json_content}\nEOF"
            ]
            
            command_script = " && ".join(commands)
            result = self.main_instance.execute_generic_command("bash", ["-c", command_script])
            
            return result.get("success", False)
            
        except Exception as e:
            print(f"Warning: ä¿å­˜è™šæ‹Ÿç¯å¢ƒçŠ¶æ€å¤±è´¥: {e}")
            return False

    def _get_current_venv(self):
        """è·å–å½“å‰æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒåç§°"""
        try:
            current_shell = self.main_instance.get_current_shell()
            
            if not current_shell:
                return None
            
            shell_id = current_shell.get("id", "default")
            
            # å°è¯•ä»JSONçŠ¶æ€æ–‡ä»¶åŠ è½½
            state_data = self._load_venv_state(shell_id)
            
            if state_data and state_data.get("current_venv"):
                return state_data["current_venv"]
            
            # å›é€€åˆ°æ—§çš„txtæ–‡ä»¶æ ¼å¼
            current_venv_file = f"{self._get_venv_base_path()}/current_venv_{shell_id}.txt"
            
            # é€šè¿‡è¿œç¨‹å‘½ä»¤æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒçŠ¶æ€æ–‡ä»¶
            check_command = f'cat "{current_venv_file}" 2>/dev/null || echo "none"'
            result = self.main_instance.execute_generic_command("bash", ["-c", check_command])
            
            if result.get("success") and result.get("stdout"):
                venv_name = result["stdout"].strip()
                return venv_name if venv_name != "none" else None
            
            return None
            
        except Exception as e:
            print(f"Warning: è·å–å½“å‰è™šæ‹Ÿç¯å¢ƒå¤±è´¥: {e}")
            return None

    def _execute_python_code_remote(self, code, venv_name, save_output=False, filename=None):
        """åœ¨è¿œç¨‹è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡ŒPythonä»£ç """
        try:
            # è½¬ä¹‰Pythonä»£ç ä¸­çš„å¼•å·å’Œåæ–œæ 
            escaped_code = code.replace('\\', '\\\\').replace('"', '\\"').replace('$', '\\$')
            
            # è·å–ç¯å¢ƒæ–‡ä»¶è·¯å¾„
            current_shell = self.main_instance.get_current_shell()
            shell_id = current_shell.get("id", "default") if current_shell else "default"
            # Direct storage in REMOTE_ENV, no .tmp subdirectory needed
            env_file = f"{self.main_instance.REMOTE_ENV}/venv/venv_pythonpath.sh"
            
            # æ„å»ºè¿œç¨‹å‘½ä»¤ï¼šsourceç¯å¢ƒæ–‡ä»¶å¹¶æ‰§è¡ŒPythonä»£ç 
            commands = [
                # sourceç¯å¢ƒæ–‡ä»¶ï¼Œå¦‚æœå¤±è´¥åˆ™å¿½ç•¥
                f"source {env_file} 2>/dev/null || true",
                f'python3 -c "{escaped_code}"'
            ]
            command = " && ".join(commands)
            
            # æ‰§è¡Œè¿œç¨‹å‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", command])
            
            if result.get("success"):
                return {
                    "success": True,
                    "stdout": result.get("stdout", ""),
                    "stderr": result.get("stderr", ""),
                    "return_code": result.get("exit_code", 0),
                    "environment": venv_name
                }
            else:
                return {
                    "success": False,
                    "error": f"User directed feedback is as above. ",
                    "stdout": result.get("stdout", ""),
                    "stderr": result.get("stderr", "")
                }
                
        except Exception as e:
            return {"success": False, "error": f"è¿œç¨‹Pythonæ‰§è¡Œæ—¶å‡ºé”™: {e}"}

    def cmd_mkdir_remote(self, target_path, recursive=False):
        """
        é€šè¿‡è¿œç«¯å‘½ä»¤åˆ›å»ºç›®å½•çš„æ¥å£ï¼ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼‰
        
        Args:
            target_path (str): ç›®æ ‡è·¯å¾„
            recursive (bool): æ˜¯å¦é€’å½’åˆ›å»º
            
        Returns:
            dict: åˆ›å»ºç»“æœ
        """
        try:
            # è·å–å½“å‰shellä»¥è§£æç›¸å¯¹è·¯å¾„
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            # è§£æç»å¯¹è·¯å¾„
            absolute_path = self.main_instance.resolve_remote_absolute_path(target_path, current_shell)
            if not absolute_path:
                return {"success": False, "error": f"æ— æ³•è§£æè·¯å¾„: {target_path}"}
            
            # ç”Ÿæˆè¿œç«¯mkdirå‘½ä»¤ï¼Œæ·»åŠ æ¸…å±å’ŒæˆåŠŸ/å¤±è´¥æç¤ºï¼ˆæ€»æ˜¯ä½¿ç”¨-pç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨ï¼‰
            remote_command = f'mkdir -p "{absolute_path}"'
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = {
                "target_path": target_path,
                "absolute_path": absolute_path,
                "recursive": recursive
            }
            
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£æ‰§è¡Œè¿œç«¯å‘½ä»¤
            execution_result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            if execution_result["success"]:
                # æ‰§è¡ŒæˆåŠŸåï¼Œè¿›è¡ŒéªŒè¯ä»¥ç¡®ä¿ç›®å½•çœŸæ­£åˆ›å»ºï¼ˆæœ€å¤š60æ¬¡é‡è¯•ï¼‰
                verification_result = self.main_instance.verify_creation_with_ls(target_path, current_shell, creation_type="dir", max_attempts=60)
                
                if verification_result["success"]:
                    # éªŒè¯æˆåŠŸï¼Œç®€æ´è¿”å›ï¼Œåƒbash shellä¸€æ ·æˆåŠŸæ—¶ä¸æ˜¾ç¤ºä»»ä½•ä¿¡æ¯
                    return {
                        "success": True,
                        "path": target_path,
                        "absolute_path": absolute_path,
                        "remote_command": remote_command,
                        "message": "",  # ç©ºæ¶ˆæ¯ï¼Œä¸æ˜¾ç¤ºä»»ä½•å†…å®¹
                        "verification": verification_result
                    }
                else:
                    # éªŒè¯å¤±è´¥ï¼Œè¿”å›é”™è¯¯
                    return {
                        "success": False,
                        "error": f"Directory creation verification failed: {verification_result.get('error', 'Unknown error')}",
                        "path": target_path,
                        "verification": verification_result
                    }
            else:
                return execution_result
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": f"è¿œç«¯mkdirå‘½ä»¤ç”Ÿæˆå¤±è´¥: {e}"
            }

    def _parse_line_ranges(self, args):
        """
        è§£æè¡Œæ•°èŒƒå›´å‚æ•°
        
        å‚æ•°æ ¼å¼:
        - æ— å‚æ•°: è¿”å›None (è¯»å–å…¨éƒ¨)
        - å•ä¸ªæ•°å­—: è¿”å›[(start, None)] (ä»startè¡Œå¼€å§‹è¯»å–åˆ°æœ«å°¾)
        - ä¸¤ä¸ªæ•°å­—: è¿”å›[(start, end)] (è¯»å–startåˆ°endè¡Œ)
        - JSONæ ¼å¼å¤šèŒƒå›´: "[[start1, end1], [start2, end2], ...]"
        
        è¿”å›:
        - None: è¯»å–å…¨éƒ¨è¡Œ
        - [(start, end), ...]: è¡Œæ•°èŒƒå›´åˆ—è¡¨
        - False: å‚æ•°æ ¼å¼é”™è¯¯
        - {"error_info": str}: é”™è¯¯ä¿¡æ¯
        """
        try:
            # è¿‡æ»¤æ‰Noneå‚æ•°
            filtered_args = [arg for arg in args if arg is not None]
            
            if not filtered_args:
                return None  # è¯»å–å…¨éƒ¨
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¢«ç©ºæ ¼åˆ†å‰²çš„JSONå­—ç¬¦ä¸²ï¼Œå°è¯•é‡æ–°ç»„åˆ
            if len(filtered_args) > 1 and any(arg.startswith('[') for arg in filtered_args):
                # å°è¯•å°†æ‰€æœ‰å‚æ•°è¿æ¥æˆä¸€ä¸ªJSONå­—ç¬¦ä¸²
                combined_arg = ' '.join(str(arg) for arg in filtered_args)
                if combined_arg.startswith('[') and combined_arg.endswith(']'):
                    try:
                        import json
                        ranges = json.loads(combined_arg)
                        if isinstance(ranges, list):
                            # æˆåŠŸè§£æä¸ºJSONï¼Œå¤„ç†å¤šèŒƒå›´
                            parsed_ranges = []
                            for range_item in ranges:
                                if not isinstance(range_item, list) or len(range_item) != 2:
                                    return {"error_info": "æ¯ä¸ªèŒƒå›´å¿…é¡»æ˜¯åŒ…å«ä¸¤ä¸ªæ•°å­—çš„åˆ—è¡¨ [start, end]"}
                                
                                start, end = range_item
                                if not isinstance(start, int) or not isinstance(end, int):
                                    return {"error_info": "èŒƒå›´çš„èµ·å§‹å’Œç»“æŸä½ç½®å¿…é¡»æ˜¯æ•´æ•°"}
                                
                                if start < 0 or end < 0:
                                    return {"error_info": "è¡Œå·ä¸èƒ½ä¸ºè´Ÿæ•°"}
                                
                                if start > end:
                                    return {"error_info": f"èµ·å§‹è¡Œå·({start})ä¸èƒ½å¤§äºç»“æŸè¡Œå·({end})"}
                                
                                parsed_ranges.append((start, end))
                            
                            return parsed_ranges
                    except json.JSONDecodeError:
                        pass  # ç»§ç»­å¤„ç†å…¶ä»–æƒ…å†µ
            
            if len(filtered_args) == 1:
                # å•ä¸ªå‚æ•°ï¼šå¯èƒ½æ˜¯æ•°å­—æˆ–JSONæ ¼å¼çš„å¤šèŒƒå›´
                arg = filtered_args[0]
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯JSONæ ¼å¼çš„å¤šèŒƒå›´
                if isinstance(arg, str) and arg.strip().startswith('['):
                    try:
                        import json
                        ranges = json.loads(arg)
                        if not isinstance(ranges, list):
                            return {"error_info": "å¤šèŒƒå›´æ ¼å¼å¿…é¡»æ˜¯åˆ—è¡¨"}
                        
                        parsed_ranges = []
                        for range_item in ranges:
                            if not isinstance(range_item, list) or len(range_item) != 2:
                                return {"error_info": "æ¯ä¸ªèŒƒå›´å¿…é¡»æ˜¯åŒ…å«ä¸¤ä¸ªæ•°å­—çš„åˆ—è¡¨ [start, end]"}
                            
                            start, end = range_item
                            if not isinstance(start, int) or not isinstance(end, int):
                                return {"error_info": "èŒƒå›´çš„èµ·å§‹å’Œç»“æŸä½ç½®å¿…é¡»æ˜¯æ•´æ•°"}
                            
                            if start < 0 or end < 0:
                                return {"error_info": "è¡Œå·ä¸èƒ½ä¸ºè´Ÿæ•°"}
                            
                            if start > end:
                                return {"error_info": f"èµ·å§‹è¡Œå·({start})ä¸èƒ½å¤§äºç»“æŸè¡Œå·({end})"}
                            
                            parsed_ranges.append((start, end))
                        
                        return parsed_ranges
                    
                    except json.JSONDecodeError as e:
                        return {"error_info": f"JSONæ ¼å¼é”™è¯¯: {str(e)}"}
                
                # å°è¯•è§£æä¸ºå•ä¸ªæ•°å­—
                try:
                    start = int(arg)
                    if start < 0:
                        return {"error_info": "è¡Œå·ä¸èƒ½ä¸ºè´Ÿæ•°"}
                    return [(start, None)]
                except ValueError:
                    return {"error_info": "å‚æ•°å¿…é¡»æ˜¯æ•°å­—æˆ–æœ‰æ•ˆçš„JSONæ ¼å¼å¤šèŒƒå›´"}
            
            elif len(filtered_args) == 2:
                # ä¸¤ä¸ªå‚æ•°ï¼šè¯»å–æŒ‡å®šèŒƒå›´
                try:
                    start = int(filtered_args[0])
                    end = int(filtered_args[1])
                    if start < 0 or end < 0:
                        return {"error_info": "è¡Œå·ä¸èƒ½ä¸ºè´Ÿæ•°"}
                    if start > end:
                        return {"error_info": "èµ·å§‹è¡Œå·ä¸èƒ½å¤§äºç»“æŸè¡Œå·"}
                    return [(start, end)]
                except ValueError:
                    return {"error_info": "è¡Œå·å¿…é¡»æ˜¯æ•°å­—"}
            
            else:
                return {"error_info": "å‚æ•°è¿‡å¤šï¼Œæ”¯æŒæ ¼å¼: read file [start end] æˆ– read file '[[start1,end1],[start2,end2]]'"}
                
        except Exception as e:
            return {"error_info": f"è§£æè¡Œæ•°èŒƒå›´æ—¶å‡ºé”™: {e}"}

    def _download_and_get_content(self, filename, remote_absolute_path, force=False):
        """
        ä¸‹è½½æ–‡ä»¶å¹¶è·å–å†…å®¹ï¼ˆç”¨äºreadå‘½ä»¤ï¼‰
        
        Args:
            filename (str): æ–‡ä»¶å
            remote_absolute_path (str): è¿œç¨‹ç»å¯¹è·¯å¾„
            force (bool): æ˜¯å¦å¼ºåˆ¶ä¸‹è½½å¹¶æ›´æ–°ç¼“å­˜
        """
        try:
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            # è§£æè·¯å¾„ä»¥è·å–ç›®æ ‡æ–‡ä»¶å¤¹å’Œæ–‡ä»¶å
            path_parts = remote_absolute_path.strip('/').split('/')
            actual_filename = path_parts[-1]
            
            # å¯¹äºç»å¯¹è·¯å¾„ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if remote_absolute_path.startswith('/content/drive/MyDrive/REMOTE_ROOT/'):
                # ç§»é™¤å‰ç¼€ï¼Œè·å–ç›¸å¯¹äºREMOTE_ROOTçš„è·¯å¾„
                relative_path = remote_absolute_path.replace('/content/drive/MyDrive/REMOTE_ROOT/', '')
                relative_parts = relative_path.split('/')
                actual_filename = relative_parts[-1]
                parent_relative_path = '/'.join(relative_parts[:-1]) if len(relative_parts) > 1 else ''
                
                if parent_relative_path:
                    # è½¬æ¢ä¸º~è·¯å¾„æ ¼å¼
                    parent_logical_path = '~/' + parent_relative_path
                    resolve_result = self.main_instance.path_resolver.resolve_path(parent_logical_path, current_shell)
                    if isinstance(resolve_result, tuple) and len(resolve_result) >= 2:
                        target_folder_id, _ = resolve_result
                        if not target_folder_id:
                            return {"success": False, "error": f"æ— æ³•è§£æç›®æ ‡è·¯å¾„: {parent_logical_path}"}
                    else:
                        return {"success": False, "error": f"è·¯å¾„è§£æè¿”å›æ ¼å¼é”™è¯¯: {parent_logical_path}"}
                else:
                    # æ–‡ä»¶åœ¨REMOTE_ROOTæ ¹ç›®å½•
                    target_folder_id = self.main_instance.REMOTE_ROOT_FOLDER_ID
            else:
                # ä½¿ç”¨å½“å‰shellçš„æ–‡ä»¶å¤¹ID
                target_folder_id = current_shell.get("current_folder_id", self.main_instance.REMOTE_ROOT_FOLDER_ID)
            
            # åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾æ–‡ä»¶
            result = self.drive_service.list_files(folder_id=target_folder_id, max_results=100)
            if not result['success']:
                return {"success": False, "error": f"æ— æ³•åˆ—å‡ºæ–‡ä»¶å¤¹å†…å®¹: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"}
            
            file_info = None
            files = result['files']
            for file in files:
                if file['name'] == actual_filename:
                    file_info = file
                    break
            
            if not file_info:
                return {"success": False, "error": f"File does not exist: {actual_filename}"}
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆä¸æ˜¯æ–‡ä»¶å¤¹ï¼‰
            if file_info['mimeType'] == 'application/vnd.google-apps.folder':
                return {"success": False, "error": f"{actual_filename} æ˜¯ä¸€ä¸ªç›®å½•ï¼Œæ— æ³•è¯»å–"}
            
            # ä½¿ç”¨Google Drive APIä¸‹è½½æ–‡ä»¶å†…å®¹
            try:
                file_id = file_info['id']
                request = self.drive_service.service.files().get_media(fileId=file_id)
                content = request.execute()
                
                # å°†å­—èŠ‚å†…å®¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if isinstance(content, bytes):
                    try:
                        content_str = content.decode('utf-8')
                    except UnicodeDecodeError:
                        try:
                            content_str = content.decode('gbk')
                        except UnicodeDecodeError:
                            content_str = content.decode('utf-8', errors='replace')
                else:
                    content_str = str(content)
                

                
                return {
                    "success": True,
                    "content": content_str,
                    "file_info": file_info
                }
                
            except Exception as e:
                return {"success": False, "error": f"ä¸‹è½½æ–‡ä»¶å†…å®¹å¤±è´¥: {e}"}
                
        except Exception as e:
            return {"success": False, "error": f"ä¸‹è½½å’Œè·å–å†…å®¹æ—¶å‡ºé”™: {e}"}

    def _format_read_output(self, selected_lines):
        """
        æ ¼å¼åŒ–è¯»å–è¾“å‡º
        
        Args:
            selected_lines: åŒ…å«(line_number, line_content)å…ƒç»„çš„åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–åçš„è¾“å‡ºå­—ç¬¦ä¸²
        """
        if not selected_lines:
            return ""
        
        # æ ¼å¼åŒ–æ¯è¡Œï¼Œæ˜¾ç¤ºè¡Œå·å’Œå†…å®¹
        formatted_lines = ["line_num: line_content"]
        for line_num, line_content in selected_lines:
            # è¡Œå·ä»0å¼€å§‹, 0-indexed
            formatted_lines.append(f"{line_num:4d}: {line_content}")
        
        return "\n".join(formatted_lines)

    def cmd_read(self, filename, *args, force=False):
        """è¯»å–è¿œç«¯æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒæ™ºèƒ½ç¼“å­˜å’Œè¡Œæ•°èŒƒå›´
        
        Args:
            filename (str): æ–‡ä»¶å
            *args: è¡Œæ•°èŒƒå›´å‚æ•°
            force (bool): æ˜¯å¦å¼ºåˆ¶ä»è¿œç«¯é‡æ–°ä¸‹è½½ï¼Œå¿½ç•¥ç¼“å­˜
        """
        try:
            if not filename:
                return {"success": False, "error": "è¯·æŒ‡å®šè¦è¯»å–çš„æ–‡ä»¶"}
            
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            remote_absolute_path = self.main_instance.resolve_remote_absolute_path(filename, current_shell)
            if not remote_absolute_path:
                return {"success": False, "error": f"æ— æ³•è§£ææ–‡ä»¶è·¯å¾„: {filename}"}
            
            line_ranges = self._parse_line_ranges(args)
            
            if line_ranges is False:
                return {"success": False, "error": "è¡Œæ•°èŒƒå›´å‚æ•°æ ¼å¼é”™è¯¯"}
            elif isinstance(line_ranges, dict) and "error" in line_ranges:
                return {"success": False, "error": line_ranges["error_info"]}
            
            file_content = None
            source = "unknown"
            
            # ç¡®ä¿Pathå·²å¯¼å…¥
            from pathlib import Path
            
            # å¦‚æœforce=Trueï¼Œè·³è¿‡ç¼“å­˜æ£€æŸ¥ï¼Œç›´æ¥ä¸‹è½½å¹¶æ›´æ–°ç¼“å­˜
            if force:
                # ä½¿ç”¨cmd_downloadæ¥ä¸‹è½½å¹¶æ›´æ–°ç¼“å­˜
                download_result = self.cmd_download(filename, force=True)
                if not download_result["success"]:
                    return download_result
                
                # ä»ç¼“å­˜è¯»å–å†…å®¹
                cache_status = self.main_instance.is_remote_file_cached(remote_absolute_path)
                cache_file_path = cache_status["cache_file_path"]
                
                if cache_file_path and Path(cache_file_path).exists():
                    with open(cache_file_path, 'r', encoding='utf-8', errors='replace') as f:
                        file_content = f.read()
                    source = "download (forced)"
                else:
                    return {"success": False, "error": "Failed to read from updated cache"}
            else:
                # æ­£å¸¸çš„ç¼“å­˜æ£€æŸ¥é€»è¾‘
                freshness_result = self.main_instance.is_cached_file_up_to_date(remote_absolute_path)
                
                if (freshness_result["success"] and 
                    freshness_result["is_cached"] and 
                    freshness_result["is_up_to_date"]):
                    
                    cache_status = self.main_instance.is_remote_file_cached(remote_absolute_path)
                    cache_file_path = cache_status["cache_file_path"]
                    
                    if cache_file_path and Path(cache_file_path).exists():
                        with open(cache_file_path, 'r', encoding='utf-8', errors='replace') as f:
                            file_content = f.read()
                        source = "cache"
                    else:
                        download_result = self._download_and_get_content(filename, remote_absolute_path, force=False)
                        if not download_result["success"]:
                            return download_result
                        file_content = download_result["content"]
                        source = "download"
                else:
                    download_result = self._download_and_get_content(filename, remote_absolute_path, force=False)
                    if not download_result["success"]:
                        return download_result
                    file_content = download_result["content"]
                    source = "download"
            
            lines = file_content.split('\n')
            
            if not line_ranges:
                selected_lines = [(i, line) for i, line in enumerate(lines)]
            else:
                selected_lines = []
                
                for range_item in line_ranges:
                    try:
                        # å°è¯•è§£åŒ…
                        if isinstance(range_item, (tuple, list)) and len(range_item) == 2:
                            start, end = range_item
                        else:
                            return {"success": False, "error": f"Invalid range format: {range_item}"}
                            
                        # å¤„ç†è¡Œæ•°èŒƒå›´
                        if end is None:
                            # ä»startè¡Œå¼€å§‹åˆ°æ–‡ä»¶æœ«å°¾
                            for i in range(max(0, start), len(lines)):
                                selected_lines.append((i, lines[i]))
                        else:
                            # ä»startè¡Œåˆ°endè¡Œ
                            for i in range(max(0, start), min(len(lines), end + 1)):
                                selected_lines.append((i, lines[i]))
                                
                    except Exception as e:
                        return {"success": False, "error": f"Error processing line range: {e}"}
            
            formatted_output = self._format_read_output(selected_lines)
            
            return {
                "success": True,
                "remote_path": remote_absolute_path,
                "source": source,
                "total_lines": len(lines),
                "selected_lines": len(selected_lines),
                "line_ranges": line_ranges,
                "output": formatted_output,
                "lines_data": selected_lines
            }
            
        except Exception as e:
            return {"success": False, "error": f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}"}

    def _parse_find_args(self, args):
        """è§£æfindå‘½ä»¤å‚æ•°"""
        try:
            args_list = list(args)
            
            # é»˜è®¤å€¼
            path = "."
            pattern = "*"
            case_sensitive = True
            file_type = None  # None=both, "f"=files, "d"=directories
            
            i = 0
            while i < len(args_list):
                arg = args_list[i]
                
                if arg == "-name" and i + 1 < len(args_list):
                    pattern = args_list[i + 1]
                    case_sensitive = True
                    i += 2
                elif arg == "-iname" and i + 1 < len(args_list):
                    pattern = args_list[i + 1]
                    case_sensitive = False
                    i += 2
                elif arg == "-type" and i + 1 < len(args_list):
                    file_type = args_list[i + 1]
                    if file_type not in ["f", "d"]:
                        return {"success": False, "error": "æ— æ•ˆçš„æ–‡ä»¶ç±»å‹ï¼Œä½¿ç”¨ 'f' (æ–‡ä»¶) æˆ– 'd' (ç›®å½•)"}
                    i += 2
                elif not arg.startswith("-"):
                    # è¿™æ˜¯è·¯å¾„å‚æ•°
                    path = arg
                    i += 1
                else:
                    i += 1
            
            return {
                "success": True,
                "path": path,
                "pattern": pattern,
                "case_sensitive": case_sensitive,
                "file_type": file_type
            }
            
        except Exception as e:
            return {"success": False, "error": f"å‚æ•°è§£æé”™è¯¯: {e}"}
    
    def cmd_find(self, *args):
        """
        GDS findå‘½ä»¤å®ç°ï¼Œç±»ä¼¼bash find
        
        ç”¨æ³•:
            find [path] -name [pattern]
            find [path] -iname [pattern]  # å¤§å°å†™ä¸æ•æ„Ÿ
            find [path] -type f -name [pattern]  # åªæŸ¥æ‰¾æ–‡ä»¶
            find [path] -type d -name [pattern]  # åªæŸ¥æ‰¾ç›®å½•
        
        Args:
            *args: å‘½ä»¤å‚æ•°
            
        Returns:
            dict: æŸ¥æ‰¾ç»“æœ
        """
        try:
            if not args:
                return {
                    "success": False,
                    "error": "ç”¨æ³•: find [path] -name [pattern] æˆ– find [path] -type [f|d] -name [pattern]"
                }
            
            # è§£æå‚æ•°
            parsed_args = self._parse_find_args(args)
            if not parsed_args["success"]:
                return parsed_args
            
            search_path = parsed_args["path"]
            pattern = parsed_args["pattern"]
            case_sensitive = parsed_args["case_sensitive"]
            file_type = parsed_args["file_type"]  # "f" for files, "d" for directories, None for both
            
            # é€’å½’æœç´¢æ–‡ä»¶
            results = self._recursive_find(search_path, pattern, case_sensitive, file_type)
            
            if results["success"]:
                found_files = results["files"]
                
                # æ ¼å¼åŒ–è¾“å‡º
                output_lines = []
                for file_path in sorted(found_files):
                    output_lines.append(file_path)
                
                return {
                    "success": True,
                    "files": found_files,
                    "count": len(found_files),
                    "output": "\n".join(output_lines) if output_lines else "No files found matching the pattern."
                }
            else:
                return results
                
        except Exception as e:
            return {
                "success": False,
                "error": f"Find command error: {e}"
            }

    def _recursive_find(self, search_path, pattern, case_sensitive=True, file_type=None):
        """
        é€’å½’æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å’Œç›®å½•
        
        Args:
            search_path: æœç´¢è·¯å¾„
            pattern: æœç´¢æ¨¡å¼ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
            case_sensitive: æ˜¯å¦å¤§å°å†™æ•æ„Ÿ
            file_type: æ–‡ä»¶ç±»å‹è¿‡æ»¤ ("f" for files, "d" for directories, None for both)
        
        Returns:
            dict: {"success": bool, "files": list, "error": str}
        """
        try:
            import fnmatch
            
            # è§£ææœç´¢è·¯å¾„
            if search_path == ".":
                # ä½¿ç”¨å½“å‰shellè·¯å¾„
                current_shell = self.main_instance.get_current_shell()
                if current_shell:
                    search_path = current_shell.get("current_path", "~")
            
            # å°†~è½¬æ¢ä¸ºå®é™…çš„REMOTE_ROOTè·¯å¾„
            if search_path.startswith("~"):
                search_path = search_path.replace("~", "/content/drive/MyDrive/REMOTE_ROOT", 1)
            
            # ç”Ÿæˆè¿œç¨‹findå‘½ä»¤
            find_cmd_parts = ["find", f'"{search_path}"']
            
            # æ·»åŠ æ–‡ä»¶ç±»å‹è¿‡æ»¤
            if file_type == "f":
                find_cmd_parts.append("-type f")
            elif file_type == "d":
                find_cmd_parts.append("-type d")
            
            # æ·»åŠ åç§°æ¨¡å¼
            if case_sensitive:
                find_cmd_parts.append(f'-name "{pattern}"')
            else:
                find_cmd_parts.append(f'-iname "{pattern}"')
            
            find_command = " ".join(find_cmd_parts)
            
            # æ‰§è¡Œè¿œç¨‹findå‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", find_command])
            
            if result.get("success"):
                stdout = result.get("stdout", "").strip()
                if stdout:
                    # åˆ†å‰²è¾“å‡ºä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨
                    files = [line.strip() for line in stdout.split("\n") if line.strip()]
                    return {
                        "success": True,
                        "files": files
                    }
                else:
                    return {
                        "success": True,
                        "files": []
                    }
            else:
                return {
                    "success": False,
                    "error": f"Remote find command failed: {result.get('error', 'Unknown error')}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"Error executing find: {e}"
            }

    def _generate_edit_diff(self, original_lines, modified_lines, parsed_replacements):
        """
        ç”Ÿæˆç¼–è¾‘å·®å¼‚ä¿¡æ¯
        
        Args:
            original_lines: åŸå§‹æ–‡ä»¶è¡Œåˆ—è¡¨
            modified_lines: ä¿®æ”¹åæ–‡ä»¶è¡Œåˆ—è¡¨
            parsed_replacements: è§£æåçš„æ›¿æ¢æ“ä½œåˆ—è¡¨
            
        Returns:
            dict: å·®å¼‚ä¿¡æ¯
        """
        try:
            import difflib
            
            # ç”Ÿæˆunified diff
            diff = list(difflib.unified_diff(
                original_lines,
                modified_lines,
                fromfile='original',
                tofile='modified',
                lineterm=''
            ))
            
            # ç»Ÿè®¡å˜æ›´ä¿¡æ¯
            lines_added = len(modified_lines) - len(original_lines)
            changes_count = len(parsed_replacements)
            
            # ç”Ÿæˆç®€åŒ–çš„å˜æ›´æ‘˜è¦
            changes_summary = []
            for replacement in parsed_replacements:
                if replacement["type"] == "line_range":
                    changes_summary.append(f"Lines {replacement['start_line']}-{replacement['end_line']}: range replacement")
                elif replacement["type"] == "line_insert":
                    changes_summary.append(f"Line {replacement['insert_line']}: content insertion")
                elif replacement["type"] == "text_search":
                    changes_summary.append(f"Text search: '{replacement['old_text'][:50]}...' -> '{replacement['new_text'][:50]}...'")
            
            return {
                "diff_lines": diff,
                "lines_added": lines_added,
                "changes_count": changes_count,
                "changes_summary": changes_summary,
                "original_line_count": len(original_lines),
                "modified_line_count": len(modified_lines)
            }
            
        except Exception as e:
            return {
                "error": f"Failed to generate diff: {e}",
                "diff_lines": [],
                "lines_added": 0,
                "changes_count": 0,
                "changes_summary": []
            }

    def _generate_local_diff_preview(self, filename, original_lines, modified_lines, parsed_replacements):
        """
        ç”Ÿæˆæœ¬åœ°diffé¢„è§ˆï¼Œåªæ˜¾ç¤ºä¿®æ”¹çš„éƒ¨åˆ†
        
        Args:
            filename (str): æ–‡ä»¶å
            original_lines (list): åŸå§‹æ–‡ä»¶è¡Œ
            modified_lines (list): ä¿®æ”¹åæ–‡ä»¶è¡Œ
            parsed_replacements (list): è§£æåçš„æ›¿æ¢æ“ä½œ
            
        Returns:
            dict: åŒ…å«diffè¾“å‡ºå’Œå˜æ›´æ‘˜è¦
        """
        try:
            import tempfile
            import os
            import subprocess
            import hashlib
            import time
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_base_dir = os.path.join(os.path.expanduser("~"), ".local", "bin", "GOOGLE_DRIVE_DATA", "tmp")
            os.makedirs(temp_base_dir, exist_ok=True)
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å“ˆå¸Œæ–‡ä»¶å
            timestamp = str(int(time.time() * 1000))
            content_hash = hashlib.md5(filename.encode()).hexdigest()[:8]
            
            original_filename = f"{content_hash}_{timestamp}_original.tmp"
            modified_filename = f"{content_hash}_{timestamp}_modified.tmp"
            
            original_path = os.path.join(temp_base_dir, original_filename)
            modified_path = os.path.join(temp_base_dir, modified_filename)
            
            try:
                # å†™å…¥åŸå§‹æ–‡ä»¶
                with open(original_path, 'w', encoding='utf-8') as f:
                    f.writelines(original_lines)
                
                # å†™å…¥ä¿®æ”¹åæ–‡ä»¶
                with open(modified_path, 'w', encoding='utf-8') as f:
                    f.writelines(modified_lines)
                
                # æ‰§è¡Œdiffå‘½ä»¤
                diff_cmd = ['diff', '-u', original_path, modified_path]
                result = subprocess.run(diff_cmd, capture_output=True, text=True, encoding='utf-8')
                
                # diffå‘½ä»¤è¿”å›ç ï¼š0=æ— å·®å¼‚ï¼Œ1=æœ‰å·®å¼‚ï¼Œ2=é”™è¯¯
                if result.returncode == 0:
                    diff_output = "No changes detected"
                elif result.returncode == 1:
                    # æœ‰å·®å¼‚ï¼Œå¤„ç†è¾“å‡º
                    diff_lines = result.stdout.splitlines()
                    # ç§»é™¤æ–‡ä»¶è·¯å¾„è¡Œï¼Œåªä¿ç•™å·®å¼‚å†…å®¹
                    filtered_lines = []
                    for line in diff_lines:
                        if line.startswith('---') or line.startswith('+++'):
                            # æ›¿æ¢ä¸´æ—¶æ–‡ä»¶è·¯å¾„ä¸ºå®é™…æ–‡ä»¶å
                            if line.startswith('---'):
                                filtered_lines.append(f"--- {filename} (original)")
                            elif line.startswith('+++'):
                                filtered_lines.append(f"+++ {filename} (modified)")
                        else:
                            filtered_lines.append(line)
                    diff_output = '\n'.join(filtered_lines)
                else:
                    diff_output = f"Diff command error: {result.stderr}"
                
                # ç”Ÿæˆå˜æ›´æ‘˜è¦
                changes_summary = []
                for replacement in parsed_replacements:
                    if replacement["type"] == "line_range":
                        changes_summary.append(f"Lines {replacement['start_line']}-{replacement['end_line']}: range replacement")
                    elif replacement["type"] == "line_insert":
                        changes_summary.append(f"Line {replacement['insert_line']}: content insertion")
                    elif replacement["type"] == "text_search":
                        changes_summary.append(f"Text search: '{replacement['old_text'][:50]}...' -> '{replacement['new_text'][:50]}...'")
                
                return {
                    "diff_output": diff_output,
                    "changes_summary": changes_summary,
                    "temp_files_created": [original_path, modified_path]
                }
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if os.path.exists(original_path):
                        os.unlink(original_path)
                    if os.path.exists(modified_path):
                        os.unlink(modified_path)
                except Exception as cleanup_error:
                    # æ¸…ç†å¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½
                    pass
                    
        except Exception as e:
            return {
                "diff_output": f"Failed to generate diff preview: {str(e)}",
                "changes_summary": [],
                "temp_files_created": []
            }

    def cmd_edit(self, filename, replacement_spec, preview=False, backup=False):
        """
        GDS editå‘½ä»¤ - æ”¯æŒå¤šæ®µæ–‡æœ¬åŒæ­¥æ›¿æ¢çš„æ–‡ä»¶ç¼–è¾‘åŠŸèƒ½
        
        Args:
            filename (str): è¦ç¼–è¾‘çš„æ–‡ä»¶å
            replacement_spec (str): æ›¿æ¢è§„èŒƒï¼Œæ”¯æŒå¤šç§æ ¼å¼
            preview (bool): é¢„è§ˆæ¨¡å¼ï¼Œåªæ˜¾ç¤ºä¿®æ”¹ç»“æœä¸å®é™…ä¿å­˜
            backup (bool): æ˜¯å¦åˆ›å»ºå¤‡ä»½æ–‡ä»¶
            
        Returns:
            dict: ç¼–è¾‘ç»“æœ
            
        æ”¯æŒçš„æ›¿æ¢æ ¼å¼:
        1. è¡Œå·æ›¿æ¢: '[[[1, 2], "new content"], [[5, 7], "another content"]]'
        2. è¡Œå·æ’å…¥: '[[[1, null], "content to insert"], [[5, null], "another insert"]]'
        3. æ–‡æœ¬æœç´¢æ›¿æ¢: '[["old text", "new text"], ["another old", "another new"]]'
        4. æ··åˆæ¨¡å¼: '[[[1, 1], "line replacement"], [[3, null], "insertion"], ["text", "replace"]]'
        """
        # Debugä¿¡æ¯æ”¶é›†å™¨
        debug_info = []
        # åˆå§‹åŒ–å˜é‡ä»¥é¿å…ä½œç”¨åŸŸé—®é¢˜
        files_to_upload = []
        
        def debug_log(message):
            debug_info.append(message)
        
        try:
            
            import json
            import re
            import tempfile
            import shutil
            import os
            from datetime import datetime
            
            # å¯¼å…¥ç¼“å­˜ç®¡ç†å™¨
            import sys
            from pathlib import Path
            cache_manager_path = Path(__file__).parent.parent / "cache_manager.py"
            if cache_manager_path.exists():
                sys.path.insert(0, str(Path(__file__).parent.parent))
                from cache_manager import GDSCacheManager
                cache_manager = GDSCacheManager()
            else:
                return {"success": False, "error": "Cache manager not found"}
            
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "No active remote shell"}
            
            # 1. è§£ææ›¿æ¢è§„èŒƒ
            try:
                replacements = json.loads(replacement_spec)
                if not isinstance(replacements, list):
                    return {"success": False, "error": "Replacement specification must be an array"}
            except json.JSONDecodeError as e:
                # æä¾›æ›´æœ‰å»ºè®¾æ€§çš„é”™è¯¯ä¿¡æ¯
                error_msg = f"JSON parsing failed: {e}\n\n"
                error_msg += "Common issues:\n"
                error_msg += "1. Missing quotes around strings\n"
                error_msg += "2. Unescaped quotes inside strings (use \\\" instead of \")\n" 
                error_msg += "3. Missing commas between array elements\n"
                error_msg += "4. Shell quote conflicts. Try using single quotes around JSON\n\n"
                error_msg += f"Your input: {repr(replacement_spec)}\n"
                error_msg += "Correct format examples:\n"
                error_msg += "  Text replacement: '[[\"old\", \"new\"]]'\n"
                error_msg += "  Line replacement: '[[[1, 3], \"new content\"]]'\n"
                error_msg += "  Mixed: '[[[1, 2], \"line\"], [\"old\", \"new\"]]'"
                return {"success": False, "error": error_msg}
            
            # 2. ä¸‹è½½æ–‡ä»¶åˆ°ç¼“å­˜
            download_result = self.cmd_download(filename, force=True)  # å¼ºåˆ¶é‡æ–°ä¸‹è½½ç¡®ä¿æœ€æ–°å†…å®¹
            if not download_result["success"]:
                return {"success": False, "error": f"{download_result.get('error')}"}  #TODO
            
            cache_file_path = download_result.get("cache_path") or download_result.get("cached_path")
            if not cache_file_path or not os.path.exists(cache_file_path):
                return {"success": False, "error": "Failed to get cache file path"}
            
            # 3. è¯»å–æ–‡ä»¶å†…å®¹
            try:
                with open(cache_file_path, 'r', encoding='utf-8') as f:
                    original_lines = f.readlines()
            except UnicodeDecodeError:
                # å°è¯•å…¶ä»–ç¼–ç 
                try:
                    with open(cache_file_path, 'r', encoding='gbk') as f:
                        original_lines = f.readlines()
                except:
                    return {"success": False, "error": "Unsupported file encoding, please ensure the file is UTF-8 or GBK encoded"}
            except Exception as e:
                return {"success": False, "error": f"Failed to read file: {e}"}
            
            # 4. è§£æå’ŒéªŒè¯æ›¿æ¢æ“ä½œ
            parsed_replacements = []
            for i, replacement in enumerate(replacements):
                if not isinstance(replacement, list) or len(replacement) != 2:
                    return {"success": False, "error": f"Replacement specification item {i+1} has incorrect format, should be [source, target] format"}
                
                source, target = replacement
                
                if isinstance(source, list) and len(source) == 2:
                    start_line, end_line = source
                    
                    # æ£€æŸ¥æ’å…¥æ¨¡å¼ï¼š[a, null] æˆ– [a, ""] æˆ– [a, None]
                    if end_line is None or end_line == "" or end_line == "null":
                        # æ’å…¥æ¨¡å¼: [[line_number, null], "content_to_insert"]
                        if not isinstance(start_line, int):
                            return {"success": False, "error": f"Insert mode requires integer line number, got: {start_line}"}
                        
                        if start_line < 0 or start_line > len(original_lines):
                            return {"success": False, "error": f"Insert line number error: {start_line} (valid range: 0-{len(original_lines)}, 0-based index)"}
                        
                        parsed_replacements.append({
                            "type": "line_insert",
                            "insert_after_idx": start_line,
                            "insert_line": start_line,
                            "new_content": target,
                            "original_content": ""  # æ’å…¥æ¨¡å¼æ²¡æœ‰åŸå§‹å†…å®¹
                        })
                        
                    elif isinstance(start_line, int) and isinstance(end_line, int):
                        # æ›¿æ¢æ¨¡å¼: [[start_line, end_line], "new_content"] (0-based, [a, b] åŒ…å«è¯­æ³•)
                        # ä½¿ç”¨0-basedç´¢å¼•ï¼Œ[a, b] åŒ…å«è¯­æ³•ï¼Œä¸readå‘½ä»¤ä¿æŒä¸€è‡´
                        start_idx = start_line
                        end_idx = end_line  # end_lineæ˜¯inclusiveçš„
                        
                        if start_idx < 0 or start_idx >= len(original_lines) or end_line >= len(original_lines) or start_idx > end_idx:
                            return {"success": False, "error": f"Line number range error: [{start_line}, {end_line}] in file with {len(original_lines)} lines (0-based index)"}
                        
                        parsed_replacements.append({
                            "type": "line_range",
                            "start_idx": start_idx,
                            "end_idx": end_idx,
                            "start_line": start_line,
                            "end_line": end_line,
                            "new_content": target,
                            "original_content": "".join(original_lines[start_idx:end_line + 1]).rstrip()
                        })
                    else:
                        return {"success": False, "error": f"Invalid line specification: [{start_line}, {end_line}]. Use [start, end] for replacement or [line, null] for insertion."}
                    
                elif isinstance(source, str):
                    # æ–‡æœ¬æœç´¢æ›¿æ¢æ¨¡å¼: ["old_text", "new_text"]
                    if source not in "".join(original_lines):
                        return {"success": False, "error": f"Text not found to replace: {source[:50]}..."}
                    
                    parsed_replacements.append({
                        "type": "text_search",
                        "old_text": source,
                        "new_text": target
                    })
                else:
                    return {"success": False, "error": f"Source format for replacement specification item {i+1} is not supported, should be line number array [start, end] or text string"}
            
            # 5. æ‰§è¡Œæ›¿æ¢å’Œæ’å…¥æ“ä½œ
            modified_lines = original_lines.copy()
            
            # å…ˆå¤„ç†æ’å…¥æ“ä½œï¼ˆæŒ‰è¡Œå·å€’åºï¼Œé¿å…è¡Œå·å˜åŒ–å½±å“åç»­æ’å…¥ï¼‰
            line_insertions = [r for r in parsed_replacements if r["type"] == "line_insert"]
            line_insertions.sort(key=lambda x: x["insert_after_idx"], reverse=True)
            
            for insertion in line_insertions:
                insert_after_idx = insertion["insert_after_idx"]
                new_content = insertion["new_content"]
                
                # å°†æ–°å†…å®¹æŒ‰æ¢è¡Œç¬¦æ‹†åˆ†æˆè¡Œåˆ—è¡¨ï¼Œæ­£ç¡®å¤„ç†\n
                if new_content:
                    # å¤„ç†æ¢è¡Œç¬¦ï¼Œå°†\nè½¬æ¢ä¸ºå®é™…æ¢è¡Œ
                    processed_content = new_content.replace('\\n', '\n')
                    # å¤„ç†ç©ºæ ¼å ä½ç¬¦ï¼Œæ”¯æŒå¤šç§æ ¼å¼
                    processed_content = processed_content.replace('_SPACE_', ' ')  # å•ä¸ªç©ºæ ¼
                    processed_content = processed_content.replace('_SP_', ' ')     # ç®€å†™å½¢å¼
                    processed_content = processed_content.replace('_4SP_', '    ') # 4ä¸ªç©ºæ ¼ï¼ˆå¸¸ç”¨ç¼©è¿›ï¼‰
                    processed_content = processed_content.replace('_TAB_', '\t')   # åˆ¶è¡¨ç¬¦
                    new_lines = processed_content.split('\n')
                    
                    # ç¡®ä¿æ¯è¡Œéƒ½ä»¥æ¢è¡Œç¬¦ç»“å°¾
                    formatted_new_lines = []
                    for i, line in enumerate(new_lines):
                        if i < len(new_lines) - 1:  # ä¸æ˜¯æœ€åä¸€è¡Œ
                            formatted_new_lines.append(line + '\n')
                        else:  # æœ€åä¸€è¡Œ
                            formatted_new_lines.append(line + '\n')  # æ’å…¥çš„å†…å®¹æ€»æ˜¯æ·»åŠ æ¢è¡Œç¬¦
                    
                    # åœ¨æŒ‡å®šè¡Œä¹‹åæ’å…¥å†…å®¹
                    # insert_after_idx = 0 è¡¨ç¤ºåœ¨ç¬¬0è¡Œåæ’å…¥ï¼ˆå³ç¬¬1è¡Œä¹‹å‰ï¼‰
                    # insert_after_idx = len(lines) è¡¨ç¤ºåœ¨æ–‡ä»¶æœ«å°¾æ’å…¥
                    insert_position = insert_after_idx + 1 if insert_after_idx < len(modified_lines) else len(modified_lines)
                    modified_lines[insert_position:insert_position] = formatted_new_lines
            
            # ç„¶åæŒ‰è¡Œå·å€’åºå¤„ç†è¡Œæ›¿æ¢ï¼Œé¿å…è¡Œå·å˜åŒ–å½±å“åç»­æ›¿æ¢
            line_replacements = [r for r in parsed_replacements if r["type"] == "line_range"]
            line_replacements.sort(key=lambda x: x["start_idx"], reverse=True)
            
            for replacement in line_replacements:
                start_idx = replacement["start_idx"]
                end_idx = replacement["end_idx"]
                new_content = replacement["new_content"]
                
                # å°†æ–°å†…å®¹æŒ‰æ¢è¡Œç¬¦æ‹†åˆ†æˆè¡Œåˆ—è¡¨ï¼Œæ­£ç¡®å¤„ç†\n
                if new_content:
                    # å¤„ç†æ¢è¡Œç¬¦ï¼Œå°†\nè½¬æ¢ä¸ºå®é™…æ¢è¡Œ
                    processed_content = new_content.replace('\\n', '\n')
                    # å¤„ç†ç©ºæ ¼å ä½ç¬¦ï¼Œæ”¯æŒå¤šç§æ ¼å¼
                    processed_content = processed_content.replace('_SPACE_', ' ')  # å•ä¸ªç©ºæ ¼
                    processed_content = processed_content.replace('_SP_', ' ')     # ç®€å†™å½¢å¼
                    processed_content = processed_content.replace('_4SP_', '    ') # 4ä¸ªç©ºæ ¼ï¼ˆå¸¸ç”¨ç¼©è¿›ï¼‰
                    processed_content = processed_content.replace('_TAB_', '\t')   # åˆ¶è¡¨ç¬¦
                    new_lines = processed_content.split('\n')
                    
                    # ç¡®ä¿æ¯è¡Œéƒ½ä»¥æ¢è¡Œç¬¦ç»“å°¾ï¼ˆé™¤äº†æœ€åä¸€è¡Œï¼‰
                    formatted_new_lines = []
                    for i, line in enumerate(new_lines):
                        if i < len(new_lines) - 1:  # ä¸æ˜¯æœ€åä¸€è¡Œ
                            formatted_new_lines.append(line + '\n')
                        else:  # æœ€åä¸€è¡Œ
                            # æ ¹æ®åŸæ–‡ä»¶çš„æœ€åä¸€è¡Œæ˜¯å¦æœ‰æ¢è¡Œç¬¦æ¥å†³å®š
                            if end_idx == len(original_lines) and original_lines and not original_lines[-1].endswith('\n'):
                                formatted_new_lines.append(line)  # ä¸æ·»åŠ æ¢è¡Œç¬¦
                            else:
                                formatted_new_lines.append(line + '\n')  # æ·»åŠ æ¢è¡Œç¬¦
                    
                    # æ›¿æ¢è¡ŒèŒƒå›´ (ä½¿ç”¨[a, b]åŒ…å«è¯­æ³•)
                    modified_lines[start_idx:end_idx + 1] = formatted_new_lines
                else:
                    # ç©ºå†…å®¹ï¼Œåˆ é™¤è¡ŒèŒƒå›´
                    modified_lines[start_idx:end_idx + 1] = []
            
            # å¤„ç†æ–‡æœ¬æœç´¢æ›¿æ¢
            text_replacements = [r for r in parsed_replacements if r["type"] == "text_search"]
            if text_replacements:
                file_content = "".join(modified_lines)
                for replacement in text_replacements:
                    file_content = file_content.replace(replacement["old_text"], replacement["new_text"])
                modified_lines = file_content.splitlines(keepends=True)
            
            # 6. ç”Ÿæˆç»“æœé¢„è§ˆ
            diff_info = self._generate_edit_diff(original_lines, modified_lines, parsed_replacements)
            
            if preview:
                # é¢„è§ˆæ¨¡å¼ï¼šä½¿ç”¨diffæ˜¾ç¤ºä¿®æ”¹å†…å®¹ï¼Œä¸ä¿å­˜æ–‡ä»¶
                diff_result = self._generate_local_diff_preview(filename, original_lines, modified_lines, parsed_replacements)
                return {
                    "success": True,
                    "mode": "preview",
                    "filename": filename,
                    "original_lines": len(original_lines),
                    "modified_lines": len(modified_lines),
                    "replacements_applied": len(parsed_replacements),
                    "diff_output": diff_result.get("diff_output", ""),
                    "changes_summary": diff_result.get("changes_summary", []),
                    "message": f"ğŸ“ é¢„è§ˆæ¨¡å¼ - æ–‡ä»¶: {filename}\nåŸå§‹è¡Œæ•°: {len(original_lines)}, ä¿®æ”¹åè¡Œæ•°: {len(modified_lines)}\nåº”ç”¨æ›¿æ¢: {len(parsed_replacements)} ä¸ª"
                }
            
            # 7. å‡†å¤‡ä¸´æ—¶ç›®å½•å’Œæ–‡ä»¶ä¸Šä¼ åˆ—è¡¨
            import tempfile
            import os
            temp_dir = tempfile.gettempdir()
            
            # ä»å®Œæ•´è·¯å¾„ä¸­æå–æ–‡ä»¶åï¼Œä¿æŒåŸå§‹æ–‡ä»¶åç”¨äºæ›¿æ¢
            actual_filename = os.path.basename(filename)
            # ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œä¸æ·»åŠ æ—¶é—´æˆ³ï¼Œè¿™æ ·uploadæ—¶ä¼šç›´æ¥æ›¿æ¢
            temp_file_path = os.path.join(temp_dir, actual_filename)
            
            files_to_upload = []
            backup_info = {}
            
            if backup:
                # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³é¿å…å†²çªï¼ŒåŒ…å«æ¯«ç§’
                import time
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') + f"_{int(time.time() * 1000) % 10000:04d}"
                backup_filename = f"{filename}.backup.{timestamp}"
                
                debug_log("Creating backup file for batch upload...")
                # ä¸‹è½½åŸæ–‡ä»¶åˆ°ç¼“å­˜
                download_result = self.cmd_download(filename, force=True)
                if download_result["success"]:
                    cache_file_path = download_result.get("cache_path") or download_result.get("cached_path")
                    if cache_file_path and os.path.exists(cache_file_path):
                        # åˆ›å»ºä¸´æ—¶å¤‡ä»½æ–‡ä»¶
                        temp_backup_path = os.path.join(temp_dir, backup_filename)
                        import shutil
                        shutil.copy2(cache_file_path, temp_backup_path)
                        files_to_upload.append(temp_backup_path)
                        debug_log(f"Backup file prepared: {temp_backup_path}")
                        
                        backup_info = {
                            "backup_created": True,
                            "backup_filename": backup_filename,
                            "backup_temp_path": temp_backup_path
                        }
                    else:
                        backup_info = {
                            "backup_created": False,
                            "backup_error": "Failed to get cache file for backup"
                        }
                else:
                    backup_info = {
                        "backup_created": False,
                        "backup_error": f"Failed to download original file for backup: {download_result.get('error')}"
                    }
            
            # æ·»åŠ ä¿®æ”¹åçš„æ–‡ä»¶åˆ°ä¸Šä¼ åˆ—è¡¨
            files_to_upload.append(temp_file_path)
            debug_log(f"Files to upload: {files_to_upload}")
            
            # 8. ä¿å­˜ä¿®æ”¹åçš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å
            debug_log(f"Using temp_file_path='{temp_file_path}' for original filename='{actual_filename}'")
            
            with open(temp_file_path, 'w', encoding='utf-8') as temp_file:
                temp_file.writelines(modified_lines)
            
            try:
                # 9. æ›´æ–°ç¼“å­˜
                remote_absolute_path = self.main_instance.resolve_remote_absolute_path(filename, current_shell)
                cache_result = cache_manager.cache_file(remote_absolute_path, temp_file_path)
                
                if not cache_result["success"]:
                    return {"success": False, "error": f"Failed to update cache: {cache_result.get('error')}"}
                
                # 10. ä¸Šä¼ ä¿®æ”¹åçš„æ–‡ä»¶ï¼Œç¡®ä¿ç¼“å­˜çŠ¶æ€æ­£ç¡®æ›´æ–°
                debug_log(f"About to upload edited file - temp_file_path='{temp_file_path}', filename='{filename}'")
                debug_log(f"temp_file exists: {os.path.exists(temp_file_path)}")
                if os.path.exists(temp_file_path):
                    with open(temp_file_path, 'r', encoding='utf-8') as f:
                        content_preview = f.read()[:200]
                    debug_log(f"temp_file content preview: {content_preview}...")
                
                # æ‰¹é‡ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶ï¼ˆå¤‡ä»½æ–‡ä»¶+ä¿®æ”¹åçš„æ–‡ä»¶ï¼‰
                debug_log("Starting batch upload...")
                upload_result = self.cmd_upload(files_to_upload, force=True)
                debug_log(f"Batch upload result: {upload_result}")
                
                if upload_result["success"]:
                    # ç”Ÿæˆdiffé¢„è§ˆç”¨äºæ˜¾ç¤º
                    diff_result = self._generate_local_diff_preview(filename, original_lines, modified_lines, parsed_replacements)
                    
                    result = {
                        "success": True,
                        "filename": filename,
                        "original_lines": len(original_lines),
                        "modified_lines": len(modified_lines),
                        "replacements_applied": len(parsed_replacements),
                        "diff": diff_info,
                        "diff_output": diff_result.get("diff_output", ""),
                        "cache_updated": True,
                        "uploaded": True,
                        "message": f"File {filename} edited successfully, applied {len(parsed_replacements)} replacements"
                    }
                    result.update(backup_info)
                    
                    # å¦‚æœæœ‰å¤‡ä»½æ–‡ä»¶ï¼Œæ·»åŠ æˆåŠŸä¿¡æ¯
                    if backup_info.get("backup_created"):
                        result["message"] += f"\nğŸ“‹ Backup created: {backup_info['backup_filename']}"
                    
                    # åœ¨ç¼–è¾‘å®Œæˆåè¿è¡Œlinteræ£€æŸ¥
                    try:
                        linter_result = self._run_linter_on_content(''.join(modified_lines), filename)
                        if linter_result.get("has_issues"):
                            result["linter_output"] = linter_result.get("formatted_output", "")
                            result["has_linter_issues"] = True
                        else:
                            result["has_linter_issues"] = False
                    except Exception as e:
                        # Linter failure shouldn't break the edit operation
                        result["linter_error"] = f"Linter check failed: {str(e)}"
                    
                    return result
                else:
                    return {
                        "success": False,
                        "error": f"Failed to upload files: {upload_result.get('error')}",
                        "cache_updated": True,
                        "diff": diff_info,
                        "backup_info": backup_info
                    }
                    
            finally:
                # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                for temp_path in files_to_upload:
                    try:
                        if os.path.exists(temp_path):
                            os.unlink(temp_path)
                            debug_log(f"Cleaned up temp file: {temp_path}")
                    except Exception as cleanup_error:
                        debug_log(f"Failed to cleanup temp file {temp_path}: {cleanup_error}")
            
        except KeyboardInterrupt:
            # ç”¨æˆ·ä¸­æ–­ï¼Œè¾“å‡ºdebugä¿¡æ¯
            if debug_info:
                print(f"\nDEBUG INFO (due to KeyboardInterrupt):")
                for i, info in enumerate(debug_info, 1):
                    print(f"  {i}. {info}")
            raise  # é‡æ–°æŠ›å‡ºKeyboardInterrupt
        except Exception as e:
            # è¾“å‡ºdebugä¿¡æ¯ç”¨äºå¼‚å¸¸è¯Šæ–­
            if debug_info:
                print(f"DEBUG INFO (due to exception):")
                for i, info in enumerate(debug_info, 1):
                    print(f"  {i}. {info}")
            return {"success": False, "error": f"Edit operation failed: {str(e)}"}

    def _create_backup(self, filename, backup_filename):
        """
        åˆ›å»ºæ–‡ä»¶çš„å¤‡ä»½å‰¯æœ¬
        
        Args:
            filename (str): åŸæ–‡ä»¶å
            backup_filename (str): å¤‡ä»½æ–‡ä»¶å
            
        Returns:
            dict: å¤‡ä»½ç»“æœ
        """
        # å¤‡ä»½debugä¿¡æ¯æ”¶é›†å™¨
        backup_debug = []
        
        def backup_debug_log(message):
            backup_debug.append(message)
        
        try:
            backup_debug_log(f"Starting backup: {filename} -> {backup_filename}")
            
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                backup_debug_log("ERROR: No active remote shell")
                return {"success": False, "error": "No active remote shell"}
            
            backup_debug_log(f"Current shell: {current_shell.get('id', 'unknown')}")
            
            # ä¸‹è½½åŸæ–‡ä»¶åˆ°ç¼“å­˜
            backup_debug_log("Step 1: Downloading original file to cache...")
            download_result = self.cmd_download(filename, force=True)
            backup_debug_log(f"Download result: success={download_result.get('success')}, error={download_result.get('error')}")
            
            if not download_result["success"]:
                if backup_debug:
                    print(f"BACKUP DEBUG INFO (download failed):")
                    for i, info in enumerate(backup_debug, 1):
                        print(f"  {i}. {info}")
                return {"success": False, "error": f"Failed to download original file for backup: {download_result.get('error')}"}
            
            import os
            cache_file_path = download_result.get("cache_path") or download_result.get("cached_path")
            backup_debug_log(f"Cache file path: {cache_file_path}")
            backup_debug_log(f"Cache file exists: {os.path.exists(cache_file_path) if cache_file_path else False}")
            
            if not cache_file_path or not os.path.exists(cache_file_path):
                if backup_debug:
                    print(f"BACKUP DEBUG INFO (cache file not found):")
                    for i, info in enumerate(backup_debug, 1):
                        print(f"  {i}. {info}")
                return {"success": False, "error": "Failed to get cache file path for backup"}
            
            # ä¸Šä¼ ç¼“å­˜æ–‡ä»¶ä½œä¸ºå¤‡ä»½
            backup_debug_log("Step 2: Creating backup file with correct name...")
            backup_debug_log(f"Cache file path: {cache_file_path}")
            backup_debug_log(f"Backup filename: {backup_filename}")
            
            # åˆ›å»ºä¸´æ—¶å¤‡ä»½æ–‡ä»¶ï¼Œä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶å
            import tempfile
            temp_dir = tempfile.gettempdir()
            temp_backup_path = os.path.join(temp_dir, backup_filename)
            backup_debug_log(f"Temp backup path: {temp_backup_path}")
            
            # å¤åˆ¶ç¼“å­˜æ–‡ä»¶åˆ°ä¸´æ—¶å¤‡ä»½æ–‡ä»¶
            import shutil
            shutil.copy2(cache_file_path, temp_backup_path)
            backup_debug_log(f"Copied cache to temp backup: {cache_file_path} -> {temp_backup_path}")
            
            try:
                # ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
                backup_debug_log("Step 3: Uploading backup file...")
                upload_result = self.cmd_upload([temp_backup_path], force=True)
                backup_debug_log(f"Upload result: success={upload_result.get('success')}, error={upload_result.get('error')}")
                backup_debug_log(f"Upload file_moves: {upload_result.get('file_moves', [])}")
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if os.path.exists(temp_backup_path):
                        os.unlink(temp_backup_path)
                        backup_debug_log(f"Cleaned up temp backup file: {temp_backup_path}")
                except Exception as cleanup_error:
                    backup_debug_log(f"Failed to cleanup temp backup file: {cleanup_error}")
            
            if upload_result.get("success", False):
                backup_debug_log("Backup creation completed successfully")
                return {"success": True, "message": f"Backup created: {backup_filename}"}
            else:
                if backup_debug:
                    print(f"BACKUP DEBUG INFO (upload failed):")
                    for i, info in enumerate(backup_debug, 1):
                        print(f"  {i}. {info}")
                return {"success": False, "error": f"Failed to create backup: {upload_result.get('error')}"}
                
        except KeyboardInterrupt:
            # ç”¨æˆ·ä¸­æ–­å¤‡ä»½è¿‡ç¨‹
            if backup_debug:
                print(f"\nBACKUP DEBUG INFO (due to KeyboardInterrupt):")
                for i, info in enumerate(backup_debug, 1):
                    print(f"  {i}. {info}")
            raise
        except Exception as e:
            return {"success": False, "error": f"Backup creation failed: {str(e)}"}

    def cmd_venv(self, *args):
        """
        è™šæ‹Ÿç¯å¢ƒç®¡ç†å‘½ä»¤
        
        æ”¯æŒçš„å­å‘½ä»¤ï¼š
        - --create <env_name>: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
        - --delete <env_name>: åˆ é™¤è™šæ‹Ÿç¯å¢ƒ
        - --activate <env_name>: æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆè®¾ç½®PYTHONPATHï¼‰
        - --deactivate: å–æ¶ˆæ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆæ¸…é™¤PYTHONPATHï¼‰
        - --list: åˆ—å‡ºæ‰€æœ‰è™šæ‹Ÿç¯å¢ƒ
        - --current: æ˜¾ç¤ºå½“å‰æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒ
        
        Args:
            *args: å‘½ä»¤å‚æ•°
            
        Returns:
            dict: æ“ä½œç»“æœ
        """
        try:
            if not args:
                return {
                    "success": False,
                    "error": "Usage: venv --create|--delete|--activate|--deactivate|--list|--current [env_name...]"
                }
            
            action = args[0]
            env_names = args[1:] if len(args) > 1 else []
            
            if action == "--create":
                if not env_names:
                    return {"success": False, "error": "Please specify at least one environment name"}
                return self._venv_create_batch(env_names)
            elif action == "--delete":
                if not env_names:
                    return {"success": False, "error": "Please specify at least one environment name"}
                return self._venv_delete_batch(env_names)
            elif action == "--activate":
                if len(env_names) != 1:
                    return {"success": False, "error": "Please specify exactly one environment name for activation"}
                return self._venv_activate(env_names[0])
            elif action == "--deactivate":
                return self._venv_deactivate()
            elif action == "--list":
                return self._venv_list()
            elif action == "--current":
                return self._venv_current()
            else:
                return {
                    "success": False,
                    "error": f"Unknown venv command: {action}. Supported commands: --create, --delete, --activate, --deactivate, --list, --current"
                }
                
        except Exception as e:
            return {"success": False, "error": f"venvå‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"}
    
    def _venv_create(self, env_name):
        """åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ"""
        if not env_name:
            return {"success": False, "error": "Environment name required"}
        
        if env_name.startswith('.'):
            return {"success": False, "error": "Environment name cannot start with '.'"}
        
        try:
            # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å·²å­˜åœ¨
            env_path = f"{self._get_venv_base_path()}/{env_name}"
            
            # ä½¿ç”¨ç»Ÿä¸€çš„APIç®¡ç†å™¨æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å­˜åœ¨
            try:
                api_manager = self._get_venv_api_manager()
                existing_envs = api_manager.list_venv_environments()
                
                if env_name in existing_envs:
                    return {
                        "success": False,
                        "error": f"Virtual environment '{env_name}' already exists"
                    }
                        
            except Exception as e:
                # Silently handle environment existence check errors
                pass
            
            # ç”Ÿæˆåˆ›å»ºç¯å¢ƒçš„è¿œç¨‹å‘½ä»¤ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å¤æ‚å¼•å·åµŒå¥—ï¼‰
            commands = [
                f"mkdir -p '{env_path}'",
                f"echo '# Virtual environment {env_name} created at {env_path}' > '{env_path}/env_info.txt'",
                f"echo 'Environment: {env_name}' >> '{env_path}/env_info.txt'",
                f"echo 'Created: '\"$(date)\" >> '{env_path}/env_info.txt'",
                f"echo 'Path: {env_path}' >> '{env_path}/env_info.txt'"
            ]
            
            # ä½¿ç”¨bash -cæ‰§è¡Œå‘½ä»¤è„šæœ¬
            command_script = " && ".join(commands)
            result = self.main_instance.execute_generic_command("bash", ["-c", command_script])
            
            if result.get("success", False):
                # æ£€æŸ¥è¿œç¨‹å‘½ä»¤çš„å®é™…æ‰§è¡Œç»“æœ
                exit_code = result.get("exit_code", -1)
                stdout = result.get("stdout", "")
                
                # è¿œç¨‹å‘½ä»¤æˆåŠŸæ‰§è¡Œï¼ˆexit_code == 0 è¡¨ç¤ºæˆåŠŸï¼Œä¸éœ€è¦æ£€æŸ¥ç‰¹å®šè¾“å‡ºï¼‰
                if exit_code == 0:
                    # æ›´æ–°venv_states.jsonï¼Œä¸ºæ–°ç¯å¢ƒæ·»åŠ æ¡ç›®
                    self._initialize_venv_state(env_name)
                    
                    return {
                        "success": True,
                        "message": f"Virtual environment '{env_name}' created successfully",
                        "env_path": env_path,
                        "action": "create",
                        "remote_output": stdout.strip()
                    }
                else:
                    # è·å–å®Œæ•´çš„ç»“æœæ•°æ®ç”¨äºè°ƒè¯•
                    stderr = result.get("stderr", "")
                    
                    # æ„å»ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    error_details = []
                    error_details.append(f"remote command failed with exit code {exit_code}")
                    
                    if stdout.strip():
                        error_details.append(f"stdout: {stdout.strip()}")
                    
                    if stderr.strip():
                        error_details.append(f"stderr: {stderr.strip()}")
                    
                    # æ£€æŸ¥å¸¸è§çš„é”™è¯¯æ¨¡å¼å¹¶æä¾›å»ºè®®
                    error_message = f"Failed to create virtual environment: {'; '.join(error_details)}"
                    
                    if "Permission denied" in stdout or "Permission denied" in stderr:
                        error_message += ". Suggestion: Check if you have write permissions to the remote environment directory."
                    elif "No such file or directory" in stdout or "No such file or directory" in stderr:
                        error_message += ". Suggestion: The remote environment path may not exist or be accessible."
                    elif "python" in stdout.lower() or "python" in stderr.lower():
                        error_message += ". Suggestion: Python may not be available or properly configured in the remote environment."
                    
                    return {
                        "success": False,
                        "error": error_message,
                        "remote_output": stdout.strip(),
                        "stderr": stderr.strip(),
                        "exit_code": exit_code
                    }
            else:
                return {
                    "success": False,
                    "error": f"Failed to create virtual environment: {result.get('error', 'Unknown error')}"
                }
                
        except Exception as e:
            return {"success": False, "error": f"Error creating virtual environment: {str(e)}"}
    
    def _venv_delete(self, env_name):
        """åˆ é™¤è™šæ‹Ÿç¯å¢ƒ"""
        if not env_name:
            return {"success": False, "error": "Please specify the environment name"}
        
        if env_name.startswith('.'):
            return {"success": False, "error": "Environment name cannot start with '.'"}
        
        try:
            # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å­˜åœ¨
            env_path = f"{self._get_venv_base_path()}/{env_name}"
            
            # ä½¿ç”¨Google Drive APIæ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
            if self.drive_service:
                try:
                    folders_result = self.drive_service.list_files(
                        folder_id=self.main_instance.REMOTE_ENV_FOLDER_ID,
                        max_results=100
                    )
                    folders = folders_result.get('files', []) if folders_result.get('success') else []
                    folders = [f for f in folders if f.get('mimeType') == 'application/vnd.google-apps.folder']
                    
                    existing_env = next((f for f in folders if f['name'] == env_name), None)
                    if not existing_env:
                        return {
                            "success": False,
                            "error": f"Virtual environment '{env_name}' does not exist"
                        }
                        
                except Exception as e:
                    # Silently handle environment existence check errors
                    pass
            
            # ç”Ÿæˆåˆ é™¤ç¯å¢ƒçš„è¿œç¨‹å‘½ä»¤ï¼Œæ·»åŠ æ‰§è¡ŒçŠ¶æ€æç¤º
            command = f"rm -rf {env_path}"
            result = self.main_instance.execute_generic_command("bash", ["-c", command])
            
            if result.get("success", False):
                return {
                    "success": True,
                    "message": f"Virtual environment '{env_name}' deleted successfully",
                    "action": "delete"
                }
            else:
                return {
                    "success": False,
                    "error": f"Failed to delete virtual environment: {result.get('error', 'Unknown error')}"
                }
                
        except Exception as e:
            return {"success": False, "error": f"Error deleting virtual environment: {str(e)}"}
    
    def _venv_activate(self, env_name):
        """æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆè®¾ç½®PYTHONPATHï¼‰- ç®€åŒ–ç‰ˆæœ¬"""
        if not env_name:
            return {"success": False, "error": "Please specify the environment name"}
        
        if env_name.startswith('.'):
            return {"success": False, "error": "Environment name cannot start with '.'"}
        
        try:
            # æ„å»ºå•ä¸ªè¿œç¨‹å‘½ä»¤æ¥æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆåŒ…å«éªŒè¯ï¼‰
            # è¿™ä¸ªå‘½ä»¤ä¼šï¼š1) æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å­˜åœ¨ï¼Œ2) æ£€æŸ¥æ˜¯å¦å·²æ¿€æ´»ï¼Œ3) ä¿å­˜çŠ¶æ€åˆ°JSONæ–‡ä»¶ï¼Œ4) éªŒè¯ä¿å­˜æˆåŠŸ
            remote_command = f'''
# è·å–å½“å‰shell ID
SHELL_ID="${{GDS_SHELL_ID:-default_shell}}"

# æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å­˜åœ¨
ENV_PATH="{self._get_venv_base_path()}/{env_name}"
if [ ! -d "$ENV_PATH" ]; then
    echo "ERROR: Virtual environment '{env_name}' does not exist"
    exit 1
fi

# æ£€æŸ¥æ˜¯å¦å·²ç»æ¿€æ´»
VENV_STATES_FILE="{self._get_venv_state_file_path()}"
if [ -f "$VENV_STATES_FILE" ]; then
    CURRENT_VENV=$(cat "$VENV_STATES_FILE" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    shell_id = '$SHELL_ID'
    if shell_id in data and data[shell_id].get('current_venv') == '{env_name}':
        print('already_active')
    else:
        print('not_active')
except:
    print('not_active')
")
else
    CURRENT_VENV="not_active"
fi

if [ "$CURRENT_VENV" = "already_active" ]; then
    echo "Virtual environment '{env_name}' is already active"
    exit 0
fi

# ä¿å­˜æ–°çš„çŠ¶æ€åˆ°JSONæ–‡ä»¶
mkdir -p "{self._get_venv_base_path()}"
python3 -c "
import json
import os
from datetime import datetime

# è¯»å–ç°æœ‰çŠ¶æ€
states = {{}}
if os.path.exists('$VENV_STATES_FILE'):
    try:
        with open('$VENV_STATES_FILE', 'r') as f:
            states = json.load(f)
    except:
        states = {{}}

# æ›´æ–°å½“å‰shellçš„çŠ¶æ€
states['$SHELL_ID'] = {{
    'current_venv': '{env_name}',
    'env_path': '$ENV_PATH',
    'activated_at': datetime.now().isoformat(),
    'shell_id': '$SHELL_ID'
}}

# ä¿å­˜çŠ¶æ€
with open('$VENV_STATES_FILE', 'w') as f:
    json.dump(states, f, indent=2, ensure_ascii=False)

print('Virtual environment \\'{env_name}\\' activated successfully')
"

# éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
sleep 1
VERIFICATION_RESULT=$(cat "$VENV_STATES_FILE" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    shell_id = '$SHELL_ID'
    if shell_id in data and data[shell_id].get('current_venv') == '{env_name}':
        print('VERIFICATION_SUCCESS')
    else:
        print('VERIFICATION_FAILED')
except:
    print('VERIFICATION_FAILED')
")

if [ "$VERIFICATION_RESULT" = "VERIFICATION_SUCCESS" ]; then
    echo "Virtual environment '{env_name}' activated successfully"
else
    echo "ERROR: Virtual environment activation verification failed"
    exit 1
fi
'''
            
            # æ‰§è¡Œå•ä¸ªè¿œç¨‹å‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            # å¤„ç†ä¸åŒçš„æ‰§è¡Œç»“æœ
            if result.get("success") or result.get("action") == "direct_feedback":
                output = result.get("stdout", "").strip()
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ¿€æ´»
                if "already active" in output:
                    return {
                        "success": True,
                        "message": f"Virtual environment '{env_name}' is already active",
                        "environment": env_name,
                        "skipped": True
                    }
                
                # å¯¹äºæˆåŠŸæˆ–ç›´æ¥åé¦ˆï¼Œéƒ½è¿›è¡ŒAPIéªŒè¯
                if "activated successfully" in output or result.get("action") == "direct_feedback":
                    # æœ¬åœ°éªŒè¯ï¼šé€šè¿‡APIæ£€æŸ¥æ¿€æ´»çŠ¶æ€
                    try:
                        current_shell = self.main_instance.get_current_shell()
                        shell_id = current_shell.get("id", "default") if current_shell else "default"
                        
                        # é€šè¿‡APIè¯»å–æœ€æ–°çŠ¶æ€
                        all_states = self._load_all_venv_states()
                        
                        # éªŒè¯æ¿€æ´»æ˜¯å¦æˆåŠŸ
                        if shell_id in all_states and all_states[shell_id].get("current_venv") == env_name:
                            verification_note = "verified via API"
                            if result.get("action") == "direct_feedback":
                                verification_note += " (after direct feedback)"
                            
                            return {
                                "success": True,
                                "message": f"Virtual environment '{env_name}' activated successfully",
                                "env_path": f"{self._get_venv_base_path()}/{env_name}",
                                "pythonpath": f"{self._get_venv_base_path()}/{env_name}",
                                "action": "activate",
                                "note": f"Virtual environment state saved and {verification_note}"
                            }
                        else:
                            return {
                                "success": False,
                                "error": f"Virtual environment activation failed"
                            }
                    except Exception as verify_error:
                        return {
                            "success": False,
                            "error": f"Virtual environment activation verification failed: {verify_error}"
                        }
                else:
                    return {"success": False, "error": f"Failed to activate virtual environment: {output}"}
            else:
                return {"success": False, "error": f"Failed to activate virtual environment: {result.get('error', 'Unknown error')}"}
                
        except Exception as e:
            return {"success": False, "error": f"Error activating virtual environment: {str(e)}"}
    
    def _verify_venv_activation(self, env_name, max_retries=3):
        """éªŒè¯è™šæ‹Ÿç¯å¢ƒæ¿€æ´»æ˜¯å¦æˆåŠŸ"""
        for attempt in range(max_retries):
            try:
                # ç­‰å¾…ä¸€ç§’è®©æ–‡ä»¶åŒæ­¥
                import time
                time.sleep(1)
                
                # æ£€æŸ¥å½“å‰è™šæ‹Ÿç¯å¢ƒ
                current_result = self._venv_current()
                if current_result.get("success") and current_result.get("environment") == env_name:
                    return True
                
                # å¦‚æœéªŒè¯å¤±è´¥ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´å†é‡è¯•
                if attempt < max_retries - 1:
                    time.sleep(2)
                    
            except Exception as e:
                print(f"Warning: éªŒè¯å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
        
        return False
    
    def _verify_venv_deactivation(self, max_retries=3):
        """éªŒè¯è™šæ‹Ÿç¯å¢ƒå–æ¶ˆæ¿€æ´»æ˜¯å¦æˆåŠŸ"""
        for attempt in range(max_retries):
            try:
                # ç­‰å¾…ä¸€ç§’è®©æ–‡ä»¶åŒæ­¥
                import time
                time.sleep(1)
                
                # æ£€æŸ¥å½“å‰è™šæ‹Ÿç¯å¢ƒ
                current_result = self._venv_current()
                if current_result.get("success") and current_result.get("environment") is None:
                    return True
                
                # å¦‚æœéªŒè¯å¤±è´¥ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´å†é‡è¯•
                if attempt < max_retries - 1:
                    time.sleep(2)
                    
            except Exception as e:
                print(f"Warning: éªŒè¯å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
        
        return False
    
    def _venv_deactivate(self):
        """å–æ¶ˆæ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆæ¸…é™¤PYTHONPATHï¼‰"""
        try:
            # æ„å»ºå•ä¸ªè¿œç¨‹å‘½ä»¤æ¥å–æ¶ˆæ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆåŒ…å«éªŒè¯ï¼‰
            # è¿™ä¸ªå‘½ä»¤ä¼šï¼š1) è·å–å½“å‰shell IDï¼Œ2) ä»JSONæ–‡ä»¶ä¸­ç§»é™¤è¯¥shellçš„çŠ¶æ€ï¼Œ3) éªŒè¯ç§»é™¤æˆåŠŸ
            remote_command = f'''
# è·å–å½“å‰shell ID
SHELL_ID="${{GDS_SHELL_ID:-default_shell}}"

# ä»JSONæ–‡ä»¶ä¸­ç§»é™¤å½“å‰shellçš„çŠ¶æ€
VENV_STATES_FILE="{self._get_venv_state_file_path()}"
if [ -f "$VENV_STATES_FILE" ]; then
    python3 -c "
import json
import os

# è¯»å–ç°æœ‰çŠ¶æ€
states = {{}}
if os.path.exists('$VENV_STATES_FILE'):
    try:
        with open('$VENV_STATES_FILE', 'r') as f:
            states = json.load(f)
    except:
        states = {{}}

# ç§»é™¤å½“å‰shellçš„çŠ¶æ€
if '$SHELL_ID' in states:
    del states['$SHELL_ID']

# ä¿å­˜çŠ¶æ€
with open('$VENV_STATES_FILE', 'w') as f:
    json.dump(states, f, indent=2, ensure_ascii=False)

print('Virtual environment deactivated successfully')
"
else
    echo "Virtual environment deactivated successfully"
fi

# éªŒè¯ç§»é™¤æ˜¯å¦æˆåŠŸ
sleep 1
if [ -f "$VENV_STATES_FILE" ]; then
    VERIFICATION_RESULT=$(cat "$VENV_STATES_FILE" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    shell_id = '$SHELL_ID'
    if shell_id in data:
        print('VERIFICATION_FAILED')
    else:
        print('VERIFICATION_SUCCESS')
except:
    print('VERIFICATION_SUCCESS')
")
else
    VERIFICATION_RESULT="VERIFICATION_SUCCESS"
fi

if [ "$VERIFICATION_RESULT" = "VERIFICATION_SUCCESS" ]; then
    echo "Virtual environment deactivated successfully"
else
    echo "ERROR: Virtual environment deactivation verification failed"
    exit 1
fi
'''
            
            # æ‰§è¡Œå•ä¸ªè¿œç¨‹å‘½ä»¤
            result = self.main_instance.execute_generic_command("bash", ["-c", remote_command])
            
            # å¤„ç†ä¸åŒçš„æ‰§è¡Œç»“æœ
            if result.get("success") or result.get("action") == "direct_feedback":
                output = result.get("stdout", "").strip()
                
                # å¯¹äºæˆåŠŸæˆ–ç›´æ¥åé¦ˆï¼Œéƒ½è¿›è¡ŒAPIéªŒè¯
                if "deactivated successfully" in output or result.get("action") == "direct_feedback":
                    # æœ¬åœ°éªŒè¯ï¼šé€šè¿‡APIæ£€æŸ¥å–æ¶ˆæ¿€æ´»çŠ¶æ€
                    try:
                        current_shell = self.main_instance.get_current_shell()
                        shell_id = current_shell.get("id", "default") if current_shell else "default"
                        
                        # é€šè¿‡APIè¯»å–æœ€æ–°çŠ¶æ€
                        all_states = self._load_all_venv_states()
                        
                        # éªŒè¯å–æ¶ˆæ¿€æ´»æ˜¯å¦æˆåŠŸï¼ˆshell_idåº”è¯¥ä¸åœ¨çŠ¶æ€ä¸­ï¼Œæˆ–è€…current_venvåº”è¯¥ä¸ºç©ºï¼‰
                        if shell_id not in all_states or not all_states[shell_id].get("current_venv"):
                            verification_note = "verified via API"
                            if result.get("action") == "direct_feedback":
                                verification_note += " (after direct feedback)"
                                
                            return {
                                "success": True,
                                "message": "Virtual environment deactivated successfully",
                                "action": "deactivate",
                                "note": f"Virtual environment state cleared and {verification_note}"
                            }
                        else:
                            return {
                                "success": False,
                                "error": f"Virtual environment deactivation failed verification - state still exists in API"
                            }
                    except Exception as verify_error:
                        return {
                            "success": False,
                            "error": f"Virtual environment deactivation verification failed: {verify_error}"
                        }
                else:
                    return {"success": False, "error": f"Failed to deactivate virtual environment: {output}"}
            else:
                return {
                    "success": False,
                    "error": f"Failed to deactivate virtual environment: {result.get('error', 'Unknown error')}"
                }
                
        except Exception as e:
            return {"success": False, "error": f"Failed to deactivate virtual environment: {str(e)}"}

    def _venv_list(self):
        """åˆ—å‡ºæ‰€æœ‰è™šæ‹Ÿç¯å¢ƒï¼ˆé€šè¿‡APIï¼Œæ— è¿œç¨‹çª—å£ï¼‰"""
        try:
            # é€šè¿‡APIåˆ—å‡ºvenvç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹
            env_names = self._get_venv_environments_via_api()
            
            # è·å–å½“å‰æ¿€æ´»çš„ç¯å¢ƒï¼ˆé€šè¿‡APIè¯»å–çŠ¶æ€æ–‡ä»¶ï¼‰
            current_env = None
            try:
                current_shell = self.main_instance.get_current_shell()
                shell_id = current_shell.get("id", "default") if current_shell else "default"
                
                # é€šè¿‡APIè¯»å–å½“å‰çŠ¶æ€
                all_states = self._load_all_venv_states()
                if shell_id in all_states and all_states[shell_id].get("current_venv"):
                    current_env = all_states[shell_id]["current_venv"]
            except Exception as e:
                print(f"Warning: Failed to check current environment: {e}")
                current_env = None
            
            if not env_names:
                return {
                    "success": True,
                    "message": "No virtual environments found",
                    "environments": [],
                    "count": 0
                }
            
            # æ ¼å¼åŒ–è¾“å‡º
            env_list = []
            for env_name in sorted(env_names):
                if env_name == current_env:
                    env_list.append(f"* {env_name}")
                else:
                    env_list.append(f"  {env_name}")
            
            return {
                "success": True,
                "message": f"Virtual environments ({len(env_names)} total):",
                "environments": env_list,
                "count": len(env_names),
                "current": current_env
            }
            
        except Exception as e:
            return {"success": False, "error": f"Failed to list virtual environments: {str(e)}"}

    def _venv_current(self):
        """æ˜¾ç¤ºå½“å‰æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒï¼ˆä¼˜å…ˆä½¿ç”¨APIï¼Œæ— è¿œç¨‹çª—å£ï¼‰"""
        try:
            # è·å–å½“å‰shell ID
            current_shell = self.main_instance.get_current_shell()
            if not current_shell:
                return {"success": False, "error": "æ²¡æœ‰æ´»è·ƒçš„è¿œç¨‹shell"}
            
            shell_id = current_shell.get("id", "default")
            
            # ç›´æ¥é€šè¿‡APIè¯»å–çŠ¶æ€ï¼ˆä¸å¼¹å‡ºè¿œç¨‹çª—å£ï¼‰
            all_states = self._load_all_venv_states()
            
            # æ£€æŸ¥å½“å‰shellæ˜¯å¦æœ‰æ¿€æ´»çš„è™šæ‹Ÿç¯å¢ƒ
            if shell_id in all_states and all_states[shell_id].get("current_venv"):
                env_name = all_states[shell_id]["current_venv"]
                return {
                    "success": True,
                    "message": f"Current virtual environment: {env_name}",
                    "environment": env_name
                }
            else:
                return {
                    "success": True,
                    "message": "No virtual environment is currently activated",
                    "environment": None
                }
                
        except Exception as e:
            return {"success": False, "error": f"Failed to get current virtual environment: {str(e)}"}

    def _venv_create_batch(self, env_names):
        """æ‰¹é‡åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆä¼˜åŒ–ç‰ˆï¼šä¸€ä¸ªè¿œç¨‹å‘½ä»¤åˆ›å»ºå¤šä¸ªç¯å¢ƒï¼‰"""
        import time
        
        # è¿‡æ»¤æ‰æ— æ•ˆçš„ç¯å¢ƒå
        valid_env_names = []
        invalid_names = []
        
        for env_name in env_names:
            if env_name.startswith('.'):
                invalid_names.append(env_name)
            else:
                valid_env_names.append(env_name)
        
        if invalid_names:
            print(f"Warning:  Skipped {len(invalid_names)} invalid environment name(s): {', '.join(invalid_names)} (cannot start with '.')")
        
        if not valid_env_names:
            return {
                "success": False,
                "message": "No valid environments to create",
                "skipped": invalid_names
            }
        
        print(f"Creating {len(valid_env_names)} virtual environment(s): {', '.join(valid_env_names)}")
        
        # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å·²å­˜åœ¨
        try:
            api_manager = self._get_venv_api_manager()
            existing_envs = api_manager.list_venv_environments()
            
            already_exist = []
            new_env_names = []
            
            for env_name in valid_env_names:
                if env_name in existing_envs:
                    already_exist.append(env_name)
                else:
                    new_env_names.append(env_name)
            
            if already_exist:
                print(f"Warning:  Environments already exist: {', '.join(already_exist)}")
            
            if not new_env_names:
                return {
                    "success": False,
                    "message": "All specified environments already exist",
                    "already_exist": already_exist,
                    "skipped": invalid_names
                }
            
            # æ›´æ–°è¦åˆ›å»ºçš„ç¯å¢ƒåˆ—è¡¨
            valid_env_names = new_env_names
        except Exception as e:
            print(f"Warning: Could not check existing environments: {str(e)}")
            # ç»§ç»­æ‰§è¡Œï¼Œä½†å¯èƒ½ä¼šæœ‰é‡å¤åˆ›å»º
        
        # ç”Ÿæˆå•ä¸ªè¿œç¨‹å‘½ä»¤æ¥åˆ›å»ºå¤šä¸ªç¯å¢ƒ
        create_commands = []
        for env_name in valid_env_names:
            env_path = f"{self._get_venv_base_path()}/{env_name}"
            create_commands.append(f'mkdir -p "{env_path}"')
        
        # åˆå¹¶ä¸ºä¸€ä¸ªå‘½ä»¤ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼ŒçŠ¶æ€åˆå§‹åŒ–å°†åœ¨éªŒè¯åè¿›è¡Œï¼‰
        combined_command = " && ".join(create_commands)
        full_command = f'{combined_command} && echo "Batch create completed: {len(valid_env_names)} environments created"'
        
        # æ‰§è¡Œè¿œç¨‹å‘½ä»¤
        result = self.main_instance.execute_generic_command("bash", ["-c", full_command])
        
        if not result.get("success"):
            return {
                "success": False,
                "error": f"Failed to create environments: {result.get('error', 'Unknown error')}",
                "attempted": valid_env_names,
                "skipped": invalid_names
            }
        
        # å¼‚æ­¥éªŒè¯æ‰€æœ‰ç¯å¢ƒæ˜¯å¦åˆ›å»ºæˆåŠŸ
        print(f"â³ Validating environment creation ...", end="", flush=True)
        
        # åªåœ¨çœŸæ­£çš„è°ƒè¯•æ¨¡å¼ä¸‹è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        debug_mode = os.environ.get('GDS_DEBUG', '').lower() in ('1', 'true', 'yes')
        if debug_mode:
            debug_print(f"Starting validation for {len(valid_env_names)} environments: {valid_env_names}")
        
        max_attempts = 60
        verified_envs = set()
        
        for attempt in range(max_attempts):
            if debug_mode:
                debug_print(f"Validation attempt {attempt + 1}/{max_attempts}")
            
            # æ£€æŸ¥æ¯ä¸ªç¯å¢ƒæ˜¯å¦å­˜åœ¨
            try:
                if debug_mode:
                    debug_print(f"Using unified API manager to list environments...")
                
                # ä½¿ç”¨ç»Ÿä¸€çš„APIç®¡ç†å™¨
                api_manager = self._get_venv_api_manager()
                existing_envs = set(api_manager.list_venv_environments())
                
                if debug_mode:
                    debug_print(f"Found environments via API: {list(existing_envs)}")
                
                # æ£€æŸ¥æ–°éªŒè¯çš„ç¯å¢ƒ
                newly_verified = []
                for env_name in valid_env_names:
                    if env_name not in verified_envs and env_name in existing_envs:
                        verified_envs.add(env_name)
                        newly_verified.append(env_name)
                        if debug_mode:
                            debug_print(f"Newly verified: {env_name}")
                
                # è¾“å‡ºæ–°éªŒè¯çš„ç¯å¢ƒ
                for env_name in newly_verified:
                    print(f"{env_name} âˆš; ", end="", flush=True)
                
                if debug_mode:
                    debug_print(f"Total verified: {len(verified_envs)}/{len(valid_env_names)}")
                
                # å¦‚æœæ‰€æœ‰ç¯å¢ƒéƒ½éªŒè¯äº†ï¼Œå®Œæˆ
                if len(verified_envs) == len(valid_env_names):
                    print()  # æ¢è¡Œ
                    
                    # ä¸ºæ¯ä¸ªæˆåŠŸåˆ›å»ºçš„ç¯å¢ƒåˆå§‹åŒ–çŠ¶æ€ï¼ˆç®€åŒ–æ¨¡å¼ï¼‰
                    for env_name in verified_envs:
                        self._initialize_venv_state_simple(env_name)
                    
                    return {
                        "success": True,
                        "message": f"Successfully created {len(valid_env_names)} environments",
                        "created": list(verified_envs),
                        "skipped": invalid_names,
                        "total_requested": len(env_names),
                        "total_created": len(verified_envs),
                        "total_skipped": len(invalid_names)
                    }
                
                # å¦‚æœè¿˜æ²¡å…¨éƒ¨éªŒè¯ï¼Œç»§ç»­ç­‰å¾…
                if debug_mode:
                    debug_print(f"Waiting 1 second before next attempt...")
                time.sleep(1)
                print(f".", end="", flush=True)
                
            except Exception as e:
                debug_print(f"Exception during verification: {type(e).__name__}: {str(e)}")
                print(f"\nWarning: Error during verification: {str(e)[:50]}")
                break
        
        # è¶…æ—¶å¤„ç†
        print(f"\nVerification timeout after {max_attempts}s")
        return {
            "success": len(verified_envs) > 0,
            "message": f"Created {len(verified_envs)}/{len(valid_env_names)} environments (verification timeout)",
            "created": list(verified_envs),
            "unverified": [name for name in valid_env_names if name not in verified_envs],
            "skipped": invalid_names,
            "total_requested": len(env_names),
            "total_created": len(verified_envs),
            "total_skipped": len(invalid_names),
            "verification_timeout": True
        }

    def _venv_delete_batch(self, env_names):
        """æ‰¹é‡åˆ é™¤è™šæ‹Ÿç¯å¢ƒï¼ˆä¼˜åŒ–ç‰ˆï¼šä¸€ä¸ªè¿œç¨‹å‘½ä»¤å®Œæˆæ£€æŸ¥å’Œåˆ é™¤ï¼‰"""
        debug_mode = os.environ.get('GDS_DEBUG', '').lower() in ('1', 'true', 'yes')
        if debug_mode:
            debug_print(f"Starting _venv_delete_batch")
            debug_print(f"Input env_names: {env_names}")
        
        # ä¸å†é¢„å…ˆæ£€æŸ¥ï¼Œç›´æ¥åœ¨è¿œç¨‹å‘½ä»¤ä¸­è¿›è¡Œæ‰€æœ‰æ£€æŸ¥å’Œåˆ é™¤
        # åˆ†ç±»å¤„ç†ç¯å¢ƒåï¼ˆåªåšåŸºæœ¬çš„ä¿æŠ¤æ£€æŸ¥ï¼‰
        protected_envs = {"GaussianObject"}
        candidate_envs = []
        skipped_protected = []
        
        for env_name in env_names:
            if env_name in protected_envs:
                skipped_protected.append(env_name)
            else:
                candidate_envs.append(env_name)
        
        if skipped_protected:
            print(f"Warning:  Skipped {len(skipped_protected)} protected environment(s): {', '.join(skipped_protected)}")
        
        if not candidate_envs:
            return {
                "success": False,
                "message": "No valid environments to delete",
                "skipped": {"protected": skipped_protected}
            }
        
        print(f"Deleting {len(candidate_envs)} virtual environment(s): {', '.join(candidate_envs)}")
        
        # ç”Ÿæˆæ™ºèƒ½åˆ é™¤å‘½ä»¤ï¼šåœ¨è¿œç¨‹ç«¯è¿›è¡Œæ‰€æœ‰æ£€æŸ¥
        current_shell = self.main_instance.get_current_shell()
        shell_id = current_shell.get("id", "default") if current_shell else "default"
        # Direct storage in REMOTE_ENV, no .tmp subdirectory needed
        current_venv_file = f"{self.main_instance.REMOTE_ENV}/current_venv_{shell_id}.txt"
        
        # æ„å»ºæ™ºèƒ½åˆ é™¤è„šæœ¬
        delete_script_parts = [
            # å¼€å§‹æç¤º
            'echo -n "Removing virtual environments ... "',
            
            # è·å–å½“å‰æ¿€æ´»çš„ç¯å¢ƒ
            f'CURRENT_ENV=$(cat "{current_venv_file}" 2>/dev/null || echo "none")'
        ]
        
        # ä¸ºæ¯ä¸ªå€™é€‰ç¯å¢ƒæ·»åŠ æ£€æŸ¥å’Œåˆ é™¤é€»è¾‘
        for env_name in candidate_envs:
            env_path = f"{self._get_venv_base_path()}/{env_name}"
            # æ„å»ºå•ä¸ªç¯å¢ƒçš„å¤„ç†è„šæœ¬
            env_script = f'''
if [ "$CURRENT_ENV" = "{env_name}" ]; then
  echo -n "âš "
elif [ -d "{env_path}" ]; then
  rm -rf "{env_path}"
  echo -n "âˆš"
else
  echo -n "?"
fi
'''
            delete_script_parts.append(env_script.strip())
        
        # æœ€ç»ˆæŠ¥å‘Š - ä¸åœ¨è¿œç¨‹ç»Ÿè®¡ï¼Œæ”¹ä¸ºåœ¨Pythonä¸­ç»Ÿè®¡
        delete_script_parts.append('echo ""')  # æ¢è¡Œ
        
        # åˆå¹¶ä¸ºä¸€ä¸ªå‘½ä»¤ï¼Œä½¿ç”¨åˆ†å·åˆ†éš”ä¸åŒçš„è„šæœ¬å—
        full_command = "; ".join(delete_script_parts)
        if debug_mode:
            debug_print(f"Generated smart delete command (first 200 chars): {full_command[:200]}...")
        
        # æ‰§è¡Œå•ä¸ªè¿œç¨‹å‘½ä»¤
        if debug_mode:
            debug_print(f"About to call execute_generic_command for SMART_DELETE")
        result = self.main_instance.execute_generic_command("bash", ["-c", full_command])
        if debug_mode:
            debug_print(f"execute_generic_command for SMART_DELETE returned: success={result.get('success')}")
        
        if result.get("success"):
            # è§£æè¿œç¨‹è¾“å‡ºï¼Œç»Ÿè®¡åˆ é™¤ç»“æœ
            stdout = result.get("stdout", "")
            if debug_mode:
                debug_print(f"Remote stdout: {stdout}")
            
            # ç»Ÿè®¡ç¬¦å·
            deleted_count = stdout.count("âˆš")  # æˆåŠŸåˆ é™¤çš„ç¯å¢ƒ
            skipped_active_count = stdout.count("âš ")  # è·³è¿‡çš„æ¿€æ´»ç¯å¢ƒ
            skipped_nonexistent_count = stdout.count("?")  # ä¸å­˜åœ¨çš„ç¯å¢ƒ
            total_skipped = skipped_active_count + skipped_nonexistent_count + len(skipped_protected)
            
            # ç”Ÿæˆè¯¦ç»†çš„ç»“æœæ¶ˆæ¯
            if deleted_count > 0:
                message = f"Successfully deleted {deleted_count} environment(s)"
            else:
                message = "No environments were deleted"
            
            if total_skipped > 0:
                skip_details = []
                if len(skipped_protected) > 0:
                    skip_details.append(f"{len(skipped_protected)} protected")
                if skipped_active_count > 0:
                    skip_details.append(f"{skipped_active_count} active")
                if skipped_nonexistent_count > 0:
                    skip_details.append(f"{skipped_nonexistent_count} non-existent")
                message += f", skipped {total_skipped} ({', '.join(skip_details)})"
            
            return {
                "success": True,
                "message": message,
                "attempted": candidate_envs,
                "deleted_count": deleted_count,
                "skipped_count": total_skipped,
                "skipped_details": {
                    "protected": skipped_protected,
                    "active_count": skipped_active_count,
                    "nonexistent_count": skipped_nonexistent_count
                },
                "total_requested": len(env_names),
                "stdout": stdout
            }
        else:
            return {
                "success": False,
                "error": f"Failed to delete environments: {result.get('error', 'Unknown error')}",
                "attempted": candidate_envs,
                "skipped": {"protected": skipped_protected}
            }

    def _validate_pip_install_packages(self, packages_args):
        """
        ä¿®å¤é—®é¢˜#4: éªŒè¯pip installåŒ…çš„å¯å®‰è£…æ€§ï¼Œç‰¹åˆ«æ˜¯æœ¬åœ°è·¯å¾„åŒ…
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬'install'ï¼‰
            
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        try:
            # è¿‡æ»¤å‡ºå®é™…çš„åŒ…å/è·¯å¾„ï¼ˆæ’é™¤é€‰é¡¹å‚æ•°ï¼‰
            packages = []
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg.startswith('-'):
                    # è·³è¿‡é€‰é¡¹å‚æ•°
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        i += 2  # è·³è¿‡é€‰é¡¹å’Œå…¶å€¼
                    else:
                        i += 1  # è·³è¿‡å•ä¸ªé€‰é¡¹
                else:
                    packages.append(arg)
                    i += 1
            
            # æ£€æŸ¥æœ¬åœ°è·¯å¾„åŒ…
            local_path_issues = []
            for package in packages:
                if package.startswith('./') or package.startswith('/') or package.startswith('~/'):
                    # è¿™æ˜¯ä¸€ä¸ªæœ¬åœ°è·¯å¾„åŒ…ï¼Œéœ€è¦æ£€æŸ¥å…¶å­˜åœ¨æ€§å’Œå¯å®‰è£…æ€§
                    path_check_result = self._check_local_package_installability(package)
                    if not path_check_result["success"]:
                        local_path_issues.append({
                            "package": package,
                            "issue": path_check_result["error"],
                            "suggestion": path_check_result.get("suggestion", "")
                        })
            
            if local_path_issues:
                error_messages = ["âŒ Local package installation issues found:"]
                for issue in local_path_issues:
                    error_messages.append(f"  â€¢ {issue['package']}: {issue['issue']}")
                    if issue['suggestion']:
                        error_messages.append(f"    ğŸ’¡ Suggestion: {issue['suggestion']}")
                
                return {
                    "success": False,
                    "error": "\n".join(error_messages),
                    "local_path_issues": local_path_issues
                }
            
            return {"success": True}
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Package validation failed: {str(e)}"
            }
    
    def _check_pip_version_conflicts(self, packages_args):
        """
        ä¿®å¤é—®é¢˜#6: æ£€æµ‹pip installå¯èƒ½çš„ç‰ˆæœ¬å†²çª
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬'install'ï¼‰
            
        Returns:
            dict: å†²çªæ£€æµ‹ç»“æœ
        """
        try:
            # æå–åŒ…åï¼ˆæ’é™¤é€‰é¡¹ï¼‰
            packages = []
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg.startswith('-'):
                    # è·³è¿‡é€‰é¡¹å‚æ•°
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        i += 2
                    else:
                        i += 1
                else:
                    # è§£æåŒ…åå’Œç‰ˆæœ¬è¦æ±‚
                    if '==' in arg or '>=' in arg or '<=' in arg or '>' in arg or '<' in arg or '!=' in arg:
                        # åŒ…å«ç‰ˆæœ¬è¦æ±‚çš„åŒ…
                        packages.append(arg)
                    else:
                        # æ™®é€šåŒ…å
                        packages.append(arg)
                    i += 1
            
            # å·²çŸ¥çš„å¸¸è§ç‰ˆæœ¬å†²çªæ¨¡å¼
            conflict_patterns = {
                'pandas': {
                    'conflicting_packages': ['dask-cudf-cu12', 'cudf-cu12'],
                    'version_constraint': '<2.2.4',
                    'description': 'CUDA packages require pandas < 2.2.4'
                },
                'numpy': {
                    'conflicting_packages': ['numba'],
                    'version_constraint': '<2.1',
                    'description': 'numba requires numpy < 2.1'
                },
                'torch': {
                    'conflicting_packages': ['tensorflow'],
                    'version_constraint': 'varies',
                    'description': 'PyTorch and TensorFlow may have CUDA compatibility issues'
                }
            }
            
            conflicts = []
            suggestions = []
            
            # æ£€æŸ¥åŒ…åˆ—è¡¨ä¸­çš„æ½œåœ¨å†²çª
            package_names = [pkg.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0] 
                           for pkg in packages if not pkg.startswith('./') and not pkg.startswith('/')]
            
            for pkg in package_names:
                if pkg in conflict_patterns:
                    pattern = conflict_patterns[pkg]
                    conflicting_present = any(conflict_pkg in package_names 
                                            for conflict_pkg in pattern['conflicting_packages'])
                    if conflicting_present:
                        conflicts.append(f"â€¢ {pkg} may conflict with {', '.join(pattern['conflicting_packages'])}: {pattern['description']}")
                        suggestions.append(f"Consider specifying version constraints for {pkg} ({pattern['version_constraint']})")
            
            # æ£€æŸ¥åŒä¸€åŒ…çš„å¤šä¸ªç‰ˆæœ¬è¦æ±‚
            pkg_versions = {}
            for pkg in packages:
                if not pkg.startswith('./') and not pkg.startswith('/'):
                    base_name = pkg.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
                    if base_name in pkg_versions:
                        conflicts.append(f"â€¢ Multiple version requirements for {base_name}: {pkg_versions[base_name]} and {pkg}")
                        suggestions.append(f"Specify only one version requirement for {base_name}")
                    else:
                        pkg_versions[base_name] = pkg
            
            has_conflicts = len(conflicts) > 0
            conflicts_summary = '\n'.join(conflicts) if conflicts else "No conflicts detected"
            suggestion = '; '.join(suggestions) if suggestions else "Proceed with installation"
            
            return {
                "has_conflicts": has_conflicts,
                "conflicts_summary": conflicts_summary,
                "suggestion": suggestion,
                "checked_packages": package_names
            }
            
        except Exception as e:
            # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä¸é˜»æ­¢å®‰è£…ï¼Œåªè®°å½•è­¦å‘Š
            return {
                "has_conflicts": False,
                "conflicts_summary": f"Conflict detection failed: {str(e)}",
                "suggestion": "Proceed with caution",
                "checked_packages": []
            }
    
    def _smart_pip_install(self, packages_args):
        """
        æ™ºèƒ½åŒ…ä¾èµ–ç®¡ç†ç³»ç»Ÿ
        
        åŠŸèƒ½ï¼š
        1. è·å–åŒ…çš„ä¾èµ–å…³ç³»
        2. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒé—´çš„åŒ…å…±äº«å¯èƒ½æ€§
        3. ç»„è£…é€’å½’çš„pipå®‰è£…å‘½ä»¤ï¼ˆæœ€å¤š2å±‚é€’å½’ï¼‰
        4. é¿å…é‡å¤ä¸‹è½½
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬'install'ï¼‰
            
        Returns:
            dict: æ™ºèƒ½å®‰è£…ç»“æœ
        """
        try:
            # æå–å®é™…çš„åŒ…åï¼ˆæ’é™¤é€‰é¡¹ï¼‰
            packages = []
            install_options = []
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg.startswith('-'):
                    # æ”¶é›†å®‰è£…é€‰é¡¹
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        install_options.extend([arg, packages_args[i + 1]])
                        i += 2
                    else:
                        install_options.append(arg)
                        i += 1
                else:
                    packages.append(arg)
                    i += 1
            
            # åªå¯¹å¤šåŒ…å®‰è£…æˆ–å¤æ‚ä¾èµ–å¯ç”¨æ™ºèƒ½å®‰è£…
            if len(packages) < 2:
                return {"use_smart_install": False}
            
            # æ’é™¤æœ¬åœ°è·¯å¾„åŒ…ï¼ˆå®ƒä»¬ä¸é€‚ç”¨äºä¾èµ–åˆ†æï¼‰
            remote_packages = [pkg for pkg in packages 
                             if not pkg.startswith('./') and not pkg.startswith('/') and not pkg.startswith('~/')]
            
            if len(remote_packages) < 2:
                return {"use_smart_install": False}
            
            print(f"Activating smart package management system...")
            print(f"Analyzing {len(remote_packages)} packages for dependency optimization")
            
            # æ£€æµ‹å½“å‰è™šæ‹Ÿç¯å¢ƒä¸­å·²æœ‰çš„åŒ…
            current_packages = self._detect_current_environment_packages(None)
            print(f"Current environment has {len(current_packages)} packages installed")
            
            # è·å–åŒ…ä¾èµ–å…³ç³»
            dependency_analysis = self._analyze_package_dependencies(remote_packages, installed_packages=current_packages)
            
            # æ£€æŸ¥ç¯å¢ƒé—´åŒ…å…±äº«å¯èƒ½æ€§
            sharing_opportunities = self._check_package_sharing_opportunities(remote_packages)
            
            # ç”Ÿæˆä¼˜åŒ–çš„å®‰è£…è®¡åˆ’
            install_plan = self._generate_optimized_install_plan(
                remote_packages, 
                dependency_analysis, 
                sharing_opportunities,
                install_options,
                current_packages  # ä¼ å…¥å·²å®‰è£…åŒ…ä¿¡æ¯
            )
            
            if install_plan['optimizations_found']:
                print(f"Smart optimizations found:")
                for optimization in install_plan['optimizations']:
                    print(f"  - {optimization}")
                
                # æ˜¾ç¤ºè·³è¿‡çš„åŒ…
                if install_plan.get('skipped_packages'):
                    print(f"Skipped packages already installed: {', '.join(install_plan['skipped_packages'])}")
                
                # æ˜¾ç¤ºè­¦å‘Š
                if install_plan.get('warnings'):
                    print(f"Warnings:")
                    for warning in install_plan['warnings']:
                        print(f"  - {warning}")
                
                # æ‰§è¡Œä¼˜åŒ–çš„å®‰è£…è®¡åˆ’
                return self._execute_smart_install_plan(install_plan)
            else:
                print(f"No significant optimizations found, using standard installation")
                return {"use_smart_install": False}
                
        except Exception as e:
            print(f"Smart install system error: {str(e)}")
            print(f"Falling back to standard pip install")
            return {"use_smart_install": False}
    
    def _ensure_pipdeptree_available(self):
        """æ£€æŸ¥pipdeptreeå‘½ä»¤æ˜¯å¦å¯ç”¨"""
        try:
            # Checking if pipdeptree command is available
            import subprocess
            # ç›´æ¥æµ‹è¯•å‘½ä»¤æ˜¯å¦å¯ç”¨ï¼Œè€Œä¸æ˜¯import
            result = subprocess.run(['pipdeptree', '--version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                # pipdeptree command is available
                return True
            else:
                # pipdeptree command failed
                return False
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            # pipdeptree command not found
            print(f"Please install pipdeptree with: pip install pipdeptree")
            return False

    def _get_package_dependencies_with_pipdeptree(self, package_name, installed_packages=None):
        """ä½¿ç”¨pipdeptreeè·å–å•ä¸ªåŒ…çš„ä¾èµ–ä¿¡æ¯"""
        try:
            # Getting dependencies for package
            
            # é¦–å…ˆæ£€æŸ¥åŒ…æ˜¯å¦åœ¨å·²å®‰è£…åŒ…åˆ—è¡¨ä¸­
            if installed_packages:
                # æ ‡å‡†åŒ–åŒ…åè¿›è¡Œæ¯”è¾ƒ
                pkg_variants = [package_name, package_name.replace('-', '_'), package_name.replace('_', '-')]
                found_in_installed = False
                actual_pkg_name = package_name
                
                for variant in pkg_variants:
                    if variant.lower() in [pkg.lower() for pkg in installed_packages.keys()]:
                        found_in_installed = True
                        # æ‰¾åˆ°å®é™…çš„åŒ…åï¼ˆä¿æŒåŸå§‹å¤§å°å†™ï¼‰
                        for installed_pkg in installed_packages.keys():
                            if installed_pkg.lower() == variant.lower():
                                actual_pkg_name = installed_pkg
                                break
                        break
                
                if not found_in_installed:
                    # Package not found in installed packages
                    return None
                
                # Package found in installed packages
            
            # æ–¹æ³•1ï¼šå°è¯•æœ¬åœ°pipdeptree (å¯èƒ½ä¸ä¼šæ‰¾åˆ°è¿œç¨‹åŒ…ï¼Œä½†å€¼å¾—ä¸€è¯•)
            try:
                import subprocess
                import json
                
                cmd = ['pipdeptree', '-p', package_name, '--json', '--warn', 'silence']
                # Running local command
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                # Local command completed
                
                if result.returncode == 0 and result.stdout.strip():
                    dep_data = json.loads(result.stdout)
                    # Local pipdeptree found packages
                    
                    for pkg_info in dep_data:
                        pkg_name_in_data = pkg_info['package']['package_name']
                        if pkg_name_in_data.lower() == package_name.lower():
                            # Found matching package locally
                            dependencies = []
                            for dep in pkg_info.get('dependencies', []):
                                dependencies.append(dep['package_name'])
                            # Local dependencies found
                            return dependencies
                
                # Package not found in local pipdeptree, trying fallback
                
            except Exception as e:
                # Local pipdeptree failed
                
                # æ–¹æ³•2ï¼šä½¿ç”¨è¿œç¨‹pip showå‘½ä»¤è·å–ä¾èµ–ä¿¡æ¯
                return self._get_dependencies_via_remote_pip_show(package_name)
                
        except Exception as e:
            # Error getting dependencies
            import traceback
            traceback.print_exc()
            return None

    def _get_dependencies_via_remote_pip_show(self, package_name):
        """é€šè¿‡è¿œç¨‹pip showå‘½ä»¤è·å–åŒ…ä¾èµ–ä¿¡æ¯"""
        try:
            # Using remote pip show for package
            
            # æ„å»ºè¿œç¨‹pip showå‘½ä»¤
            pip_show_cmd = f"pip show {package_name}"
            result = self.main_instance.execute_generic_command("bash", ["-c", pip_show_cmd])
            
            if not result.get("success"):
                # Remote pip show failed
                return []
            
            output = result.get("stdout", "")
            # pip show output received
            
            # è§£æpip showè¾“å‡ºä¸­çš„Requireså­—æ®µ
            dependencies = []
            for line in output.split('\n'):
                if line.startswith('Requires:'):
                    requires_text = line.replace('Requires:', '').strip()
                    if requires_text and requires_text != 'None':
                        # è§£æä¾èµ–ï¼Œå¤„ç†ç‰ˆæœ¬çº¦æŸ
                        for dep in requires_text.split(','):
                            dep = dep.strip()
                            if dep:
                                # ç§»é™¤ç‰ˆæœ¬çº¦æŸï¼Œåªä¿ç•™åŒ…å
                                dep_name = dep.split('>=')[0].split('<=')[0].split('==')[0].split('>')[0].split('<')[0].split('!=')[0].split('~=')[0].strip()
                                if dep_name:
                                    dependencies.append(dep_name)
                    break
            
            # Remote pip show dependencies found
            return dependencies
            
        except Exception as e:
            # Remote pip show error
            return []

    def _get_pypi_dependencies(self, package_name):
        """
        ä»PyPI JSON APIè·å–åŒ…çš„ç›´æ¥ä¾èµ–ä¿¡æ¯
        
        Args:
            package_name: åŒ…å
            
        Returns:
            list: ä¾èµ–åŒ…ååˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            import requests
            
            # Getting PyPI dependencies
            api_url = f"https://pypi.org/pypi/{package_name}/json"
            
            response = requests.get(api_url, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            requires_dist = data.get("info", {}).get("requires_dist")
            
            if requires_dist is None:
                # No requires_dist found
                return []
            
            # è§£æä¾èµ–è§„æ ¼ï¼Œæå–åŒ…å
            dependencies = []
            for dep_spec in requires_dist:
                # å¤„ç†ä¾èµ–è§„æ ¼ï¼Œå¦‚ "numpy>=1.0.0" -> "numpy"
                # ä¹Ÿå¤„ç†æ¡ä»¶ä¾èµ–ï¼Œå¦‚ "pytest; extra == 'test'" -> "pytest"
                dep_spec = dep_spec.split(';')[0].strip()  # ç§»é™¤æ¡ä»¶éƒ¨åˆ†
                
                # æå–åŒ…åï¼ˆç§»é™¤ç‰ˆæœ¬çº¦æŸï¼‰
                import re
                match = re.match(r'^([a-zA-Z0-9_-]+)', dep_spec)
                if match:
                    dep_name = match.group(1)
                    dependencies.append(dep_name)
            
            # PyPI dependencies found
            return dependencies
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                # Package not found on PyPI
                return None
            else:
                # HTTP error for package
                return None
        except Exception as e:
            # Error getting PyPI dependencies
            return None

    def _analyze_dependencies_recursive(self, packages, max_depth=2, installed_packages=None):
        """
        é€’å½’åˆ†æåŒ…ä¾èµ–å…³ç³»ï¼ˆä½¿ç”¨PyPI API + å¹¶è¡Œå¤„ç†ï¼‰
        
        Args:
            packages: è¦åˆ†æçš„åŒ…åˆ—è¡¨
            max_depth: æœ€å¤§é€’å½’æ·±åº¦
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
            
        Returns:
            dict: é€’å½’ä¾èµ–åˆ†æç»“æœ
        """
        try:
            import concurrent.futures
            import threading
            from collections import defaultdict, deque
            
            # Starting recursive dependency analysis
            
            # ç”¨äºå­˜å‚¨æ‰€æœ‰ä¾èµ–å…³ç³»
            all_dependencies = {}  # {package: [direct_deps]}
            dependencies_by_level = defaultdict(lambda: defaultdict(list))  # {package: {level: [deps]}}
            processed_packages = set()
            lock = threading.Lock()
            
            def process_package_batch(package_list, current_level):
                """å¹¶è¡Œå¤„ç†ä¸€æ‰¹åŒ…"""
                if current_level > max_depth:
                    return []
                
                # Processing dependency level
                
                next_level_packages = []
                
                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–ä¾èµ–
                with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_package = {
                        executor.submit(self._get_pypi_dependencies, pkg): pkg 
                        for pkg in package_list
                    }
                    
                    # æ”¶é›†ç»“æœ
                    for future in concurrent.futures.as_completed(future_to_package):
                        pkg = future_to_package[future]
                        try:
                            deps = future.result()
                            
                            with lock:
                                if deps is not None:
                                    all_dependencies[pkg] = deps
                                    dependencies_by_level[pkg][current_level] = deps
                                    
                                    # æ·»åŠ åˆ°ä¸‹ä¸€å±‚å¤„ç†é˜Ÿåˆ—
                                    for dep in deps:
                                        if dep not in processed_packages:
                                            next_level_packages.append(dep)
                                            processed_packages.add(dep)
                                else:
                                    # PyPIæŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•fallbackæ–¹æ³•
                                    # PyPI failed, trying fallback
                                    fallback_deps = self._get_package_dependencies_with_pipdeptree(pkg, installed_packages)
                                    if fallback_deps:
                                        all_dependencies[pkg] = fallback_deps
                                        dependencies_by_level[pkg][current_level] = fallback_deps
                                        for dep in fallback_deps:
                                            if dep not in processed_packages:
                                                next_level_packages.append(dep)
                                                processed_packages.add(dep)
                                    else:
                                        all_dependencies[pkg] = []
                                        dependencies_by_level[pkg][current_level] = []
                                
                                processed_packages.add(pkg)
                                
                        except Exception as e:
                            # Error processing package
                            with lock:
                                all_dependencies[pkg] = []
                                dependencies_by_level[pkg][current_level] = []
                
                return next_level_packages
            
            # å¼€å§‹é€’å½’å¤„ç†
            current_level = 0
            current_packages = [pkg.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0] for pkg in packages]
            
            while current_packages and current_level <= max_depth:
                current_packages = process_package_batch(current_packages, current_level)
                current_level += 1
            
            # ç»Ÿè®¡ç»“æœ
            all_deps = set()
            dependency_count = defaultdict(int)
            
            for pkg_deps in all_dependencies.values():
                for dep in pkg_deps:
                    all_deps.add(dep)
                    dependency_count[dep] += 1
            
            # è®¡ç®—å…±äº«ä¾èµ–
            shared_deps = [(dep, count) for dep, count in dependency_count.items() if count > 1]
            shared_deps.sort(key=lambda x: x[1], reverse=True)
            
            result = {
                "dependencies": all_dependencies,
                "dependencies_by_level": dict(dependencies_by_level),
                "total_unique_deps": len(all_deps),
                "shared_dependencies": shared_deps,
                "dependency_count": dict(dependency_count)
            }
            
            # Recursive analysis complete
            
            return result
            
        except Exception as e:
            # Recursive dependency analysis failed
            import traceback
            traceback.print_exc()
            return self._fallback_dependency_analysis(packages)

    def _analyze_package_dependencies(self, packages, max_depth=2, installed_packages=None):
        """
        åˆ†æåŒ…ä¾èµ–å…³ç³»ï¼ˆä¼˜å…ˆä½¿ç”¨PyPI APIï¼Œpipdeptreeä½œä¸ºfallbackï¼‰
        
        Args:
            packages: è¦åˆ†æçš„åŒ…åˆ—è¡¨
            max_depth: åˆ†ææ·±åº¦
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
            
        Returns:
            dict: ä¾èµ–åˆ†æç»“æœ
        """
        try:
            # Dependency analysis starting (debug output removed)
            
            # ä½¿ç”¨æ–°çš„é€’å½’åˆ†ææ–¹æ³•
            return self._analyze_dependencies_recursive(packages, max_depth, installed_packages)
            
        except Exception as e:
            # Dependency analysis failed
            import traceback
            traceback.print_exc()
            return self._fallback_dependency_analysis(packages)

    def _fallback_dependency_analysis(self, packages):
        """å›é€€çš„ä¾èµ–åˆ†æï¼ˆå½“pipdeptreeä¸å¯ç”¨æ—¶ï¼‰"""
        print(f"Using fallback dependency analysis")
        dependencies = {}
        dependencies_by_level = {}
        
        for package in packages:
            dependencies[package] = []
            dependencies_by_level[package] = {0: []}
        
        return {
            "dependencies": dependencies,
            "dependencies_by_level": dependencies_by_level,
            "total_unique_deps": 0,
            "shared_dependencies": [],
            "dependency_count": {}
        }

    def _normalize_package_name(self, package_name):
        """
        æ ‡å‡†åŒ–åŒ…åè¿›è¡Œæ¯”è¾ƒ
        å°†ä¸‹åˆ’çº¿è½¬æ¢ä¸ºè¿å­—ç¬¦ï¼Œå¹¶è½¬æ¢ä¸ºå°å†™
        """
        if not package_name:
            return ""
        # ç§»é™¤ç‰ˆæœ¬ä¿¡æ¯
        base_name = package_name.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
        # å°†ä¸‹åˆ’çº¿è½¬æ¢ä¸ºè¿å­—ç¬¦ï¼Œè½¬æ¢ä¸ºå°å†™
        normalized = base_name.replace('_', '-').lower().strip()
        return normalized

    def _show_dependency_tree(self, packages_args, installed_packages=None):
        """
        æ˜¾ç¤ºåŒ…çš„ä¾èµ–æ ‘ç»“æ„
        
        Args:
            packages_args: pip installçš„å‚æ•°åˆ—è¡¨ï¼ˆåŒ…æ‹¬--show-depsé€‰é¡¹ï¼‰
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ï¼Œå¦‚æœæä¾›åˆ™ä¸é‡æ–°æ‰«æ
            
        Returns:
            dict: ä¾èµ–æ ‘æ˜¾ç¤ºç»“æœ
        """
        try:
            # è¿‡æ»¤å‡ºå®é™…çš„åŒ…åï¼ˆæ’é™¤é€‰é¡¹ï¼‰æˆ–å¤„ç†requirements.txt
            packages = []
            max_depth = 2  # é»˜è®¤æ˜¾ç¤º2å±‚
            
            i = 0
            while i < len(packages_args):
                arg = packages_args[i]
                if arg == '--show-deps':
                    i += 1
                    continue
                elif arg.startswith('--depth='):
                    max_depth = int(arg.split('=')[1])
                    i += 1
                    continue
                elif arg == '-r' or arg == '--requirement':
                    # å¤„ç†requirements.txtæ–‡ä»¶
                    if i + 1 < len(packages_args):
                        requirements_file = packages_args[i + 1]
                        packages_from_file = self._parse_requirements_file(requirements_file)
                        packages.extend(packages_from_file)
                        i += 2
                    else:
                        i += 1
                elif arg.startswith('-r'):
                    # å¤„ç† -rrequirements.txt æ ¼å¼
                    requirements_file = arg[2:]  # å»æ‰-r
                    packages_from_file = self._parse_requirements_file(requirements_file)
                    packages.extend(packages_from_file)
                    i += 1
                elif arg.endswith('.txt') and ('requirements' in arg.lower() or 'req' in arg.lower()):
                    # ç›´æ¥æŒ‡å®šrequirementsæ–‡ä»¶
                    packages_from_file = self._parse_requirements_file(arg)
                    packages.extend(packages_from_file)
                    i += 1
                elif arg.startswith('-'):
                    # è·³è¿‡å…¶ä»–é€‰é¡¹
                    if arg in ['--target', '--index-url', '--extra-index-url', '--find-links']:
                        i += 2
                    else:
                        i += 1
                else:
                    packages.append(arg)
                    i += 1
            
            if not packages:
                return {
                    "success": False,
                    "error": "No packages specified for dependency tree analysis"
                }
            
            print(f"Analyzing dependency tree (max depth: {max_depth})")
            
            # è·å–ä¾èµ–åˆ†æ
            dependency_analysis = self._analyze_package_dependencies(packages, max_depth=max_depth, installed_packages=installed_packages)
            
            # è·å–å·²å®‰è£…åŒ…çš„ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨æä¾›çš„åŒ…ä¿¡æ¯ï¼Œé¿å…é‡å¤æ‰«æï¼‰
            if installed_packages is None:
                installed_packages = self._detect_current_environment_packages(None)
            
            # æ˜¾ç¤ºæ¯ä¸ªåŒ…çš„ä¾èµ–æ ‘
            for package in packages:
                self._display_package_dependency_tree(package, dependency_analysis, max_depth, installed_packages)
                print()
            
            # æ˜¾ç¤ºç®€å•çš„å±‚çº§ä¿¡æ¯
            self._display_simple_level_summary(dependency_analysis, packages)
            
            return {
                "success": True,
                "message": f"Dependency tree analysis completed for {len(packages)} package(s)",
                "dependency_analysis": dependency_analysis
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Dependency tree analysis failed: {str(e)}"
            }
    
    def _display_package_dependency_tree(self, package, dependency_analysis, max_depth, installed_packages=None):
        """
        æ˜¾ç¤ºå•ä¸ªåŒ…çš„2å±‚ä¾èµ–æ ‘
        
        Args:
            package: åŒ…å
            dependency_analysis: ä¾èµ–åˆ†æç»“æœ
            max_depth: æœ€å¤§æ·±åº¦
            installed_packages: å·²å®‰è£…åŒ…çš„å­—å…¸ {package_name: version}
        """
        base_name = package.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
        
        # æ£€æŸ¥ä¸»åŒ…æ˜¯å¦å·²å®‰è£…
        normalized_base_name = self._normalize_package_name(base_name)
        is_installed = False
        if installed_packages:
            # åˆ›å»ºæ ‡å‡†åŒ–çš„å·²å®‰è£…åŒ…å­—å…¸
            normalized_installed = {self._normalize_package_name(pkg): pkg for pkg in installed_packages.keys()}
            is_installed = normalized_base_name in normalized_installed
        
        main_package_status = " [âˆš]" if is_installed else ""
        print(f"{package}{main_package_status}")
        
        # è·å–ä¾èµ–å…³ç³»
        dependencies = dependency_analysis.get("dependencies", {})
        dependencies_by_level = dependency_analysis.get("dependencies_by_level", {})
        
        if package in dependencies:
            all_deps = dependencies[package]
            if all_deps and package in dependencies_by_level:
                level_deps = dependencies_by_level[package]
                
                # è·å–ç›´æ¥ä¾èµ–ï¼ˆLevel 0ï¼‰
                direct_deps = level_deps.get(0, [])
                if direct_deps:
                    # æˆ‘ä»¬éœ€è¦ä»é€’å½’åˆ†æç»“æœä¸­è·å–æ¯ä¸ªä¾èµ–çš„å­ä¾èµ–
                    # ä½¿ç”¨åŸå§‹çš„dependencieså­—å…¸æ¥è·å–æ¯ä¸ªåŒ…çš„ä¾èµ–
                    for i, direct_dep in enumerate(direct_deps):
                        is_last_direct = (i == len(direct_deps) - 1)
                        direct_connector = "â””â”€" if is_last_direct else "â”œâ”€"
                        
                        # æ£€æŸ¥ç›´æ¥ä¾èµ–æ˜¯å¦å·²å®‰è£…
                        direct_dep_base = direct_dep.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
                        normalized_direct_name = self._normalize_package_name(direct_dep_base)
                        direct_is_installed = False
                        if installed_packages:
                            direct_is_installed = normalized_direct_name in normalized_installed
                        direct_status = " [âˆš]" if direct_is_installed else ""
                        
                        print(f"   {direct_connector} {direct_dep}{direct_status}")
                        
                        # è·å–è¿™ä¸ªç›´æ¥ä¾èµ–çš„å­ä¾èµ–
                        sub_deps = dependencies.get(direct_dep_base, [])
                        if sub_deps:
                            prefix = "              " if is_last_direct else "   â”‚          "
                            
                            # é™åˆ¶æ˜¾ç¤ºæ•°é‡ï¼Œé¿å…è¿‡é•¿
                            display_sub_deps = sub_deps[:4]  # æœ€å¤šæ˜¾ç¤º4ä¸ªå­ä¾èµ–
                            
                            for j, sub_dep in enumerate(display_sub_deps):
                                sub_is_last = (j == len(display_sub_deps) - 1) and len(sub_deps) <= 4
                                sub_connector = "â””â”€" if sub_is_last else "â”œâ”€"
                                
                                # æ£€æŸ¥å­ä¾èµ–æ˜¯å¦å·²å®‰è£…
                                sub_dep_base = sub_dep.split('==')[0].split('>=')[0].split('<=')[0].split('>')[0].split('<')[0].split('!=')[0]
                                normalized_sub_name = self._normalize_package_name(sub_dep_base)
                                sub_is_installed = False
                                if installed_packages:
                                    sub_is_installed = normalized_sub_name in normalized_installed
                                sub_status = " [âˆš]" if sub_is_installed else ""
                                
                                print(f"{prefix}{sub_connector} {sub_dep}{sub_status}")
                            
                            # å¦‚æœæœ‰æ›´å¤šå­ä¾èµ–ï¼Œæ˜¾ç¤ºçœç•¥å·
                            if len(sub_deps) > 4:
                                ellipsis_prefix = "              " if is_last_direct else "   â”‚          "
                                print(f"{ellipsis_prefix}â””â”€ ... ({len(sub_deps) - 4} more)")
            else:
                print(f"   â””â”€ No dependencies")
        else:
            print(f"   â””â”€ Package not in known dependencies database")
    
    def _display_simple_level_summary(self, dependency_analysis, packages):
        """
        æ˜¾ç¤ºç®€å•çš„å±‚çº§æ±‡æ€»
        
        Args:
            dependency_analysis: ä¾èµ–åˆ†æç»“æœ
            packages: åŒ…åˆ—è¡¨
        """
        dependencies = dependency_analysis.get("dependencies", {})
        
        # æ”¶é›†æ‰€æœ‰å±‚çº§çš„åŒ…ï¼ˆä½¿ç”¨setå»é‡ï¼‰
        level_1_packages = set()
        level_2_packages = set()
        
        # Level 1: ä¸»åŒ…çš„ç›´æ¥ä¾èµ–
        for package in packages:
            if package in dependencies:
                level_1_packages.update(dependencies[package])
        
        # Level 2: Level 1åŒ…çš„ä¾èµ–
        for level_1_pkg in level_1_packages:
            if level_1_pkg in dependencies:
                level_2_packages.update(dependencies[level_1_pkg])
        
        # æ˜¾ç¤ºå±‚çº§ï¼ˆå»é™¤é‡å¤ï¼‰
        if level_1_packages:
            level_1_str = ", ".join(sorted(level_1_packages))
            print(f"Level 1: {level_1_str}")
        
        if level_2_packages:
            # ä»Level 2ä¸­ç§»é™¤å·²ç»åœ¨Level 1ä¸­çš„åŒ…
            level_2_unique = level_2_packages - level_1_packages
            if level_2_unique:
                level_2_str = ", ".join(sorted(level_2_unique))
                print(f"Level 2: {level_2_str}")
    
    def _display_dependency_summary_old(self, dependency_analysis, packages):
        """
        æ˜¾ç¤ºä¾èµ–åˆ†ææ±‡æ€»
        
        Args:
            dependency_analysis: ä¾èµ–åˆ†æç»“æœ
            packages: åŒ…åˆ—è¡¨
        """
        print(f"Dependency Analysis Summary")
        print(f"-" * 40)
        
        shared_deps = dependency_analysis.get("shared_dependencies", [])
        total_deps = dependency_analysis.get("total_unique_deps", 0)
        dependency_count = dependency_analysis.get("dependency_count", {})
        
        print(f"Packages analyzed: {len(packages)}")
        print(f"Total unique dependencies: {total_deps}")
        print(f"Shared dependencies: {len(shared_deps)}")
        
        if shared_deps:
            print(f"\nMost frequently used dependencies:")
            for dep, count in shared_deps[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(f"  â€¢ {dep}: used by {count} package(s)")
        
        if dependency_count:
            print(f"\nInstallation order suggestion:")
            # æŒ‰ä¾èµ–æ¬¡æ•°æ’åºï¼ˆä¾èµ–æ¬¡æ•°å¤šçš„å…ˆè£…ï¼‰
            sorted_deps = sorted(dependency_count.items(), key=lambda x: x[1], reverse=True)
            level_groups = {}
            max_count = max(dependency_count.values()) if dependency_count else 1
            
            for dep, count in sorted_deps:
                level = max_count - count
                if level not in level_groups:
                    level_groups[level] = []
                level_groups[level].append(dep)
            
            for level in sorted(level_groups.keys()):
                deps = level_groups[level]
                print(f"  Level {level}: {', '.join(deps[:5])}{'...' if len(deps) > 5 else ''}")
            
            print(f"  Final: {', '.join(packages)}")
    

    
    def _get_environment_json_path(self, is_remote=True):
        """
        è·å–ç¯å¢ƒJSONæ–‡ä»¶çš„è·¯å¾„
        
        Args:
            is_remote: æ˜¯å¦ä¸ºè¿œç«¯è·¯å¾„
            
        Returns:
            str: JSONæ–‡ä»¶è·¯å¾„
        """
        if is_remote:
            return "/content/drive/MyDrive/REMOTE_ROOT/environments.json"
        else:
            return os.path.join(self.main_instance.REMOTE_ENV or ".", "environments_local.json")
    
    def _load_environment_json(self, is_remote=True):
        """
        åŠ è½½ç¯å¢ƒJSONæ•°æ®
        
        Args:
            is_remote: æ˜¯å¦åŠ è½½è¿œç«¯æ•°æ®
            
        Returns:
            dict: ç¯å¢ƒæ•°æ®
        """
        try:
            import json
            json_path = self._get_environment_json_path(is_remote)
            
            if is_remote:
                # ä½¿ç”¨è¿œç¨‹å‘½ä»¤è¯»å–
                result = self.main_instance.execute_generic_command("cat", [json_path])
                if result.get("success"):
                    json_content = result.get("output", "{}")
                    return json.loads(json_content)
                else:
                    return {}
            else:
                # æœ¬åœ°æ–‡ä»¶è¯»å–
                if os.path.exists(json_path):
                    with open(json_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
                else:
                    return {}
        except Exception as e:
            print(f"Warning: Failed to load environment JSON ({'remote' if is_remote else 'local'}): {e}")
            return {}
    
    def _save_environment_json(self, data, is_remote=True):
        """
        ä¿å­˜ç¯å¢ƒJSONæ•°æ®
        
        Args:
            data: ç¯å¢ƒæ•°æ®
            is_remote: æ˜¯å¦ä¿å­˜åˆ°è¿œç«¯
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            import json
            json_path = self._get_environment_json_path(is_remote)
            json_content = json.dumps(data, indent=2, ensure_ascii=False)
            
            if is_remote:
                # ä½¿ç”¨è¿œç¨‹å‘½ä»¤å†™å…¥
                temp_file = f"/tmp/env_update_{int(time.time())}.json"
                with open(temp_file, 'w', encoding='utf-8') as f:
                    f.write(json_content)
                
                # ä¸Šä¼ åˆ°è¿œç¨‹
                result = self.main_instance.execute_generic_command("bash", [
                    "-c", f"mkdir -p $(dirname '{json_path}') && cat > '{json_path}' << 'EOF'\n{json_content}\nEOF"
                ])
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_file):
                    os.remove(temp_file)
                    
                return result.get("success", False)
            else:
                # æœ¬åœ°æ–‡ä»¶å†™å…¥
                os.makedirs(os.path.dirname(json_path), exist_ok=True)
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                return True
        except Exception as e:
            print(f"Warning: Failed to save environment JSON ({'remote' if is_remote else 'local'}): {e}")
            return False
    
    def _update_package_in_environment_json(self, env_name, package_name, version, action="install"):
        """
        æ›´æ–°ç¯å¢ƒJSONä¸­çš„åŒ…ä¿¡æ¯
        
        Args:
            env_name: ç¯å¢ƒåç§°
            package_name: åŒ…å
            version: ç‰ˆæœ¬
            action: æ“ä½œç±»å‹ ("install" æˆ– "uninstall")
        """
        import time
        
        # æ›´æ–°è¿œç«¯å’Œæœ¬åœ°çš„JSON
        for is_remote in [True, False]:
            try:
                data = self._load_environment_json(is_remote)
                
                # åˆå§‹åŒ–æ•°æ®ç»“æ„
                if "environments" not in data:
                    data["environments"] = {}
                if env_name not in data["environments"]:
                    data["environments"][env_name] = {
                        "created_at": time.time(),
                        "packages": {}
                    }
                
                env_data = data["environments"][env_name]
                
                if action == "install":
                    env_data["packages"][package_name] = {
                        "version": version,
                        "installed_at": time.time()
                    }
                elif action == "uninstall":
                    if package_name in env_data["packages"]:
                        del env_data["packages"][package_name]
                
                # æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
                env_data["last_modified"] = time.time()
                
                # ä¿å­˜
                success = self._save_environment_json(data, is_remote)
                if success:
                    print(f"Updated {'remote' if is_remote else 'local'} environment JSON for {env_name}")
                else:
                    print(f"Failed to update {'remote' if is_remote else 'local'} environment JSON for {env_name}")
                    
            except Exception as e:
                print(f"Error updating {'remote' if is_remote else 'local'} environment JSON: {e}")

    def _scan_environment_via_api(self, env_name):
        """ä½¿ç”¨Google Drive APIç›´æ¥æ‰«æè™šæ‹Ÿç¯å¢ƒç›®å½•"""
        try:
            print(f"ä½¿ç”¨APIæ‰«æè™šæ‹Ÿç¯å¢ƒ '{env_name}'...")
            
            if not self.drive_service:
                print(f"Error:  Google Drive APIæœåŠ¡æœªåˆå§‹åŒ–")
                return {}
            
            # æ‰¾åˆ°REMOTE_ENVæ–‡ä»¶å¤¹
            env_files_result = self.drive_service.list_files(
                folder_id=self.main_instance.REMOTE_ENV_FOLDER_ID, 
                max_results=100
            )
            
            if not env_files_result['success']:
                print(f"Error:  æ— æ³•åˆ—å‡ºREMOTE_ENVç›®å½•å†…å®¹")
                return {}
            
            # å¯»æ‰¾venvæ–‡ä»¶å¤¹
            venv_folder_id = None
            for file in env_files_result['files']:
                if file['name'] == 'venv' and file['mimeType'] == 'application/vnd.google-apps.folder':
                    venv_folder_id = file['id']
                    break
            
            if not venv_folder_id:
                print(f"Error:  venvæ–‡ä»¶å¤¹ä¸å­˜åœ¨")
                return {}
            
            # åœ¨venvæ–‡ä»¶å¤¹ä¸­å¯»æ‰¾æŒ‡å®šçš„ç¯å¢ƒæ–‡ä»¶å¤¹
            venv_files_result = self.drive_service.list_files(
                folder_id=venv_folder_id, 
                max_results=100
            )
            
            if not venv_files_result['success']:
                print(f"Error:  æ— æ³•åˆ—å‡ºvenvç›®å½•å†…å®¹")
                return {}
            
            env_folder_id = None
            for file in venv_files_result['files']:
                if file['name'] == env_name and file['mimeType'] == 'application/vnd.google-apps.folder':
                    env_folder_id = file['id']
                    break
            
            if not env_folder_id:
                print(f"Error: ç¯å¢ƒæ–‡ä»¶å¤¹ '{env_name}' ä¸å­˜åœ¨")
                return {}
            
            # åˆ—å‡ºç¯å¢ƒæ–‡ä»¶å¤¹çš„å†…å®¹
            env_contents_result = self.drive_service.list_files(
                folder_id=env_folder_id, 
                max_results=200
            )
            
            if not env_contents_result['success']:
                print(f"Error: æ— æ³•åˆ—å‡ºç¯å¢ƒ '{env_name}' çš„å†…å®¹")
                return {}
            
            print(f"ç¯å¢ƒ '{env_name}' åŒ…å« {len(env_contents_result['files'])} ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹")
            
            detected_packages = {}
            dist_info_files = []
            egg_info_files = []
            package_dirs = []
            
            for file in env_contents_result['files']:
                file_name = file['name']
                print(f"  - {file_name} ({'æ–‡ä»¶å¤¹' if file['mimeType'] == 'application/vnd.google-apps.folder' else 'æ–‡ä»¶'})")
                
                if file_name.endswith('.dist-info') and file['mimeType'] == 'application/vnd.google-apps.folder':
                    dist_info_files.append(file_name)
                    # ä».dist-infoç›®å½•åæå–åŒ…åå’Œç‰ˆæœ¬
                    pkg_info = file_name.replace('.dist-info', '')
                    if '-' in pkg_info:
                        parts = pkg_info.split('-')
                        if len(parts) >= 2:
                            # æ‰¾åˆ°æœ€åä¸€ä¸ªçœ‹èµ·æ¥åƒç‰ˆæœ¬å·çš„éƒ¨åˆ†
                            version_start_idx = len(parts) - 1
                            for i in range(len(parts) - 1, 0, -1):
                                part = parts[i]
                                # å¦‚æœéƒ¨åˆ†åŒ…å«æ•°å­—ï¼Œå¾ˆå¯èƒ½æ˜¯ç‰ˆæœ¬å·çš„å¼€å§‹
                                if any(c.isdigit() for c in part):
                                    version_start_idx = i
                                    break
                            
                            pkg_name = '-'.join(parts[:version_start_idx])
                            version = '-'.join(parts[version_start_idx:])
                            detected_packages[pkg_name] = version
                elif file_name.endswith('.egg-info') and file['mimeType'] == 'application/vnd.google-apps.folder':
                    egg_info_files.append(file_name)
                    # ä».egg-infoç›®å½•åæå–åŒ…åå’Œç‰ˆæœ¬
                    pkg_info = file_name.replace('.egg-info', '')
                    if '-' in pkg_info:
                        parts = pkg_info.split('-')
                        if len(parts) >= 2:
                            # æ‰¾åˆ°æœ€åä¸€ä¸ªçœ‹èµ·æ¥åƒç‰ˆæœ¬å·çš„éƒ¨åˆ†
                            version_start_idx = len(parts) - 1
                            for i in range(len(parts) - 1, 0, -1):
                                part = parts[i]
                                # å¦‚æœéƒ¨åˆ†åŒ…å«æ•°å­—ï¼Œå¾ˆå¯èƒ½æ˜¯ç‰ˆæœ¬å·çš„å¼€å§‹
                                if any(c.isdigit() for c in part):
                                    version_start_idx = i
                                    break
                            
                            pkg_name = '-'.join(parts[:version_start_idx])
                            version = '-'.join(parts[version_start_idx:])
                            detected_packages[pkg_name] = version
                elif (file['mimeType'] == 'application/vnd.google-apps.folder' and 
                      not file_name.startswith('.') and 
                      file_name not in ['bin', 'lib', 'include', 'share', '__pycache__']):
                    package_dirs.append(file_name)
            
            # Debug output removed - package detection working correctly
            
            return detected_packages
            
        except Exception as e:
            print(f"Error: APIæ‰«æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {}

    def _scan_environment_packages_real(self, env_path, env_name):
        """
        çœŸå®æ‰«æè™šæ‹Ÿç¯å¢ƒä¸­çš„åŒ…ï¼ˆç±»ä¼¼GDS lsï¼‰
        ç°åœ¨ä¼˜å…ˆä½¿ç”¨JSONæ•°æ®ï¼Œç›®å½•æ‰«æä½œä¸ºå¤‡ç”¨
        
        Args:
            env_path: ç¯å¢ƒè·¯å¾„
            env_name: ç¯å¢ƒåç§°
            
        Returns:
            dict: å·²å®‰è£…åŒ…çš„ä¿¡æ¯ {package_name: version}
        """
        try:
            print(f"Scanning packages for environment '{env_name}' using JSON-first approach...")
            
            # ä¼˜å…ˆå°è¯•ä»JSONè·å–åŒ…ä¿¡æ¯
            packages_from_json = self._get_packages_from_json(env_name)
            
            # ä½¿ç”¨Google Drive APIç›´æ¥æ£€æŸ¥ç¯å¢ƒç›®å½•è¿›è¡ŒéªŒè¯
            api_scan_result = self._scan_environment_via_api(env_name)
            
            if packages_from_json and api_scan_result:
                # æ¯”è¾ƒJSONå’ŒAPIæ‰«æç»“æœ
                if self._packages_differ(packages_from_json, api_scan_result):
                    print(f"Venv package state changes detected, updating the json file ...")
                    self._update_environment_packages_in_json(env_name, api_scan_result)
                    return api_scan_result
                else:
                    print(f"Successfully loaded {len(packages_from_json)} packages from JSON")
                    return packages_from_json
            elif packages_from_json:
                print(f"Successfully loaded {len(packages_from_json)} packages from JSON")
                return packages_from_json
            elif api_scan_result:
                print(f"APIæ‰«æå‘ç° {len(api_scan_result)} ä¸ªåŒ…")
                # æ›´æ–°JSONæ–‡ä»¶ï¼Œå› ä¸ºä¹‹å‰æ²¡æœ‰æ•°æ®
                print(f"Venv package state changes detected, updating the json file ...")
                self._update_environment_packages_in_json(env_name, api_scan_result)
                return api_scan_result
            
            print(f"No JSON data found, falling back to directory scanning...")
            
            # æ›´å…¨é¢çš„æ‰«æå‘½ä»¤ - åŒ…å«.dist-infoå’Œ.egg-infoæ–‡ä»¶
            combined_command = f"""
echo 'Scanning packages in {env_path}' && \\
if [ -d '{env_path}' ]; then \\
  echo 'Environment directory exists' && \\
  echo '=== Package directories ===' && \\
  ls -1 '{env_path}' 2>/dev/null | grep -v '__pycache__' | grep -v '^\\.' | grep -v '^bin$' | head -50 || echo 'No package directories' && \\
  echo '=== Dist-info directories ===' && \\
  find '{env_path}' -maxdepth 1 -name '*.dist-info' -type d 2>/dev/null | sed 's|.*/||' | head -50 || echo 'No dist-info found' && \\
  echo '=== Egg-info directories ===' && \\
  find '{env_path}' -maxdepth 1 -name '*.egg-info' -type d 2>/dev/null | sed 's|.*/||' | head -50 || echo 'No egg-info found' && \\
  echo '=== DEBUG: All files in environment ===' && \\
  ls -la '{env_path}' | head -20; \\
else \\
  echo 'Environment directory does not exist: {env_path}'; \\
fi
""".strip()
            
            # æ‰§è¡Œè¿œç¨‹å‘½ä»¤
            print(f"Executing directory-based package scan...")
            result = self.main_instance.execute_generic_command("bash", ["-c", combined_command])
            
            detected_packages = {}
            
            if result.get("success"):
                output = result.get("output", "")
                print(f"Directory scan result (first 800 chars): {output[:800]}...")
                
                # ä½¿ç”¨æ”¹è¿›çš„è§£æé€»è¾‘
                detected_packages = self._parse_improved_package_scan_output(output, env_name)
                
                # å¦‚æœæ‰«æåˆ°äº†åŒ…ï¼Œå°†å…¶ä¿å­˜åˆ°JSONä¸­
                if detected_packages and len(detected_packages) > 2:  # è¶…è¿‡åŸºç¡€åŒ…æ•°é‡
                    print(f"Venv package state changes detected, updating the json file ...")
                    self._update_environment_packages_in_json(env_name, detected_packages)
            else:
                print(f"Package scan failed: {result.get('error', 'Unknown error')}")
                # å›é€€åˆ°åŸºæœ¬çš„åŒ…å‡è®¾
                detected_packages = {
                    'pip': '23.0.0',
                    'setuptools': '65.0.0'
                }
            
            print(f"Final result: {len(detected_packages)} packages in environment '{env_name}': {list(detected_packages.keys())[:10]}...")
            return detected_packages
            
        except Exception as e:
            print(f"Package scanning failed: {str(e)}")
            # å›é€€åˆ°åŸºæœ¬å‡è®¾
            return {
                'pip': '23.0.0',
                'setuptools': '65.0.0'
            }
    
    def _execute_individual_fallback(self, packages, base_command, options):
        """
        æ‰¹é‡å®‰è£…å¤±è´¥æ—¶çš„é€ä¸ªå®‰è£…å›é€€æœºåˆ¶
        
        Args:
            packages: è¦é€ä¸ªå®‰è£…çš„åŒ…åˆ—è¡¨
            base_command: åŸºç¡€å‘½ä»¤ï¼ˆpip installï¼‰
            options: å®‰è£…é€‰é¡¹
            
        Returns:
            list: é€ä¸ªå®‰è£…çš„ç»“æœåˆ—è¡¨
        """
        results = []
        
        for package in packages:
            print(f"Individual installation of {package}")
            individual_command = f"{base_command} {' '.join(options)} {package}"
            individual_args = individual_command.split()[2:]  # å»æ‰ 'pip install'
            
            try:
                individual_result = self._execute_standard_pip_install(individual_args)
                individual_success = individual_result.get("success", False)
                
                # ä½¿ç”¨GDS lsç±»ä¼¼çš„åˆ¤å®šæœºåˆ¶éªŒè¯å®‰è£…ç»“æœ
                verification_result = self._verify_package_installation(package)
                final_success = individual_success and verification_result
                
                results.append({
                    "success": final_success,
                    "packages": [package],
                    "batch_size": 1,
                    "method": "individual_fallback",
                    "verification": verification_result
                })
                
                if final_success:
                    print(f"Individual installation of {package} successful")
                else:
                    print(f"Individual installation of {package} failed")
                    
            except Exception as e:
                print(f"Individual installation of {package} error: {str(e)}")
                results.append({
                    "success": False,
                    "packages": [package],
                    "batch_size": 1,
                    "method": "individual_fallback",
                    "error": str(e)
                })
        
        return results

    def _execute_pip_command_enhanced(self, pip_command, current_env, target_info):
        """å¼ºåŒ–çš„pipå‘½ä»¤æ‰§è¡Œï¼Œæ”¯æŒé”™è¯¯å¤„ç†å’Œç»“æœéªŒè¯"""
        try:
            import time
            import random
            
            # ç”Ÿæˆå”¯ä¸€çš„ç»“æœæ–‡ä»¶å
            timestamp = int(time.time())
            random_id = f"{random.randint(1000, 9999):04x}"
            result_filename = f"pip_result_{timestamp}_{random_id}.json"
            result_file_path = f"/content/drive/MyDrive/REMOTE_ROOT/tmp/{result_filename}"
            
            # ä½¿ç”¨Python subprocessåŒ…è£…pipæ‰§è¡Œï¼Œç¡®ä¿æ­£ç¡®æ•è·æ‰€æœ‰è¾“å‡ºå’Œé”™è¯¯
            python_script = f'''
import subprocess
import json
import sys
from datetime import datetime

print(f"Starting pip {pip_command}...")

# æ‰§è¡Œpipå‘½ä»¤å¹¶æ•è·æ‰€æœ‰è¾“å‡º
try:
    result = subprocess.run(
        ["pip"] + "{pip_command}".split(),
        capture_output=True,
        text=True
    )
    
    # æ˜¾ç¤ºpipçš„å®Œæ•´è¾“å‡º
    if result.stdout:
        print(f"STDOUT:")
        print(result.stdout)
    if result.stderr:
        print(f"STDERR:")
        print(result.stderr)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡ERRORå…³é”®å­—ï¼ˆæ’é™¤ä¾èµ–å†²çªè­¦å‘Šï¼‰
    has_error = False
    if result.returncode != 0:  # åªæœ‰åœ¨é€€å‡ºç é0æ—¶æ‰æ£€æŸ¥é”™è¯¯
        has_error = "ERROR:" in result.stderr or "ERROR:" in result.stdout
    
    print(f"Pip command completed with exit code: {{result.returncode}}")
    if has_error:
        print(f" Detected ERROR messages in pip output")
    
    # ç”Ÿæˆç»“æœJSON
    result_data = {{
        "success": result.returncode == 0 and not has_error,
        "pip_command": "{pip_command}",
        "exit_code": result.returncode,
        "environment": "{current_env or 'system'}",
        "stdout": result.stdout,
        "stderr": result.stderr,
        "has_error": has_error,
        "timestamp": datetime.now().isoformat()
    }}
    
    with open("{result_file_path}", "w") as f:
        json.dump(result_data, f, indent=2)
    
    # æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
    if result.returncode == 0 and not has_error:
        print(f"pip command completed successfully")
    else:
        print(f"pip command failed (exit_code: {{result.returncode}}, has_error: {{has_error}})")

except subprocess.TimeoutExpired:
    print(f"Error:  Pip command timed out after 5 minutes")
    result_data = {{
        "success": False,
        "pip_command": "{pip_command}",
        "exit_code": -1,
        "environment": "{current_env or 'system'}",
        "error": "Command timed out",
        "timestamp": datetime.now().isoformat()
    }}
    with open("{result_file_path}", "w") as f:
        json.dump(result_data, f, indent=2)

except Exception as e:
    print(f"Error: Error executing pip command: {{e}}")
    result_data = {{
        "success": False,
        "pip_command": "{pip_command}",
        "exit_code": -1,
        "environment": "{current_env or 'system'}",
        "error": str(e),
        "timestamp": datetime.now().isoformat()
    }}
    with open("{result_file_path}", "w") as f:
        json.dump(result_data, f, indent=2)
'''
            
            commands = [
                f"mkdir -p {self.main_instance.REMOTE_ROOT}/tmp",  # ç¡®ä¿è¿œç¨‹tmpç›®å½•å­˜åœ¨
                f"python3 -c '{python_script}'",
                "clear && echo 'âœ… æ‰§è¡Œå®Œæˆ'"  # æ¸…å±å¹¶æ˜¾ç¤ºå®Œæˆæç¤º
            ]
            
            full_command = " && ".join(commands)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„tkinterçª—å£ç•Œé¢ï¼ˆä¸activate/deactivateä¿æŒä¸€è‡´ï¼‰
            window_title = f"Execute command to run pip {pip_command} {target_info}"
            
            # è°ƒç”¨ç»Ÿä¸€çš„è¿œç¨‹å‘½ä»¤çª—å£
            try:
                result = self.main_instance.remote_commands._show_command_window(
                    "pip",  # cmd
                    pip_command.split(),  # args
                    full_command,  # remote_command
                    window_title  # debug_info
                )
                
                if result.get("action") == "failed":
                    return {
                        "success": False, 
                        "error": result.get("message", "User reported execution failed"),
                        "source": "user_reported_failure"
                    }
                elif result.get("action") == "direct_feedback":
                    # ç”¨æˆ·æä¾›äº†ç›´æ¥åé¦ˆï¼Œè·³è¿‡æ–‡ä»¶æ£€æµ‹
                    return {
                        "success": True,
                        "message": result.get("message", "Pip command executed successfully"),
                        "source": "direct_feedback"
                    }
            except Exception as e:
                # å¦‚æœtkinterçª—å£å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•ç»ˆç«¯æç¤º
                return {
                    "success": False,
                    "error": f"Failed to show command window: {str(e)}"
                }
            
            # ç­‰å¾…å¹¶æ£€æµ‹ç»“æœæ–‡ä»¶
            remote_file_path = f"~/tmp/{result_filename}"
            
            print(f"â³ Validating results ...", end="", flush=True)
            max_attempts = 60
            
            for attempt in range(max_attempts):
                try:
                    # æ£€æŸ¥è¿œç¨‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    check_result = self.main_instance.remote_commands._check_remote_file_exists(result_file_path)
                    
                    if check_result.get("exists"):
                        # æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å†…å®¹
                        print(f"âˆš")  # æˆåŠŸæ ‡è®°
                        read_result = self.main_instance.remote_commands._read_result_file_via_gds(result_filename)
                        
                        if read_result.get("success"):
                            try:
                                result_data = read_result.get("data", {})
                                
                                # éªŒè¯pipå‘½ä»¤ç»“æœ
                                command_success = result_data.get("success", False)
                                exit_code = result_data.get("exit_code", -1)
                                has_error = result_data.get("has_error", False)
                                stdout = result_data.get("stdout", "")
                                stderr = result_data.get("stderr", "")
                                
                                # æ˜¾ç¤ºpipå‘½ä»¤çš„å®é™…è¾“å‡ºï¼ˆç®€æ´æ ¼å¼ï¼‰
                                if stdout.strip():
                                    print(stdout.strip())
                                
                                if stderr.strip() and not command_success:
                                    print(f"Warning:  {stderr.strip()}")
                                
                                if command_success:
                                    # è§£æpipå®‰è£…æˆåŠŸçš„åŒ…ä¿¡æ¯å¹¶æ›´æ–°JSON
                                    self._parse_and_update_installed_packages(pip_command, current_env, stdout, stderr)
                                    
                                    return {
                                        "success": True,
                                        "message": "",  # ä¸æ˜¾ç¤ºé¢å¤–çš„æˆåŠŸæ¶ˆæ¯ï¼Œä¿æŒåŸç”Ÿpipä½“éªŒ
                                        "stdout": stdout,
                                        "stderr": stderr,
                                        "data": result_data
                                    }
                                else:
                                    return {
                                        "success": False,
                                        "error": f"Pip command failed (exit_code: {exit_code}): {stderr}",
                                        "stdout": stdout,
                                        "stderr": stderr,
                                        "data": result_data
                                    }
                            except Exception as e:
                                return {
                                    "success": False,
                                    "error": f"Failed to parse pip result: {str(e)}"
                                }
                        else:
                            return {
                                "success": False,
                                "error": f"Failed to read pip result file: {read_result.get('error', 'Unknown error')}"
                            }
                    
                    # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç­‰å¾…ä¸€ä¸‹å†æ£€æŸ¥
                    if attempt < max_attempts - 1:
                        time.sleep(1)
                        print(f".", end="", flush=True)
                    
                except Exception as e:
                    if attempt < max_attempts - 1:
                        time.sleep(1)
                        print(f".", end="", flush=True)
                    else:
                        return {
                            "success": False,
                            "error": f"Error checking pip result file: {str(e)}"
                        }
            
            # è¶…æ—¶
            print()  # æ¢è¡Œ
            return {
                "success": False,
                "error": f"Timeout waiting for pip result file after {max_attempts} seconds"
            }
            
        except Exception as e:
            return {"success": False, "error": f"Error executing pip command: {str(e)}"}
