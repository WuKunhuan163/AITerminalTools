#!/usr/bin/env python3
"""
æ¼”ç¤º Google Drive Shell ç¼“å­˜å¢å¼ºåŠŸèƒ½
å±•ç¤ºå®Œæ•´çš„ç¼“å­˜æµç¨‹ï¼šæ£€æŸ¥ç¼“å­˜ã€è·å–è¿œç«¯æ—¶é—´ã€åˆ¤æ–­æ–°é²œåº¦
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from google_drive_shell import GoogleDriveShell
from cache_manager import GDSCacheManager

def demo_cache_workflow():
    """æ¼”ç¤ºå®Œæ•´çš„ç¼“å­˜å·¥ä½œæµç¨‹"""
    print("ğŸš€ Google Drive Shell ç¼“å­˜å¢å¼ºåŠŸèƒ½æ¼”ç¤º")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç»„ä»¶
    gds = GoogleDriveShell()
    cache_manager = GDSCacheManager()
    
    # æ¨¡æ‹Ÿæ–‡ä»¶è·¯å¾„
    test_remote_path = "~/demo/test_document.txt"
    
    print(f"ğŸ“„ æ¼”ç¤ºæ–‡ä»¶: {test_remote_path}")
    print("-" * 80)
    
    # æ­¥éª¤ 1: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¼“å­˜
    print("ğŸ” æ­¥éª¤ 1: æ£€æŸ¥æ–‡ä»¶ç¼“å­˜çŠ¶æ€")
    cache_status = gds.is_remote_file_cached(test_remote_path)
    
    if cache_status["success"]:
        if cache_status["is_cached"]:
            print(f"âœ… æ–‡ä»¶å·²ç¼“å­˜")
            print(f"   ç¼“å­˜æ–‡ä»¶: {cache_status['cached_info']['cache_file']}")
            print(f"   ç¼“å­˜æ—¶é—´: {cache_status['cached_info'].get('upload_time', 'N/A')}")
            print(f"   è¿œç«¯ä¿®æ”¹æ—¶é—´: {cache_status['cached_info'].get('remote_modified_time', 'N/A')}")
        else:
            print(f"âŒ æ–‡ä»¶æœªç¼“å­˜")
    else:
        print(f"âŒ æ£€æŸ¥ç¼“å­˜çŠ¶æ€å¤±è´¥: {cache_status.get('error', 'Unknown error')}")
    
    print()
    
    # æ­¥éª¤ 2: æ¨¡æ‹Ÿè·å–è¿œç«¯æ–‡ä»¶ä¿®æ”¹æ—¶é—´
    print("ğŸŒ æ­¥éª¤ 2: è·å–è¿œç«¯æ–‡ä»¶ä¿®æ”¹æ—¶é—´")
    print("   (æ¨¡æ‹Ÿ - å®é™…éœ€è¦ Google Drive API è¿æ¥)")
    
    # æ¨¡æ‹Ÿè¿œç«¯æ–‡ä»¶ä¿¡æ¯
    simulated_remote_time = "2025-01-23T15:30:00.000Z"
    print(f"   æ¨¡æ‹Ÿè¿œç«¯ä¿®æ”¹æ—¶é—´: {simulated_remote_time}")
    print()
    
    # æ­¥éª¤ 3: åˆ›å»ºæµ‹è¯•ç¼“å­˜æ–‡ä»¶
    print("ğŸ“ æ­¥éª¤ 3: åˆ›å»ºæµ‹è¯•ç¼“å­˜æ–‡ä»¶")
    
    # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
    test_file_path = Path(__file__).parent / "demo_temp_file.txt"
    test_content = f"""è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºæ–‡ä»¶
åˆ›å»ºæ—¶é—´: {datetime.now().isoformat()}
ç”¨äºæ¼”ç¤º Google Drive Shell ç¼“å­˜å¢å¼ºåŠŸèƒ½

åŒ…å«çš„æ–°åŠŸèƒ½:
1. è¿œç«¯æ–‡ä»¶ä¿®æ”¹æ—¶é—´è·Ÿè¸ª
2. ç¼“å­˜æ–°é²œåº¦æ£€æŸ¥
3. æ™ºèƒ½ç¼“å­˜æ›´æ–°æœºåˆ¶
"""
    
    with open(test_file_path, 'w', encoding='utf-8') as f:
        f.write(test_content)
    
    try:
        # ç¼“å­˜æ–‡ä»¶ï¼ˆåŒ…å«è¿œç«¯ä¿®æ”¹æ—¶é—´ï¼‰
        cache_result = cache_manager.cache_file(
            remote_path=test_remote_path,
            temp_file_path=str(test_file_path),
            remote_modified_time=simulated_remote_time
        )
        
        if cache_result["success"]:
            print(f"âœ… æ–‡ä»¶ç¼“å­˜æˆåŠŸ")
            print(f"   ç¼“å­˜æ–‡ä»¶: {cache_result['cache_file']}")
            print(f"   ç¼“å­˜è·¯å¾„: {cache_result['cache_path']}")
            print(f"   è¿œç«¯ä¿®æ”¹æ—¶é—´: {cache_result['remote_modified_time']}")
        else:
            print(f"âŒ æ–‡ä»¶ç¼“å­˜å¤±è´¥: {cache_result.get('error', 'Unknown error')}")
            return
        
        print()
        
        # æ­¥éª¤ 4: å†æ¬¡æ£€æŸ¥ç¼“å­˜çŠ¶æ€
        print("ğŸ”„ æ­¥éª¤ 4: å†æ¬¡æ£€æŸ¥ç¼“å­˜çŠ¶æ€")
        updated_cache_status = gds.is_remote_file_cached(test_remote_path)
        
        if updated_cache_status["success"] and updated_cache_status["is_cached"]:
            cached_info = updated_cache_status["cached_info"]
            print(f"âœ… æ–‡ä»¶ç°å·²ç¼“å­˜")
            print(f"   ç¼“å­˜æ–‡ä»¶: {cached_info['cache_file']}")
            print(f"   æœ¬åœ°ç¼“å­˜æ—¶é—´: {cached_info.get('upload_time', 'N/A')}")
            print(f"   è¿œç«¯ä¿®æ”¹æ—¶é—´: {cached_info.get('remote_modified_time', 'N/A')}")
            print(f"   å†…å®¹å“ˆå¸Œ: {cached_info.get('content_hash', 'N/A')}")
            print(f"   çŠ¶æ€: {cached_info.get('status', 'N/A')}")
        
        print()
        
        # æ­¥éª¤ 5: æ¼”ç¤ºç¼“å­˜æ–°é²œåº¦æ£€æŸ¥
        print("ğŸ• æ­¥éª¤ 5: æ¼”ç¤ºç¼“å­˜æ–°é²œåº¦æ£€æŸ¥")
        
        # æƒ…å†µ 1: æ–‡ä»¶æœªå˜æ›´ï¼ˆç›¸åŒçš„ä¿®æ”¹æ—¶é—´ï¼‰
        print("   æƒ…å†µ 1: è¿œç«¯æ–‡ä»¶æœªå˜æ›´")
        freshness_result = gds.is_cached_file_up_to_date(test_remote_path)
        
        if freshness_result["success"]:
            print(f"   ç¼“å­˜æ˜¯å¦æœ€æ–°: {freshness_result['is_up_to_date']}")
            print(f"   åˆ¤æ–­åŸå› : {freshness_result.get('reason', 'N/A')}")
            
            if 'remote_modification_time' in freshness_result:
                print(f"   è¿œç«¯ä¿®æ”¹æ—¶é—´: {freshness_result['remote_modification_time']}")
            if 'cached_remote_time' in freshness_result:
                print(f"   ç¼“å­˜çš„è¿œç«¯æ—¶é—´: {freshness_result['cached_remote_time']}")
        
        print()
        
        # æƒ…å†µ 2: æ¨¡æ‹Ÿæ–‡ä»¶æ›´æ–°
        print("   æƒ…å†µ 2: æ¨¡æ‹Ÿè¿œç«¯æ–‡ä»¶å·²æ›´æ–°")
        newer_remote_time = "2025-01-23T16:00:00.000Z"
        print(f"   æ–°çš„è¿œç«¯ä¿®æ”¹æ—¶é—´: {newer_remote_time}")
        
        # æ‰‹åŠ¨æ›´æ–°ç¼“å­˜ä¿¡æ¯ä¸­çš„è¿œç«¯æ—¶é—´ä»¥æ¨¡æ‹Ÿæ¯”è¾ƒ
        print("   (å®é™…ä½¿ç”¨ä¸­ä¼šé€šè¿‡ GDS ls å‘½ä»¤è·å–æœ€æ–°çš„è¿œç«¯ä¿®æ”¹æ—¶é—´)")
        
        print()
        
        # æ­¥éª¤ 6: æ˜¾ç¤ºç¼“å­˜é…ç½®æ–‡ä»¶
        print("ğŸ“‹ æ­¥éª¤ 6: æŸ¥çœ‹ç¼“å­˜é…ç½®æ–‡ä»¶")
        cache_config_file = Path(__file__).parent / "cache_config.json"
        
        if cache_config_file.exists():
            with open(cache_config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            print("   å½“å‰ç¼“å­˜é…ç½®:")
            print(json.dumps(config, indent=4, ensure_ascii=False))
        
        print()
        
        # æ­¥éª¤ 7: ç¼“å­˜ç»Ÿè®¡
        print("ğŸ“Š æ­¥éª¤ 7: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
        stats = cache_manager.get_cache_stats()
        
        if stats["success"]:
            print(f"   æ€»ç¼“å­˜æ–‡ä»¶æ•°: {stats['total_files']}")
            print(f"   æ€»ç¼“å­˜å¤§å°: {stats['total_size_mb']} MB")
            print(f"   ç¼“å­˜ç›®å½•: {stats['cache_root']}")
        
        print()
        print("âœ… æ¼”ç¤ºå®Œæˆ!")
        print("\nğŸ’¡ ä¸»è¦æ”¹è¿›:")
        print("   1. cache_config.json ç°åœ¨åŒ…å« remote_modified_time å­—æ®µ")
        print("   2. æ–°å¢äº† 3 ä¸ªæ¥å£å‡½æ•°ç”¨äºç¼“å­˜çŠ¶æ€æ£€æŸ¥å’Œæ–°é²œåº¦åˆ¤æ–­")
        print("   3. ä¸‹è½½æ–‡ä»¶æ—¶ä¼šè‡ªåŠ¨ä¿å­˜è¿œç«¯ä¿®æ”¹æ—¶é—´")
        print("   4. æ”¯æŒåŸºäºè¿œç«¯ä¿®æ”¹æ—¶é—´çš„æ™ºèƒ½ç¼“å­˜æ›´æ–°")
        
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if test_file_path.exists():
            test_file_path.unlink()
        
        # æ¸…ç†æ¼”ç¤ºç¼“å­˜
        cache_manager.cleanup_cache(test_remote_path)
        print(f"\nğŸ§¹ å·²æ¸…ç†æ¼”ç¤ºæ–‡ä»¶å’Œç¼“å­˜")

if __name__ == "__main__":
    demo_cache_workflow() 