{
  "success": true,
  "content": "# 数据结构与算法：高级进阶练习\n\n## 1. 基础知识测试\n\n1.  **ADT 与实现：** 解释抽象数据类型 (ADT) 的核心概念，并说明为什么分离接口与实现对于软件工程至关重要。\n    <details>\n    <summary>答案</summary>\n    ADT 是一个数学模型，定义了一组操作及其行为，而不指定具体实现。核心概念包括接口（操作集合与签名）、封装（隐藏内部细节）、不变性（始终保持的属性）和参数化类型（泛型）。分离接口与实现至关重要，因为它允许在不改变使用代码的情况下，优化或替换底层数据结构，提高了代码的可维护性、可复用性和灵活性。\n    </details>\n\n2.  **渐进分析：** 考虑函数 $f(n) = 3n^2 + 5n \\log n + 100$。请使用 Big O, Big Omega, 和 Big Theta 符号精确描述其渐进上界、下界和紧确界。\n    <details>\n    <summary>答案</summary>\n    $f(n) = 3n^2 + 5n \\log n + 100$\n    *   **Big O (渐进上界):** $O(n^2)$。因为当 $n$ 足够大时，$n^2$ 是主导项，增长速度远超 $n \\log n$ 和常数项。\n    *   **Big Omega (渐进下界):** $\\Omega(n^2)$。因为 $n^2$ 是其最低的增长阶。\n    *   **Big Theta (紧确界):** $\\Theta(n^2)$。因为其上界和下界都是 $n^2$，所以它是 $n^2$ 的紧确界。\n    </details>\n\n3.  **摊还分析：** 设有一个动态数组，初始容量为 1，每次插入元素时，如果容量已满，则将容量加倍并复制所有元素。使用势能法分析 $N$ 次插入操作的总摊还成本。\n    <details>\n    <summary>答案</summary>\n    设 $c$ 为当前容量，$s$ 为当前实际元素数量。定义势能函数 $\\Phi(D) = 2s - c$。\n    *   **插入时容量未满 ($s < c$)：**\n        *   实际成本 $c_{actual} = 1$ (添加元素)。\n        *   操作后 $s' = s+1, c' = c$。\n        *   势能变化 $\\Delta \\Phi = (2(s+1) - c) - (2s - c) = 2$。\n        *   摊还成本 $c^a = c_{actual} + \\Delta \\Phi = 1 + 2 = 3$。\n    *   **插入时容量已满 ($s = c$)：**\n        *   实际成本 $c_{actual} = c + 1$ (复制 $c$ 个元素，添加 1 个新元素)。\n        *   操作后 $s' = c+1, c' = 2c$。\n        *   势能变化 $\\Delta \\Phi = (2(c+1) - 2c) - (2c - c) = (2c+2-2c) - c = 2 - c$。\n        *   摊还成本 $c^a = c_{actual} + \\Delta \\Phi = (c+1) + (2-c) = 3$。\n    在所有情况下的摊还成本均为常数 3，因此 $N$ 次插入的总摊还成本为 $O(N)$。\n    </details>\n\n## 2. 理解应用题\n\n1.  **平衡树选择：** 在什么情况下，AVL 树可能比 Red-Black Tree 更优？反之，Red-Black Tree 何时更具优势？\n    <details>\n    <summary>答案</summary>\n    *   **AVL 树更优：** 当对查找操作的性能要求极高，且插入/删除操作相对较少，或者插入/删除操作的分布较为均匀（不会频繁触发大量旋转）时，AVL 树由于其更严格的平衡性，能提供略微更低的查找延迟（因为树高更小）。\n    *   **Red-Black Tree 更优：** 在更普遍的场景下，当插入和删除操作的频率较高，或者需要更少的旋转操作来维护平衡时，Red-Black Tree 更具优势。其平衡性要求较宽松，使得插入和删除操作的平均性能开销更低，在实践中更常用。\n    </details>\n\n2.  **哈希表冲突：** 链地址法和开地址法（特别是线性探测）在处理高负载因子时，各自会面临什么性能问题？如何通过调整策略来缓解？\n    <details>\n    <summary>答案</summary>\n    *   **链地址法：** 高负载因子 ($\\alpha$) 会导致链表过长，使得查找、插入、删除的最坏情况复杂度接近 $O(n)$。缓解方法是当负载因子超过预设阈值（例如 0.75）时，进行扩容（通常是容量加倍）并重新哈希所有元素。\n    *   **开地址法（线性探测）：** 高负载因子不仅会增加查找/插入/删除的平均探测次数，还会加剧 **聚集 (Clustering)** 问题，即连续的已占用槽位块会越来越大，进一步降低性能。缓解方法包括：\n        *   保持较低的负载因子（例如 < 0.7）。\n        *   使用二次探测或双重散列来减少聚集。\n        *   当负载因子过高时，进行扩容并重新哈希。\n    </details>\n\n3.  **最短路径与 MST：** Dijkstra 算法和 Prim 算法在思想上有何相似之处？它们分别用于解决什么问题？如果图中有负权边，Dijkstra 算法是否还能直接使用？\n    <details>\n    <summary>答案</summary>\n    *   **相似之处：** 两者都基于贪心策略，都维护一个“已处理”的集合（Dijkstra 的已确定最短路径顶点集合，Prim 的已生成树顶点集合），并利用优先队列（或类似结构）来选择下一个“最优”的元素（Dijkstra 选择距离源点最近的未确定顶点，Prim 选择连接已生成树和外部的最小权边）。\n    *   **解决问题：** Dijkstra 算法用于计算单源最短路径。Prim 算法用于找到图的最小生成树。\n    *   **负权边：** 如果图中有负权边，Dijkstra 算法不能直接使用。原因在于 Dijkstra 的贪心选择依赖于“一旦确定最短路径，就不会再被更短路径更新”的假设，而负权边可能会破坏这个假设。此时应使用 Bellman-Ford 算法。\n    </details>\n\n## 3. 实践练习题\n\n1.  **实现带删除操作的哈希表：** 使用开地址法（如线性探测或双重散列）实现一个哈希表，支持插入、查找和删除操作。在实现删除时，要正确处理“已删除”状态，以保证后续查找的正确性。\n    <details>\n    <summary>答案</summary>\n    ```python\n    class HashTableOpenAddressing:\n        def __init__(self, capacity=11): # 推荐使用素数作为初始容量\n            self.capacity = capacity\n            self.EMPTY = object()\n            self.DELETED = object()\n            self.table = [self.EMPTY] * self.capacity\n            self.size = 0\n            self.load_factor_threshold = 0.7\n\n        def _hash1(self, key):\n            # 主哈希函数 (例如，Python 内建 hash 结合模运算)\n            return hash(key) % self.capacity\n\n        def _hash2(self, key):\n            # 次哈希函数，用于双重散列，必须保证不为 0\n            # 确保返回一个与 capacity 互质的值，通常选择一个较小的素数\n            prime = 7 # 假设 capacity > 7\n            return prime - (hash(key) % prime)\n\n        def _probe(self, key, i):\n            # 双重散列探测序列\n            return (self._hash1(key) + i * self._hash2(key)) % self.capacity\n\n        def _resize(self):\n            old_table = self.table\n            old_capacity = self.capacity\n            self.capacity = self._next_prime(old_capacity * 2) # 扩容并选择下一个素数\n            self.table = [self.EMPTY] * self.capacity\n            self.size = 0\n\n            for item in old_table:\n                if item is not self.EMPTY and item is not self.DELETED:\n                    self.insert(item[0], item[1])\n\n        def _is_prime(self, n):\n            if n <= 1: return False\n            if n <= 3: return True\n            if n % 2 == 0 or n % 3 == 0: return False\n            i = 5\n            while i * i <= n:\n                if n % i == 0 or n % (i + 2) == 0:\n                    return False\n                i += 6\n            return True\n\n        def _next_prime(self, n):\n            if n <= 1: return 2\n            prime = n\n            found = False\n            while not found:\n                prime += 1\n                if self._is_prime(prime):\n                    found = True\n            return prime\n\n        def insert(self, key, value):\n            if self.size / self.capacity >= self.load_factor_threshold:\n                self._resize()\n\n            i = 0\n            while i < self.capacity:\n                index = self._probe(key, i)\n                if self.table[index] is self.EMPTY or self.table[index] is self.DELETED:\n                    self.table[index] = (key, value)\n                    self.size += 1\n                    return True # 成功插入\n                elif self.table[index][0] == key:\n                    self.table[index] = (key, value) # 更新现有键的值\n                    return True # 成功更新\n                i += 1\n            return False # 表已满，尽管我们有扩容机制，但理论上可能发生\n\n        def search(self, key):\n            i = 0\n            while i < self.capacity:\n                index = self._probe(key, i)\n                if self.table[index] is self.EMPTY:\n                    return None # 遇到 EMPTY，键不存在\n                elif self.table[index] is not self.DELETED and self.table[index][0] == key:\n                    return self.table[index][1] # 找到键，返回对应值\n                i += 1\n            return None # 搜索完所有可能位置，键不存在\n\n        def delete(self, key):\n            i = 0\n            while i < self.capacity:\n                index = self._probe(key, i)\n                if self.table[index] is self.EMPTY:\n                    return False # 遇到 EMPTY，键不存在\n                elif self.table[index] is not self.DELETED and self.table[index][0] == key:\n                    self.table[index] = self.DELETED # 标记为已删除\n                    self.size -= 1\n                    return True # 成功删除\n                i += 1\n            return False # 搜索完所有可能位置，键不存在\n\n        def __len__(self):\n            return self.size\n\n        def __str__(self):\n            items = []\n            for i, item in enumerate(self.table):\n                if item is self.EMPTY:\n                    items.append(f\"{i}: EMPTY\")\n                elif item is self.DELETED:\n                    items.append(f\"{i}: DELETED\")\n                else:\n                    items.append(f\"{i}: {item[0]} -> {item[1]}\")\n            return \"\\n\".join(items)\n\n    # 示例使用\n    ht = HashTableOpenAddressing(capacity=5)\n    ht.insert(\"apple\", 10)\n    ht.insert(\"banana\", 20)\n    ht.insert(\"cherry\", 30)\n    print(ht)\n    print(f\"Search 'banana': {ht.search('banana')}\")\n    ht.delete(\"banana\")\n    print(\"After deleting 'banana':\")\n    print(ht)\n    print(f\"Search 'banana': {ht.search('banana')}\")\n    ht.insert(\"date\", 40) # 可能会触发扩容\n    print(\"After inserting 'date':\")\n    print(ht)\n    ```\n    </details>\n\n2.  **动态规划：最长公共子序列 (LCS)**\n    给定两个字符串 `text1` 和 `text2`，返回这两个字符串的最长公共子序列的长度。如果不存在公共子序列，则返回 0。\n    一个字符串的子序列是另一个字符串删除任意数量字符（可能不删除，也可能删除所有字符）后形成的序列。例如，`\"ace\"` 是 `\"abcde\"` 的子序列。\n    两个字符串的公共子序列是这两个字符串都拥有的子序列。\n    <details>\n    <summary>答案</summary>\n    ```python\n    def longest_common_subsequence(text1: str, text2: str) -> int:\n        m, n = len(text1), len(text2)\n        # dp[i][j] 表示 text1 的前 i 个字符和 text2 的前 j 个字符的最长公共子序列长度\n        dp = [[0] * (n + 1) for _ in range(m + 1)]\n\n        for i in range(1, m + 1):\n            for j in range(1, n + 1):\n                if text1[i - 1] == text2[j - 1]:\n                    # 如果当前字符匹配，则 LCS 长度等于前一个子问题的 LCS 长度加 1\n                    dp[i][j] = dp[i - 1][j - 1] + 1\n                else:\n                    # 如果当前字符不匹配，则 LCS 长度等于不考虑 text1 的当前字符或不考虑 text2 的当前字符时 LCS 长度的最大值\n                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n\n        return dp[m][n]\n\n    # 示例\n    print(f\"LCS('abcde', 'ace'): {longest_common_subsequence('abcde', 'ace')}\") # 输出: 3\n    print(f\"LCS('abc', 'abc'): {longest_common_subsequence('abc', 'abc')}\")   # 输出: 3\n    print(f\"LCS('abc', 'def'): {longest_common_subsequence('abc', 'def')}\")   # 输出: 0\n    ```\n    </details>\n\n## 4. 思考题\n\n1.  **摊还分析的意义：** 为什么在某些情况下，摊还分析比最坏情况分析更能反映算法在实际应用中的性能？请举例说明。\n    <details>\n    <summary>答案</summary>\n    摊还分析比最坏情况分析更能反映算法在实际应用中的性能，因为它考虑了操作序列的 *平均* 成本，而不是单个操作的极端成本。许多数据结构（如动态数组、哈希表）通过偶尔执行昂贵的操作（如扩容、重新哈希）来换取大多数操作的低成本。最坏情况分析会关注这些昂贵操作，而摊还分析则将这些成本“分摊”到所有操作上，给出更公平的整体性能评估。\n    **示例：** 动态数组的扩容操作，其最坏情况成本可能是 $O(n)$（复制 $n$ 个元素）。但如果仅看一次扩容，这似乎效率低下。然而，摊还分析表明，平均每次插入的成本是常数 $O(1)$。这意味着，在进行一系列插入操作时，我们不必担心偶尔的 $O(n)$ 操作会显著影响整体性能，因为它们发生的频率足够低，其成本已被大量 $O(1)$ 操作所平摊。\n    </details>\n\n2.  **平衡树的权衡：** AVL 树和 Red-Black trees 都属于平衡二叉搜索树，但它们在平衡策略和性能特性上有所不同。请讨论在设计一个需要频繁插入、删除和查找操作的系统时，如何选择适合的平衡树，以及需要考虑哪些因素？\n    <details>\n    <summary>答案</summary>\n    在设计一个频繁进行插入、删除和查找操作的系统时，选择平衡树需要权衡以下因素：\n\n    1.  **查找频率 vs. 修改频率：**\n        *   如果查找操作远多于插入/删除操作，且对查找速度有极高要求，AVL 树可能更适合，因为它提供了更严格的平衡，树高更小，查找性能理论上略优。\n        *   如果插入/删除操作的频率很高，Red-Black trees 通常是更好的选择。其平衡条件相对宽松，使得插入/删除操作所需的旋转次数可能更少，从而降低了修改操作的常数开销。\n\n    2.  **实现复杂度：**\n        *   AVL 树的平衡条件（左右子树高度差不超过 1）和维护（单/双旋转）相对直接，但需要精确计算和更新节点高度。\n        *   Red-Black trees 的规则（颜色、根黑色、红色节点子节点黑色、黑色高度一致）和维护（颜色翻转、旋转）更加复杂，实现难度稍高。\n\n    3.  **内存开销：**\n        *   AVL 树通常需要在每个节点中存储高度信息，这会增加额外的内存开销。\n        *   Red-Black trees 通常在节点中存储颜色信息（一个比特位即可），内存开销相对较小。\n\n    4.  **实际性能：**\n        *   虽然理论上都是 $O(\\log n)$，但实际性能会受到常数因子、缓存局部性等因素影响。在某些特定硬件和数据分布下，Red-Black trees 的实际性能可能更优，因为其修改操作的平均开销更低。\n\n    **决策流程：**\n    *   **首选：** 对于大多数通用场景，Red-Black trees 是一个安全且高效的选择，因为它在查找和修改操作之间提供了良好的平衡，且实现相对标准化（例如 C++ STL map/set）。\n    *   **特殊优化：** 如果系统对查找性能有极致要求，且修改操作频率较低，可以考虑 AVL 树。\n    *   **替代方案：** 对于非常特殊的性能要求，也可以考虑 B 树及其变种（如 B+ 树），尤其是在数据量巨大、需要考虑磁盘 I/O 的场景下。\n    </details>",
  "model": "google/gemini-2.5-flash-lite-preview-06-17",
  "usage": {
    "input_tokens": 9591,
    "output_tokens": 4336,
    "total_tokens": 13927
  },
  "cost": 0.0026934999999999997,
  "model_info": {
    "input_cost_per_1m": 0.1,
    "output_cost_per_1m": 0.4,
    "context_length": 1048576,
    "useable": true
  }
}