#!/usr/bin/env python3
"""
EXTRACT_PDF.py - Enhanced PDF extraction using MinerU with integrated post-processing
All-in-one PDF processing tool with image analysis using IMG2TEXT
"""

import os
import sys
import json
import subprocess
import argparse
import hashlib
import re
import tempfile
import shutil
import time
import io
from pathlib import Path
from typing import Dict, List, Optional, Tuple


def get_pdf_extractor_data_dir():
    """Get the PDF extractor data directory path."""
    script_dir = Path(__file__).parent
    # ä¼˜å…ˆä½¿ç”¨EXTRACT_PDF_DATAç›®å½•ï¼ˆæ•°æ®ä¸ä»£ç åˆ†ç¦»ï¼‰
    data_dir = script_dir / "EXTRACT_PDF_DATA"
    if not data_dir.exists():
        data_dir.mkdir(parents=True, exist_ok=True)
        # åˆ›å»ºå¿…è¦çš„å­ç›®å½•
        (data_dir / "images").mkdir(exist_ok=True)
        (data_dir / "markdown").mkdir(exist_ok=True)
    return data_dir


def save_to_unified_data_directory(content: str, pdf_path: Path, page_spec: str = None, images_data: list = None) -> Tuple[str, str]:
    """
    ç»Ÿä¸€çš„æ•°æ®å­˜å‚¨æ¥å£ï¼Œä¾›basicå’Œmineruæ¨¡å¼å…±ç”¨
    
    Args:
        content: markdownå†…å®¹
        pdf_path: åŸPDFæ–‡ä»¶è·¯å¾„
        page_spec: é¡µç è§„æ ¼ (å¦‚ "1", "1-5", "1,3,5")
        images_data: å›¾ç‰‡æ•°æ®åˆ—è¡¨ [{'bytes': bytes, 'hash': str, 'filename': str}, ...]
    
    Returns:
        tuple: (data_directory_md_path, pdf_directory_md_path)
    """
    import shutil
    
    # è·å–æ•°æ®ç›®å½•
    data_dir = get_pdf_extractor_data_dir()
    markdown_dir = data_dir / "markdown"
    images_dir = data_dir / "images"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    markdown_dir.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(parents=True, exist_ok=True)
    
    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„æ•°å­—æ–‡ä»¶å
    counter = 0
    while True:
        target_file = markdown_dir / f"{counter}.md"
        if not target_file.exists():
            break
        counter += 1
    
    # ä¿å­˜markdownåˆ°æ•°æ®ç›®å½•
    with open(target_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    # ä¿å­˜å›¾ç‰‡åˆ°æ•°æ®ç›®å½•
    if images_data:
        for img_data in images_data:
            img_file = images_dir / img_data['filename']
            with open(img_file, 'wb') as f:
                f.write(img_data['bytes'])
    
    # åˆ›å»ºPDFåŒå±‚ç›®å½•çš„æ–‡ä»¶
    pdf_stem = pdf_path.stem
    if page_spec:
        pdf_stem_with_pages = f"{pdf_stem}_p{page_spec}"
    else:
        pdf_stem_with_pages = pdf_stem
    
    same_name_md_file = pdf_path.parent / f"{pdf_stem_with_pages}.md"
    
    # æ›´æ–°å›¾ç‰‡è·¯å¾„åˆ°ç»å¯¹è·¯å¾„ (æŒ‡å‘EXTRACT_PDF_DATA)
    updated_content = update_image_paths_to_data_directory(content, str(data_dir))
    
    # ä¿å­˜åˆ°PDFåŒå±‚ç›®å½•
    with open(same_name_md_file, 'w', encoding='utf-8') as f:
        f.write(updated_content)
    
    # å¤åˆ¶å›¾ç‰‡åˆ°PDFåŒå±‚ç›®å½•çš„imagesæ–‡ä»¶å¤¹
    if images_data:
        pdf_images_dir = pdf_path.parent / "images"
        pdf_images_dir.mkdir(exist_ok=True)
        
        for img_data in images_data:
            src_file = images_dir / img_data['filename']
            dst_file = pdf_images_dir / img_data['filename']
            if src_file.exists():
                shutil.copy2(src_file, dst_file)
    
    return str(target_file), str(same_name_md_file)


def update_image_paths_to_data_directory(content: str, data_dir: str) -> str:
    """æ›´æ–°markdownå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„ï¼ŒæŒ‡å‘EXTRACT_PDF_DATAç›®å½•"""
    import re
    
    # å°†ç›¸å¯¹è·¯å¾„çš„å›¾ç‰‡å¼•ç”¨æ›´æ–°ä¸ºç»å¯¹è·¯å¾„
    def replace_image_path(match):
        image_filename = match.group(2)
        abs_image_path = Path(data_dir) / "images" / image_filename
        return f"![{match.group(1)}]({abs_image_path})"
    
    # åŒ¹é… ![...](images/filename) æ ¼å¼
    updated_content = re.sub(r'!\[([^\]]*)\]\(images/([^)]+)\)', replace_image_path, content)
    
    return updated_content


def create_postprocess_status_file(pdf_path: Path, page_spec: str = None, images_data: list = None) -> str:
    """åˆ›å»ºåå¤„ç†çŠ¶æ€æ–‡ä»¶ï¼Œç”¨äºè¿½è¸ªplaceholderå¤„ç†çŠ¶æ€"""
    import json
    from datetime import datetime
    
    pdf_stem = pdf_path.stem
    if page_spec:
        pdf_stem_with_pages = f"{pdf_stem}_p{page_spec}"
    else:
        pdf_stem_with_pages = pdf_stem
    
    status_file = pdf_path.parent / f"{pdf_stem_with_pages}_postprocess.json"
    
    # åˆ›å»ºçŠ¶æ€æ•°æ®
    status_data = {
        "pdf_file": str(pdf_path),
        "created_at": datetime.now().isoformat(),
        "page_range": page_spec,
        "total_items": len(images_data) if images_data else 0,
        "processed_items": 0,
        "items": []
    }
    
    # æ·»åŠ å›¾ç‰‡é¡¹ç›®
    if images_data:
        for img_data in images_data:
            item = {
                "id": img_data['hash'],
                "type": "image",  # basicæ¨¡å¼ä¸»è¦å¤„ç†å›¾ç‰‡
                "filename": img_data['filename'],
                "image_path": f"images/{img_data['filename']}",  # æ·»åŠ image_pathå­—æ®µ
                "processor": "basic_extractor",
                "processed": False,
                "placeholder": f"![](images/{img_data['filename']})",
                "bbox": img_data.get('bbox', []),
                "page": img_data.get('page', 1)
            }
            status_data["items"].append(item)
    
    # ä¿å­˜çŠ¶æ€æ–‡ä»¶
    with open(status_file, 'w', encoding='utf-8') as f:
        json.dump(status_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ åå¤„ç†çŠ¶æ€ä¿å­˜è‡³: {status_file.name}")
    return str(status_file)

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# å…¨å±€å˜é‡
original_pdf_dir = None

def is_run_environment(command_identifier=None):
    """Check if running in RUN environment by checking environment variables"""
    if command_identifier:
        return os.environ.get(f'RUN_IDENTIFIER_{command_identifier}') == 'True'
    return False

def write_to_json_output(data, command_identifier=None):
    """å°†ç»“æœå†™å…¥åˆ°æŒ‡å®šçš„ JSON è¾“å‡ºæ–‡ä»¶ä¸­"""
    if not is_run_environment(command_identifier):
        return False
    
    # Get the specific output file for this command identifier
    if command_identifier:
        output_file = os.environ.get(f'RUN_DATA_FILE_{command_identifier}')
    else:
        output_file = os.environ.get('RUN_DATA_FILE')
    
    if not output_file:
        return False
    
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"Error writing to JSON output file: {e}")
        return False

class PDFExtractor:
    """PDFæå–å™¨ï¼Œé›†æˆæ‰€æœ‰PDFå¤„ç†åŠŸèƒ½"""
    
    def __init__(self, debug: bool = False):
        self.debug = debug
        self.script_dir = Path(__file__).parent
        self.proj_dir = self.script_dir / "EXTRACT_PDF_PROJ"
        
    def extract_pdf_basic(self, pdf_path: Path, page_spec: str = None, output_dir: Path = None) -> Tuple[bool, str]:
        """åŸºç¡€PDFæå–åŠŸèƒ½ - ä½¿ç”¨ç»Ÿä¸€æ•°æ®å­˜å‚¨æ¥å£"""
        import time
        import hashlib
        
        start_time = time.time()
        
        try:
            # ä½¿ç”¨Pythonçš„åŸºç¡€PDFå¤„ç†åº“
            import fitz  # PyMuPDF
            
            # æ‰“å¼€PDFæ–‡ä»¶
            doc = fitz.open(str(pdf_path))
            
            # ç¡®å®šè¦å¤„ç†çš„é¡µé¢
            if page_spec:
                pages = self._parse_page_spec(page_spec, doc.page_count)
            else:
                pages = list(range(doc.page_count))
            
            content = []
            images_data = []
            
            # å¤„ç†æ¯ä¸€é¡µ
            for page_num in pages:
                page = doc[page_num]
                
                # æå–æ–‡æœ¬
                text = page.get_text()
                content.append(f"# Page {page_num + 1}\n\n{text}\n\n")
                
                # æå–å›¾ç‰‡
                image_list = page.get_images()
                for img_index, img in enumerate(image_list):
                    # è·å–å›¾ç‰‡æ•°æ®
                    xref = img[0]
                    pix = fitz.Pixmap(doc, xref)
                    
                    if pix.n - pix.alpha < 4:  # ç¡®ä¿æ˜¯RGBæˆ–ç°åº¦å›¾åƒ
                        # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
                        if pix.alpha:
                            pix = fitz.Pixmap(fitz.csRGB, pix)
                        
                        img_bytes = pix.tobytes("jpeg")
                        
                        # ç”Ÿæˆhashæ–‡ä»¶å
                        img_hash = hashlib.md5(img_bytes).hexdigest()
                        img_filename = f"{img_hash}.jpg"
                        
                        # è·å–å›¾ç‰‡ä½ç½®ä¿¡æ¯
                        img_rects = page.get_image_rects(xref)
                        bbox = list(img_rects[0]) if img_rects else []
                        
                        # ä¿å­˜å›¾ç‰‡æ•°æ®
                        images_data.append({
                            'bytes': img_bytes,
                            'hash': img_hash,
                            'filename': img_filename,
                            'bbox': bbox,
                            'page': page_num + 1
                        })
                        
                        # åœ¨markdownä¸­æ·»åŠ å›¾ç‰‡å¼•ç”¨
                        content.append(f"![](images/{img_filename})\n\n")
                    
                    pix = None  # é‡Šæ”¾å†…å­˜
            
            doc.close()
            
            # åˆå¹¶æ‰€æœ‰å†…å®¹
            full_content = '\n'.join(content)
            
            # ä½¿ç”¨ç»Ÿä¸€æ•°æ®å­˜å‚¨æ¥å£ä¿å­˜æ•°æ®
            data_md_path, pdf_md_path = save_to_unified_data_directory(
                full_content, pdf_path, page_spec, images_data
            )
            
            # åˆ›å»ºpostprocessçŠ¶æ€æ–‡ä»¶
            if images_data:
                create_postprocess_status_file(pdf_path, page_spec, images_data)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            end_time = time.time()
            processing_time = end_time - start_time
            
            print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ°: {data_md_path}")
            if images_data:
                print(f"ğŸ–¼ï¸  æå–äº† {len(images_data)} å¼ å›¾ç‰‡")
            
            return True, f"Basic extraction completed: {pdf_md_path}"
            
        except Exception as e:
            return False, f"Basic extraction failed: {str(e)}"
    
    def extract_pdf_mineru(self, pdf_path: Path, page_spec: str = None, output_dir: Path = None, 
                          enable_analysis: bool = False) -> Tuple[bool, str]:
        """ä½¿ç”¨MinerUè¿›è¡ŒPDFæå–"""
        import time
        
        start_time = time.time()
        
        try:
            # æ£€æŸ¥MinerU CLIæ˜¯å¦å¯ç”¨
            mineru_cli = self.proj_dir / "pdf_extract_cli.py"
            if not mineru_cli.exists():
                return False, "MinerU CLI not available"
            
            # æ„å»ºMinerUå‘½ä»¤
            cmd = [
                sys.executable, 
                str(mineru_cli),
                str(pdf_path)
            ]
            
            if page_spec:
                cmd.extend(['--page', page_spec])
            
            if output_dir:
                cmd.extend(['--output', str(output_dir)])
            
            # å§‹ç»ˆä½¿ç”¨MinerU
            cmd.append('--use-mineru')
            
            if not enable_analysis:
                cmd.append('--no-image-api')
                cmd.append('--async-mode')
            
            # æ‰§è¡ŒMinerU
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            # Print stderr for debugging
            if result.stderr:
                print(result.stderr, file=sys.stderr)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            end_time = time.time()
            processing_time = end_time - start_time
            
            if result.returncode == 0:
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶è¢«åˆ›å»ºï¼Œå¹¶å¤åˆ¶åˆ°ç”¨æˆ·æŒ‡å®šçš„ç›®å½•
                output_file = self._handle_mineru_output(pdf_path, output_dir, result.stdout, page_spec)
                print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
                return True, f"MinerU extraction completed: {output_file}"
            else:
                print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
                return False, f"MinerU extraction failed: {result.stderr}"
                
        except Exception as e:
            return False, f"MinerU extraction error: {str(e)}"
    
    def _parse_page_spec(self, page_spec: str, total_pages: int) -> List[int]:
        """è§£æé¡µé¢è§„æ ¼"""
        pages = []
        
        for part in page_spec.split(','):
            part = part.strip()
            if '-' in part:
                start, end = part.split('-', 1)
                start = int(start.strip()) - 1  # è½¬æ¢ä¸º0-based
                end = int(end.strip()) - 1
                pages.extend(range(max(0, start), min(total_pages, end + 1)))
            else:
                page = int(part.strip()) - 1  # è½¬æ¢ä¸º0-based
                if 0 <= page < total_pages:
                    pages.append(page)
        
        return sorted(list(set(pages)))
    
    def _handle_mineru_output(self, pdf_path: Path, output_dir: Path, stdout: str, page_spec: str = None) -> str:
        """å¤„ç†MinerUè¾“å‡ºï¼Œå°†æ–‡ä»¶å¤åˆ¶åˆ°ç”¨æˆ·æŒ‡å®šçš„ç›®å½•å¹¶ä¿®æ­£å›¾ç‰‡è·¯å¾„"""
        try:
            # ç¡®å®šè¾“å‡ºç›®å½•
            if output_dir is None:
                output_dir = pdf_path.parent
            else:
                output_dir.mkdir(parents=True, exist_ok=True)
            
            # æŸ¥æ‰¾MinerUç”Ÿæˆçš„markdownæ–‡ä»¶
            mineru_data_dir = get_pdf_extractor_data_dir() / "markdown"
            if mineru_data_dir.exists():
                # æ‰¾åˆ°æœ€æ–°çš„markdownæ–‡ä»¶
                md_files = list(mineru_data_dir.glob("*.md"))
                if md_files:
                    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
                    latest_md = max(md_files, key=lambda f: f.stat().st_mtime)
                    
                    # è¯»å–markdownå†…å®¹å¹¶ä¿®æ­£å›¾ç‰‡è·¯å¾„
                    with open(latest_md, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ä¿®æ­£å›¾ç‰‡è·¯å¾„ï¼šä»ç›¸å¯¹è·¯å¾„æ”¹ä¸ºç»å¯¹è·¯å¾„
                    images_dir = get_pdf_extractor_data_dir() / "images"
                    content = self._fix_image_paths(content, images_dir)
                    
                    # æ„å»ºç›®æ ‡æ–‡ä»¶åï¼ŒåŒ…å«é¡µç ä¿¡æ¯
                    base_name = pdf_path.stem
                    if page_spec:
                        # æ ¼å¼åŒ–é¡µç ä¿¡æ¯ï¼šä¾‹å¦‚ "1,3,5" -> "_p1,3,5"ï¼Œ"1-5" -> "_p1-5"
                        page_suffix = f"_p{page_spec}"
                        target_filename = f"{base_name}{page_suffix}.md"
                    else:
                        target_filename = f"{base_name}.md"
                    
                    target_file = output_dir / target_filename
                    with open(target_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    return str(target_file)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œè¿”å›åŸå§‹è¾“å‡º
            return stdout.strip()
            
        except Exception as e:
            return f"Output handling failed: {str(e)}"
    
    def _fix_image_paths(self, content: str, images_dir: Path) -> str:
        """ä¿®æ­£markdownå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„"""
        import re
        
        # åŒ¹é…å›¾ç‰‡å¼•ç”¨ï¼š![alt](images/filename.jpg)
        pattern = r'!\[([^\]]*)\]\(images/([^)]+)\)'
        
        def replace_path(match):
            alt_text = match.group(1)
            filename = match.group(2)
            # ä½¿ç”¨ç»å¯¹è·¯å¾„
            absolute_path = images_dir / filename
            return f'![{alt_text}]({absolute_path})'
        
        return re.sub(pattern, replace_path, content)
    
    def clean_data(self) -> Tuple[bool, str]:
        """æ¸…ç†EXTRACT_PDF_PROJä¸­çš„ç¼“å­˜æ•°æ®"""
        try:
            data_dir = get_pdf_extractor_data_dir()
            
            if not data_dir.exists():
                return True, "No cached data found"
            
            # ç»Ÿè®¡è¦åˆ é™¤çš„æ–‡ä»¶
            markdown_dir = data_dir / "markdown"
            images_dir = data_dir / "images"
            
            md_count = len(list(markdown_dir.glob("*.md"))) if markdown_dir.exists() else 0
            img_count = len(list(images_dir.glob("*"))) if images_dir.exists() else 0
            
            # åˆ é™¤markdownæ–‡ä»¶
            if markdown_dir.exists():
                for md_file in markdown_dir.glob("*.md"):
                    md_file.unlink()
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {md_count} ä¸ªmarkdownæ–‡ä»¶")
            
            # åˆ é™¤å›¾ç‰‡æ–‡ä»¶
            if images_dir.exists():
                for img_file in images_dir.glob("*"):
                    if img_file.is_file():
                        img_file.unlink()
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {img_count} ä¸ªå›¾ç‰‡æ–‡ä»¶")
            
            # åˆ é™¤å…¶ä»–ç¼“å­˜æ–‡ä»¶
            cache_files = [
                data_dir / "images_analysis_cache.json"
            ]
            
            cache_count = 0
            for cache_file in cache_files:
                if cache_file.exists():
                    cache_file.unlink()
                    cache_count += 1
            
            if cache_count > 0:
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {cache_count} ä¸ªç¼“å­˜æ–‡ä»¶")
            
            total_deleted = md_count + img_count + cache_count
            if total_deleted > 0:
                return True, f"Successfully cleaned {total_deleted} cached files"
            else:
                return True, "No files to clean"
                
        except Exception as e:
            return False, f"Failed to clean data: {str(e)}"
    
    def extract_pdf(self, pdf_path: str, page_spec: str = None, output_dir: str = None, 
                   engine_mode: str = "mineru") -> Tuple[bool, str]:
        """æ‰§è¡ŒPDFæå–"""
        pdf_path = Path(pdf_path).expanduser().resolve()
        
        # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
        engine_descriptions = {
            "basic": "åŸºç¡€æå–å™¨ï¼ˆæ— å›¾åƒ/å…¬å¼/è¡¨æ ¼å¤„ç†ï¼‰",
            "basic-asyn": "åŸºç¡€æå–å™¨å¼‚æ­¥æ¨¡å¼ï¼ˆç¦ç”¨åˆ†æï¼‰",
            "mineru": "MinerUæå–å™¨ï¼ˆæ— å›¾åƒ/å…¬å¼/è¡¨æ ¼å¤„ç†ï¼‰",
            "mineru-asyn": "MinerUæå–å™¨å¼‚æ­¥æ¨¡å¼ï¼ˆç¦ç”¨åˆ†æï¼‰",
            "full": "å®Œæ•´å¤„ç†æµç¨‹ï¼ˆåŒ…å«å›¾åƒ/å…¬å¼/è¡¨æ ¼å¤„ç†ï¼‰"
        }
        
        if engine_mode in engine_descriptions:
            print(f"ğŸš€ ä½¿ç”¨å¼•æ“: {engine_descriptions[engine_mode]}")
        
        if not pdf_path.exists():
            return False, f"PDF file not found: {pdf_path}"
        
        output_dir_path = Path(output_dir) if output_dir else None
        
        # æ ¹æ®å¼•æ“æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹å¼
        if engine_mode == "basic":
            return self.extract_pdf_basic_with_images(pdf_path, page_spec, output_dir_path)
        elif engine_mode == "basic-asyn":
            return self.extract_pdf_basic(pdf_path, page_spec, output_dir_path)
        elif engine_mode == "mineru":
            return self.extract_pdf_mineru(pdf_path, page_spec, output_dir_path, enable_analysis=False)
        elif engine_mode == "mineru-asyn":
            return self.extract_pdf_mineru(pdf_path, page_spec, output_dir_path, enable_analysis=False)
        elif engine_mode == "full":
            return self.extract_pdf_mineru(pdf_path, page_spec, output_dir_path, enable_analysis=True)
        else:
            return False, f"Unknown engine mode: {engine_mode}"
    
    def extract_pdf_basic_with_images(self, pdf_path: Path, page_spec: str = None, output_dir: Path = None) -> Tuple[bool, str]:
        """åŸºç¡€PDFæå–åŠŸèƒ½ï¼ŒåŒ…å«å›¾ç‰‡æå–å’Œplaceholderç”Ÿæˆ - ä½¿ç”¨ç»Ÿä¸€æ•°æ®å­˜å‚¨"""
        import time
        import hashlib
        from PIL import Image
        
        start_time = time.time()
        
        try:
            # ä½¿ç”¨Pythonçš„åŸºç¡€PDFå¤„ç†åº“
            import fitz  # PyMuPDF
            
            # æ‰“å¼€PDFæ–‡ä»¶
            doc = fitz.open(str(pdf_path))
            
            # ç¡®å®šè¦å¤„ç†çš„é¡µé¢
            if page_spec:
                pages = self._parse_page_spec(page_spec, doc.page_count)
            else:
                pages = list(range(doc.page_count))
            
            content = []
            images_data = []
            
            # ç»“æŸæ€§æ ‡ç‚¹ç¬¦å·åˆ—è¡¨
            ending_punctuations = {'ã€‚', '.', '!', '?', 'ï¼', 'ï¼Ÿ', ':', 'ï¼š', ';', 'ï¼›'}
            
            for page_num in pages:
                page = doc[page_num]
                text = page.get_text()
                
                # æå–é¡µé¢ä¸­çš„å›¾ç‰‡
                image_list = page.get_images(full=True)
                page_content = f"# Page {page_num + 1}\n\n"
                
                # å›¾ç‰‡åˆå¹¶å¤„ç†ï¼šå°†ä¸´è¿‘çš„å›¾ç‰‡åˆå¹¶æˆä¸€å¼ å¤§å›¾
                if image_list:
                    merged_images_info = self._merge_nearby_images_to_data(doc, page, image_list, page_num + 1)
                    
                    # æ”¶é›†å›¾ç‰‡æ•°æ®
                    images_data.extend(merged_images_info)
                    
                    # ä¸ºæ¯ä¸ªåˆå¹¶åçš„å›¾ç‰‡æ·»åŠ placeholder
                    for img_info in merged_images_info:
                        page_content += f"[placeholder: image]\n"
                        page_content += f"![](images/{img_info['filename']})\n\n"
                
                # å¤„ç†æ­£æ–‡æ¢è¡Œç¬¦
                processed_text = self._process_text_linebreaks(text, ending_punctuations)
                
                # æ·»åŠ é¡µé¢æ–‡æœ¬
                page_content += f"{processed_text}\n\n"
                content.append(page_content)
            
            doc.close()
            
            # åˆå¹¶æ‰€æœ‰å†…å®¹
            full_content = '\n'.join(content)
            
            # ä½¿ç”¨ç»Ÿä¸€æ•°æ®å­˜å‚¨æ¥å£ä¿å­˜æ•°æ®
            data_md_path, pdf_md_path = save_to_unified_data_directory(
                full_content, pdf_path, page_spec, images_data
            )
            
            # åˆ›å»ºpostprocessçŠ¶æ€æ–‡ä»¶
            if images_data:
                create_postprocess_status_file(pdf_path, page_spec, images_data)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            end_time = time.time()
            processing_time = end_time - start_time
            
            print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ°: {data_md_path}")
            if images_data:
                print(f"ğŸ–¼ï¸  æå–å¹¶åˆå¹¶äº† {len(images_data)} å¼ å›¾ç‰‡")
            
            return True, f"Basic extraction with images completed: {pdf_md_path}"
            
        except Exception as e:
            return False, f"Basic extraction with images failed: {str(e)}"
    
    def _merge_nearby_images_to_data(self, doc, page, image_list, page_num):
        """åˆå¹¶ä¸´è¿‘çš„å›¾ç‰‡æˆä¸€å¼ å¤§å›¾ï¼Œè¿”å›å›¾ç‰‡æ•°æ®"""
        from PIL import Image
        import hashlib
        import fitz
        import io
        
        images_data = []
        
        if not image_list:
            return images_data
        
        try:
            # æå–æ‰€æœ‰å›¾ç‰‡çš„ä½ç½®å’Œæ•°æ®
            image_data = []
            for img_index, img in enumerate(image_list):
                try:
                    xref = img[0]
                    pix = fitz.Pixmap(doc, xref)
                    
                    # è·³è¿‡CMYKå›¾ç‰‡
                    if pix.n - pix.alpha >= 4:
                        pix = None
                        continue
                    
                    # è½¬æ¢ä¸ºRGB
                    if pix.n - pix.alpha == 1:  # ç°åº¦å›¾
                        pix = fitz.Pixmap(fitz.csRGB, pix)
                    
                    # è·å–å›¾ç‰‡åœ¨é¡µé¢ä¸­çš„ä½ç½®ï¼ˆç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨å›¾ç‰‡ç´¢å¼•ä½œä¸ºä½ç½®ï¼‰
                    y_position = img_index * 100  # ç®€åŒ–çš„ä½ç½®è®¡ç®—
                    
                    image_data.append({
                        'index': img_index,
                        'pix': pix,
                        'y_pos': y_position,
                        'page': page_num
                    })
                    
                except Exception as e:
                    print(f"âš ï¸  å¤„ç†å›¾ç‰‡ {img_index} æ—¶å‡ºé”™: {e}")
                    continue
            
            if not image_data:
                return images_data
            
            # æŒ‰Yä½ç½®æ’åº
            image_data.sort(key=lambda x: x['y_pos'])
            
            # åˆå¹¶ä¸´è¿‘çš„å›¾ç‰‡ï¼ˆç®€åŒ–ç‰ˆï¼šå°†æ‰€æœ‰å›¾ç‰‡å‚ç›´åˆå¹¶æˆä¸€å¼ å¤§å›¾ï¼‰
            if len(image_data) > 1:
                # è®¡ç®—åˆå¹¶åå›¾ç‰‡çš„æ€»é«˜åº¦å’Œæœ€å¤§å®½åº¦
                total_height = 0
                max_width = 0
                pil_images = []
                
                for img_info in image_data:
                    pix = img_info['pix']
                    # è½¬æ¢ä¸ºPIL Image
                    img_data = pix.tobytes("png")
                    pil_img = Image.open(io.BytesIO(img_data))
                    pil_images.append(pil_img)
                    
                    total_height += pil_img.height
                    max_width = max(max_width, pil_img.width)
                
                # åˆ›å»ºåˆå¹¶åçš„å¤§å›¾
                merged_img = Image.new('RGB', (max_width, total_height), 'white')
                
                y_offset = 0
                for pil_img in pil_images:
                    # å±…ä¸­æ”¾ç½®æ¯å¼ å›¾ç‰‡
                    x_offset = (max_width - pil_img.width) // 2
                    merged_img.paste(pil_img, (x_offset, y_offset))
                    y_offset += pil_img.height
                
                # ç”Ÿæˆåˆå¹¶å›¾ç‰‡çš„å­—èŠ‚æ•°æ®å’Œå“ˆå¸Œæ–‡ä»¶å
                img_bytes_io = io.BytesIO()
                merged_img.save(img_bytes_io, format='PNG')
                img_bytes = img_bytes_io.getvalue()
                img_hash = hashlib.md5(img_bytes).hexdigest()  # ä½¿ç”¨md5ä¿æŒä¸€è‡´æ€§
                merged_filename = f"{img_hash}.png"
                
                # æ·»åŠ åˆ°å›¾ç‰‡æ•°æ®åˆ—è¡¨
                images_data.append({
                    'bytes': img_bytes,
                    'hash': img_hash,
                    'filename': merged_filename,
                    'bbox': [],  # åˆå¹¶å›¾ç‰‡æ²¡æœ‰å•ä¸€çš„bbox
                    'page': page_num
                })
                
                print(f"ğŸ–¼ï¸  åˆå¹¶äº† {len(image_data)} å¼ å›¾ç‰‡æˆä¸€å¼ å¤§å›¾: {merged_filename}")
                
                # æ¸…ç†ä¸´æ—¶èµ„æº
                for img_info in image_data:
                    if img_info['pix']:
                        img_info['pix'] = None
                        
            elif len(image_data) == 1:
                # åªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œç›´æ¥å¤„ç†
                pix = image_data[0]['pix']
                img_data = pix.tobytes("jpeg")
                img_hash = hashlib.md5(img_data).hexdigest()
                img_filename = f"{img_hash}.jpg"
                
                # è·å–å›¾ç‰‡ä½ç½®ä¿¡æ¯
                try:
                    xref = image_list[0][0]
                    img_rects = page.get_image_rects(xref)
                    bbox = list(img_rects[0]) if img_rects else []
                except:
                    bbox = []
                
                images_data.append({
                    'bytes': img_data,
                    'hash': img_hash,
                    'filename': img_filename,
                    'bbox': bbox,
                    'page': page_num
                })
                
                pix = None
                
        except Exception as e:
            print(f"âš ï¸  å›¾ç‰‡åˆå¹¶è¿‡ç¨‹å‡ºé”™: {e}")
            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œå›é€€åˆ°å•ç‹¬å¤„ç†æ¯å¼ å›¾ç‰‡
            for img_index, img in enumerate(image_list):
                try:
                    xref = img[0]
                    pix = fitz.Pixmap(doc, xref)
                    
                    if pix.n - pix.alpha < 4:
                        if pix.n - pix.alpha == 1:
                            pix = fitz.Pixmap(fitz.csRGB, pix)
                        
                        img_data = pix.tobytes("jpeg")
                        img_hash = hashlib.md5(img_data).hexdigest()
                        img_filename = f"{img_hash}.jpg"
                        
                        # è·å–å›¾ç‰‡ä½ç½®ä¿¡æ¯
                        try:
                            img_rects = page.get_image_rects(xref)
                            bbox = list(img_rects[0]) if img_rects else []
                        except:
                            bbox = []
                        
                        images_data.append({
                            'bytes': img_data,
                            'hash': img_hash,
                            'filename': img_filename,
                            'bbox': bbox,
                            'page': page_num
                        })
                    
                    pix = None
                    
                except Exception as e:
                    print(f"âš ï¸  ä¿å­˜å•å¼ å›¾ç‰‡ {img_index} å¤±è´¥: {e}")
        
        return images_data
    
    def _process_text_linebreaks(self, text, ending_punctuations):
        """å¤„ç†æ­£æ–‡æ¢è¡Œç¬¦ï¼Œæ™ºèƒ½åˆå¹¶å¥å­å’Œåˆ†æ®µ"""
        if not text.strip():
            return text
        
        lines = text.split('\n')
        processed_lines = []
        current_paragraph = []
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not line:
                if current_paragraph:
                    # å¦‚æœå½“å‰æ®µè½æœ‰å†…å®¹ï¼Œç»“æŸå½“å‰æ®µè½
                    paragraph_text = ' '.join(current_paragraph)
                    processed_lines.append(paragraph_text)
                    current_paragraph = []
                    processed_lines.append('')  # æ·»åŠ ç©ºè¡Œè¡¨ç¤ºæ®µè½åˆ†éš”
                continue
            
            # å°†å½“å‰è¡Œæ·»åŠ åˆ°æ®µè½ä¸­
            current_paragraph.append(line)
            
            # æ£€æŸ¥è¡Œæ˜¯å¦ä»¥ç»“æŸæ€§æ ‡ç‚¹ç¬¦å·ç»“å°¾
            if line and line[-1] in ending_punctuations:
                # ç»“æŸå½“å‰æ®µè½
                paragraph_text = ' '.join(current_paragraph)
                processed_lines.append(paragraph_text)
                current_paragraph = []
                processed_lines.append('')  # æ·»åŠ ç©ºè¡Œè¡¨ç¤ºæ®µè½åˆ†éš”
        
        # å¤„ç†æœ€åä¸€ä¸ªæ®µè½
        if current_paragraph:
            paragraph_text = ' '.join(current_paragraph)
            processed_lines.append(paragraph_text)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        result = []
        prev_empty = False
        for line in processed_lines:
            if line == '':
                if not prev_empty:
                    result.append(line)
                prev_empty = True
            else:
                result.append(line)
                prev_empty = False
        
        return '\n'.join(result)

    def process_file_unified_moved_to_postprocessor(self, file_path: str, process_type: str, specific_ids: str = None, custom_prompt: str = None, force: bool = False) -> bool:
        """
        ç»Ÿä¸€çš„åå¤„ç†æ¥å£ - ä¸ä¾èµ–äºæå–æ¨¡å¼
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„æˆ–markdownæ–‡ä»¶è·¯å¾„
            process_type: å¤„ç†ç±»å‹ ('image', 'formula', 'table', 'all')
            specific_ids: ç‰¹å®šIDåˆ—è¡¨æˆ–å…³é”®è¯
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        file_path = Path(file_path)
        
        # ç¡®å®šPDFæ–‡ä»¶å’Œmarkdownæ–‡ä»¶è·¯å¾„
        if file_path.suffix == '.pdf':
            pdf_file_path = file_path
            md_file = file_path.parent / f"{file_path.stem}.md"
        elif file_path.suffix == '.md':
            md_file = file_path
            # å°è¯•æ‰¾åˆ°å¯¹åº”çš„PDFæ–‡ä»¶
            pdf_file_path = file_path.parent / f"{file_path.stem}.pdf"
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path.suffix}")
            return False
            
        if not md_file.exists():
            print(f"âŒ Markdownæ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
            return False
            
        print(f"ğŸ”„ å¼€å§‹ç»Ÿä¸€åå¤„ç† {md_file.name}...")
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šç¡®ä¿æœ‰postprocessçŠ¶æ€æ–‡ä»¶
            status_file = self._ensure_postprocess_status_file(pdf_file_path, md_file)
            if not status_file:
                print("âŒ æ— æ³•åˆ›å»ºæˆ–æ‰¾åˆ°çŠ¶æ€æ–‡ä»¶")
                return False
            
            # ç¬¬äºŒæ­¥ï¼šè¯»å–çŠ¶æ€æ–‡ä»¶
            with open(status_file, 'r', encoding='utf-8') as f:
                status_data = json.load(f)
            
            # ç¬¬ä¸‰æ­¥ï¼šåŒæ­¥markdownå’ŒJSONä¸­çš„placeholderä¿¡æ¯
            print("ğŸ”„ åŒæ­¥markdownå’ŒJSONä¸­çš„placeholderä¿¡æ¯...")
            status_data = self._sync_placeholders_with_markdown(md_file, status_data, status_file)
            
            # ç¬¬å››æ­¥ï¼šç­›é€‰è¦å¤„ç†çš„é¡¹ç›®
            items_to_process = self._filter_items_to_process(status_data, process_type, specific_ids, force)
            
            if not items_to_process:
                print("â„¹ï¸  æ²¡æœ‰éœ€è¦å¤„ç†çš„é¡¹ç›®")
                return True
            
            # ç¬¬äº”æ­¥ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ··åˆå¤„ç†æ–¹å¼
            success = self._process_items_unified(str(pdf_file_path), str(md_file), status_data, 
                                                items_to_process, process_type, custom_prompt, force)
            
            return success
            
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€åå¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def _ensure_postprocess_status_file(self, pdf_file_path: Path, md_file: Path) -> Optional[Path]:
        """ç¡®ä¿å­˜åœ¨postprocessçŠ¶æ€æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
        status_file = pdf_file_path.parent / f"{pdf_file_path.stem}_postprocess.json"
        
        if status_file.exists():
            return status_file
        
        print("ğŸ“„ çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»markdowné‡æ–°ç”Ÿæˆ...")
        
        # ä»markdownæ–‡ä»¶åˆ†æplaceholderï¼Œåˆ›å»ºçŠ¶æ€æ–‡ä»¶
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾æ‰€æœ‰placeholderå’Œå›¾ç‰‡å¼•ç”¨
            import re
            # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…åŒ…å«åˆ†æç»“æœçš„å®Œæ•´placeholderå—
            # è¿™ä¸ªæ¨¡å¼åŒ¹é…ï¼š[placeholder: type]\n![...](path) åé¢å¯èƒ½è·Ÿç€åˆ†æç»“æœ
            placeholder_pattern = r'\[placeholder:\s*(\w+)\]\s*\n!\[[^\]]*\]\(([^)]+)\)(?:\s*\n\n\*\*[^*]+\*\*.*?)?'
            matches = re.findall(placeholder_pattern, content, re.DOTALL)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°placeholderï¼Œæ— éœ€åå¤„ç†")
                return None
            
            # åˆ›å»ºçŠ¶æ€æ•°æ®
            from datetime import datetime
            status_data = {
                "pdf_file": str(pdf_file_path),
                "created_at": datetime.now().isoformat(),
                "page_range": None,
                "total_items": len(matches),
                "processed_items": 0,
                "items": []
            }
            
            # æ·»åŠ é¡¹ç›®
            for item_type, image_path in matches:
                # ä»å›¾ç‰‡è·¯å¾„æå–hash ID
                image_filename = Path(image_path).name
                hash_id = Path(image_path).stem
                
                item = {
                    "id": hash_id,
                    "type": item_type,
                    "filename": image_filename,
                    "image_path": image_path,
                    "processor": "unified_processor",
                    "processed": False,
                    "placeholder": f"[placeholder: {item_type}]",
                    "bbox": [],
                    "page": 1  # é»˜è®¤é¡µç 
                }
                status_data["items"].append(item)
            
            # ä¿å­˜çŠ¶æ€æ–‡ä»¶
            with open(status_file, 'w', encoding='utf-8') as f:
                json.dump(status_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åˆ›å»ºçŠ¶æ€æ–‡ä»¶: {status_file.name}")
            return status_file
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºçŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _filter_items_to_process(self, status_data: dict, process_type: str, specific_ids: str, force: bool) -> list:
        """ç­›é€‰éœ€è¦å¤„ç†çš„é¡¹ç›®"""
        items_to_process = []
        
        for item in status_data.get('items', []):
            # è·³è¿‡å·²å¤„ç†çš„é¡¹ç›®ï¼ˆé™¤éå¼ºåˆ¶é‡æ–°å¤„ç†ï¼‰
            if item.get('processed', False) and not force:
                continue
            
            item_type = item.get('type')
            item_id = item.get('id')
            
            # æ ¹æ®å¤„ç†ç±»å‹ç­›é€‰
            if process_type != 'all':
                if process_type == 'image' and item_type != 'image':
                    continue
                elif process_type == 'formula' and item_type not in ['formula', 'interline_equation']:
                    continue
                elif process_type == 'table' and item_type != 'table':
                    continue
            
            # æ ¹æ®specific_idsç­›é€‰
            if specific_ids:
                if specific_ids in ['all_images', 'all_formulas', 'all_tables', 'all']:
                    if specific_ids == 'all':
                        pass  # å¤„ç†æ‰€æœ‰ç±»å‹
                    elif specific_ids == 'all_images' and item_type != 'image':
                        continue
                    elif specific_ids == 'all_formulas' and item_type not in ['formula', 'interline_equation']:
                        continue
                    elif specific_ids == 'all_tables' and item_type != 'table':
                        continue
                else:
                    # å…·ä½“çš„hash IDåˆ—è¡¨
                    target_ids = [id.strip() for id in specific_ids.split(',')]
                    if item_id not in target_ids:
                        continue
            
            items_to_process.append(item_id)
        
        return items_to_process
    
    def _process_items_unified(self, pdf_file: str, md_file: str, status_data: dict, 
                             items_to_process: list, process_type: str, custom_prompt: str = None, force: bool = False) -> bool:
        """ç»Ÿä¸€çš„é¡¹ç›®å¤„ç†æ–¹æ³•"""
        try:
            # è¯»å–markdownæ–‡ä»¶
            with open(md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # å¤„ç†æ¯ä¸ªé¡¹ç›®
            updated = False
            for item_id in items_to_process:
                # æ‰¾åˆ°å¯¹åº”çš„é¡¹ç›®
                item = None
                for status_item in status_data.get('items', []):
                    if status_item.get('id') == item_id:
                        item = status_item
                        break
                
                if not item:
                    print(f"âš ï¸  æœªæ‰¾åˆ°é¡¹ç›®: {item_id}")
                    continue
                
                item_type = item.get('type')
                image_path = item.get('image_path', '')
                
                if not image_path:
                    print(f"âš ï¸  å›¾ç‰‡è·¯å¾„ä¸ºç©º: {item_id}")
                    continue
                
                # æŸ¥æ‰¾å®é™…çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„
                actual_image_path = self._find_actual_image_path(pdf_file, image_path)
                if not actual_image_path:
                    print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue
                
                print(f"ğŸ”„ å¤„ç† {item_type} é¡¹ç›®: {item_id}")
                
                # æ ¹æ®ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
                result_text = ""
                if item_type == 'image':
                    result_text = self._process_image_with_api(actual_image_path, custom_prompt)
                elif item_type in ['formula', 'interline_equation']:
                    result_text = self._process_with_unimernet(actual_image_path, "formula", force)
                elif item_type == 'table':
                    result_text = self._process_with_unimernet(actual_image_path, "table", force)
                
                if result_text:
                    # æ›´æ–°markdownå†…å®¹
                    success = self._update_markdown_with_result(md_content, item, result_text)
                    if success:
                        md_content = success
                        item['processed'] = True
                        updated = True
                        print(f"âœ… å®Œæˆ {item_type} å¤„ç†: {item_id}")
                    else:
                        print(f"âš ï¸  æ›´æ–°markdownå¤±è´¥: {item_id}")
                else:
                    print(f"âŒ å¤„ç†å¤±è´¥: {item_id}")
            
            if updated:
                # ä¿å­˜æ›´æ–°çš„markdownæ–‡ä»¶
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(md_content)
                
                # æ›´æ–°çŠ¶æ€æ–‡ä»¶
                status_file = Path(pdf_file).parent / f"{Path(pdf_file).stem}_postprocess.json"
                with open(status_file, 'w', encoding='utf-8') as f:
                    json.dump(status_data, f, indent=2, ensure_ascii=False)
                
                print(f"ğŸ“ å·²æ›´æ–°æ–‡ä»¶: {Path(md_file).name}")
                return True
            else:
                print("â„¹ï¸  æ²¡æœ‰å†…å®¹éœ€è¦æ›´æ–°")
                return True
                
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€å¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def _update_markdown_with_result(self, md_content: str, item: dict, result_text: str) -> Optional[str]:
        """æ›´æ–°markdownå†…å®¹ï¼Œä¿ç•™placeholderï¼Œæ¸…é™¤å·²æœ‰åˆ†æç»“æœå¹¶æ›¿æ¢ä¸ºæ–°ç»“æœ"""
        import re
        
        item_type = item.get('type')
        image_path = item.get('image_path', '')
        
        # æ„å»ºæ›´å¤æ‚çš„æ¨¡å¼æ¥åŒ¹é…æ•´ä¸ªå—ï¼ˆåŒ…æ‹¬å¯èƒ½å­˜åœ¨çš„åˆ†æç»“æœï¼‰
        # å…ˆå°è¯•åŒ¹é…å·²ç»åŒ…å«åˆ†æç»“æœçš„å®Œæ•´å—
        image_filename = Path(image_path).name
        escaped_filename = re.escape(image_filename)
        escaped_type = re.escape(item_type)
        
        # æ¨¡å¼1: åŒ¹é…åŒ…å«åˆ†æç»“æœçš„å®Œæ•´å—
        # [placeholder: type]\n![...](path)\n\n**åˆ†æç»“æœ:**...\n ç›´åˆ°ä¸‹ä¸€ä¸ªç©ºè¡Œæˆ–æ–‡ä»¶ç»“æŸ
        complete_block_pattern = (
            rf'\[placeholder:\s*{escaped_type}\]\s*\n'
            rf'!\[[^\]]*\]\([^)]*{escaped_filename}\)[^)]*\)\s*\n'
            rf'(?:\n\*\*å›¾ç‰‡åˆ†æ:\*\*.*?(?=\n\n|\n#|\Z))?'
            rf'(?:\n\n\*\*å›¾ç‰‡åˆ†æ:\*\*.*?(?=\n\n|\n#|\Z))?'
            rf'(?:\n\*\*è¡¨æ ¼å†…å®¹:\*\*.*?(?=\n\n|\n#|\Z))?'
            rf'(?:\n\*\*åˆ†æç»“æœ:\*\*.*?(?=\n\n|\n#|\Z))?'
        )
        
        # æ¨¡å¼2: ç®€å•åŒ¹é…placeholderå’Œå›¾ç‰‡ï¼ˆæ²¡æœ‰åˆ†æç»“æœçš„æƒ…å†µï¼‰
        simple_pattern = (
            rf'\[placeholder:\s*{escaped_type}\]\s*\n'
            rf'!\[[^\]]*\]\([^)]*{escaped_filename}\)[^)]*\)'
        )
        
        # å…ˆå°è¯•å®Œæ•´å—æ¨¡å¼
        if re.search(complete_block_pattern, md_content, re.DOTALL):
            pattern_to_use = complete_block_pattern
            flags = re.DOTALL
        elif re.search(simple_pattern, md_content):
            pattern_to_use = simple_pattern
            flags = 0
        else:
            # å°è¯•æ›´å®½æ¾çš„åŒ¹é…ï¼ˆåªåŒ¹é…æ–‡ä»¶åï¼‰
            loose_pattern = rf'\[placeholder:\s*{escaped_type}\]\s*\n!\[[^\]]*\]\([^)]*{escaped_filename}[^)]*\)'
            if re.search(loose_pattern, md_content):
                pattern_to_use = loose_pattern
                flags = 0
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„placeholderæ¨¡å¼")
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºmarkdownä¸­å®é™…å­˜åœ¨çš„placeholder
                debug_pattern = r'\[placeholder:\s*(\w+)\]\s*!\[[^\]]*\]\(([^)]+)\)'
                debug_matches = re.findall(debug_pattern, md_content)
                if debug_matches:
                    print(f"ğŸ“‹ markdownä¸­æ‰¾åˆ°çš„placeholder: {debug_matches}")
                return None
        
        def replace_with_new_result(match):
            # è·å–åŸå§‹çš„placeholderå’Œå›¾ç‰‡å¼•ç”¨éƒ¨åˆ†
            matched_text = match.group(0)
            
            # æå–placeholderå’Œå›¾ç‰‡å¼•ç”¨ï¼ˆå»æ‰å¯èƒ½å­˜åœ¨çš„åˆ†æç»“æœï¼‰
            placeholder_img_pattern = rf'(\[placeholder:\s*{escaped_type}\]\s*\n!\[[^\]]*\]\([^)]*{escaped_filename}[^)]*\))'
            placeholder_img_match = re.search(placeholder_img_pattern, matched_text)
            
            if placeholder_img_match:
                placeholder_and_img = placeholder_img_match.group(1)
            else:
                # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨æ•´ä¸ªåŒ¹é…çš„å¼€å¤´éƒ¨åˆ†
                lines = matched_text.split('\n')
                if len(lines) >= 2:
                    placeholder_and_img = f"{lines[0]}\n{lines[1]}"
                else:
                    placeholder_and_img = matched_text
            
            # æ„å»ºæ–°çš„å†…å®¹
            if item_type == 'image':
                return f"{placeholder_and_img}\n\n**å›¾ç‰‡åˆ†æ:** {result_text}\n"
            elif item_type in ['formula', 'interline_equation']:
                return f"{placeholder_and_img}\n\n{result_text}\n"
            elif item_type == 'table':
                return f"{placeholder_and_img}\n\n**è¡¨æ ¼å†…å®¹:**\n{result_text}\n"
            else:
                return f"{placeholder_and_img}\n\n**åˆ†æç»“æœ:**\n{result_text}\n"
        
        # æ‰§è¡Œæ›¿æ¢
        updated_content = re.sub(pattern_to_use, replace_with_new_result, md_content, flags=flags)
        
        # æ£€æŸ¥æ˜¯å¦å®é™…è¿›è¡Œäº†æ›¿æ¢
        if updated_content != md_content:
            return updated_content
        else:
            print(f"âš ï¸  æ²¡æœ‰è¿›è¡Œä»»ä½•æ›¿æ¢ï¼Œä½¿ç”¨çš„æ¨¡å¼: {pattern_to_use}")
            return None

class PDFPostProcessor:
    """PDFåå¤„ç†å™¨ï¼Œç”¨äºå¤„ç†å›¾ç‰‡ã€å…¬å¼ã€è¡¨æ ¼çš„æ ‡ç­¾æ›¿æ¢"""
    
    def __init__(self, debug: bool = False):
        self.debug = debug
        self.script_dir = Path(__file__).parent
        
        # Use UNIMERNET tool for formula/table recognition instead of MinerU
        self.unimernet_tool = self.script_dir / "UNIMERNET"
        
        # Import MinerUWrapper for image processing only
        sys.path.insert(0, str(self.script_dir / "EXTRACT_PDF_PROJ"))
        from mineru_wrapper import MinerUWrapper
        self.mineru_wrapper = MinerUWrapper()
    
    def process_file_unified(self, file_path: str, process_type: str, specific_ids: str = None, custom_prompt: str = None, force: bool = False) -> bool:
        """
        ç»Ÿä¸€çš„åå¤„ç†æ¥å£ - ä¸ä¾èµ–äºæå–æ¨¡å¼
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„æˆ–markdownæ–‡ä»¶è·¯å¾„
            process_type: å¤„ç†ç±»å‹ ('image', 'formula', 'table', 'all')
            specific_ids: ç‰¹å®šIDåˆ—è¡¨æˆ–å…³é”®è¯
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        file_path = Path(file_path)
        
        # ç¡®å®šPDFæ–‡ä»¶å’Œmarkdownæ–‡ä»¶è·¯å¾„
        if file_path.suffix == '.pdf':
            pdf_file_path = file_path
            md_file = file_path.parent / f"{file_path.stem}.md"
        elif file_path.suffix == '.md':
            md_file = file_path
            # å°è¯•æ‰¾åˆ°å¯¹åº”çš„PDFæ–‡ä»¶
            pdf_file_path = file_path.parent / f"{file_path.stem}.pdf"
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path.suffix}")
            return False
            
        if not md_file.exists():
            print(f"âŒ Markdownæ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
            return False
            
        print(f"ğŸ”„ å¼€å§‹ç»Ÿä¸€åå¤„ç† {md_file.name}...")
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šç¡®ä¿æœ‰postprocessçŠ¶æ€æ–‡ä»¶
            status_file = self._ensure_postprocess_status_file(pdf_file_path, md_file)
            if not status_file:
                print("âŒ æ— æ³•åˆ›å»ºæˆ–æ‰¾åˆ°çŠ¶æ€æ–‡ä»¶")
                return False
            
            # ç¬¬äºŒæ­¥ï¼šè¯»å–çŠ¶æ€æ–‡ä»¶
            with open(status_file, 'r', encoding='utf-8') as f:
                status_data = json.load(f)
            
            # ç¬¬ä¸‰æ­¥ï¼šåŒæ­¥markdownå’ŒJSONä¸­çš„placeholderä¿¡æ¯
            print("ğŸ”„ åŒæ­¥markdownå’ŒJSONä¸­çš„placeholderä¿¡æ¯...")
            status_data = self._sync_placeholders_with_markdown(md_file, status_data, status_file)
            
            # ç¬¬å››æ­¥ï¼šç­›é€‰è¦å¤„ç†çš„é¡¹ç›®
            items_to_process = self._filter_items_to_process(status_data, process_type, specific_ids, force)
            
            if not items_to_process:
                print("â„¹ï¸  æ²¡æœ‰éœ€è¦å¤„ç†çš„é¡¹ç›®")
                return True
            
            # ç¬¬äº”æ­¥ï¼šä½¿ç”¨ç»Ÿä¸€çš„æ··åˆå¤„ç†æ–¹å¼
            success = self._process_items_unified(str(pdf_file_path), str(md_file), status_data, 
                                                items_to_process, process_type, custom_prompt, force)
            
            return success
            
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€åå¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def _ensure_postprocess_status_file(self, pdf_file_path: Path, md_file: Path) -> Optional[Path]:
        """ç¡®ä¿å­˜åœ¨postprocessçŠ¶æ€æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
        status_file = pdf_file_path.parent / f"{pdf_file_path.stem}_postprocess.json"
        
        if status_file.exists():
            return status_file
        
        print("ğŸ“„ çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»markdowné‡æ–°ç”Ÿæˆ...")
        
        # ä»markdownæ–‡ä»¶åˆ†æplaceholderï¼Œåˆ›å»ºçŠ¶æ€æ–‡ä»¶
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾æ‰€æœ‰placeholderå’Œå›¾ç‰‡å¼•ç”¨
            import re
            # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…åŒ…å«åˆ†æç»“æœçš„å®Œæ•´placeholderå—
            # è¿™ä¸ªæ¨¡å¼åŒ¹é…ï¼š[placeholder: type]\n![...](path) åé¢å¯èƒ½è·Ÿç€åˆ†æç»“æœ
            placeholder_pattern = r'\[placeholder:\s*(\w+)\]\s*\n!\[[^\]]*\]\(([^)]+)\)(?:\s*\n\n\*\*[^*]+\*\*.*?)?'
            matches = re.findall(placeholder_pattern, content, re.DOTALL)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°placeholderï¼Œæ— éœ€åå¤„ç†")
                return None
            
            # åˆ›å»ºçŠ¶æ€æ•°æ®
            from datetime import datetime
            status_data = {
                "pdf_file": str(pdf_file_path),
                "created_at": datetime.now().isoformat(),
                "page_range": None,
                "total_items": len(matches),
                "processed_items": 0,
                "items": []
            }
            
            # æ·»åŠ é¡¹ç›®
            for item_type, image_path in matches:
                # ä»å›¾ç‰‡è·¯å¾„æå–hash ID
                image_filename = Path(image_path).name
                hash_id = Path(image_path).stem
                
                item = {
                    "id": hash_id,
                    "type": item_type,
                    "filename": image_filename,
                    "image_path": image_path,
                    "processor": "unified_processor",
                    "processed": False,
                    "placeholder": f"[placeholder: {item_type}]",
                    "bbox": [],
                    "page": 1  # é»˜è®¤é¡µç 
                }
                status_data["items"].append(item)
            
            # ä¿å­˜çŠ¶æ€æ–‡ä»¶
            with open(status_file, 'w', encoding='utf-8') as f:
                json.dump(status_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åˆ›å»ºçŠ¶æ€æ–‡ä»¶: {status_file.name}")
            return status_file
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºçŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _filter_items_to_process(self, status_data: dict, process_type: str, specific_ids: str, force: bool) -> list:
        """ç­›é€‰éœ€è¦å¤„ç†çš„é¡¹ç›®"""
        items_to_process = []
        
        for item in status_data.get('items', []):
            # è·³è¿‡å·²å¤„ç†çš„é¡¹ç›®ï¼ˆé™¤éå¼ºåˆ¶é‡æ–°å¤„ç†ï¼‰
            if item.get('processed', False) and not force:
                continue
            
            item_type = item.get('type')
            item_id = item.get('id')
            
            # æ ¹æ®å¤„ç†ç±»å‹ç­›é€‰
            if process_type != 'all':
                if process_type == 'image' and item_type != 'image':
                    continue
                elif process_type == 'formula' and item_type not in ['formula', 'interline_equation']:
                    continue
                elif process_type == 'table' and item_type != 'table':
                    continue
            
            # æ ¹æ®specific_idsç­›é€‰
            if specific_ids:
                if specific_ids in ['all_images', 'all_formulas', 'all_tables', 'all']:
                    if specific_ids == 'all':
                        pass  # å¤„ç†æ‰€æœ‰ç±»å‹
                    elif specific_ids == 'all_images' and item_type != 'image':
                        continue
                    elif specific_ids == 'all_formulas' and item_type not in ['formula', 'interline_equation']:
                        continue
                    elif specific_ids == 'all_tables' and item_type != 'table':
                        continue
                else:
                    # å…·ä½“çš„hash IDåˆ—è¡¨
                    target_ids = [id.strip() for id in specific_ids.split(',')]
                    if item_id not in target_ids:
                        continue
            
            items_to_process.append(item_id)
        
        return items_to_process
    
    def _process_items_unified(self, pdf_file: str, md_file: str, status_data: dict, 
                             items_to_process: list, process_type: str, custom_prompt: str = None, force: bool = False) -> bool:
        """ç»Ÿä¸€çš„é¡¹ç›®å¤„ç†æ–¹æ³•"""
        try:
            # è¯»å–markdownæ–‡ä»¶
            with open(md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # å¤„ç†æ¯ä¸ªé¡¹ç›®
            updated = False
            for item_id in items_to_process:
                # æ‰¾åˆ°å¯¹åº”çš„é¡¹ç›®
                item = None
                for status_item in status_data.get('items', []):
                    if status_item.get('id') == item_id:
                        item = status_item
                        break
                
                if not item:
                    print(f"âš ï¸  æœªæ‰¾åˆ°é¡¹ç›®: {item_id}")
                    continue
                
                item_type = item.get('type')
                image_path = item.get('image_path', '')
                
                if not image_path:
                    print(f"âš ï¸  å›¾ç‰‡è·¯å¾„ä¸ºç©º: {item_id}")
                    continue
                
                # æŸ¥æ‰¾å®é™…çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„
                actual_image_path = self._find_actual_image_path(pdf_file, image_path)
                if not actual_image_path:
                    print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue
                
                print(f"ğŸ”„ å¤„ç† {item_type} é¡¹ç›®: {item_id}")
                
                # æ ¹æ®ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
                result_text = ""
                if item_type == 'image':
                    result_text = self._process_image_with_api(actual_image_path, custom_prompt)
                elif item_type in ['formula', 'interline_equation']:
                    result_text = self._process_with_unimernet(actual_image_path, "formula", force)
                elif item_type == 'table':
                    result_text = self._process_with_unimernet(actual_image_path, "table", force)
                
                if result_text:
                    # æ›´æ–°markdownå†…å®¹
                    success = self._update_markdown_with_result(md_content, item, result_text)
                    if success:
                        md_content = success
                        item['processed'] = True
                        updated = True
                        print(f"âœ… å®Œæˆ {item_type} å¤„ç†: {item_id}")
                    else:
                        print(f"âš ï¸  æ›´æ–°markdownå¤±è´¥: {item_id}")
                else:
                    print(f"âŒ å¤„ç†å¤±è´¥: {item_id}")
            
            if updated:
                # ä¿å­˜æ›´æ–°çš„markdownæ–‡ä»¶
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(md_content)
                
                # æ›´æ–°çŠ¶æ€æ–‡ä»¶
                status_file = Path(pdf_file).parent / f"{Path(pdf_file).stem}_postprocess.json"
                with open(status_file, 'w', encoding='utf-8') as f:
                    json.dump(status_data, f, indent=2, ensure_ascii=False)
                
                print(f"ğŸ“ å·²æ›´æ–°æ–‡ä»¶: {Path(md_file).name}")
                return True
            else:
                print("â„¹ï¸  æ²¡æœ‰å†…å®¹éœ€è¦æ›´æ–°")
                return True
                
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€å¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def _update_markdown_with_result(self, md_content: str, item: dict, result_text: str) -> Optional[str]:
        """æ›´æ–°markdownå†…å®¹ï¼Œä¿ç•™placeholderï¼Œæ¸…é™¤å·²æœ‰åˆ†æç»“æœå¹¶æ›¿æ¢ä¸ºæ–°ç»“æœ"""
        import re
        
        item_type = item.get('type')
        image_path = item.get('image_path', '')
        
        # æ„å»ºæ›´å¤æ‚çš„æ¨¡å¼æ¥åŒ¹é…æ•´ä¸ªå—ï¼ˆåŒ…æ‹¬å¯èƒ½å­˜åœ¨çš„åˆ†æç»“æœï¼‰
        # å…ˆå°è¯•åŒ¹é…å·²ç»åŒ…å«åˆ†æç»“æœçš„å®Œæ•´å—
        image_filename = Path(image_path).name
        escaped_filename = re.escape(image_filename)
        escaped_type = re.escape(item_type)
        
        # æ¨¡å¼1: åŒ¹é…åŒ…å«åˆ†æç»“æœçš„å®Œæ•´å—
        # [placeholder: type]\n![...](path)\n\n**åˆ†æç»“æœ:**...\n ç›´åˆ°ä¸‹ä¸€ä¸ªç©ºè¡Œæˆ–æ–‡ä»¶ç»“æŸ
        complete_block_pattern = (
            rf'\[placeholder:\s*{escaped_type}\]\s*\n'
            rf'!\[[^\]]*\]\([^)]*{escaped_filename}\)[^)]*\)\s*\n'
            rf'(?:\n\*\*å›¾ç‰‡åˆ†æ:\*\*.*?(?=\n\n|\n#|\Z))?'
            rf'(?:\n\n\*\*å›¾ç‰‡åˆ†æ:\*\*.*?(?=\n\n|\n#|\Z))?'
            rf'(?:\n\*\*è¡¨æ ¼å†…å®¹:\*\*.*?(?=\n\n|\n#|\Z))?'
            rf'(?:\n\*\*åˆ†æç»“æœ:\*\*.*?(?=\n\n|\n#|\Z))?'
        )
        
        # æ¨¡å¼2: ç®€å•åŒ¹é…placeholderå’Œå›¾ç‰‡ï¼ˆæ²¡æœ‰åˆ†æç»“æœçš„æƒ…å†µï¼‰
        simple_pattern = (
            rf'\[placeholder:\s*{escaped_type}\]\s*\n'
            rf'!\[[^\]]*\]\([^)]*{escaped_filename}\)[^)]*\)'
        )
        
        # å…ˆå°è¯•å®Œæ•´å—æ¨¡å¼
        if re.search(complete_block_pattern, md_content, re.DOTALL):
            pattern_to_use = complete_block_pattern
            flags = re.DOTALL
        elif re.search(simple_pattern, md_content):
            pattern_to_use = simple_pattern
            flags = 0
        else:
            # å°è¯•æ›´å®½æ¾çš„åŒ¹é…ï¼ˆåªåŒ¹é…æ–‡ä»¶åï¼‰
            loose_pattern = rf'\[placeholder:\s*{escaped_type}\]\s*\n!\[[^\]]*\]\([^)]*{escaped_filename}[^)]*\)'
            if re.search(loose_pattern, md_content):
                pattern_to_use = loose_pattern
                flags = 0
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„placeholderæ¨¡å¼")
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºmarkdownä¸­å®é™…å­˜åœ¨çš„placeholder
                debug_pattern = r'\[placeholder:\s*(\w+)\]\s*!\[[^\]]*\]\(([^)]+)\)'
                debug_matches = re.findall(debug_pattern, md_content)
                if debug_matches:
                    print(f"ğŸ“‹ markdownä¸­æ‰¾åˆ°çš„placeholder: {debug_matches}")
                return None
        
        def replace_with_new_result(match):
            # è·å–åŸå§‹çš„placeholderå’Œå›¾ç‰‡å¼•ç”¨éƒ¨åˆ†
            matched_text = match.group(0)
            
            # æå–placeholderå’Œå›¾ç‰‡å¼•ç”¨ï¼ˆå»æ‰å¯èƒ½å­˜åœ¨çš„åˆ†æç»“æœï¼‰
            placeholder_img_pattern = rf'(\[placeholder:\s*{escaped_type}\]\s*\n!\[[^\]]*\]\([^)]*{escaped_filename}[^)]*\))'
            placeholder_img_match = re.search(placeholder_img_pattern, matched_text)
            
            if placeholder_img_match:
                placeholder_and_img = placeholder_img_match.group(1)
            else:
                # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨æ•´ä¸ªåŒ¹é…çš„å¼€å¤´éƒ¨åˆ†
                lines = matched_text.split('\n')
                if len(lines) >= 2:
                    placeholder_and_img = f"{lines[0]}\n{lines[1]}"
                else:
                    placeholder_and_img = matched_text
            
            # æ„å»ºæ–°çš„å†…å®¹
            if item_type == 'image':
                return f"{placeholder_and_img}\n\n**å›¾ç‰‡åˆ†æ:** {result_text}\n"
            elif item_type in ['formula', 'interline_equation']:
                return f"{placeholder_and_img}\n\n{result_text}\n"
            elif item_type == 'table':
                return f"{placeholder_and_img}\n\n**è¡¨æ ¼å†…å®¹:**\n{result_text}\n"
            else:
                return f"{placeholder_and_img}\n\n**åˆ†æç»“æœ:**\n{result_text}\n"
        
        # æ‰§è¡Œæ›¿æ¢
        updated_content = re.sub(pattern_to_use, replace_with_new_result, md_content, flags=flags)
        
        # æ£€æŸ¥æ˜¯å¦å®é™…è¿›è¡Œäº†æ›¿æ¢
        if updated_content != md_content:
            return updated_content
        else:
            print(f"âš ï¸  æ²¡æœ‰è¿›è¡Œä»»ä½•æ›¿æ¢ï¼Œä½¿ç”¨çš„æ¨¡å¼: {pattern_to_use}")
            return None
    
    def _find_actual_image_path(self, pdf_file: str, image_filename: str) -> Optional[str]:
        """æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶çš„å®é™…è·¯å¾„"""
        pdf_path = Path(pdf_file)
        pdf_directory = pdf_path.parent
        
        # æ£€æŸ¥å¯èƒ½çš„å›¾ç‰‡ä½ç½®
        possible_locations = [
            Path(image_filename),  # ç»å¯¹è·¯å¾„
            pdf_directory / image_filename,  # ç›¸å¯¹äºPDFçš„è·¯å¾„
            pdf_directory / "images" / Path(image_filename).name,  # PDFç›®å½•ä¸‹çš„imagesæ–‡ä»¶å¤¹
            get_pdf_extractor_data_dir() / "images" / Path(image_filename).name,  # ç»Ÿä¸€æ•°æ®ç›®å½•
        ]
        
        for location in possible_locations:
            if location.exists():
                return str(location)
        
        return None
    
    def _process_image_with_api(self, image_path: str, custom_prompt: str = None) -> str:
        """ä½¿ç”¨IMG2TEXT APIå¤„ç†å›¾ç‰‡"""
        try:
            # è°ƒç”¨IMG2TEXTå·¥å…·
            img2text_path = self.script_dir / "IMG2TEXT"
            if not img2text_path.exists():
                return "IMG2TEXTå·¥å…·ä¸å¯ç”¨"
            
            cmd = [str(img2text_path), image_path, "--json"]
            if custom_prompt:
                cmd.extend(["--prompt", custom_prompt])
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                try:
                    # å°è¯•è§£æJSONè¾“å‡º
                    output_data = json.loads(result.stdout)
                    if output_data.get('success'):
                        description = output_data.get('result', 'å›¾ç‰‡åˆ†æå®Œæˆ')
                        return description
                    else:
                        error_msg = output_data.get('error', 'Unknown error')
                        return f"å›¾ç‰‡åˆ†æå¤±è´¥: {error_msg}"
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨è¾“å‡º
                    return result.stdout.strip() if result.stdout.strip() else "å›¾ç‰‡åˆ†æå®Œæˆ"
            else:
                return f"IMG2TEXTæ‰§è¡Œå¤±è´¥: {result.stderr}"
                
        except Exception as e:
            return f"å›¾ç‰‡å¤„ç†å¼‚å¸¸: {e}"
    
    def _sync_placeholders_with_markdown(self, md_file: Path, status_data: dict, status_file: Path) -> dict:
        """åŒæ­¥markdownå’ŒJSONæ–‡ä»¶ä¸­çš„placeholderä¿¡æ¯"""
        try:
            # è¯»å–markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾æ‰€æœ‰placeholderå’Œå›¾ç‰‡å¼•ç”¨
            import re
            # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…åŒ…å«åˆ†æç»“æœçš„å®Œæ•´placeholderå—
            # è¿™ä¸ªæ¨¡å¼åŒ¹é…ï¼š[placeholder: type]\n![...](path) åé¢å¯èƒ½è·Ÿç€åˆ†æç»“æœ
            placeholder_pattern = r'\[placeholder:\s*(\w+)\]\s*\n!\[[^\]]*\]\(([^)]+)\)(?:\s*\n\n\*\*[^*]+\*\*.*?)?'
            matches = re.findall(placeholder_pattern, content, re.DOTALL)
            
            # æ›´æ–°çŠ¶æ€æ•°æ®ä¸­çš„é¡¹ç›®
            existing_items = {item.get('id'): item for item in status_data.get('items', [])}
            updated_items = []
            
            for item_type, image_path in matches:
                # ä»å›¾ç‰‡è·¯å¾„æå–hash ID
                image_filename = Path(image_path).name
                hash_id = Path(image_path).stem
                
                # å¦‚æœé¡¹ç›®å·²å­˜åœ¨ï¼Œä¿æŒå…¶processedçŠ¶æ€
                if hash_id in existing_items:
                    existing_item = existing_items[hash_id]
                    existing_item.update({
                        "type": item_type,
                        "filename": image_filename,
                        "image_path": image_path,
                        "placeholder": f"[placeholder: {item_type}]"
                    })
                    updated_items.append(existing_item)
                else:
                    # æ–°é¡¹ç›®
                    item = {
                        "id": hash_id,
                        "type": item_type,
                        "filename": image_filename,
                        "image_path": image_path,
                        "processor": "unified_processor",
                        "processed": False,
                        "placeholder": f"[placeholder: {item_type}]",
                        "bbox": [],
                        "page": 1
                    }
                    updated_items.append(item)
            
            # æ›´æ–°çŠ¶æ€æ•°æ®
            status_data["items"] = updated_items
            status_data["total_items"] = len(updated_items)
            status_data["processed_items"] = sum(1 for item in updated_items if item.get('processed', False))
            
            # ä¿å­˜æ›´æ–°çš„çŠ¶æ€æ–‡ä»¶
            with open(status_file, 'w', encoding='utf-8') as f:
                json.dump(status_data, f, ensure_ascii=False, indent=2)
            
            return status_data
            
        except Exception as e:
            print(f"âŒ åŒæ­¥placeholderä¿¡æ¯å¤±è´¥: {e}")
            return status_data
    
    def _process_with_unimernet(self, image_path: str, content_type: str = "auto", force: bool = False) -> str:
        """ä½¿ç”¨UNIMERNETå·¥å…·å¤„ç†å…¬å¼æˆ–è¡¨æ ¼å›¾ç‰‡"""
        try:
            # ä½¿ç”¨EXTRACT_IMGå·¥å…·ï¼ˆæ•´åˆäº†UNIMERNETå’Œcacheï¼‰
            extract_img_tool = self.script_dir / "EXTRACT_IMG"
            if not extract_img_tool.exists():
                print(f"âš ï¸  EXTRACT_IMGå·¥å…·ä¸å¯ç”¨: {extract_img_tool}")
                return ""
            
            # æ„å»ºEXTRACT_IMGå‘½ä»¤
            cmd = [str(extract_img_tool), image_path, "--json"]
            if content_type != "auto":
                cmd.extend(["--type", content_type])
            else:
                cmd.extend(["--type", "formula"])  # Default to formula for UNIMERNET
            
            # æ·»åŠ forceå‚æ•°
            if force:
                cmd.append("--force")
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                # è§£æEXTRACT_IMGçš„JSONè¾“å‡º
                try:
                    extract_result = json.loads(result.stdout)
                    if extract_result.get('success'):
                        recognition_result = extract_result.get('result', '')
                        if recognition_result:
                            # Check if it's from cache
                            cache_info = " (æ¥è‡ªç¼“å­˜)" if extract_result.get('from_cache') else ""
                            # Get processing time if available
                            processing_time = extract_result.get('processing_time', 0)
                            time_info = f" (è€—æ—¶: {processing_time:.2f}ç§’)" if processing_time > 0 else ""
                            print(f"âœ… EXTRACT_IMGè¯†åˆ«æˆåŠŸ{cache_info}{time_info}: {len(recognition_result)} å­—ç¬¦")
                            # Directly format as $$ without description wrapper
                            cleaned_result = recognition_result.strip()
                            return f"$$\n{cleaned_result}\n$$"
                        else:
                            print("âš ï¸  EXTRACT_IMGè¿”å›ç©ºç»“æœ")
                            return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: EXTRACT_IMGè¿”å›ç©ºç»“æœ\n```"
                    else:
                        error_msg = extract_result.get('error', 'Unknown error')
                        print(f"âŒ EXTRACT_IMGå¤„ç†å¤±è´¥: {error_msg}")
                        return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: {error_msg}\n```"
                except json.JSONDecodeError as e:
                    error_msg = f"JSONè§£æå¤±è´¥: {e}\nåŸå§‹è¾“å‡º: {result.stdout[:200]}..."
                    print(f"âŒ æ— æ³•è§£æEXTRACT_IMG JSONè¾“å‡º: {e}")
                    print(f"   åŸå§‹è¾“å‡º: {result.stdout[:200]}...")
                    return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: {error_msg}\n```"
            else:
                error_msg = f"EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}"
                print(f"âŒ EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: {error_msg}\n```"
                
        except Exception as e:
            print(f"âŒ UNIMERNETå¤„ç†å¼‚å¸¸: {e}")
            return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: UNIMERNETå¤„ç†å¼‚å¸¸: {e}\n```"
    
    def _process_items_hybrid(self, pdf_file: str, md_file: str, status_data: dict, 
                             items_to_process: list, process_type: str, custom_prompt: str = None, force: bool = False) -> bool:
        """ä½¿ç”¨æ··åˆæ–¹å¼å¤„ç†é¡¹ç›®ï¼šå›¾åƒç”¨ä¼ ç»ŸAPIï¼Œå…¬å¼è¡¨æ ¼ç”¨UNIMERNET"""
        try:
            # è¯»å–markdownæ–‡ä»¶
            with open(md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # å¤„ç†æ¯ä¸ªé¡¹ç›®
            updated = False
            for item_id in items_to_process:
                # åœ¨status_dataä¸­æ‰¾åˆ°å¯¹åº”çš„é¡¹ç›®
                item = None
                for status_item in status_data.get('items', []):
                    status_item_id = status_item.get('id')
                    if not status_item_id:
                        # ä»image_pathç”ŸæˆID
                        image_path = status_item.get('image_path', '')
                        if image_path:
                            status_item_id = Path(image_path).stem
                    
                    if status_item_id == item_id:
                        item = status_item
                        break
                
                if not item:
                    print(f"âš ï¸  æœªæ‰¾åˆ°é¡¹ç›®: {item_id}")
                    continue
                
                if item.get('processed', False) and not force:
                    print(f"â­ï¸  è·³è¿‡å·²å¤„ç†é¡¹ç›®: {item_id}")
                    continue
                elif item.get('processed', False) and force:
                    print(f"ğŸ”„ å¼ºåˆ¶é‡æ–°å¤„ç†é¡¹ç›®: {item_id}")
                
                item_type = item.get('type')
                image_path = item.get('image_path', '')
                
                if not image_path:
                    print(f"âš ï¸  å›¾ç‰‡è·¯å¾„ä¸ºç©º: {item_id}")
                    continue
                
                # æŸ¥æ‰¾å®é™…çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„
                actual_image_path = self._find_actual_image_path(pdf_file, image_path)
                if not actual_image_path:
                    print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue
                
                print(f"ğŸ”„ å¤„ç† {item_type} é¡¹ç›®: {item_id}")
                
                # æ ¹æ®ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
                result_text = ""
                if item_type == 'image':
                    # å›¾åƒä½¿ç”¨ä¼ ç»Ÿçš„å›¾åƒAPIï¼ˆé€šè¿‡MinerU wrapperï¼‰
                    result_text = self._process_image_with_api(actual_image_path, custom_prompt)
                elif item_type in ['formula', 'interline_equation']:
                    # å…¬å¼ä½¿ç”¨UNIMERNET
                    result_text = self._process_with_unimernet(actual_image_path, "formula", force)
                elif item_type == 'table':
                    # è¡¨æ ¼ä½¿ç”¨UNIMERNET
                    result_text = self._process_with_unimernet(actual_image_path, "table", force)
                
                if result_text:
                    # æ›´æ–°markdownæ–‡ä»¶ä¸­çš„å ä½ç¬¦ - ä½¿ç”¨æ–°çš„placeholderæ ¼å¼
                    # æŸ¥æ‰¾ [placeholder: type] å’Œå¯¹åº”çš„å›¾ç‰‡è¡Œ
                    import re
                    
                    # æ„å»ºå›¾ç‰‡è·¯å¾„çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ”¯æŒç»å¯¹å’Œç›¸å¯¹è·¯å¾„ï¼‰
                    image_filename = Path(image_path).name
                    # åŒ¹é…placeholderå’Œå›¾ç‰‡ï¼Œä»¥åŠå¯èƒ½å­˜åœ¨çš„descriptionæˆ–reason
                    # ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œè€ƒè™‘åˆ°reasonå—å¯èƒ½åŒ…å«åµŒå¥—çš„æ–¹æ‹¬å·
                    placeholder_pattern = rf'\[placeholder:\s*{item_type}\]\s*\n!\[[^\]]*\]\([^)]*{re.escape(image_filename)}\)(\s*\n\n\[(description|reason):.*?\n\n---+\])?'
                    
                    # Check if result_text contains error information
                    is_error = any(error_keyword in result_text for error_keyword in 
                                  ["å¤±è´¥", "é”™è¯¯ä¿¡æ¯", "å¤„ç†å¼‚å¸¸", "æ‰§è¡Œå¤±è´¥", "è§£æå¤±è´¥"])
                    
                    # Use absolute path for images
                    abs_image_path = get_pdf_extractor_data_dir() / "images" / image_filename
                    
                    if is_error:
                        # For errors, keep placeholder and add error info below image
                        replacement = f"[placeholder: {item_type}]\n![]({abs_image_path})\n\n[description: {result_text}]"
                    else:
                        # For successful processing
                        if item_type in ['formula', 'interline_equation', 'table'] and result_text.strip().startswith('$$') and result_text.strip().endswith('$$'):
                            # For formulas and tables already in $$ format, don't add description wrapper
                            replacement = f"[placeholder: {item_type}]\n![]({abs_image_path})\n\n{result_text}"
                        else:
                            # For image content and other types, keep placeholder and add description below image
                            replacement = f"[placeholder: {item_type}]\n![]({abs_image_path})\n\n[description: {result_text}]"
                    
                    if re.search(placeholder_pattern, md_content, re.DOTALL):
                        # Use lambda to avoid regex interpretation of replacement string
                        md_content = re.sub(placeholder_pattern, lambda m: replacement, md_content, flags=re.DOTALL)
                        
                        # Additional cleanup: remove any remaining fragments of old reason/description blocks
                        # This handles cases where the regex didn't capture the complete block
                        cleanup_pattern = rf'----+\]\s*.*?ä½¿ç”¨.*?å¯†é’¥æ—¶å¤±è´¥.*?\n\n---+\]'
                        md_content = re.sub(cleanup_pattern, '', md_content, flags=re.DOTALL)
                        
                        updated = True
                        
                        # æ ‡è®°ä¸ºå·²å¤„ç†
                        item['processed'] = True
                        if is_error:
                            print(f"âš ï¸  å¤„ç†å¤±è´¥ä½†å·²è®°å½•é”™è¯¯ä¿¡æ¯: {item_id}")
                        else:
                            print(f"âœ… å®Œæˆ {item_type} å¤„ç†: {item_id}")
                    else:
                        print(f"âš ï¸  æœªæ‰¾åˆ°å ä½ç¬¦æ¨¡å¼: [placeholder: {item_type}] + image {image_filename}")
                        if self.debug:
                            print(f"   è°ƒè¯•ï¼šæœç´¢æ¨¡å¼: {placeholder_pattern}")
                            # æ˜¾ç¤ºmarkdownå†…å®¹çš„å‰å‡ è¡Œä»¥ä¾¿è°ƒè¯•
                            lines = md_content.split('\n')[:20]
                            print("   è°ƒè¯•ï¼šmarkdownå‰20è¡Œ:")
                            for i, line in enumerate(lines):
                                print(f"   {i+1:2d}: {line}")
                else:
                    print(f"âŒ å¤„ç†å¤±è´¥: {item_id}")
            
            if updated:
                # ä¿å­˜æ›´æ–°çš„markdownæ–‡ä»¶
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(md_content)
                
                # æ›´æ–°çŠ¶æ€æ–‡ä»¶
                status_file = Path(pdf_file).parent / f"{Path(pdf_file).stem}_postprocess.json"
                with open(status_file, 'w', encoding='utf-8') as f:
                    json.dump(status_data, f, indent=2, ensure_ascii=False)
                
                print(f"ğŸ“ å·²æ›´æ–°æ–‡ä»¶: {Path(md_file).name}")
                return True
            else:
                print("â„¹ï¸  æ²¡æœ‰å†…å®¹éœ€è¦æ›´æ–°")
                return True
                
        except Exception as e:
            print(f"âŒ æ··åˆå¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def _process_image_with_api(self, image_path: str, custom_prompt: str = None) -> str:
        """ä½¿ç”¨EXTRACT_IMGå·¥å…·å¤„ç†å›¾åƒ"""
        try:
            print(f"ğŸ–¼ï¸  ä½¿ç”¨EXTRACT_IMGå¤„ç†: {Path(image_path).name}")
            
            # è°ƒç”¨EXTRACT_IMGå·¥å…·ï¼ˆæ•´åˆäº†IMG2TEXTå’Œcacheï¼‰
            extract_img_tool = self.script_dir / "EXTRACT_IMG"
            if not extract_img_tool.exists():
                print(f"âš ï¸  EXTRACT_IMGå·¥å…·ä¸å¯ç”¨: {extract_img_tool}")
                return ""
            
            cmd = [str(extract_img_tool), image_path, "--type", "image", "--mode", "academic", "--json"]
            if custom_prompt:
                cmd.extend(["--prompt", custom_prompt])
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                # è§£æEXTRACT_IMGçš„JSONè¾“å‡º
                try:
                    extract_result = json.loads(result.stdout)
                    if extract_result.get('success'):
                        analysis_result = extract_result.get('result', '')
                        if analysis_result:
                            # Check if it's from cache
                            cache_info = " (æ¥è‡ªç¼“å­˜)" if extract_result.get('from_cache') else ""
                            print(f"âœ… EXTRACT_IMGåˆ†æå®Œæˆ{cache_info}: {len(analysis_result)} å­—ç¬¦")
                            return f"--- å›¾åƒåˆ†æç»“æœ ---\n\n{analysis_result}\n\n--------------------"
                        else:
                            print("âš ï¸  EXTRACT_IMGè¿”å›ç©ºç»“æœ")
                            return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: EXTRACT_IMGè¿”å›ç©ºç»“æœ\n\n--------------------"
                    else:
                        error_msg = extract_result.get('error', 'Unknown error')
                        print(f"âŒ EXTRACT_IMGå¤„ç†å¤±è´¥: {error_msg}")
                        return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n-------------------"
                except json.JSONDecodeError as e:
                    error_msg = f"JSONè§£æå¤±è´¥: {e}\nåŸå§‹è¾“å‡º: {result.stdout[:200]}..."
                    print(f"âŒ æ— æ³•è§£æEXTRACT_IMG JSONè¾“å‡º: {e}")
                    print(f"   åŸå§‹è¾“å‡º: {result.stdout[:200]}...")
                    return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n--------------------"
            else:
                error_msg = f"EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}"
                print(f"âŒ EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n--------------------"
                
        except Exception as e:
            print(f"âŒ IMG2TEXTå¤„ç†å¼‚å¸¸: {e}")
            return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: IMG2TEXTå¤„ç†å¼‚å¸¸: {e}\n\n--------------------"
    
    def _select_markdown_file_interactive(self) -> str:
        """äº¤äº’å¼é€‰æ‹©markdownæ–‡ä»¶"""
        print("ğŸ” é€‰æ‹©markdownæ–‡ä»¶è¿›è¡Œåå¤„ç†...")
        
        # ä½¿ç”¨FILEDIALOGå·¥å…·é€‰æ‹©æ–‡ä»¶
        try:
            filedialog_path = self.script_dir / "FILEDIALOG"
            if not filedialog_path.exists():
                print("âš ï¸  FILEDIALOGå·¥å…·ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼é€‰æ‹©æ–‡ä»¶")
                return self._select_markdown_file_traditional()
            
            # è°ƒç”¨FILEDIALOGå·¥å…·é€‰æ‹©.mdæ–‡ä»¶
            cmd = [str(filedialog_path), '--types', 'md', '--title', 'Select Markdown File for Post-processing']
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                # è§£æFILEDIALOGçš„è¾“å‡º
                output_text = result.stdout.strip()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯"âœ… Selected file:"æ ¼å¼çš„è¾“å‡º
                if "âœ… Selected file:" in output_text:
                    lines = output_text.split('\n')
                    for line in lines:
                        if "âœ… Selected file:" in line:
                            selected_file = line.split("âœ… Selected file: ", 1)[1].strip()
                            if selected_file and Path(selected_file).exists():
                                print(f"âœ… å·²é€‰æ‹©: {Path(selected_file).name}")
                                return selected_file
                            break
                    print("âŒ æ— æ³•è§£æé€‰æ‹©çš„æ–‡ä»¶è·¯å¾„")
                    return None
                else:
                    # å°è¯•è§£æJSONè¾“å‡ºï¼ˆRUNç¯å¢ƒä¸‹ï¼‰
                    try:
                        output_data = json.loads(output_text)
                        if output_data.get('success') and output_data.get('selected_file'):
                            selected_file = output_data['selected_file']
                            print(f"âœ… å·²é€‰æ‹©: {Path(selected_file).name}")
                            return selected_file
                        else:
                            print("âŒ ç”¨æˆ·å–æ¶ˆäº†æ–‡ä»¶é€‰æ‹©")
                            return None
                    except json.JSONDecodeError:
                        # å¦‚æœæ—¢ä¸æ˜¯æ ‡å‡†æ ¼å¼ä¹Ÿä¸æ˜¯JSONï¼Œç›´æ¥ä½¿ç”¨è¾“å‡º
                        if output_text and Path(output_text).exists():
                            print(f"âœ… å·²é€‰æ‹©: {Path(output_text).name}")
                            return output_text
                        else:
                            print("âŒ ç”¨æˆ·å–æ¶ˆäº†æ–‡ä»¶é€‰æ‹©")
                            return None
            else:
                print("âŒ æ–‡ä»¶é€‰æ‹©å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âš ï¸  ä½¿ç”¨FILEDIALOGæ—¶å‡ºé”™: {e}")
            print("ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼é€‰æ‹©æ–‡ä»¶")
            return self._select_markdown_file_traditional()
    
    def _select_markdown_file_traditional(self) -> str:
        """ä¼ ç»Ÿæ–¹å¼é€‰æ‹©markdownæ–‡ä»¶ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print("ğŸ” æœç´¢EXTRACT_PDFç”Ÿæˆçš„markdownæ–‡ä»¶...")
        
        # æœç´¢å½“å‰ç›®å½•åŠå…¶å­ç›®å½•ä¸­çš„markdownæ–‡ä»¶
        md_files = []
        search_dirs = [Path.cwd(), get_pdf_extractor_data_dir()]
        
        for search_dir in search_dirs:
            if search_dir.exists():
                for md_file in search_dir.rglob("*.md"):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯EXTRACT_PDFç”Ÿæˆçš„æ–‡ä»¶
                    # æ–¹æ³•1ï¼šæœ‰å¯¹åº”çš„extract_dataç›®å½•
                    extract_data_dir = md_file.parent / f"{md_file.stem}_extract_data"
                    # æ–¹æ³•2ï¼šæ–‡ä»¶åŒ…å«placeholderæ ‡è®°
                    has_placeholder = False
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        has_placeholder = '[placeholder:' in content
                    except:
                        pass
                    
                    if extract_data_dir.exists() or has_placeholder:
                        md_files.append(md_file)
        
        if not md_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•EXTRACT_PDFç”Ÿæˆçš„markdownæ–‡ä»¶")
            return None
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        print("\nğŸ“„ æ‰¾åˆ°ä»¥ä¸‹markdownæ–‡ä»¶:")
        for i, md_file in enumerate(md_files, 1):
            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„placeholder
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                image_count = len(re.findall(r'\[placeholder: image\]', content))
                formula_count = len(re.findall(r'\[placeholder: formula\]', content))
                table_count = len(re.findall(r'\[placeholder: table\]', content))
                total_count = image_count + formula_count + table_count
                
                status = f"({total_count}ä¸ªå¾…å¤„ç†é¡¹ç›®: ğŸ–¼ï¸{image_count} ğŸ§®{formula_count} ğŸ“Š{table_count})" if total_count > 0 else "(å·²å¤„ç†)"
                print(f"  {i}. {md_file.name} {status}")
                print(f"     è·¯å¾„: {md_file}")
                
            except Exception as e:
                print(f"  {i}. {md_file.name} (æ— æ³•è¯»å–)")
                print(f"     è·¯å¾„: {md_file}")
        
        # ç”¨æˆ·é€‰æ‹©
        while True:
            try:
                choice = input(f"\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶ (1-{len(md_files)}, æˆ–æŒ‰å›è½¦å–æ¶ˆ): ").strip()
                
                if not choice:
                    print("âŒ å·²å–æ¶ˆ")
                    return None
                
                choice_num = int(choice)
                if 1 <= choice_num <= len(md_files):
                    selected_file = md_files[choice_num - 1]
                    print(f"âœ… å·²é€‰æ‹©: {selected_file.name}")
                    return str(selected_file)
                else:
                    print(f"âŒ è¯·è¾“å…¥1-{len(md_files)}ä¹‹é—´çš„æ•°å­—")
                    
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\nâŒ å·²å–æ¶ˆ")
                return None
        
    def process_file(self, file_path: str, process_type: str, specific_ids: str = None, custom_prompt: str = None, force: bool = False) -> bool:
        """
        å¤„ç†PDFæ–‡ä»¶çš„åå¤„ç† - ä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼ˆä¸ä¾èµ–äºæå–æ¨¡å¼ï¼‰
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„æˆ–markdownæ–‡ä»¶è·¯å¾„ï¼Œæˆ–è€…"interactive"è¿›å…¥äº¤äº’æ¨¡å¼
            process_type: å¤„ç†ç±»å‹ ('image', 'formula', 'table', 'all')
            specific_ids: ç‰¹å®šIDåˆ—è¡¨æˆ–å…³é”®è¯
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        # æ£€æŸ¥æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼
        if file_path == "interactive":
            file_path = self._select_markdown_file_interactive()
            if not file_path:
                return False
        
        # ç›´æ¥è°ƒç”¨ç»Ÿä¸€æ¥å£
        return self.process_file_unified(file_path, process_type, specific_ids, custom_prompt, force)
    
    def _process_file_traditional(self, md_file: Path, process_type: str) -> bool:
        """ä¼ ç»Ÿçš„æ–‡ä»¶å¤„ç†æ–¹å¼ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print(f"ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç† {md_file.name}...")
        
        # ä¸å†ä¾èµ–äºç‰¹å®šçš„extract_dataç›®å½•ç»“æ„
        # ç›´æ¥ä»markdownæ–‡ä»¶ä¸­è§£æå›¾ç‰‡è·¯å¾„
        extract_data_dir = None  # è®¾ç½®ä¸ºNoneï¼Œè¡¨ç¤ºä½¿ç”¨ç»å¯¹è·¯å¾„æ¨¡å¼
            
        # æ ¹æ®å¤„ç†ç±»å‹æ‰§è¡Œç›¸åº”çš„å¤„ç†
        if process_type == 'all':
            success = True
            success &= self._process_images(md_file, extract_data_dir)
            success &= self._process_formulas(md_file, extract_data_dir)
            success &= self._process_tables(md_file, extract_data_dir)
            return success
        elif process_type == 'image':
            return self._process_images(md_file, extract_data_dir)
        elif process_type == 'formula':
            return self._process_formulas(md_file, extract_data_dir)
        elif process_type == 'table':
            return self._process_tables(md_file, extract_data_dir)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„å¤„ç†ç±»å‹: {process_type}")
            return False
    
    def _process_images(self, md_file: Path, extract_data_dir: Path) -> bool:
        """å¤„ç†å›¾ç‰‡æ ‡ç­¾æ›¿æ¢"""
        print("ğŸ–¼ï¸  å¤„ç†å›¾ç‰‡...")
        
        try:
            # è¯»å–markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾å›¾ç‰‡placeholder
            placeholder_pattern = r'\[placeholder: image\]\s*\n!\[([^\]]*)\]\(([^)]+)\)'
            matches = re.findall(placeholder_pattern, content)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„å›¾ç‰‡placeholder")
                return True
            
            processed_count = 0
            for alt_text, image_path in matches:
                # æ„å»ºå®Œæ•´çš„å›¾ç‰‡è·¯å¾„
                if image_path.startswith('/'):
                    # ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                    full_image_path = Path(image_path)
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŸºäºextract_data_dir
                    if extract_data_dir is None:
                        print(f"âš ï¸  ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æå–æ•°æ®ç›®å½•: {image_path}")
                        continue
                    full_image_path = extract_data_dir / image_path
                
                if full_image_path.exists():
                    # ä½¿ç”¨IMG2TEXTå·¥å…·åˆ†æå›¾ç‰‡
                    success, description = self._analyze_image_with_img2text(str(full_image_path))
                    
                    if success:
                        # ä¿ç•™placeholderï¼Œåœ¨ä¸‹æ–¹æ·»åŠ åˆ†æç»“æœ
                        old_pattern = f"[placeholder: image]\n![{alt_text}]({image_path})"
                        new_content = f"[placeholder: image]\n![{alt_text}]({image_path})\n\n**å›¾ç‰‡åˆ†æ:** {description}\n"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        processed_count += 1
                    else:
                        # APIè°ƒç”¨å¤±è´¥ï¼Œä¿ç•™placeholderï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
                        old_pattern = f"[placeholder: image]\n![{alt_text}]({image_path})"
                        new_content = f"[placeholder: image]\n[message: {description}]\n![{alt_text}]({image_path})"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        print(f"âš ï¸  å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œä¿ç•™placeholder: {description}")
                else:
                    # å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿæ·»åŠ é”™è¯¯ä¿¡æ¯
                    old_pattern = f"[placeholder: image]\n![{alt_text}]({image_path})"
                    new_content = f"[placeholder: image]\n[message: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}]\n![{alt_text}]({image_path})"
                    
                    content = content.replace(old_pattern, new_content, 1)
                    print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
            
            # å†™å›æ–‡ä»¶
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            if processed_count > 0:
                print(f"âœ… æˆåŠŸå¤„ç†äº† {processed_count} ä¸ªå›¾ç‰‡")
            else:
                print("â„¹ï¸  æ²¡æœ‰å›¾ç‰‡è¢«æˆåŠŸå¤„ç†")
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            return False
    
    def _analyze_image_with_img2text(self, image_path: str) -> tuple[bool, str]:
        """ä½¿ç”¨IMG2TEXTå·¥å…·åˆ†æå›¾ç‰‡
        
        Returns:
            tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, åˆ†æç»“æœæˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            # è°ƒç”¨IMG2TEXTå·¥å…·
            img2text_path = self.script_dir / "IMG2TEXT"
            if not img2text_path.exists():
                return False, "IMG2TEXTå·¥å…·ä¸å¯ç”¨"
            
            cmd = [str(img2text_path), image_path]
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                try:
                    # å°è¯•è§£æJSONè¾“å‡º
                    output_data = json.loads(result.stdout)
                    if output_data.get('success'):
                        description = output_data.get('result', 'å›¾ç‰‡åˆ†æå®Œæˆ')
                        return True, description
                    else:
                        # ä»JSONä¸­è·å–è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                        error_msg = output_data.get('reason', output_data.get('message', 'å›¾ç‰‡åˆ†æå¤±è´¥'))
                        return False, error_msg
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›æ–‡æœ¬
                    output_text = result.stdout.strip()
                    if output_text:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯ä¿¡æ¯æ ¼å¼
                        if output_text.startswith("*[") and output_text.endswith("]*"):
                            # ç§»é™¤é”™è¯¯ä¿¡æ¯çš„åŒ…è£…ç¬¦å·
                            error_msg = output_text[2:-2]  # å»æ‰ *[ å’Œ ]*
                            return False, error_msg
                        else:
                            return True, output_text
                    else:
                        return False, "å›¾ç‰‡åˆ†ææ— è¾“å‡º"
            else:
                # æ£€æŸ¥stderræ˜¯å¦æœ‰è¯¦ç»†é”™è¯¯ä¿¡æ¯
                stderr_text = result.stderr.strip()
                if stderr_text:
                    return False, f"å›¾ç‰‡åˆ†æå¤±è´¥: {stderr_text}"
                else:
                    return False, "å›¾ç‰‡åˆ†æå¤±è´¥: æœªçŸ¥é”™è¯¯"
                
        except Exception as e:
            return False, f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
    
    def _process_formulas(self, md_file: Path, extract_data_dir: Path) -> bool:
        """å¤„ç†å…¬å¼æ ‡ç­¾æ›¿æ¢"""
        print("ğŸ§® å¤„ç†å…¬å¼...")
        
        try:
            # è¯»å–markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾å…¬å¼placeholder
            placeholder_pattern = r'\[placeholder: formula\]\s*\n!\[([^\]]*)\]\(([^)]+)\)'
            matches = re.findall(placeholder_pattern, content)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„å…¬å¼placeholder")
                return True
            
            processed_count = 0
            for alt_text, image_path in matches:
                # æ„å»ºå®Œæ•´çš„å›¾ç‰‡è·¯å¾„
                if image_path.startswith('/'):
                    # ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                    full_image_path = Path(image_path)
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŸºäºextract_data_dir
                    if extract_data_dir is None:
                        print(f"âš ï¸  ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æå–æ•°æ®ç›®å½•: {image_path}")
                        continue
                    full_image_path = extract_data_dir / image_path
                
                if full_image_path.exists():
                    # ä½¿ç”¨UnimerNetåˆ†æå…¬å¼å›¾ç‰‡
                    success, formula_latex = self._analyze_formula_with_unimernet(str(full_image_path))
                    
                    if success:
                        # æ›¿æ¢placeholderå’Œå›¾ç‰‡å¼•ç”¨
                        old_pattern = f"[placeholder: formula]\n![{alt_text}]({image_path})"
                        new_content = f"![{alt_text}]({image_path})\n\n**å…¬å¼è¯†åˆ«:** {formula_latex}\n"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        processed_count += 1
                    else:
                        # APIè°ƒç”¨å¤±è´¥ï¼Œä¿ç•™placeholderï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
                        old_pattern = f"[placeholder: formula]\n![{alt_text}]({image_path})"
                        new_content = f"[placeholder: formula]\n[message: {formula_latex}]\n![{alt_text}]({image_path})"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        print(f"âš ï¸  å…¬å¼è¯†åˆ«å¤±è´¥ï¼Œä¿ç•™placeholder: {formula_latex}")
                else:
                    # å…¬å¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿæ·»åŠ é”™è¯¯ä¿¡æ¯
                    old_pattern = f"[placeholder: formula]\n![{alt_text}]({image_path})"
                    new_content = f"[placeholder: formula]\n[message: å…¬å¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}]\n![{alt_text}]({image_path})"
                    
                    content = content.replace(old_pattern, new_content, 1)
                    print(f"âš ï¸  å…¬å¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
            
            # å†™å›æ–‡ä»¶
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            if processed_count > 0:
                print(f"âœ… æˆåŠŸå¤„ç†äº† {processed_count} ä¸ªå…¬å¼")
            else:
                print("â„¹ï¸  æ²¡æœ‰å…¬å¼è¢«æˆåŠŸå¤„ç†")
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å…¬å¼æ—¶å‡ºé”™: {e}")
            return False
    
    def _analyze_formula_with_unimernet(self, image_path: str) -> tuple[bool, str]:
        """ä½¿ç”¨UnimerNetåˆ†æå…¬å¼å›¾ç‰‡
        
        Returns:
            tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, åˆ†æç»“æœæˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            # æ£€æŸ¥UnimerNetæ˜¯å¦å¯ç”¨
            unimernet_processor = self.script_dir / "EXTRACT_PDF_PROJ" / "unimernet_processor.py"
            if not unimernet_processor.exists():
                return False, "UnimerNetå¤„ç†å™¨ä¸å¯ç”¨"
            
            # è°ƒç”¨UnimerNetå¤„ç†å™¨
            cmd = [sys.executable, str(unimernet_processor), image_path]
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                output_text = result.stdout.strip()
                if output_text:
                    return True, output_text
                else:
                    return False, "å…¬å¼è¯†åˆ«æ— è¾“å‡º"
            else:
                return False, f"å…¬å¼è¯†åˆ«å¤±è´¥: {result.stderr}"
                
        except Exception as e:
            return False, f"å…¬å¼è¯†åˆ«å¤±è´¥: {str(e)}"

    def _process_tables(self, md_file: Path, extract_data_dir: Path) -> bool:
        """å¤„ç†è¡¨æ ¼æ ‡ç­¾æ›¿æ¢"""
        print("ğŸ“Š å¤„ç†è¡¨æ ¼...")
        
        try:
            # è¯»å–markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾è¡¨æ ¼placeholder
            placeholder_pattern = r'\[placeholder: table\]\s*\n!\[([^\]]*)\]\(([^)]+)\)'
            matches = re.findall(placeholder_pattern, content)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„è¡¨æ ¼placeholder")
                return True
            
            processed_count = 0
            for alt_text, image_path in matches:
                # æ„å»ºå®Œæ•´çš„å›¾ç‰‡è·¯å¾„
                if image_path.startswith('/'):
                    # ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                    full_image_path = Path(image_path)
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŸºäºextract_data_dir
                    if extract_data_dir is None:
                        print(f"âš ï¸  ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æå–æ•°æ®ç›®å½•: {image_path}")
                        continue
                    full_image_path = extract_data_dir / image_path
                
                if full_image_path.exists():
                    # ä½¿ç”¨IMG2TEXTå·¥å…·åˆ†æè¡¨æ ¼å›¾ç‰‡
                    success, table_text = self._analyze_image_with_img2text(str(full_image_path))
                    
                    if success:
                        # æ›¿æ¢placeholderå’Œå›¾ç‰‡å¼•ç”¨
                        old_pattern = f"[placeholder: table]\n![{alt_text}]({image_path})"
                        new_content = f"![{alt_text}]({image_path})\n\n**è¡¨æ ¼è¯†åˆ«:**\n{table_text}\n"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        processed_count += 1
                    else:
                        # APIè°ƒç”¨å¤±è´¥ï¼Œä¿ç•™placeholderï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
                        old_pattern = f"[placeholder: table]\n![{alt_text}]({image_path})"
                        new_content = f"[placeholder: table]\n[message: {table_text}]\n![{alt_text}]({image_path})"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        print(f"âš ï¸  è¡¨æ ¼åˆ†æå¤±è´¥ï¼Œä¿ç•™placeholder: {table_text}")
                else:
                    # è¡¨æ ¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿæ·»åŠ é”™è¯¯ä¿¡æ¯
                    old_pattern = f"[placeholder: table]\n![{alt_text}]({image_path})"
                    new_content = f"[placeholder: table]\n[message: è¡¨æ ¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}]\n![{alt_text}]({image_path})"
                    
                    content = content.replace(old_pattern, new_content, 1)
                    print(f"âš ï¸  è¡¨æ ¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
            
            # å†™å›æ–‡ä»¶
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            if processed_count > 0:
                print(f"âœ… æˆåŠŸå¤„ç†äº† {processed_count} ä¸ªè¡¨æ ¼")
            else:
                print("â„¹ï¸  æ²¡æœ‰è¡¨æ ¼è¢«æˆåŠŸå¤„ç†")
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†è¡¨æ ¼æ—¶å‡ºé”™: {e}")
            return False
    
    def _sync_placeholders_with_markdown(self, md_file: Path, status_data: dict, status_file: Path) -> dict:
        """
        åŒæ­¥markdownæ–‡ä»¶å’ŒJSONæ–‡ä»¶ä¸­çš„placeholderä¿¡æ¯
        
        Args:
            md_file: markdownæ–‡ä»¶è·¯å¾„
            status_data: JSONçŠ¶æ€æ•°æ®
            status_file: JSONçŠ¶æ€æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€æ•°æ®
        """
        try:
            # è¯»å–markdownæ–‡ä»¶å†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # è§£æmarkdownä¸­çš„placeholderä¿¡æ¯
            md_placeholders = self._parse_placeholders_from_markdown(md_content)
            print(f"   ğŸ“‹ ä»markdownä¸­è¯†åˆ«åˆ° {len(md_placeholders)} ä¸ªplaceholder")
            
            # åˆ›å»ºJSONä¸­ç°æœ‰é¡¹ç›®çš„æ˜ å°„
            json_items = {item['id']: item for item in status_data.get('items', [])}
            print(f"   ğŸ“„ JSONä¸­ç°æœ‰ {len(json_items)} ä¸ªé¡¹ç›®")
            
            # åŒæ­¥è¿‡ç¨‹
            updated_items = []
            md_content_modified = False
            
            # 1. å¤„ç†markdownä¸­çš„placeholderï¼Œæ›´æ–°æˆ–æ·»åŠ åˆ°JSON
            for img_id, placeholder_type in md_placeholders.items():
                if img_id in json_items:
                    # æ›´æ–°ç°æœ‰é¡¹ç›®çš„ç±»å‹
                    item = json_items[img_id]
                    old_type = item.get('type', 'unknown')
                    if old_type != placeholder_type:
                        print(f"   ğŸ”„ æ›´æ–°é¡¹ç›® {img_id[:8]}... ç±»å‹: {old_type} â†’ {placeholder_type}")
                        item['type'] = placeholder_type
                        item['processed'] = False  # é‡ç½®å¤„ç†çŠ¶æ€
                        # æ›´æ–°å¤„ç†å™¨
                        if placeholder_type == 'image':
                            item['processor'] = 'Google API'
                        elif placeholder_type in ['formula', 'interline_equation']:
                            item['processor'] = 'UnimerNet'
                        elif placeholder_type == 'table':
                            item['processor'] = 'UnimerNet'
                    updated_items.append(item)
                    del json_items[img_id]  # ä»å¾…å¤„ç†åˆ—è¡¨ä¸­ç§»é™¤
                else:
                    # æ–°å¢é¡¹ç›®åˆ°JSON
                    print(f"   â• æ–°å¢é¡¹ç›® {img_id[:8]}... ç±»å‹: {placeholder_type}")
                    new_item = {
                        "id": img_id,
                        "type": placeholder_type,
                        "page": 1,  # é»˜è®¤é¡µç 
                        "block_index": -1,  # æ ‡è®°ä¸ºç”¨æˆ·æ·»åŠ 
                        "image_path": f"{img_id}.jpg",
                        "bbox": [],
                        "processed": False,
                        "processor": self._get_processor_for_type(placeholder_type)
                    }
                    updated_items.append(new_item)
            
            # 2. å¤„ç†JSONä¸­å‰©ä½™çš„é¡¹ç›®ï¼ˆmarkdownä¸­ç¼ºå¤±çš„ï¼‰
            for img_id, item in json_items.items():
                print(f"   ğŸ”§ æ¢å¤ç¼ºå¤±çš„placeholder {img_id[:8]}... ç±»å‹: {item['type']}")
                # åœ¨markdownä¸­æ¢å¤placeholder
                md_content = self._restore_placeholder_in_markdown(md_content, img_id, item['type'])
                md_content_modified = True
                updated_items.append(item)
            
            # 3. ä¿å­˜ä¿®æ”¹åçš„markdownæ–‡ä»¶
            if md_content_modified:
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(md_content)
                print(f"   ğŸ’¾ å·²æ›´æ–°markdownæ–‡ä»¶")
            
            # 4. æ›´æ–°çŠ¶æ€æ•°æ®
            status_data['items'] = updated_items
            status_data['total_items'] = len(updated_items)
            
            # é‡æ–°è®¡ç®—counts
            counts = {"images": 0, "formulas": 0, "tables": 0}
            for item in updated_items:
                if not item.get('processed', False):  # åªè®¡ç®—æœªå¤„ç†çš„é¡¹ç›®
                    item_type = item.get('type', '')
                    if item_type == 'image':
                        counts['images'] += 1
                    elif item_type in ['formula', 'interline_equation']:
                        counts['formulas'] += 1
                    elif item_type == 'table':
                        counts['tables'] += 1
            
            status_data['counts'] = counts
            
            # 5. ä¿å­˜æ›´æ–°åçš„JSONæ–‡ä»¶
            with open(status_file, 'w', encoding='utf-8') as f:
                json.dump(status_data, f, ensure_ascii=False, indent=2)
            
            print(f"   âœ… åŒæ­¥å®Œæˆ: {len(updated_items)} ä¸ªé¡¹ç›®")
            return status_data
            
        except Exception as e:
            print(f"   âš ï¸  åŒæ­¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return status_data
    
    def _parse_placeholders_from_markdown(self, md_content: str) -> dict:
        """ä»markdownå†…å®¹ä¸­è§£æplaceholderä¿¡æ¯"""
        import re
        
        placeholders = {}
        
        # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ä»¥æ­£ç¡®åŒ¹é…å®Œæ•´çš„å“ˆå¸Œæ–‡ä»¶å
        # åŒ¹é… [placeholder: type] åè·Ÿ ![](path/to/hash.ext) çš„æ¨¡å¼
        pattern = r'\[placeholder:\s*(\w+)\]\s*\n!\[[^\]]*\]\([^)]*\/([a-f0-9]{16,64})\.(jpg|jpeg|png|gif|webp)\)'
        
        matches = re.findall(pattern, md_content)
        for placeholder_type, img_id, ext in matches:
            placeholders[img_id] = placeholder_type
        
        return placeholders
    
    def _restore_placeholder_in_markdown(self, md_content: str, img_id: str, placeholder_type: str) -> str:
        """åœ¨markdownä¸­æ¢å¤ç¼ºå¤±çš„placeholder"""
        import re
        
        # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡å¼•ç”¨
        pattern = rf'!\[[^\]]*\]\([^)]*{re.escape(img_id)}\.jpg\)'
        match = re.search(pattern, md_content)
        
        if match:
            # åœ¨å›¾ç‰‡å‰æ·»åŠ placeholder
            img_ref = match.group(0)
            placeholder_line = f"[placeholder: {placeholder_type}]\n{img_ref}"
            md_content = md_content.replace(img_ref, placeholder_line)
        
        return md_content
    
    def _get_processor_for_type(self, item_type: str) -> str:
        """æ ¹æ®ç±»å‹è·å–å¤„ç†å™¨åç§°"""
        if item_type == 'image':
            return "Google API"
        elif item_type in ['formula', 'interline_equation']:
            return "UnimerNet"
        elif item_type == 'table':
            return "UnimerNet"
        else:
            return "Unknown"

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = """EXTRACT_PDF - Enhanced PDF extraction using MinerU with post-processing

Usage: EXTRACT_PDF <pdf_file> [options]
       EXTRACT_PDF --post [<markdown_file>] [--post-type <type>]
       EXTRACT_PDF --full <pdf_file> [options]
       EXTRACT_PDF --clean-data

Options:
  --page <spec>        Extract specific page(s) (e.g., 3, 1-5, 1,3,5)
  --output <dir>       Output directory (default: same as PDF)
  --engine <mode>      Processing engine mode:
                       basic        - Basic extractor, no image/formula/table processing
                       basic-asyn   - Basic extractor, async mode (disable analysis)
                       mineru       - MinerU extractor, no image/formula/table processing
                       mineru-asyn  - MinerU extractor, async mode (disable analysis)
                       full         - Full pipeline with image/formula/table processing
                       (default: mineru)
  --post [<file>]      Post-process markdown file (replace placeholders)
                       If no file specified, enter interactive mode
  --post-type <type>   Post-processing type: image, formula, table, all (default: all)
  --ids <ids>          Specific hash IDs to process (comma-separated) or keywords:
                       all_images, all_formulas, all_tables, all
  --prompt <text>      Custom prompt for IMG2TEXT image analysis
  --force              Force reprocessing even if items are marked as processed
  --full <file>        Full pipeline: extract PDF then post-process automatically
  --clean-data         Clean all cached markdown files and images from EXTRACT_PDF_PROJ
  --help, -h           Show this help message

Examples:
  EXTRACT_PDF document.pdf --page 3
  EXTRACT_PDF paper.pdf --page 1-5 --output /path/to/output
  EXTRACT_PDF document.pdf --engine full
  EXTRACT_PDF document.pdf --engine mineru
  EXTRACT_PDF --post document.md --post-type all
EXTRACT_PDF --post document.md --post-type image
EXTRACT_PDF --post document.md --ids 4edf23de78f80bedade9e9628d7de04677faf669c945a7438bc5741c054af036
EXTRACT_PDF --post document.md --ids all_images --prompt "Analyze this research figure focusing on quantitative results"
EXTRACT_PDF --post  # Interactive mode
EXTRACT_PDF --full document.pdf  # Full pipeline
EXTRACT_PDF --clean-data  # Clean cached data"""
    
    print(help_text)

def select_pdf_file():
    """ä½¿ç”¨GUIé€‰æ‹©PDFæ–‡ä»¶"""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        root = tk.Tk()
        root.withdraw()
        
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©PDFæ–‡ä»¶",
            filetypes=[("PDF files", "*.pdf"), ("All files", "*.*")]
        )
        
        return file_path if file_path else None
    except ImportError:
        print("âŒ tkinter not available, GUI file selection not supported")
        return None
    except Exception as e:
        print(f"âŒ Error in file selection: {e}")
        return None

def main(args=None, command_identifier=None):
    """ä¸»å‡½æ•°"""
    global original_pdf_dir
    # è·å–command_identifier
    if args is None:
        args = sys.argv[1:]
    command_identifier = None
    
    # æ£€æŸ¥æ˜¯å¦è¢«RUNè°ƒç”¨ï¼ˆç¬¬ä¸€ä¸ªå‚æ•°æ˜¯command_identifierï¼‰
    if args and is_run_environment(args[0]):
        command_identifier = args[0]
        args = args[1:]  # ç§»é™¤command_identifierï¼Œä¿ç•™å®é™…å‚æ•°
    if not args:
        # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œå°è¯•ä½¿ç”¨GUIé€‰æ‹©æ–‡ä»¶
        pdf_file = select_pdf_file()
        if pdf_file:
            print(f"ğŸ“„ å·²é€‰æ‹©æ–‡ä»¶: {Path(pdf_file).name}")
            print(f"ğŸ”„ å¼€å§‹ä½¿ç”¨ MinerU å¼•æ“å¤„ç†...")
            print("â³ å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...")
            
            extractor = PDFExtractor()
            success, message = extractor.extract_pdf(pdf_file)
            
            if success:
                success_data = {
                    "success": True,
                    "message": message
                }
                if is_run_environment(command_identifier):
                    write_to_json_output(success_data, command_identifier)
                else:
                    print(f"âœ… {message}")
                return 0
            else:
                error_data = {
                    "success": False,
                    "error": message
                }
                if is_run_environment(command_identifier):
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(f"âŒ {message}")
                return 1
        else:
            if is_run_environment(command_identifier):
                error_data = {"success": False, "error": "No PDF file specified"}
                write_to_json_output(error_data, command_identifier)
            else:
                print("âŒ Error: No PDF file specified")
                print("Use --help for usage information")
            return 1
    
    # è§£æå‚æ•°
    pdf_file = None
    page_spec = None
    output_dir = None
    engine_mode = "mineru"
    post_file = None
    post_type = "all"
    post_ids = None
    post_prompt = None
    post_force = False
    original_pdf_dir = None
    full_pipeline = False
    clean_data = False
    
    i = 0
    while i < len(args):
        arg = args[i]
        
        if arg in ['--help', '-h']:
            if is_run_environment(command_identifier):
                help_data = {
                    "success": True,
                    "message": "Help information",
                    "help": show_help.__doc__
                }
                write_to_json_output(help_data, command_identifier)
            else:
                show_help()
            return 0
        elif arg == '--page':
            if i + 1 < len(args):
                page_spec = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --page requires a value"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--output':
            if i + 1 < len(args):
                output_dir = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --output requires a value"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--engine':
            if i + 1 < len(args):
                engine_mode = args[i + 1]
                if engine_mode not in ['basic', 'basic-asyn', 'mineru', 'mineru-asyn', 'full']:
                    error_msg = f"âŒ Error: Invalid engine mode: {engine_mode}"
                    if is_run_environment(command_identifier):
                        error_data = {"success": False, "error": error_msg}
                        write_to_json_output(error_data, command_identifier)
                    else:
                        print(error_msg)
                    return 1
                i += 2
            else:
                error_msg = "âŒ Error: --engine requires a value"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--post':
            if i + 1 < len(args) and not args[i + 1].startswith('-'):
                post_file = args[i + 1]
                i += 2
            else:
                # è¿›å…¥interactive mode
                post_file = "interactive"
                i += 1
        elif arg == '--full':
            if i + 1 < len(args) and not args[i + 1].startswith('-'):
                pdf_file = args[i + 1]
                full_pipeline = True
                i += 2
            else:
                error_msg = "âŒ Error: --full requires a PDF file"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--clean-data':
            clean_data = True
            i += 1
        elif arg == '--ids':
            if i + 1 < len(args):
                post_ids = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --ids requires a value"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--prompt':
            if i + 1 < len(args):
                post_prompt = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --prompt requires a value"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--post-type':
            if i + 1 < len(args):
                post_type = args[i + 1]
                if post_type not in ['image', 'formula', 'table', 'all', 'all_images', 'all_formulas', 'all_tables']:
                    error_msg = f"âŒ Error: Invalid post-type: {post_type}"
                    if is_run_environment(command_identifier):
                        error_data = {"success": False, "error": error_msg}
                        write_to_json_output(error_data, command_identifier)
                    else:
                        print(error_msg)
                    return 1
                i += 2
            else:
                error_msg = "âŒ Error: --post-type requires a value"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--original-pdf-dir':
            if i + 1 < len(args):
                original_pdf_dir = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --original-pdf-dir requires a value"
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
        elif arg == '--force':
            post_force = True
            i += 1
        elif arg.startswith('-'):
            error_msg = f"âŒ Unknown option: {arg}"
            if is_run_environment(command_identifier):
                error_data = {"success": False, "error": error_msg}
                write_to_json_output(error_data, command_identifier)
            else:
                print(error_msg)
                print("Use --help for usage information")
            return 1
        else:
            if pdf_file is None:
                pdf_file = arg
            else:
                error_msg = "âŒ Multiple PDF files specified. Only one file is supported."
                if is_run_environment(command_identifier):
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(error_msg)
                return 1
            i += 1
    
    # å¤„ç†æ¸…ç†æ•°æ®æ¨¡å¼
    if clean_data:
        extractor = PDFExtractor()
        success, message = extractor.clean_data()
        
        if success:
            success_data = {
                "success": True,
                "message": message,
                "action": "clean_data"
            }
            if is_run_environment(command_identifier):
                write_to_json_output(success_data, command_identifier)
            else:
                print(f"âœ… {message}")
            return 0
        else:
            error_data = {
                "success": False,
                "error": message,
                "action": "clean_data"
            }
            if is_run_environment(command_identifier):
                write_to_json_output(error_data, command_identifier)
            else:
                print(f"âŒ {message}")
            return 1
    
    # å¤„ç†å®Œæ•´æµç¨‹æ¨¡å¼
    if full_pipeline:
        print(f"ğŸš€ å¼€å§‹å®Œæ•´æµç¨‹å¤„ç†: {pdf_file}")
        
        # æ„é€ ç¬¬ä¸€æ­¥å‘½ä»¤ï¼šPDFæå–
        step1_cmd = [sys.executable, __file__, pdf_file]
        if page_spec:
            step1_cmd.extend(["--page", page_spec])
        if output_dir:
            step1_cmd.extend(["--output", output_dir])
        if engine_mode != "mineru":
            step1_cmd.extend(["--engine", engine_mode])
        if clean_data:
            step1_cmd.append("--clean-data")
        
        print("ğŸ“„ ç¬¬ä¸€æ­¥ï¼šPDFæå–...")
        print(f"   ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(step1_cmd)}")
        
        try:
            result1 = subprocess.run(step1_cmd, capture_output=True, text=True, check=False)
            
            if result1.returncode != 0:
                error_data = {
                    "success": False,
                    "error": f"PDF extraction failed: {result1.stderr}",
                    "step": "extraction",
                    "command": " ".join(step1_cmd)
                }
                if is_run_environment(command_identifier):
                    write_to_json_output(error_data, command_identifier)
                else:
                    print(f"âŒ PDFæå–å¤±è´¥: {result1.stderr}")
                return 1
            
            print(f"âœ… PDFæå–å®Œæˆ")
            
            # æ ¹æ®PDFæ–‡ä»¶è·¯å¾„æ¨æ–­markdownæ–‡ä»¶è·¯å¾„
            pdf_path = Path(pdf_file).expanduser().resolve()
            
            # æ„å»ºæ­£ç¡®çš„markdownæ–‡ä»¶åï¼Œè€ƒè™‘é¡µç è§„æ ¼
            if page_spec:
                page_suffix = f"_p{page_spec}"
                md_filename = f"{pdf_path.stem}{page_suffix}.md"
            else:
                md_filename = f"{pdf_path.stem}.md"
            
            if output_dir:
                md_file = Path(output_dir) / md_filename
            else:
                md_file = pdf_path.parent / md_filename
            
            if md_file.exists():
                # æ„é€ ç¬¬äºŒæ­¥å‘½ä»¤ï¼šåå¤„ç†
                step2_cmd = [sys.executable, __file__, "--post", str(md_file)]
                # ä¼ é€’åŸå§‹PDFæ–‡ä»¶ç›®å½•ï¼Œä»¥ä¾¿åå¤„ç†å™¨èƒ½æ‰¾åˆ°çŠ¶æ€æ–‡ä»¶
                step2_cmd.extend(["--original-pdf-dir", str(pdf_path.parent)])
                if post_type != "all":
                    step2_cmd.extend(["--post-type", post_type])
                if post_ids:
                    step2_cmd.extend(["--ids", post_ids])
                if post_prompt:
                    step2_cmd.extend(["--prompt", post_prompt])
                if post_force:
                    step2_cmd.append("--force")
                
                print("ğŸ”„ ç¬¬äºŒæ­¥ï¼šè‡ªåŠ¨åå¤„ç†...")
                print(f"   ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(step2_cmd)}")
                
                result2 = subprocess.run(step2_cmd, capture_output=True, text=True, check=False)
                
                if result2.returncode == 0:
                    success_data = {
                        "success": True,
                        "message": f"Full pipeline completed: {pdf_file} -> {md_file}",
                        "extraction_output": result1.stdout,
                        "post_processing": "completed",
                        "post_processing_output": result2.stdout,
                        "post_type": post_type,
                        "step1_command": " ".join(step1_cmd),
                        "step2_command": " ".join(step2_cmd)
                    }
                    if is_run_environment(command_identifier):
                        write_to_json_output(success_data, command_identifier)
                    else:
                        print(f"âœ… å®Œæ•´æµç¨‹å®Œæˆ: {pdf_file} -> {md_file}")
                    return 0
                else:
                    # å³ä½¿åå¤„ç†å¤±è´¥ï¼ŒPDFæå–å·²æˆåŠŸ
                    warning_data = {
                        "success": True,
                        "message": f"PDF extraction completed but post-processing failed: {md_file}",
                        "extraction_output": result1.stdout,
                        "post_processing": "failed",
                        "post_processing_error": result2.stderr,
                        "post_type": post_type,
                        "step1_command": " ".join(step1_cmd),
                        "step2_command": " ".join(step2_cmd)
                    }
                    if is_run_environment(command_identifier):
                        write_to_json_output(warning_data, command_identifier)
                    else:
                        print(f"âœ… PDFæå–å®Œæˆï¼Œä½†åå¤„ç†å¤±è´¥: {md_file}")
                        print("ğŸ’¡ æ‚¨å¯ä»¥ç¨åä½¿ç”¨ EXTRACT_PDF --post æ‰‹åŠ¨è¿›è¡Œåå¤„ç†")
                        print(f"âš ï¸  åå¤„ç†é”™è¯¯: {result2.stderr}")
                    return 0
            else:
                # markdownæ–‡ä»¶ä¸å­˜åœ¨
                warning_data = {
                    "success": True,
                    "message": f"PDF extraction completed but markdown file not found: {md_file}",
                    "extraction_output": result1.stdout,
                    "post_processing": "skipped",
                    "step1_command": " ".join(step1_cmd)
                }
                if is_run_environment(command_identifier):
                    write_to_json_output(warning_data, command_identifier)
                else:
                    print(f"âœ… PDFæå–å®Œæˆï¼Œä½†æœªæ‰¾åˆ°markdownæ–‡ä»¶: {md_file}")
                return 0
                
        except Exception as e:
            error_data = {
                "success": False,
                "error": f"Full pipeline execution failed: {str(e)}",
                "step": "command_execution"
            }
            if is_run_environment(command_identifier):
                write_to_json_output(error_data, command_identifier)
            else:
                print(f"âŒ å®Œæ•´æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
            return 1
    
    # å¤„ç†åå¤„ç†æ¨¡å¼
    if post_file:
        processor = PDFPostProcessor(debug=False)
        success = processor.process_file(post_file, post_type, post_ids, post_prompt, force=post_force)
        
        if success:
            success_data = {
                "success": True,
                "message": f"Post-processing completed: {post_file}",
                "post_type": post_type
            }
            if is_run_environment(command_identifier):
                write_to_json_output(success_data, command_identifier)
            else:
                print(f"âœ… åå¤„ç†å®Œæˆ: {post_file}")
            return 0
        else:
            error_data = {
                "success": False,
                "error": f"Post-processing failed: {post_file}",
                "post_type": post_type
            }
            if is_run_environment(command_identifier):
                write_to_json_output(error_data, command_identifier)
            else:
                print(f"âŒ åå¤„ç†å¤±è´¥: {post_file}")
            return 1
    
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†PDFæ–‡ä»¶
    if pdf_file is None:
        error_msg = "âŒ Error: No PDF file specified"
        if is_run_environment(command_identifier):
            error_data = {"success": False, "error": error_msg}
            write_to_json_output(error_data, command_identifier)
        else:
            print(error_msg)
            print("Use --help for usage information")
        return 1
    
    # æ‰§è¡ŒPDFæå–
    extractor = PDFExtractor()
    success, message = extractor.extract_pdf(pdf_file, page_spec, output_dir, engine_mode)
    
    if success:
        success_data = {
            "success": True,
            "message": message,
            "engine_mode": engine_mode
        }
        if is_run_environment(command_identifier):
            write_to_json_output(success_data, command_identifier)
        else:
            print(f"âœ… {message}")
        return 0
    else:
        error_data = {
            "success": False,
            "error": message,
            "engine_mode": engine_mode
        }
        if is_run_environment(command_identifier):
            write_to_json_output(error_data, command_identifier)
        else:
            print(f"âŒ {message}")
        return 1

def cleanup_images_folder():
    """Clean up images folder created by MinerU module imports in current working directory"""
    # Only clean up in the script directory (~/.local/bin), not in PDF directories
    script_dir = Path(__file__).parent
    images_path = script_dir / "images"
    
    if images_path.exists() and images_path.is_dir():
        try:
            # Only remove if it's empty or contains only MinerU-generated files
            contents = list(images_path.iterdir())
            if not contents:  # Empty folder
                images_path.rmdir()
            else:
                # Check if all contents are image files (likely from MinerU)
                image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'}
                all_images = all(
                    item.is_file() and item.suffix.lower() in image_extensions 
                    for item in contents
                )
                if all_images and len(contents) < 10:  # Safety check: only clean small image folders
                    shutil.rmtree(images_path)
                    print(f"ğŸ§¹ å·²æ¸…ç†åŒ…å« {len(contents)} ä¸ªå›¾ç‰‡æ–‡ä»¶çš„ images æ–‡ä»¶å¤¹")
        except Exception as e:
            # Silently ignore cleanup errors
            pass

if __name__ == "__main__":
    try:
        exit_code = main()
        cleanup_images_folder()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        cleanup_images_folder()
        print("\nâŒ å·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        cleanup_images_folder()
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1) 