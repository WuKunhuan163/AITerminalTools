#!/usr/bin/env python3
"""
EXTRACT_PDF.py - Enhanced PDF extraction using MinerU with integrated post-processing
All-in-one PDF processing tool with image analysis using IMG2TEXT
"""

import os
import sys
import json
import subprocess
import argparse
import hashlib
import re
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Tuple

def is_run_environment(command_identifier=None):
    """Check if running in RUN environment by checking environment variables"""
    if command_identifier:
        return os.environ.get(f'RUN_IDENTIFIER_{command_identifier}') == 'True'
    return False

def get_run_context():
    """è·å– RUN æ‰§è¡Œä¸Šä¸‹æ–‡ä¿¡æ¯"""
    run_identifier = os.environ.get('RUN_IDENTIFIER')
    output_file = os.environ.get('RUN_OUTPUT_FILE')
    
    if run_identifier and output_file:
        return {
            'in_run_context': True,
            'identifier': run_identifier,
            'output_file': output_file
        }
    else:
        return {
            'in_run_context': False,
            'identifier': None,
            'output_file': None
        }

def write_to_json_output(data, run_context):
    """å°†ç»“æœå†™å…¥åˆ°æŒ‡å®šçš„ JSON è¾“å‡ºæ–‡ä»¶ä¸­"""
    if not run_context['in_run_context'] or not run_context['output_file']:
        return False
    
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(run_context['output_file'])
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(run_context['output_file'], 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"Error writing to JSON output file: {e}")
        return False

class PDFExtractor:
    """PDFæå–å™¨ï¼Œé›†æˆæ‰€æœ‰PDFå¤„ç†åŠŸèƒ½"""
    
    def __init__(self, debug: bool = False):
        self.debug = debug
        self.script_dir = Path(__file__).parent
        self.proj_dir = self.script_dir / "EXTRACT_PDF_PROJ"
        
    def extract_pdf_basic(self, pdf_path: Path, page_spec: str = None, output_dir: Path = None) -> Tuple[bool, str]:
        """åŸºç¡€PDFæå–åŠŸèƒ½"""
        try:
            # ä½¿ç”¨Pythonçš„åŸºç¡€PDFå¤„ç†åº“
            import fitz  # PyMuPDF
            
            # æ‰“å¼€PDFæ–‡ä»¶
            doc = fitz.open(str(pdf_path))
            
            # ç¡®å®šè¾“å‡ºç›®å½•
            if output_dir is None:
                output_dir = pdf_path.parent
            else:
                output_dir = Path(output_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
            
            # ç¡®å®šè¦å¤„ç†çš„é¡µé¢
            if page_spec:
                pages = self._parse_page_spec(page_spec, doc.page_count)
            else:
                pages = list(range(doc.page_count))
            
            # æ„å»ºè¾“å‡ºæ–‡ä»¶åï¼ŒåŒ…å«é¡µç ä¿¡æ¯
            base_name = pdf_path.stem
            if page_spec:
                # æ ¼å¼åŒ–é¡µç ä¿¡æ¯ï¼šä¾‹å¦‚ "1,3,5" -> "_p1,3,5"ï¼Œ"1-5" -> "_p1-5"
                page_suffix = f"_p{page_spec}"
                output_filename = f"{base_name}{page_suffix}.md"
            else:
                output_filename = f"{base_name}.md"
            
            output_file = output_dir / output_filename
            content = []
            
            for page_num in pages:
                page = doc[page_num]
                text = page.get_text()
                content.append(f"# Page {page_num + 1}\n\n{text}\n\n")
            
            # å†™å…¥markdownæ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(content))
            
            doc.close()
            return True, f"Basic extraction completed: {output_file}"
            
        except Exception as e:
            return False, f"Basic extraction failed: {str(e)}"
    
    def extract_pdf_mineru(self, pdf_path: Path, page_spec: str = None, output_dir: Path = None, 
                          enable_analysis: bool = False) -> Tuple[bool, str]:
        """ä½¿ç”¨MinerUè¿›è¡ŒPDFæå–"""
        try:
            # æ£€æŸ¥MinerU CLIæ˜¯å¦å¯ç”¨
            mineru_cli = self.proj_dir / "pdf_extract_cli.py"
            if not mineru_cli.exists():
                return False, "MinerU CLI not available"
            
            # æ„å»ºMinerUå‘½ä»¤
            cmd = [
                sys.executable, 
                str(mineru_cli),
                str(pdf_path)
            ]
            
            if page_spec:
                cmd.extend(['--page', page_spec])
            
            if output_dir:
                cmd.extend(['--output', str(output_dir)])
            
            # å§‹ç»ˆä½¿ç”¨MinerU
            cmd.append('--use-mineru')
            
            if not enable_analysis:
                cmd.append('--no-image-api')
                cmd.append('--async-mode')
            
            # æ‰§è¡ŒMinerU
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            # Print stderr for debugging
            if result.stderr:
                print(result.stderr, file=sys.stderr)
            
            if result.returncode == 0:
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶è¢«åˆ›å»ºï¼Œå¹¶å¤åˆ¶åˆ°ç”¨æˆ·æŒ‡å®šçš„ç›®å½•
                output_file = self._handle_mineru_output(pdf_path, output_dir, result.stdout, page_spec)
                return True, f"MinerU extraction completed: {output_file}"
            else:
                return False, f"MinerU extraction failed: {result.stderr}"
                
        except Exception as e:
            return False, f"MinerU extraction error: {str(e)}"
    
    def _parse_page_spec(self, page_spec: str, total_pages: int) -> List[int]:
        """è§£æé¡µé¢è§„æ ¼"""
        pages = []
        
        for part in page_spec.split(','):
            part = part.strip()
            if '-' in part:
                start, end = part.split('-', 1)
                start = int(start.strip()) - 1  # è½¬æ¢ä¸º0-based
                end = int(end.strip()) - 1
                pages.extend(range(max(0, start), min(total_pages, end + 1)))
            else:
                page = int(part.strip()) - 1  # è½¬æ¢ä¸º0-based
                if 0 <= page < total_pages:
                    pages.append(page)
        
        return sorted(list(set(pages)))
    
    def _handle_mineru_output(self, pdf_path: Path, output_dir: Path, stdout: str, page_spec: str = None) -> str:
        """å¤„ç†MinerUè¾“å‡ºï¼Œå°†æ–‡ä»¶å¤åˆ¶åˆ°ç”¨æˆ·æŒ‡å®šçš„ç›®å½•å¹¶ä¿®æ­£å›¾ç‰‡è·¯å¾„"""
        try:
            # ç¡®å®šè¾“å‡ºç›®å½•
            if output_dir is None:
                output_dir = pdf_path.parent
            else:
                output_dir.mkdir(parents=True, exist_ok=True)
            
            # æŸ¥æ‰¾MinerUç”Ÿæˆçš„markdownæ–‡ä»¶
            mineru_data_dir = self.proj_dir / "pdf_extractor_data" / "markdown"
            if mineru_data_dir.exists():
                # æ‰¾åˆ°æœ€æ–°çš„markdownæ–‡ä»¶
                md_files = list(mineru_data_dir.glob("*.md"))
                if md_files:
                    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
                    latest_md = max(md_files, key=lambda f: f.stat().st_mtime)
                    
                    # è¯»å–markdownå†…å®¹å¹¶ä¿®æ­£å›¾ç‰‡è·¯å¾„
                    with open(latest_md, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ä¿®æ­£å›¾ç‰‡è·¯å¾„ï¼šä»ç›¸å¯¹è·¯å¾„æ”¹ä¸ºç»å¯¹è·¯å¾„
                    images_dir = self.proj_dir / "pdf_extractor_data" / "images"
                    content = self._fix_image_paths(content, images_dir)
                    
                    # æ„å»ºç›®æ ‡æ–‡ä»¶åï¼ŒåŒ…å«é¡µç ä¿¡æ¯
                    base_name = pdf_path.stem
                    if page_spec:
                        # æ ¼å¼åŒ–é¡µç ä¿¡æ¯ï¼šä¾‹å¦‚ "1,3,5" -> "_p1,3,5"ï¼Œ"1-5" -> "_p1-5"
                        page_suffix = f"_p{page_spec}"
                        target_filename = f"{base_name}{page_suffix}.md"
                    else:
                        target_filename = f"{base_name}.md"
                    
                    target_file = output_dir / target_filename
                    with open(target_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    return str(target_file)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œè¿”å›åŸå§‹è¾“å‡º
            return stdout.strip()
            
        except Exception as e:
            return f"Output handling failed: {str(e)}"
    
    def _fix_image_paths(self, content: str, images_dir: Path) -> str:
        """ä¿®æ­£markdownå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„"""
        import re
        
        # åŒ¹é…å›¾ç‰‡å¼•ç”¨ï¼š![alt](images/filename.jpg)
        pattern = r'!\[([^\]]*)\]\(images/([^)]+)\)'
        
        def replace_path(match):
            alt_text = match.group(1)
            filename = match.group(2)
            # ä½¿ç”¨ç»å¯¹è·¯å¾„
            absolute_path = images_dir / filename
            return f'![{alt_text}]({absolute_path})'
        
        return re.sub(pattern, replace_path, content)
    
    def clean_data(self) -> Tuple[bool, str]:
        """æ¸…ç†EXTRACT_PDF_PROJä¸­çš„ç¼“å­˜æ•°æ®"""
        try:
            data_dir = self.proj_dir / "pdf_extractor_data"
            
            if not data_dir.exists():
                return True, "No cached data found"
            
            # ç»Ÿè®¡è¦åˆ é™¤çš„æ–‡ä»¶
            markdown_dir = data_dir / "markdown"
            images_dir = data_dir / "images"
            
            md_count = len(list(markdown_dir.glob("*.md"))) if markdown_dir.exists() else 0
            img_count = len(list(images_dir.glob("*"))) if images_dir.exists() else 0
            
            # åˆ é™¤markdownæ–‡ä»¶
            if markdown_dir.exists():
                for md_file in markdown_dir.glob("*.md"):
                    md_file.unlink()
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {md_count} ä¸ªmarkdownæ–‡ä»¶")
            
            # åˆ é™¤å›¾ç‰‡æ–‡ä»¶
            if images_dir.exists():
                for img_file in images_dir.glob("*"):
                    if img_file.is_file():
                        img_file.unlink()
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {img_count} ä¸ªå›¾ç‰‡æ–‡ä»¶")
            
            # åˆ é™¤å…¶ä»–ç¼“å­˜æ–‡ä»¶
            cache_files = [
                data_dir / "images_analysis_cache.json"
            ]
            
            cache_count = 0
            for cache_file in cache_files:
                if cache_file.exists():
                    cache_file.unlink()
                    cache_count += 1
            
            if cache_count > 0:
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {cache_count} ä¸ªç¼“å­˜æ–‡ä»¶")
            
            total_deleted = md_count + img_count + cache_count
            if total_deleted > 0:
                return True, f"Successfully cleaned {total_deleted} cached files"
            else:
                return True, "No files to clean"
                
        except Exception as e:
            return False, f"Failed to clean data: {str(e)}"
    
    def extract_pdf(self, pdf_path: str, page_spec: str = None, output_dir: str = None, 
                   engine_mode: str = "mineru") -> Tuple[bool, str]:
        """æ‰§è¡ŒPDFæå–"""
        pdf_path = Path(pdf_path).expanduser().resolve()
        
        # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
        engine_descriptions = {
            "basic": "åŸºç¡€æå–å™¨ï¼ˆæ— å›¾åƒ/å…¬å¼/è¡¨æ ¼å¤„ç†ï¼‰",
            "basic-asyn": "åŸºç¡€æå–å™¨å¼‚æ­¥æ¨¡å¼ï¼ˆç¦ç”¨åˆ†æï¼‰",
            "mineru": "MinerUæå–å™¨ï¼ˆæ— å›¾åƒ/å…¬å¼/è¡¨æ ¼å¤„ç†ï¼‰",
            "mineru-asyn": "MinerUæå–å™¨å¼‚æ­¥æ¨¡å¼ï¼ˆç¦ç”¨åˆ†æï¼‰",
            "full": "å®Œæ•´å¤„ç†æµç¨‹ï¼ˆåŒ…å«å›¾åƒ/å…¬å¼/è¡¨æ ¼å¤„ç†ï¼‰"
        }
        
        if engine_mode in engine_descriptions:
            print(f"ğŸš€ ä½¿ç”¨å¼•æ“: {engine_descriptions[engine_mode]}")
        
        if not pdf_path.exists():
            return False, f"PDF file not found: {pdf_path}"
        
        output_dir_path = Path(output_dir) if output_dir else None
        
        # æ ¹æ®å¼•æ“æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹å¼
        if engine_mode == "basic":
            return self.extract_pdf_basic(pdf_path, page_spec, output_dir_path)
        elif engine_mode == "basic-asyn":
            return self.extract_pdf_basic(pdf_path, page_spec, output_dir_path)
        elif engine_mode == "mineru":
            return self.extract_pdf_mineru(pdf_path, page_spec, output_dir_path, enable_analysis=False)
        elif engine_mode == "mineru-asyn":
            return self.extract_pdf_mineru(pdf_path, page_spec, output_dir_path, enable_analysis=False)
        elif engine_mode == "full":
            return self.extract_pdf_mineru(pdf_path, page_spec, output_dir_path, enable_analysis=True)
        else:
            return False, f"Unknown engine mode: {engine_mode}"

class PDFPostProcessor:
    """PDFåå¤„ç†å™¨ï¼Œç”¨äºå¤„ç†å›¾ç‰‡ã€å…¬å¼ã€è¡¨æ ¼çš„æ ‡ç­¾æ›¿æ¢"""
    
    def __init__(self, debug: bool = False):
        self.debug = debug
        self.script_dir = Path(__file__).parent
        
        # Use UNIMERNET tool for formula/table recognition instead of MinerU
        self.unimernet_tool = self.script_dir / "UNIMERNET"
        
        # Import MinerUWrapper for image processing only
        sys.path.insert(0, str(self.script_dir / "EXTRACT_PDF_PROJ"))
        from mineru_wrapper import MinerUWrapper
        self.mineru_wrapper = MinerUWrapper()
    
    def _process_with_unimernet(self, image_path: str, content_type: str = "auto") -> str:
        """ä½¿ç”¨UNIMERNETå·¥å…·å¤„ç†å…¬å¼æˆ–è¡¨æ ¼å›¾ç‰‡"""
        try:
            # ä½¿ç”¨EXTRACT_IMGå·¥å…·ï¼ˆæ•´åˆäº†UNIMERNETå’Œcacheï¼‰
            extract_img_tool = self.script_dir / "EXTRACT_IMG"
            if not extract_img_tool.exists():
                print(f"âš ï¸  EXTRACT_IMGå·¥å…·ä¸å¯ç”¨: {extract_img_tool}")
                return ""
            
            # æ„å»ºEXTRACT_IMGå‘½ä»¤
            cmd = [str(extract_img_tool), image_path, "--json"]
            if content_type != "auto":
                cmd.extend(["--type", content_type])
            else:
                cmd.extend(["--type", "formula"])  # Default to formula for UNIMERNET
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                # è§£æEXTRACT_IMGçš„JSONè¾“å‡º
                try:
                    extract_result = json.loads(result.stdout)
                    if extract_result.get('success'):
                        recognition_result = extract_result.get('result', '')
                        if recognition_result:
                            # Check if it's from cache
                            cache_info = " (æ¥è‡ªç¼“å­˜)" if extract_result.get('from_cache') else ""
                            # Get processing time if available
                            processing_time = extract_result.get('processing_time', 0)
                            time_info = f" (è€—æ—¶: {processing_time:.2f}ç§’)" if processing_time > 0 else ""
                            print(f"âœ… EXTRACT_IMGè¯†åˆ«æˆåŠŸ{cache_info}{time_info}: {len(recognition_result)} å­—ç¬¦")
                            # Directly format as $$ without description wrapper
                            cleaned_result = recognition_result.strip()
                            return f"$$\n{cleaned_result}\n$$"
                        else:
                            print("âš ï¸  EXTRACT_IMGè¿”å›ç©ºç»“æœ")
                            return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: EXTRACT_IMGè¿”å›ç©ºç»“æœ\n```"
                    else:
                        error_msg = extract_result.get('error', 'Unknown error')
                        print(f"âŒ EXTRACT_IMGå¤„ç†å¤±è´¥: {error_msg}")
                        return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: {error_msg}\n```"
                except json.JSONDecodeError as e:
                    error_msg = f"JSONè§£æå¤±è´¥: {e}\nåŸå§‹è¾“å‡º: {result.stdout[:200]}..."
                    print(f"âŒ æ— æ³•è§£æEXTRACT_IMG JSONè¾“å‡º: {e}")
                    print(f"   åŸå§‹è¾“å‡º: {result.stdout[:200]}...")
                    return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: {error_msg}\n```"
            else:
                error_msg = f"EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}"
                print(f"âŒ EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: {error_msg}\n```"
                
        except Exception as e:
            print(f"âŒ UNIMERNETå¤„ç†å¼‚å¸¸: {e}")
            return f"**å…¬å¼è¯†åˆ«å¤±è´¥:**\n\n```\né”™è¯¯ä¿¡æ¯: UNIMERNETå¤„ç†å¼‚å¸¸: {e}\n```"
    
    def _process_items_hybrid(self, pdf_file: str, md_file: str, status_data: dict, 
                             items_to_process: list, process_type: str, custom_prompt: str = None, force: bool = False) -> bool:
        """ä½¿ç”¨æ··åˆæ–¹å¼å¤„ç†é¡¹ç›®ï¼šå›¾åƒç”¨ä¼ ç»ŸAPIï¼Œå…¬å¼è¡¨æ ¼ç”¨UNIMERNET"""
        try:
            # è¯»å–markdownæ–‡ä»¶
            with open(md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # å¤„ç†æ¯ä¸ªé¡¹ç›®
            updated = False
            for item_id in items_to_process:
                # åœ¨status_dataä¸­æ‰¾åˆ°å¯¹åº”çš„é¡¹ç›®
                item = None
                for status_item in status_data.get('items', []):
                    status_item_id = status_item.get('id')
                    if not status_item_id:
                        # ä»image_pathç”ŸæˆID
                        image_path = status_item.get('image_path', '')
                        if image_path:
                            status_item_id = Path(image_path).stem
                    
                    if status_item_id == item_id:
                        item = status_item
                        break
                
                if not item:
                    print(f"âš ï¸  æœªæ‰¾åˆ°é¡¹ç›®: {item_id}")
                    continue
                
                if item.get('processed', False) and not force:
                    print(f"â­ï¸  è·³è¿‡å·²å¤„ç†é¡¹ç›®: {item_id}")
                    continue
                elif item.get('processed', False) and force:
                    print(f"ğŸ”„ å¼ºåˆ¶é‡æ–°å¤„ç†é¡¹ç›®: {item_id}")
                
                item_type = item.get('type')
                image_path = item.get('image_path', '')
                
                if not image_path:
                    print(f"âš ï¸  å›¾ç‰‡è·¯å¾„ä¸ºç©º: {item_id}")
                    continue
                
                # æŸ¥æ‰¾å®é™…çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„
                actual_image_path = self._find_actual_image_path(pdf_file, image_path)
                if not actual_image_path:
                    print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue
                
                print(f"ğŸ”„ å¤„ç† {item_type} é¡¹ç›®: {item_id}")
                
                # æ ¹æ®ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
                result_text = ""
                if item_type == 'image':
                    # å›¾åƒä½¿ç”¨ä¼ ç»Ÿçš„å›¾åƒAPIï¼ˆé€šè¿‡MinerU wrapperï¼‰
                    result_text = self._process_image_with_api(actual_image_path, custom_prompt)
                elif item_type in ['formula', 'interline_equation']:
                    # å…¬å¼ä½¿ç”¨UNIMERNET
                    result_text = self._process_with_unimernet(actual_image_path, "formula")
                elif item_type == 'table':
                    # è¡¨æ ¼ä½¿ç”¨UNIMERNET
                    result_text = self._process_with_unimernet(actual_image_path, "table")
                
                if result_text:
                    # æ›´æ–°markdownæ–‡ä»¶ä¸­çš„å ä½ç¬¦ - ä½¿ç”¨æ–°çš„placeholderæ ¼å¼
                    # æŸ¥æ‰¾ [placeholder: type] å’Œå¯¹åº”çš„å›¾ç‰‡è¡Œ
                    import re
                    
                    # æ„å»ºå›¾ç‰‡è·¯å¾„çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ”¯æŒç»å¯¹å’Œç›¸å¯¹è·¯å¾„ï¼‰
                    image_filename = Path(image_path).name
                    # åŒ¹é…placeholderå’Œå›¾ç‰‡ï¼Œä»¥åŠå¯èƒ½å­˜åœ¨çš„descriptionæˆ–reason
                    # ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œè€ƒè™‘åˆ°reasonå—å¯èƒ½åŒ…å«åµŒå¥—çš„æ–¹æ‹¬å·
                    placeholder_pattern = rf'\[placeholder:\s*{item_type}\]\s*\n!\[[^\]]*\]\([^)]*{re.escape(image_filename)}\)(\s*\n\n\[(description|reason):.*?\n\n---+\])?'
                    
                    # Check if result_text contains error information
                    is_error = any(error_keyword in result_text for error_keyword in 
                                  ["å¤±è´¥", "é”™è¯¯ä¿¡æ¯", "å¤„ç†å¼‚å¸¸", "æ‰§è¡Œå¤±è´¥", "è§£æå¤±è´¥"])
                    
                    # Use absolute path for images
                    abs_image_path = Path(__file__).parent / "EXTRACT_PDF_PROJ" / "pdf_extractor_data" / "images" / image_filename
                    
                    if is_error:
                        # For errors, keep placeholder and add error info below image
                        replacement = f"[placeholder: {item_type}]\n![]({abs_image_path})\n\n[reason: {result_text}]"
                    else:
                        # For successful processing
                        if item_type in ['formula', 'interline_equation'] and result_text.strip().startswith('$$') and result_text.strip().endswith('$$'):
                            # For formulas already in $$ format, don't add description wrapper
                            replacement = f"[placeholder: {item_type}]\n![]({abs_image_path})\n\n{result_text}"
                        else:
                            # For other content, keep placeholder and add description below image
                            replacement = f"[placeholder: {item_type}]\n![]({abs_image_path})\n\n[description: {result_text}]"
                    
                    if re.search(placeholder_pattern, md_content, re.DOTALL):
                        # Use lambda to avoid regex interpretation of replacement string
                        md_content = re.sub(placeholder_pattern, lambda m: replacement, md_content, flags=re.DOTALL)
                        
                        # Additional cleanup: remove any remaining fragments of old reason/description blocks
                        # This handles cases where the regex didn't capture the complete block
                        cleanup_pattern = rf'----+\]\s*.*?ä½¿ç”¨.*?å¯†é’¥æ—¶å¤±è´¥.*?\n\n---+\]'
                        md_content = re.sub(cleanup_pattern, '', md_content, flags=re.DOTALL)
                        
                        updated = True
                        
                        # æ ‡è®°ä¸ºå·²å¤„ç†
                        item['processed'] = True
                        if is_error:
                            print(f"âš ï¸  å¤„ç†å¤±è´¥ä½†å·²è®°å½•é”™è¯¯ä¿¡æ¯: {item_id}")
                        else:
                            print(f"âœ… å®Œæˆ {item_type} å¤„ç†: {item_id}")
                    else:
                        print(f"âš ï¸  æœªæ‰¾åˆ°å ä½ç¬¦æ¨¡å¼: [placeholder: {item_type}] + image {image_filename}")
                        if self.debug:
                            print(f"   è°ƒè¯•ï¼šæœç´¢æ¨¡å¼: {placeholder_pattern}")
                            # æ˜¾ç¤ºmarkdownå†…å®¹çš„å‰å‡ è¡Œä»¥ä¾¿è°ƒè¯•
                            lines = md_content.split('\n')[:20]
                            print("   è°ƒè¯•ï¼šmarkdownå‰20è¡Œ:")
                            for i, line in enumerate(lines):
                                print(f"   {i+1:2d}: {line}")
                else:
                    print(f"âŒ å¤„ç†å¤±è´¥: {item_id}")
            
            if updated:
                # ä¿å­˜æ›´æ–°çš„markdownæ–‡ä»¶
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(md_content)
                
                # æ›´æ–°çŠ¶æ€æ–‡ä»¶
                status_file = Path(pdf_file).parent / f"{Path(pdf_file).stem}_postprocess.json"
                with open(status_file, 'w', encoding='utf-8') as f:
                    json.dump(status_data, f, indent=2, ensure_ascii=False)
                
                print(f"ğŸ“ å·²æ›´æ–°æ–‡ä»¶: {Path(md_file).name}")
                return True
            else:
                print("â„¹ï¸  æ²¡æœ‰å†…å®¹éœ€è¦æ›´æ–°")
                return True
                
        except Exception as e:
            print(f"âŒ æ··åˆå¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def _find_actual_image_path(self, pdf_file: str, image_filename: str) -> Optional[str]:
        """æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶çš„å®é™…è·¯å¾„"""
        pdf_path = Path(pdf_file)
        pdf_directory = pdf_path.parent
        
        # å¯èƒ½çš„å›¾ç‰‡ä½ç½®
        possible_locations = [
            pdf_directory / image_filename,
            pdf_directory / "images" / image_filename,
            Path(__file__).parent / "EXTRACT_PDF_PROJ" / "pdf_extractor_data" / "images" / image_filename
        ]
        
        # æœç´¢ *_extract_data ç›®å½•
        for item in pdf_directory.iterdir():
            if item.is_dir() and item.name.endswith("_extract_data"):
                extract_data_images = item / "images" / image_filename
                possible_locations.append(extract_data_images)
        
        for location in possible_locations:
            if location.exists():
                print(f"   ğŸ“ æ‰¾åˆ°å›¾ç‰‡: {location}")
                return str(location)
        
        print(f"   âŒ å›¾ç‰‡æœªæ‰¾åˆ°: {image_filename}")
        print(f"   ğŸ” æœç´¢è·¯å¾„:")
        for loc in possible_locations:
            print(f"      - {loc} ({'å­˜åœ¨' if loc.exists() else 'ä¸å­˜åœ¨'})")
        
        return None
    
    def _process_image_with_api(self, image_path: str, custom_prompt: str = None) -> str:
        """ä½¿ç”¨EXTRACT_IMGå·¥å…·å¤„ç†å›¾åƒ"""
        try:
            print(f"ğŸ–¼ï¸  ä½¿ç”¨EXTRACT_IMGå¤„ç†: {Path(image_path).name}")
            
            # è°ƒç”¨EXTRACT_IMGå·¥å…·ï¼ˆæ•´åˆäº†IMG2TEXTå’Œcacheï¼‰
            extract_img_tool = self.script_dir / "EXTRACT_IMG"
            if not extract_img_tool.exists():
                print(f"âš ï¸  EXTRACT_IMGå·¥å…·ä¸å¯ç”¨: {extract_img_tool}")
                return ""
            
            cmd = [str(extract_img_tool), image_path, "--type", "image", "--mode", "academic", "--json"]
            if custom_prompt:
                cmd.extend(["--prompt", custom_prompt])
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                # è§£æEXTRACT_IMGçš„JSONè¾“å‡º
                try:
                    extract_result = json.loads(result.stdout)
                    if extract_result.get('success'):
                        analysis_result = extract_result.get('result', '')
                        if analysis_result:
                            # Check if it's from cache
                            cache_info = " (æ¥è‡ªç¼“å­˜)" if extract_result.get('from_cache') else ""
                            print(f"âœ… EXTRACT_IMGåˆ†æå®Œæˆ{cache_info}: {len(analysis_result)} å­—ç¬¦")
                            return f"--- å›¾åƒåˆ†æç»“æœ ---\n\n{analysis_result}\n\n--------------------"
                        else:
                            print("âš ï¸  EXTRACT_IMGè¿”å›ç©ºç»“æœ")
                            return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: EXTRACT_IMGè¿”å›ç©ºç»“æœ\n\n--------------------"
                    else:
                        error_msg = extract_result.get('error', 'Unknown error')
                        print(f"âŒ EXTRACT_IMGå¤„ç†å¤±è´¥: {error_msg}")
                        return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n-------------------"
                except json.JSONDecodeError as e:
                    error_msg = f"JSONè§£æå¤±è´¥: {e}\nåŸå§‹è¾“å‡º: {result.stdout[:200]}..."
                    print(f"âŒ æ— æ³•è§£æEXTRACT_IMG JSONè¾“å‡º: {e}")
                    print(f"   åŸå§‹è¾“å‡º: {result.stdout[:200]}...")
                    return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n--------------------"
            else:
                error_msg = f"EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}"
                print(f"âŒ EXTRACT_IMGæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n--------------------"
                
        except Exception as e:
            print(f"âŒ IMG2TEXTå¤„ç†å¼‚å¸¸: {e}")
            return f"--- å›¾åƒåˆ†æå¤±è´¥ ---\n\n**é”™è¯¯ä¿¡æ¯**: IMG2TEXTå¤„ç†å¼‚å¸¸: {e}\n\n--------------------"
    
    def _select_markdown_file_interactive(self) -> str:
        """äº¤äº’å¼é€‰æ‹©markdownæ–‡ä»¶"""
        print("ğŸ” é€‰æ‹©markdownæ–‡ä»¶è¿›è¡Œåå¤„ç†...")
        
        # ä½¿ç”¨FILEDIALOGå·¥å…·é€‰æ‹©æ–‡ä»¶
        try:
            filedialog_path = self.script_dir / "FILEDIALOG"
            if not filedialog_path.exists():
                print("âš ï¸  FILEDIALOGå·¥å…·ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼é€‰æ‹©æ–‡ä»¶")
                return self._select_markdown_file_traditional()
            
            # è°ƒç”¨FILEDIALOGå·¥å…·é€‰æ‹©.mdæ–‡ä»¶
            cmd = [str(filedialog_path), '--types', 'md', '--title', 'Select Markdown File for Post-processing']
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                # è§£æFILEDIALOGçš„è¾“å‡º
                output_text = result.stdout.strip()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯"âœ… Selected file:"æ ¼å¼çš„è¾“å‡º
                if "âœ… Selected file:" in output_text:
                    lines = output_text.split('\n')
                    for line in lines:
                        if "âœ… Selected file:" in line:
                            selected_file = line.split("âœ… Selected file: ", 1)[1].strip()
                            if selected_file and Path(selected_file).exists():
                                print(f"âœ… å·²é€‰æ‹©: {Path(selected_file).name}")
                                return selected_file
                            break
                    print("âŒ æ— æ³•è§£æé€‰æ‹©çš„æ–‡ä»¶è·¯å¾„")
                    return None
                else:
                    # å°è¯•è§£æJSONè¾“å‡ºï¼ˆRUNç¯å¢ƒä¸‹ï¼‰
                    try:
                        output_data = json.loads(output_text)
                        if output_data.get('success') and output_data.get('selected_file'):
                            selected_file = output_data['selected_file']
                            print(f"âœ… å·²é€‰æ‹©: {Path(selected_file).name}")
                            return selected_file
                        else:
                            print("âŒ ç”¨æˆ·å–æ¶ˆäº†æ–‡ä»¶é€‰æ‹©")
                            return None
                    except json.JSONDecodeError:
                        # å¦‚æœæ—¢ä¸æ˜¯æ ‡å‡†æ ¼å¼ä¹Ÿä¸æ˜¯JSONï¼Œç›´æ¥ä½¿ç”¨è¾“å‡º
                        if output_text and Path(output_text).exists():
                            print(f"âœ… å·²é€‰æ‹©: {Path(output_text).name}")
                            return output_text
                        else:
                            print("âŒ ç”¨æˆ·å–æ¶ˆäº†æ–‡ä»¶é€‰æ‹©")
                            return None
            else:
                print("âŒ æ–‡ä»¶é€‰æ‹©å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âš ï¸  ä½¿ç”¨FILEDIALOGæ—¶å‡ºé”™: {e}")
            print("ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼é€‰æ‹©æ–‡ä»¶")
            return self._select_markdown_file_traditional()
    
    def _select_markdown_file_traditional(self) -> str:
        """ä¼ ç»Ÿæ–¹å¼é€‰æ‹©markdownæ–‡ä»¶ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print("ğŸ” æœç´¢EXTRACT_PDFç”Ÿæˆçš„markdownæ–‡ä»¶...")
        
        # æœç´¢å½“å‰ç›®å½•åŠå…¶å­ç›®å½•ä¸­çš„markdownæ–‡ä»¶
        md_files = []
        search_dirs = [Path.cwd(), self.script_dir / "EXTRACT_PDF_PROJ" / "pdf_extractor_data"]
        
        for search_dir in search_dirs:
            if search_dir.exists():
                for md_file in search_dir.rglob("*.md"):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯EXTRACT_PDFç”Ÿæˆçš„æ–‡ä»¶
                    # æ–¹æ³•1ï¼šæœ‰å¯¹åº”çš„extract_dataç›®å½•
                    extract_data_dir = md_file.parent / f"{md_file.stem}_extract_data"
                    # æ–¹æ³•2ï¼šæ–‡ä»¶åŒ…å«placeholderæ ‡è®°
                    has_placeholder = False
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        has_placeholder = '[placeholder:' in content
                    except:
                        pass
                    
                    if extract_data_dir.exists() or has_placeholder:
                        md_files.append(md_file)
        
        if not md_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•EXTRACT_PDFç”Ÿæˆçš„markdownæ–‡ä»¶")
            return None
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        print("\nğŸ“„ æ‰¾åˆ°ä»¥ä¸‹markdownæ–‡ä»¶:")
        for i, md_file in enumerate(md_files, 1):
            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„placeholder
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                image_count = len(re.findall(r'\[placeholder: image\]', content))
                formula_count = len(re.findall(r'\[placeholder: formula\]', content))
                table_count = len(re.findall(r'\[placeholder: table\]', content))
                total_count = image_count + formula_count + table_count
                
                status = f"({total_count}ä¸ªå¾…å¤„ç†é¡¹ç›®: ğŸ–¼ï¸{image_count} ğŸ§®{formula_count} ğŸ“Š{table_count})" if total_count > 0 else "(å·²å¤„ç†)"
                print(f"  {i}. {md_file.name} {status}")
                print(f"     è·¯å¾„: {md_file}")
                
            except Exception as e:
                print(f"  {i}. {md_file.name} (æ— æ³•è¯»å–)")
                print(f"     è·¯å¾„: {md_file}")
        
        # ç”¨æˆ·é€‰æ‹©
        while True:
            try:
                choice = input(f"\nè¯·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶ (1-{len(md_files)}, æˆ–æŒ‰å›è½¦å–æ¶ˆ): ").strip()
                
                if not choice:
                    print("âŒ å·²å–æ¶ˆ")
                    return None
                
                choice_num = int(choice)
                if 1 <= choice_num <= len(md_files):
                    selected_file = md_files[choice_num - 1]
                    print(f"âœ… å·²é€‰æ‹©: {selected_file.name}")
                    return str(selected_file)
                else:
                    print(f"âŒ è¯·è¾“å…¥1-{len(md_files)}ä¹‹é—´çš„æ•°å­—")
                    
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\nâŒ å·²å–æ¶ˆ")
                return None
        
    def process_file(self, file_path: str, process_type: str, specific_ids: str = None, custom_prompt: str = None, force: bool = False) -> bool:
        """
        å¤„ç†PDFæ–‡ä»¶çš„åå¤„ç† - ä½¿ç”¨é«˜çº§selective processing
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„æˆ–markdownæ–‡ä»¶è·¯å¾„ï¼Œæˆ–è€…"interactive"è¿›å…¥äº¤äº’æ¨¡å¼
            process_type: å¤„ç†ç±»å‹ ('image', 'formula', 'table', 'all')
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        # æ£€æŸ¥æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼
        if file_path == "interactive":
            file_path = self._select_markdown_file_interactive()
            if not file_path:
                return False
        
        file_path = Path(file_path)
        
        # ç¡®å®šPDFæ–‡ä»¶å’Œmarkdownæ–‡ä»¶è·¯å¾„
        if file_path.suffix == '.pdf':
            pdf_file = file_path
            md_file = file_path.parent / f"{file_path.stem}.md"
        elif file_path.suffix == '.md':
            md_file = file_path
            # å°è¯•æ‰¾åˆ°å¯¹åº”çš„PDFæ–‡ä»¶
            pdf_file = file_path.parent / f"{file_path.stem}.pdf"
            if not pdf_file.exists():
                print(f"âš ï¸  æœªæ‰¾åˆ°å¯¹åº”çš„PDFæ–‡ä»¶: {pdf_file}")
                print("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿå¤„ç†æ–¹å¼...")
                return self._process_file_traditional(md_file, process_type)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path.suffix}")
            return False
            
        if not md_file.exists():
            print(f"âŒ Markdownæ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
            return False
        
        if not pdf_file.exists():
            print(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
            return False
            
        print(f"ğŸ”„ å¼€å§‹é«˜çº§åå¤„ç† {md_file.name}...")
        
        try:
            # ä½¿ç”¨MinerU wrapperçš„selective processingåŠŸèƒ½
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰postprocess JSONæ–‡ä»¶
            status_file = pdf_file.parent / f"{pdf_file.stem}_postprocess.json"
            
            if status_file.exists():
                print(f"ğŸ“„ æ‰¾åˆ°çŠ¶æ€æ–‡ä»¶: {status_file.name}")
                
                # è¯»å–çŠ¶æ€æ–‡ä»¶ï¼Œè·å–æ‰€æœ‰æœªå¤„ç†çš„é¡¹ç›®
                with open(status_file, 'r', encoding='utf-8') as f:
                    status_data = json.load(f)
                
                # ç›´æ¥ä½¿ç”¨MinerU wrapperè¿›è¡Œselective processing
                # å®ƒä¼šå¤„ç†IDç”Ÿæˆå’Œç­›é€‰é€»è¾‘
                if specific_ids:
                    # å¤„ç†specific_idså‚æ•°
                    if specific_ids in ['all_images', 'all_formulas', 'all_tables', 'all']:
                        # å°†ç‰¹æ®Šå…³é”®è¯è½¬æ¢ä¸ºå…·ä½“çš„IDåˆ—è¡¨
                        items_to_process = []
                        for item in status_data.get('items', []):
                            if item.get('processed', False):
                                continue  # è·³è¿‡å·²å¤„ç†çš„é¡¹ç›®
                            
                            item_type = item.get('type')
                            # Generate ID from image_path if no id field
                            item_id = item.get('id')
                            if not item_id:
                                image_path = item.get('image_path', '')
                                if image_path:
                                    item_id = Path(image_path).stem
                            
                            if item_id:
                                if specific_ids == 'all':
                                    items_to_process.append(item_id)
                                elif specific_ids == 'all_images' and item_type == 'image':
                                    items_to_process.append(item_id)
                                elif specific_ids == 'all_formulas' and item_type in ['formula', 'interline_equation']:
                                    items_to_process.append(item_id)
                                elif specific_ids == 'all_tables' and item_type == 'table':
                                    items_to_process.append(item_id)
                    else:
                        # å¤„ç†å…·ä½“çš„hash IDåˆ—è¡¨
                        items_to_process = [id.strip() for id in specific_ids.split(',')]
                else:
                    # æ ¹æ®process_typeç­›é€‰éœ€è¦å¤„ç†çš„é¡¹ç›®
                    items_to_process = []
                    for item in status_data.get('items', []):
                        if item.get('processed', False):
                            continue  # è·³è¿‡å·²å¤„ç†çš„é¡¹ç›®
                        
                        item_type = item.get('type')
                        # Generate ID from image_path if no id field
                        item_id = item.get('id')
                        if not item_id:
                            image_path = item.get('image_path', '')
                            if image_path:
                                item_id = Path(image_path).stem
                        
                        if item_id:
                            if process_type == 'all':
                                items_to_process.append(item_id)
                            elif process_type == 'image' and item_type == 'image':
                                items_to_process.append(item_id)
                            elif process_type == 'formula' and item_type in ['formula', 'interline_equation']:
                                items_to_process.append(item_id)
                            elif process_type == 'table' and item_type == 'table':
                                items_to_process.append(item_id)
                
                if items_to_process:
                    print(f"ğŸ¯ æ‰¾åˆ° {len(items_to_process)} ä¸ªéœ€è¦å¤„ç†çš„é¡¹ç›®")
                    
                    # ä½¿ç”¨æ··åˆå¤„ç†ï¼šå›¾åƒç”¨ä¼ ç»ŸAPIï¼Œå…¬å¼è¡¨æ ¼ç”¨UNIMERNET
                    success = self._process_items_hybrid(
                        str(pdf_file), str(md_file), status_data, items_to_process, process_type, custom_prompt, force
                    )
                    
                    if success:
                        print(f"âœ… æ··åˆåå¤„ç†å®Œæˆ")
                        return True
                    else:
                        print(f"âŒ æ··åˆåå¤„ç†å¤±è´¥")
                        return False
                else:
                    print(f"â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„ {process_type} ç±»å‹é¡¹ç›®")
                    return True
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°çŠ¶æ€æ–‡ä»¶: {status_file.name}")
                print("ğŸ”„ å°è¯•é‡æ–°ç”ŸæˆçŠ¶æ€æ–‡ä»¶...")
                
                # å°è¯•é‡æ–°ç”ŸæˆçŠ¶æ€æ–‡ä»¶
                regenerated = self.mineru_wrapper._regenerate_status_from_markdown(str(pdf_file), str(md_file))
                if regenerated:
                    print("âœ… çŠ¶æ€æ–‡ä»¶é‡æ–°ç”ŸæˆæˆåŠŸï¼Œè¯·é‡æ–°è¿è¡Œåå¤„ç†å‘½ä»¤")
                    return True
                else:
                    print("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿå¤„ç†æ–¹å¼...")
                    return self._process_file_traditional(md_file, process_type)
                    
        except Exception as e:
            print(f"âŒ é«˜çº§åå¤„ç†å‡ºé”™: {e}")
            print("ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿå¤„ç†æ–¹å¼...")
            return self._process_file_traditional(md_file, process_type)
    
    def _process_file_traditional(self, md_file: Path, process_type: str) -> bool:
        """ä¼ ç»Ÿçš„æ–‡ä»¶å¤„ç†æ–¹å¼ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print(f"ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼å¤„ç† {md_file.name}...")
        
        # ä¸å†ä¾èµ–äºç‰¹å®šçš„extract_dataç›®å½•ç»“æ„
        # ç›´æ¥ä»markdownæ–‡ä»¶ä¸­è§£æå›¾ç‰‡è·¯å¾„
        extract_data_dir = None  # è®¾ç½®ä¸ºNoneï¼Œè¡¨ç¤ºä½¿ç”¨ç»å¯¹è·¯å¾„æ¨¡å¼
            
        # æ ¹æ®å¤„ç†ç±»å‹æ‰§è¡Œç›¸åº”çš„å¤„ç†
        if process_type == 'all':
            success = True
            success &= self._process_images(md_file, extract_data_dir)
            success &= self._process_formulas(md_file, extract_data_dir)
            success &= self._process_tables(md_file, extract_data_dir)
            return success
        elif process_type == 'image':
            return self._process_images(md_file, extract_data_dir)
        elif process_type == 'formula':
            return self._process_formulas(md_file, extract_data_dir)
        elif process_type == 'table':
            return self._process_tables(md_file, extract_data_dir)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„å¤„ç†ç±»å‹: {process_type}")
            return False
    
    def _process_images(self, md_file: Path, extract_data_dir: Path) -> bool:
        """å¤„ç†å›¾ç‰‡æ ‡ç­¾æ›¿æ¢"""
        print("ğŸ–¼ï¸  å¤„ç†å›¾ç‰‡...")
        
        try:
            # è¯»å–markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾å›¾ç‰‡placeholder
            placeholder_pattern = r'\[placeholder: image\]\s*\n!\[([^\]]*)\]\(([^)]+)\)'
            matches = re.findall(placeholder_pattern, content)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„å›¾ç‰‡placeholder")
                return True
            
            processed_count = 0
            for alt_text, image_path in matches:
                # æ„å»ºå®Œæ•´çš„å›¾ç‰‡è·¯å¾„
                if image_path.startswith('/'):
                    # ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                    full_image_path = Path(image_path)
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŸºäºextract_data_dir
                    if extract_data_dir is None:
                        print(f"âš ï¸  ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æå–æ•°æ®ç›®å½•: {image_path}")
                        continue
                    full_image_path = extract_data_dir / image_path
                
                if full_image_path.exists():
                    # ä½¿ç”¨IMG2TEXTå·¥å…·åˆ†æå›¾ç‰‡
                    success, description = self._analyze_image_with_img2text(str(full_image_path))
                    
                    if success:
                        # æ›¿æ¢placeholderå’Œå›¾ç‰‡å¼•ç”¨
                        old_pattern = f"[placeholder: image]\n![{alt_text}]({image_path})"
                        new_content = f"![{alt_text}]({image_path})\n\n**å›¾ç‰‡åˆ†æ:** {description}\n"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        processed_count += 1
                    else:
                        # APIè°ƒç”¨å¤±è´¥ï¼Œä¿ç•™placeholderï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
                        old_pattern = f"[placeholder: image]\n![{alt_text}]({image_path})"
                        new_content = f"[placeholder: image]\n[message: {description}]\n![{alt_text}]({image_path})"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        print(f"âš ï¸  å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œä¿ç•™placeholder: {description}")
                else:
                    # å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿæ·»åŠ é”™è¯¯ä¿¡æ¯
                    old_pattern = f"[placeholder: image]\n![{alt_text}]({image_path})"
                    new_content = f"[placeholder: image]\n[message: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}]\n![{alt_text}]({image_path})"
                    
                    content = content.replace(old_pattern, new_content, 1)
                    print(f"âš ï¸  å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
            
            # å†™å›æ–‡ä»¶
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            if processed_count > 0:
                print(f"âœ… æˆåŠŸå¤„ç†äº† {processed_count} ä¸ªå›¾ç‰‡")
            else:
                print("â„¹ï¸  æ²¡æœ‰å›¾ç‰‡è¢«æˆåŠŸå¤„ç†")
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            return False
    
    def _analyze_image_with_img2text(self, image_path: str) -> tuple[bool, str]:
        """ä½¿ç”¨IMG2TEXTå·¥å…·åˆ†æå›¾ç‰‡
        
        Returns:
            tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, åˆ†æç»“æœæˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            # è°ƒç”¨IMG2TEXTå·¥å…·
            img2text_path = self.script_dir / "IMG2TEXT"
            if not img2text_path.exists():
                return False, "IMG2TEXTå·¥å…·ä¸å¯ç”¨"
            
            cmd = [str(img2text_path), image_path]
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                try:
                    # å°è¯•è§£æJSONè¾“å‡º
                    output_data = json.loads(result.stdout)
                    if output_data.get('success'):
                        description = output_data.get('result', 'å›¾ç‰‡åˆ†æå®Œæˆ')
                        return True, description
                    else:
                        # ä»JSONä¸­è·å–è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                        error_msg = output_data.get('reason', output_data.get('message', 'å›¾ç‰‡åˆ†æå¤±è´¥'))
                        return False, error_msg
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›æ–‡æœ¬
                    output_text = result.stdout.strip()
                    if output_text:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯ä¿¡æ¯æ ¼å¼
                        if output_text.startswith("*[") and output_text.endswith("]*"):
                            # ç§»é™¤é”™è¯¯ä¿¡æ¯çš„åŒ…è£…ç¬¦å·
                            error_msg = output_text[2:-2]  # å»æ‰ *[ å’Œ ]*
                            return False, error_msg
                        else:
                            return True, output_text
                    else:
                        return False, "å›¾ç‰‡åˆ†ææ— è¾“å‡º"
            else:
                # æ£€æŸ¥stderræ˜¯å¦æœ‰è¯¦ç»†é”™è¯¯ä¿¡æ¯
                stderr_text = result.stderr.strip()
                if stderr_text:
                    return False, f"å›¾ç‰‡åˆ†æå¤±è´¥: {stderr_text}"
                else:
                    return False, "å›¾ç‰‡åˆ†æå¤±è´¥: æœªçŸ¥é”™è¯¯"
                
        except Exception as e:
            return False, f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
    
    def _process_formulas(self, md_file: Path, extract_data_dir: Path) -> bool:
        """å¤„ç†å…¬å¼æ ‡ç­¾æ›¿æ¢"""
        print("ğŸ§® å¤„ç†å…¬å¼...")
        
        try:
            # è¯»å–markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾å…¬å¼placeholder
            placeholder_pattern = r'\[placeholder: formula\]\s*\n!\[([^\]]*)\]\(([^)]+)\)'
            matches = re.findall(placeholder_pattern, content)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„å…¬å¼placeholder")
                return True
            
            processed_count = 0
            for alt_text, image_path in matches:
                # æ„å»ºå®Œæ•´çš„å›¾ç‰‡è·¯å¾„
                if image_path.startswith('/'):
                    # ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                    full_image_path = Path(image_path)
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŸºäºextract_data_dir
                    if extract_data_dir is None:
                        print(f"âš ï¸  ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æå–æ•°æ®ç›®å½•: {image_path}")
                        continue
                    full_image_path = extract_data_dir / image_path
                
                if full_image_path.exists():
                    # ä½¿ç”¨UnimerNetåˆ†æå…¬å¼å›¾ç‰‡
                    success, formula_latex = self._analyze_formula_with_unimernet(str(full_image_path))
                    
                    if success:
                        # æ›¿æ¢placeholderå’Œå›¾ç‰‡å¼•ç”¨
                        old_pattern = f"[placeholder: formula]\n![{alt_text}]({image_path})"
                        new_content = f"![{alt_text}]({image_path})\n\n**å…¬å¼è¯†åˆ«:** {formula_latex}\n"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        processed_count += 1
                    else:
                        # APIè°ƒç”¨å¤±è´¥ï¼Œä¿ç•™placeholderï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
                        old_pattern = f"[placeholder: formula]\n![{alt_text}]({image_path})"
                        new_content = f"[placeholder: formula]\n[message: {formula_latex}]\n![{alt_text}]({image_path})"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        print(f"âš ï¸  å…¬å¼è¯†åˆ«å¤±è´¥ï¼Œä¿ç•™placeholder: {formula_latex}")
                else:
                    # å…¬å¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿæ·»åŠ é”™è¯¯ä¿¡æ¯
                    old_pattern = f"[placeholder: formula]\n![{alt_text}]({image_path})"
                    new_content = f"[placeholder: formula]\n[message: å…¬å¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}]\n![{alt_text}]({image_path})"
                    
                    content = content.replace(old_pattern, new_content, 1)
                    print(f"âš ï¸  å…¬å¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
            
            # å†™å›æ–‡ä»¶
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            if processed_count > 0:
                print(f"âœ… æˆåŠŸå¤„ç†äº† {processed_count} ä¸ªå…¬å¼")
            else:
                print("â„¹ï¸  æ²¡æœ‰å…¬å¼è¢«æˆåŠŸå¤„ç†")
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å…¬å¼æ—¶å‡ºé”™: {e}")
            return False
    
    def _analyze_formula_with_unimernet(self, image_path: str) -> tuple[bool, str]:
        """ä½¿ç”¨UnimerNetåˆ†æå…¬å¼å›¾ç‰‡
        
        Returns:
            tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, åˆ†æç»“æœæˆ–é”™è¯¯ä¿¡æ¯)
        """
        try:
            # æ£€æŸ¥UnimerNetæ˜¯å¦å¯ç”¨
            unimernet_processor = self.script_dir / "EXTRACT_PDF_PROJ" / "unimernet_processor.py"
            if not unimernet_processor.exists():
                return False, "UnimerNetå¤„ç†å™¨ä¸å¯ç”¨"
            
            # è°ƒç”¨UnimerNetå¤„ç†å™¨
            cmd = [sys.executable, str(unimernet_processor), image_path]
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode == 0:
                output_text = result.stdout.strip()
                if output_text:
                    return True, output_text
                else:
                    return False, "å…¬å¼è¯†åˆ«æ— è¾“å‡º"
            else:
                return False, f"å…¬å¼è¯†åˆ«å¤±è´¥: {result.stderr}"
                
        except Exception as e:
            return False, f"å…¬å¼è¯†åˆ«å¤±è´¥: {str(e)}"

    def _process_tables(self, md_file: Path, extract_data_dir: Path) -> bool:
        """å¤„ç†è¡¨æ ¼æ ‡ç­¾æ›¿æ¢"""
        print("ğŸ“Š å¤„ç†è¡¨æ ¼...")
        
        try:
            # è¯»å–markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾è¡¨æ ¼placeholder
            placeholder_pattern = r'\[placeholder: table\]\s*\n!\[([^\]]*)\]\(([^)]+)\)'
            matches = re.findall(placeholder_pattern, content)
            
            if not matches:
                print("â„¹ï¸  æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„è¡¨æ ¼placeholder")
                return True
            
            processed_count = 0
            for alt_text, image_path in matches:
                # æ„å»ºå®Œæ•´çš„å›¾ç‰‡è·¯å¾„
                if image_path.startswith('/'):
                    # ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                    full_image_path = Path(image_path)
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŸºäºextract_data_dir
                    if extract_data_dir is None:
                        print(f"âš ï¸  ç›¸å¯¹è·¯å¾„ä½†æ²¡æœ‰æå–æ•°æ®ç›®å½•: {image_path}")
                        continue
                    full_image_path = extract_data_dir / image_path
                
                if full_image_path.exists():
                    # ä½¿ç”¨IMG2TEXTå·¥å…·åˆ†æè¡¨æ ¼å›¾ç‰‡
                    success, table_text = self._analyze_image_with_img2text(str(full_image_path))
                    
                    if success:
                        # æ›¿æ¢placeholderå’Œå›¾ç‰‡å¼•ç”¨
                        old_pattern = f"[placeholder: table]\n![{alt_text}]({image_path})"
                        new_content = f"![{alt_text}]({image_path})\n\n**è¡¨æ ¼è¯†åˆ«:**\n{table_text}\n"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        processed_count += 1
                    else:
                        # APIè°ƒç”¨å¤±è´¥ï¼Œä¿ç•™placeholderï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
                        old_pattern = f"[placeholder: table]\n![{alt_text}]({image_path})"
                        new_content = f"[placeholder: table]\n[message: {table_text}]\n![{alt_text}]({image_path})"
                        
                        content = content.replace(old_pattern, new_content, 1)
                        print(f"âš ï¸  è¡¨æ ¼åˆ†æå¤±è´¥ï¼Œä¿ç•™placeholder: {table_text}")
                else:
                    # è¡¨æ ¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿæ·»åŠ é”™è¯¯ä¿¡æ¯
                    old_pattern = f"[placeholder: table]\n![{alt_text}]({image_path})"
                    new_content = f"[placeholder: table]\n[message: è¡¨æ ¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}]\n![{alt_text}]({image_path})"
                    
                    content = content.replace(old_pattern, new_content, 1)
                    print(f"âš ï¸  è¡¨æ ¼å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
            
            # å†™å›æ–‡ä»¶
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            if processed_count > 0:
                print(f"âœ… æˆåŠŸå¤„ç†äº† {processed_count} ä¸ªè¡¨æ ¼")
            else:
                print("â„¹ï¸  æ²¡æœ‰è¡¨æ ¼è¢«æˆåŠŸå¤„ç†")
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†è¡¨æ ¼æ—¶å‡ºé”™: {e}")
            return False

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    help_text = """EXTRACT_PDF - Enhanced PDF extraction using MinerU with post-processing

Usage: EXTRACT_PDF <pdf_file> [options]
       EXTRACT_PDF --post [<markdown_file>] [--post-type <type>]
       EXTRACT_PDF --full <pdf_file> [options]
       EXTRACT_PDF --clean-data

Options:
  --page <spec>        Extract specific page(s) (e.g., 3, 1-5, 1,3,5)
  --output <dir>       Output directory (default: same as PDF)
  --engine <mode>      Processing engine mode:
                       basic        - Basic extractor, no image/formula/table processing
                       basic-asyn   - Basic extractor, async mode (disable analysis)
                       mineru       - MinerU extractor, no image/formula/table processing
                       mineru-asyn  - MinerU extractor, async mode (disable analysis)
                       full         - Full pipeline with image/formula/table processing
                       (default: mineru)
  --post [<file>]      Post-process markdown file (replace placeholders)
                       If no file specified, enter interactive mode
  --post-type <type>   Post-processing type: image, formula, table, all (default: all)
  --ids <ids>          Specific hash IDs to process (comma-separated) or keywords:
                       all_images, all_formulas, all_tables, all
  --prompt <text>      Custom prompt for IMG2TEXT image analysis
  --force              Force reprocessing even if items are marked as processed
  --full <file>        Full pipeline: extract PDF then post-process automatically
  --clean-data         Clean all cached markdown files and images from EXTRACT_PDF_PROJ
  --help, -h           Show this help message

Examples:
  EXTRACT_PDF document.pdf --page 3
  EXTRACT_PDF paper.pdf --page 1-5 --output /path/to/output
  EXTRACT_PDF document.pdf --engine full
  EXTRACT_PDF document.pdf --engine mineru
  EXTRACT_PDF --post document.md --post-type all
EXTRACT_PDF --post document.md --post-type image
EXTRACT_PDF --post document.md --ids 4edf23de78f80bedade9e9628d7de04677faf669c945a7438bc5741c054af036
EXTRACT_PDF --post document.md --ids all_images --prompt "Analyze this research figure focusing on quantitative results"
EXTRACT_PDF --post  # Interactive mode
EXTRACT_PDF --full document.pdf  # Full pipeline
EXTRACT_PDF --clean-data  # Clean cached data"""
    
    print(help_text)

def select_pdf_file():
    """ä½¿ç”¨GUIé€‰æ‹©PDFæ–‡ä»¶"""
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        root = tk.Tk()
        root.withdraw()
        
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©PDFæ–‡ä»¶",
            filetypes=[("PDF files", "*.pdf"), ("All files", "*.*")]
        )
        
        return file_path if file_path else None
    except ImportError:
        print("âŒ tkinter not available, GUI file selection not supported")
        return None
    except Exception as e:
        print(f"âŒ Error in file selection: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    run_context = get_run_context()
    
    args = sys.argv[1:]
    if not args:
        # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œå°è¯•ä½¿ç”¨GUIé€‰æ‹©æ–‡ä»¶
        pdf_file = select_pdf_file()
        if pdf_file:
            print(f"ğŸ“„ å·²é€‰æ‹©æ–‡ä»¶: {Path(pdf_file).name}")
            print(f"ğŸ”„ å¼€å§‹ä½¿ç”¨ MinerU å¼•æ“å¤„ç†...")
            print("â³ å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...")
            
            extractor = PDFExtractor()
            success, message = extractor.extract_pdf(pdf_file)
            
            if success:
                success_data = {
                    "success": True,
                    "message": message
                }
                if run_context['in_run_context']:
                    write_to_json_output(success_data, run_context)
                else:
                    print(f"âœ… {message}")
                return 0
            else:
                error_data = {
                    "success": False,
                    "error": message
                }
                if run_context['in_run_context']:
                    write_to_json_output(error_data, run_context)
                else:
                    print(f"âŒ {message}")
                return 1
        else:
            if run_context['in_run_context']:
                error_data = {"success": False, "error": "No PDF file specified"}
                write_to_json_output(error_data, run_context)
            else:
                print("âŒ Error: No PDF file specified")
                print("Use --help for usage information")
            return 1
    
    # è§£æå‚æ•°
    pdf_file = None
    page_spec = None
    output_dir = None
    engine_mode = "mineru"
    post_file = None
    post_type = "all"
    post_ids = None
    post_prompt = None
    post_force = False
    full_pipeline = False
    clean_data = False
    
    i = 0
    while i < len(args):
        arg = args[i]
        
        if arg in ['--help', '-h']:
            if run_context['in_run_context']:
                help_data = {
                    "success": True,
                    "message": "Help information",
                    "help": show_help.__doc__
                }
                write_to_json_output(help_data, run_context)
            else:
                show_help()
            return 0
        elif arg == '--page':
            if i + 1 < len(args):
                page_spec = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --page requires a value"
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
        elif arg == '--output':
            if i + 1 < len(args):
                output_dir = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --output requires a value"
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
        elif arg == '--engine':
            if i + 1 < len(args):
                engine_mode = args[i + 1]
                if engine_mode not in ['basic', 'basic-asyn', 'mineru', 'mineru-asyn', 'full']:
                    error_msg = f"âŒ Error: Invalid engine mode: {engine_mode}"
                    if run_context['in_run_context']:
                        error_data = {"success": False, "error": error_msg}
                        write_to_json_output(error_data, run_context)
                    else:
                        print(error_msg)
                    return 1
                i += 2
            else:
                error_msg = "âŒ Error: --engine requires a value"
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
        elif arg == '--post':
            if i + 1 < len(args) and not args[i + 1].startswith('-'):
                post_file = args[i + 1]
                i += 2
            else:
                # è¿›å…¥interactive mode
                post_file = "interactive"
                i += 1
        elif arg == '--full':
            if i + 1 < len(args) and not args[i + 1].startswith('-'):
                pdf_file = args[i + 1]
                full_pipeline = True
                i += 2
            else:
                error_msg = "âŒ Error: --full requires a PDF file"
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
        elif arg == '--clean-data':
            clean_data = True
            i += 1
        elif arg == '--ids':
            if i + 1 < len(args):
                post_ids = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --ids requires a value"
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
        elif arg == '--prompt':
            if i + 1 < len(args):
                post_prompt = args[i + 1]
                i += 2
            else:
                error_msg = "âŒ Error: --prompt requires a value"
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
        elif arg == '--post-type':
            if i + 1 < len(args):
                post_type = args[i + 1]
                if post_type not in ['image', 'formula', 'table', 'all', 'all_images', 'all_formulas', 'all_tables']:
                    error_msg = f"âŒ Error: Invalid post-type: {post_type}"
                    if run_context['in_run_context']:
                        error_data = {"success": False, "error": error_msg}
                        write_to_json_output(error_data, run_context)
                    else:
                        print(error_msg)
                    return 1
                i += 2
            else:
                error_msg = "âŒ Error: --post-type requires a value"
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
        elif arg == '--force':
            post_force = True
            i += 1
        elif arg.startswith('-'):
            error_msg = f"âŒ Unknown option: {arg}"
            if run_context['in_run_context']:
                error_data = {"success": False, "error": error_msg}
                write_to_json_output(error_data, run_context)
            else:
                print(error_msg)
                print("Use --help for usage information")
            return 1
        else:
            if pdf_file is None:
                pdf_file = arg
            else:
                error_msg = "âŒ Multiple PDF files specified. Only one file is supported."
                if run_context['in_run_context']:
                    error_data = {"success": False, "error": error_msg}
                    write_to_json_output(error_data, run_context)
                else:
                    print(error_msg)
                return 1
            i += 1
    
    # å¤„ç†æ¸…ç†æ•°æ®æ¨¡å¼
    if clean_data:
        extractor = PDFExtractor()
        success, message = extractor.clean_data()
        
        if success:
            success_data = {
                "success": True,
                "message": message,
                "action": "clean_data"
            }
            if run_context['in_run_context']:
                write_to_json_output(success_data, run_context)
            else:
                print(f"âœ… {message}")
            return 0
        else:
            error_data = {
                "success": False,
                "error": message,
                "action": "clean_data"
            }
            if run_context['in_run_context']:
                write_to_json_output(error_data, run_context)
            else:
                print(f"âŒ {message}")
            return 1
    
    # å¤„ç†å®Œæ•´æµç¨‹æ¨¡å¼
    if full_pipeline:
        print(f"ğŸš€ å¼€å§‹å®Œæ•´æµç¨‹å¤„ç†: {pdf_file}")
        
        # ç¬¬ä¸€æ­¥ï¼šPDFæå–
        print("ğŸ“„ ç¬¬ä¸€æ­¥ï¼šPDFæå–...")
        extractor = PDFExtractor()
        success, message = extractor.extract_pdf(pdf_file, page_spec, output_dir, engine_mode)
        
        if not success:
            error_data = {
                "success": False,
                "error": f"PDF extraction failed: {message}",
                "step": "extraction"
            }
            if run_context['in_run_context']:
                write_to_json_output(error_data, run_context)
            else:
                print(f"âŒ PDFæå–å¤±è´¥: {message}")
            return 1
        
        print(f"âœ… PDFæå–å®Œæˆ: {message}")
        
        # ç¬¬äºŒæ­¥ï¼šè‡ªåŠ¨æŸ¥æ‰¾ç”Ÿæˆçš„markdownæ–‡ä»¶å¹¶è¿›è¡Œåå¤„ç†
        print("ğŸ”„ ç¬¬äºŒæ­¥ï¼šè‡ªåŠ¨åå¤„ç†...")
        
        # æ ¹æ®PDFæ–‡ä»¶è·¯å¾„æ¨æ–­markdownæ–‡ä»¶è·¯å¾„
        pdf_path = Path(pdf_file).expanduser().resolve()
        if output_dir:
            md_file = Path(output_dir) / f"{pdf_path.stem}.md"
        else:
            md_file = pdf_path.parent / f"{pdf_path.stem}.md"
        
        if md_file.exists():
            processor = PDFPostProcessor(debug=False)
            success = processor.process_file(str(md_file), post_type)
            
            if success:
                success_data = {
                    "success": True,
                    "message": f"Full pipeline completed: {pdf_file} -> {md_file}",
                    "extraction_result": message,
                    "post_processing": "completed",
                    "post_type": post_type
                }
                if run_context['in_run_context']:
                    write_to_json_output(success_data, run_context)
                else:
                    print(f"âœ… å®Œæ•´æµç¨‹å®Œæˆ: {pdf_file} -> {md_file}")
                return 0
            else:
                # å³ä½¿åå¤„ç†å¤±è´¥ï¼ŒPDFæå–å·²æˆåŠŸ
                warning_data = {
                    "success": True,
                    "message": f"PDF extraction completed but post-processing failed: {md_file}",
                    "extraction_result": message,
                    "post_processing": "failed",
                    "post_type": post_type
                }
                if run_context['in_run_context']:
                    write_to_json_output(warning_data, run_context)
                else:
                    print(f"âœ… PDFæå–å®Œæˆï¼Œä½†åå¤„ç†å¤±è´¥: {md_file}")
                    print("ğŸ’¡ æ‚¨å¯ä»¥ç¨åä½¿ç”¨ EXTRACT_PDF --post æ‰‹åŠ¨è¿›è¡Œåå¤„ç†")
                return 0
        else:
            # markdownæ–‡ä»¶ä¸å­˜åœ¨
            warning_data = {
                "success": True,
                "message": f"PDF extraction completed but markdown file not found: {md_file}",
                "extraction_result": message,
                "post_processing": "skipped"
            }
            if run_context['in_run_context']:
                write_to_json_output(warning_data, run_context)
            else:
                print(f"âœ… PDFæå–å®Œæˆï¼Œä½†æœªæ‰¾åˆ°markdownæ–‡ä»¶: {md_file}")
            return 0
    
    # å¤„ç†åå¤„ç†æ¨¡å¼
    if post_file:
        processor = PDFPostProcessor(debug=False)
        success = processor.process_file(post_file, post_type, post_ids, post_prompt, force=post_force)
        
        if success:
            success_data = {
                "success": True,
                "message": f"Post-processing completed: {post_file}",
                "post_type": post_type
            }
            if run_context['in_run_context']:
                write_to_json_output(success_data, run_context)
            else:
                print(f"âœ… åå¤„ç†å®Œæˆ: {post_file}")
            return 0
        else:
            error_data = {
                "success": False,
                "error": f"Post-processing failed: {post_file}",
                "post_type": post_type
            }
            if run_context['in_run_context']:
                write_to_json_output(error_data, run_context)
            else:
                print(f"âŒ åå¤„ç†å¤±è´¥: {post_file}")
            return 1
    
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†PDFæ–‡ä»¶
    if pdf_file is None:
        error_msg = "âŒ Error: No PDF file specified"
        if run_context['in_run_context']:
            error_data = {"success": False, "error": error_msg}
            write_to_json_output(error_data, run_context)
        else:
            print(error_msg)
            print("Use --help for usage information")
        return 1
    
    # æ‰§è¡ŒPDFæå–
    extractor = PDFExtractor()
    success, message = extractor.extract_pdf(pdf_file, page_spec, output_dir, engine_mode)
    
    if success:
        success_data = {
            "success": True,
            "message": message,
            "engine_mode": engine_mode
        }
        if run_context['in_run_context']:
            write_to_json_output(success_data, run_context)
        else:
            print(f"âœ… {message}")
        return 0
    else:
        error_data = {
            "success": False,
            "error": message,
            "engine_mode": engine_mode
        }
        if run_context['in_run_context']:
            write_to_json_output(error_data, run_context)
        else:
            print(f"âŒ {message}")
        return 1

def cleanup_images_folder():
    """Clean up images folder created by MinerU module imports"""
    images_path = Path("images")
    if images_path.exists() and images_path.is_dir():
        try:
            # Only remove if it's empty or contains only MinerU-generated files
            contents = list(images_path.iterdir())
            if not contents:  # Empty folder
                images_path.rmdir()
                print("ğŸ§¹ å·²æ¸…ç†ç©ºçš„ images æ–‡ä»¶å¤¹")
            else:
                # Check if all contents are image files (likely from MinerU)
                image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'}
                all_images = all(
                    item.is_file() and item.suffix.lower() in image_extensions 
                    for item in contents
                )
                if all_images and len(contents) < 10:  # Safety check: only clean small image folders
                    shutil.rmtree(images_path)
                    print(f"ğŸ§¹ å·²æ¸…ç†åŒ…å« {len(contents)} ä¸ªå›¾ç‰‡æ–‡ä»¶çš„ images æ–‡ä»¶å¤¹")
        except Exception as e:
            # Silently ignore cleanup errors
            pass

if __name__ == "__main__":
    try:
        exit_code = main()
        cleanup_images_folder()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        cleanup_images_folder()
        print("\nâŒ å·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        cleanup_images_folder()
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1) 