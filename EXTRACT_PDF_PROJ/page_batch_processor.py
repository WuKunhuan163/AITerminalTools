#!/usr/bin/env python3
"""
åˆ†é¡µæ‰¹å¤„ç†å™¨ - æ”¯æŒPDFåˆ†é¡µå¤„ç†å’Œè¿›åº¦ä¿å­˜
Page Batch Processor - Supports PDF page-by-page processing with progress saving
"""

import json
import hashlib
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from datetime import datetime
import subprocess
import sys

@dataclass
class PageProgress:
    """å•é¡µå¤„ç†è¿›åº¦"""
    page_num: int
    status: str  # 'pending', 'processing', 'completed', 'failed'
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    output_file: Optional[str] = None
    error_message: Optional[str] = None

@dataclass
class BatchProgress:
    """æ‰¹å¤„ç†è¿›åº¦"""
    pdf_hash: str
    pdf_path: str
    total_pages: int
    pages: Dict[int, PageProgress]
    created_time: float
    updated_time: float
    output_dir: str
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'pdf_hash': self.pdf_hash,
            'pdf_path': self.pdf_path,
            'total_pages': self.total_pages,
            'pages': {k: asdict(v) for k, v in self.pages.items()},
            'created_time': self.created_time,
            'updated_time': self.updated_time,
            'output_dir': self.output_dir
        }
    
    @classmethod
    def from_dict(cls, data: dict):
        """ä»å­—å…¸åˆ›å»ºå¯¹è±¡"""
        pages = {int(k): PageProgress(**v) for k, v in data['pages'].items()}
        return cls(
            pdf_hash=data['pdf_hash'],
            pdf_path=data['pdf_path'],
            total_pages=data['total_pages'],
            pages=pages,
            created_time=data['created_time'],
            updated_time=data['updated_time'],
            output_dir=data['output_dir']
        )

class PageBatchProcessor:
    """åˆ†é¡µæ‰¹å¤„ç†å™¨"""
    
    def __init__(self, cache_dir: Optional[Path] = None):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        self.cache_dir = cache_dir or Path(__file__).parent / "batch_cache"
        self.cache_dir.mkdir(exist_ok=True)
        self.progress_file = self.cache_dir / "batch_progress.json"
        
    def get_pdf_hash(self, pdf_path: Path) -> str:
        """è®¡ç®—PDFæ–‡ä»¶å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        with open(pdf_path, "rb") as f:
            # è¯»å–æ–‡ä»¶å¤´éƒ¨å’Œå°¾éƒ¨æ¥è®¡ç®—å“ˆå¸Œï¼Œé¿å…å¤§æ–‡ä»¶å…¨è¯»å–
            chunk_size = 8192
            # è¯»å–å¼€å¤´
            chunk = f.read(chunk_size)
            hash_md5.update(chunk)
            
            # è¯»å–æ–‡ä»¶å¤§å°
            f.seek(0, 2)  # ç§»åˆ°æ–‡ä»¶æœ«å°¾
            file_size = f.tell()
            hash_md5.update(str(file_size).encode())
            
            # å¦‚æœæ–‡ä»¶è¶³å¤Ÿå¤§ï¼Œè¯»å–ä¸­é—´å’Œæœ«å°¾
            if file_size > chunk_size * 2:
                # è¯»å–ä¸­é—´
                f.seek(file_size // 2)
                chunk = f.read(chunk_size)
                hash_md5.update(chunk)
                
                # è¯»å–æœ«å°¾ - ä¿®å¤è´Ÿæ•°seeké—®é¢˜
                tail_size = min(chunk_size, file_size)
                if tail_size > 0:
                    f.seek(file_size - tail_size)
                    chunk = f.read()
                    hash_md5.update(chunk)
        
        return hash_md5.hexdigest()
    
    def get_pdf_page_count(self, pdf_path: Path) -> int:
        """è·å–PDFé¡µæ•°"""
        try:
            import PyPDF2
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                return len(reader.pages)
        except ImportError:
            # å¦‚æœæ²¡æœ‰PyPDF2ï¼Œä½¿ç”¨pdfinfoå‘½ä»¤
            try:
                result = subprocess.run(['pdfinfo', str(pdf_path)], 
                                      capture_output=True, text=True, check=True)
                for line in result.stdout.split('\n'):
                    if line.startswith('Pages:'):
                        return int(line.split(':')[1].strip())
            except (subprocess.CalledProcessError, FileNotFoundError):
                pass
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›é»˜è®¤å€¼
            print(f"âš ï¸ æ— æ³•è·å–PDFé¡µæ•°ï¼Œå‡è®¾ä¸º50é¡µ", file=sys.stderr)
            return 50
    
    def load_progress(self) -> Dict[str, BatchProgress]:
        """åŠ è½½è¿›åº¦æ–‡ä»¶"""
        if not self.progress_file.exists():
            return {}
        
        try:
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return {k: BatchProgress.from_dict(v) for k, v in data.items()}
        except Exception as e:
            print(f"âš ï¸ åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
            return {}
    
    def save_progress(self, progress_dict: Dict[str, BatchProgress]):
        """ä¿å­˜è¿›åº¦æ–‡ä»¶"""
        try:
            data = {k: v.to_dict() for k, v in progress_dict.items()}
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
    
    def get_or_create_batch_progress(self, pdf_path: Path, output_dir: Path, 
                                   page_range: Optional[str] = None) -> BatchProgress:
        """è·å–æˆ–åˆ›å»ºæ‰¹å¤„ç†è¿›åº¦"""
        pdf_hash = self.get_pdf_hash(pdf_path)
        progress_dict = self.load_progress()
        
        if pdf_hash in progress_dict:
            batch_progress = progress_dict[pdf_hash]
            # æ›´æ–°è¾“å‡ºç›®å½•ï¼ˆå¯èƒ½æœ‰å˜åŒ–ï¼‰
            batch_progress.output_dir = str(output_dir)
            batch_progress.updated_time = time.time()
            print(f"ğŸ“‚ æ‰¾åˆ°ç°æœ‰è¿›åº¦: {len([p for p in batch_progress.pages.values() if p.status == 'completed'])}/{batch_progress.total_pages} é¡µå·²å®Œæˆ")
            return batch_progress
        
        # åˆ›å»ºæ–°çš„æ‰¹å¤„ç†è¿›åº¦
        total_pages = self.get_pdf_page_count(pdf_path)
        
        # è§£æé¡µé¢èŒƒå›´
        if page_range:
            page_numbers = self.parse_page_range(page_range, total_pages)
        else:
            page_numbers = list(range(1, total_pages + 1))
        
        pages = {}
        for page_num in page_numbers:
            pages[page_num] = PageProgress(page_num=page_num, status='pending')
        
        batch_progress = BatchProgress(
            pdf_hash=pdf_hash,
            pdf_path=str(pdf_path),
            total_pages=len(page_numbers),
            pages=pages,
            created_time=time.time(),
            updated_time=time.time(),
            output_dir=str(output_dir)
        )
        
        print(f"ğŸ“ åˆ›å»ºæ–°çš„æ‰¹å¤„ç†è¿›åº¦: {batch_progress.total_pages} é¡µå¾…å¤„ç†")
        return batch_progress
    
    def parse_page_range(self, page_range: str, total_pages: int) -> List[int]:
        """è§£æé¡µé¢èŒƒå›´"""
        pages = []
        for part in page_range.split(','):
            part = part.strip()
            if '-' in part:
                start, end = part.split('-', 1)
                start = int(start.strip())
                end = int(end.strip())
                pages.extend(range(start, min(end + 1, total_pages + 1)))
            else:
                page_num = int(part.strip())
                if 1 <= page_num <= total_pages:
                    pages.append(page_num)
        return sorted(set(pages))
    
    def get_pending_pages(self, batch_progress: BatchProgress) -> List[int]:
        """è·å–å¾…å¤„ç†çš„é¡µé¢"""
        return [page_num for page_num, page in batch_progress.pages.items() 
                if page.status in ['pending', 'failed']]
    
    def process_single_page(self, pdf_path: Path, page_num: int, output_dir: Path) -> Tuple[bool, str, Optional[str]]:
        """å¤„ç†å•ä¸ªé¡µé¢"""
        try:
            # åˆ›å»ºå•é¡µè¾“å‡ºç›®å½•
            page_output_dir = output_dir / f"page_{page_num:03d}"
            page_output_dir.mkdir(exist_ok=True)
            
            # é¦–å…ˆæ£€æŸ¥MinerUæ˜¯å¦å¯ç”¨
            try:
                result_check = subprocess.run(
                    ["python3", "-m", "mineru.cli.client", "--help"], 
                    capture_output=True, text=True, timeout=10
                )
                if result_check.returncode != 0:
                    raise ImportError("MinerU not available")
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError):
                # MinerUä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„PDFå¤„ç†æ–¹å¼
                return self._process_single_page_fallback(pdf_path, page_num, page_output_dir)
            
            # æ„å»ºMinerUå‘½ä»¤å¤„ç†å•é¡µ
            cmd = [
                "python3", "-m", "mineru.cli.client",
                "-p", str(pdf_path.resolve()),
                "-o", str(page_output_dir),
                "-s", str(page_num),
                "-e", str(page_num),
                "-f", "false",  # ç¦ç”¨å…¬å¼è§£æä»¥æé«˜é€Ÿåº¦
                "-t", "false",  # ç¦ç”¨è¡¨æ ¼è§£æä»¥æé«˜é€Ÿåº¦
                "-d", "cpu"     # ä½¿ç”¨CPUé¿å…è®¾å¤‡é—®é¢˜
            ]
            
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
            
            if result.returncode == 0:
                # æŸ¥æ‰¾ç”Ÿæˆçš„markdownæ–‡ä»¶
                md_files = list(page_output_dir.glob("*.md"))
                if md_files:
                    return True, f"é¡µé¢ {page_num} å¤„ç†æˆåŠŸ", str(md_files[0])
                else:
                    return False, f"é¡µé¢ {page_num} å¤„ç†å®Œæˆä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶", None
            else:
                # MinerUå¤±è´¥ï¼Œå°è¯•å›é€€æ–¹å¼
                print(f"âš ï¸ MinerUå¤„ç†é¡µé¢{page_num}å¤±è´¥ï¼Œå°è¯•å›é€€æ–¹å¼", file=sys.stderr)
                return self._process_single_page_fallback(pdf_path, page_num, page_output_dir)
                
        except subprocess.TimeoutExpired:
            return False, f"é¡µé¢ {page_num} å¤„ç†è¶…æ—¶", None
        except Exception as e:
            return False, f"é¡µé¢ {page_num} å¤„ç†å¼‚å¸¸: {str(e)}", None
    
    def _process_single_page_fallback(self, pdf_path: Path, page_num: int, output_dir: Path) -> Tuple[bool, str, Optional[str]]:
        """å›é€€çš„å•é¡µå¤„ç†æ–¹æ³• - ä½¿ç”¨åŸºç¡€PDFæå–"""
        try:
            # ä½¿ç”¨PyPDF2æˆ–å…¶ä»–åŸºç¡€æ–¹æ³•æå–å•é¡µæ–‡æœ¬
            try:
                import PyPDF2
                
                with open(pdf_path, 'rb') as file:
                    reader = PyPDF2.PdfReader(file)
                    if page_num <= len(reader.pages):
                        page = reader.pages[page_num - 1]  # PyPDF2ä½¿ç”¨0-basedç´¢å¼•
                        text = page.extract_text()
                        
                        # ä¿å­˜ä¸ºmarkdownæ–‡ä»¶
                        output_file = output_dir / f"page_{page_num:03d}.md"
                        with open(output_file, 'w', encoding='utf-8') as f:
                            f.write(f"# ç¬¬ {page_num} é¡µ\n\n")
                            f.write(text)
                        
                        return True, f"é¡µé¢ {page_num} åŸºç¡€æå–æˆåŠŸ", str(output_file)
                    else:
                        return False, f"é¡µé¢ {page_num} è¶…å‡ºèŒƒå›´", None
                        
            except ImportError:
                # PyPDF2ä¹Ÿä¸å¯ç”¨ï¼Œåˆ›å»ºå ä½ç¬¦
                output_file = output_dir / f"page_{page_num:03d}.md"
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(f"# ç¬¬ {page_num} é¡µ\n\n")
                    f.write("*æ­¤é¡µé¢éœ€è¦æ‰‹åŠ¨å¤„ç† - æ‰¹å¤„ç†å™¨ç¼ºå°‘å¿…è¦çš„PDFå¤„ç†åº“*\n")
                
                return True, f"é¡µé¢ {page_num} åˆ›å»ºå ä½ç¬¦", str(output_file)
                
        except Exception as e:
            return False, f"é¡µé¢ {page_num} å›é€€å¤„ç†å¤±è´¥: {str(e)}", None
    
    def update_page_status(self, batch_progress: BatchProgress, page_num: int, 
                          status: str, output_file: Optional[str] = None, 
                          error_message: Optional[str] = None):
        """æ›´æ–°é¡µé¢çŠ¶æ€"""
        if page_num in batch_progress.pages:
            page = batch_progress.pages[page_num]
            page.status = status
            page.updated_time = time.time()
            
            if status == 'processing':
                page.start_time = time.time()
            elif status in ['completed', 'failed']:
                page.end_time = time.time()
                
            if output_file:
                page.output_file = output_file
            if error_message:
                page.error_message = error_message
            
            batch_progress.updated_time = time.time()
    
    def merge_page_outputs(self, batch_progress: BatchProgress, final_output_path: Path) -> bool:
        """åˆå¹¶æ‰€æœ‰é¡µé¢çš„è¾“å‡º"""
        try:
            completed_pages = [page for page in batch_progress.pages.values() 
                             if page.status == 'completed' and page.output_file]
            
            if not completed_pages:
                return False
            
            # æŒ‰é¡µç æ’åº
            completed_pages.sort(key=lambda x: x.page_num)
            
            # åˆå¹¶markdownå†…å®¹
            merged_content = []
            merged_content.append(f"# PDFæå–ç»“æœ\n")
            merged_content.append(f"**æ–‡ä»¶**: {batch_progress.pdf_path}\n")
            merged_content.append(f"**å¤„ç†æ—¶é—´**: {datetime.fromtimestamp(batch_progress.updated_time).strftime('%Y-%m-%d %H:%M:%S')}\n")
            merged_content.append(f"**é¡µé¢æ•°**: {len(completed_pages)}/{batch_progress.total_pages}\n\n")
            
            for page in completed_pages:
                merged_content.append(f"## ç¬¬ {page.page_num} é¡µ\n\n")
                
                # è¯»å–é¡µé¢å†…å®¹
                if page.output_file and Path(page.output_file).exists():
                    with open(page.output_file, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        merged_content.append(content)
                        merged_content.append("\n\n---\n\n")
                else:
                    merged_content.append("*é¡µé¢å†…å®¹ç¼ºå¤±*\n\n---\n\n")
            
            # å†™å…¥æœ€ç»ˆæ–‡ä»¶
            with open(final_output_path, 'w', encoding='utf-8') as f:
                f.write(''.join(merged_content))
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ åˆå¹¶è¾“å‡ºå¤±è´¥: {e}", file=sys.stderr)
            return False
    
    def process_pdf_batch(self, pdf_path: Path, output_dir: Path, 
                         page_range: Optional[str] = None, 
                         max_concurrent: int = 1) -> Tuple[bool, str]:
        """æ‰¹é‡å¤„ç†PDF"""
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–æˆ–åˆ›å»ºæ‰¹å¤„ç†è¿›åº¦
        batch_progress = self.get_or_create_batch_progress(pdf_path, output_dir, page_range)
        progress_dict = self.load_progress()
        progress_dict[batch_progress.pdf_hash] = batch_progress
        
        # è·å–å¾…å¤„ç†é¡µé¢
        pending_pages = self.get_pending_pages(batch_progress)
        
        if not pending_pages:
            print("âœ… æ‰€æœ‰é¡µé¢å·²å¤„ç†å®Œæˆ")
            # åˆå¹¶è¾“å‡º
            final_output = output_dir / f"{pdf_path.stem}_merged.md"
            if self.merge_page_outputs(batch_progress, final_output):
                return True, f"æ‰€æœ‰é¡µé¢å·²å®Œæˆï¼Œåˆå¹¶è¾“å‡º: {final_output}"
            else:
                return True, "æ‰€æœ‰é¡µé¢å·²å®Œæˆï¼Œä½†åˆå¹¶è¾“å‡ºå¤±è´¥"
        
        print(f"ğŸ“‹ å¼€å§‹å¤„ç† {len(pending_pages)} ä¸ªå¾…å¤„ç†é¡µé¢...")
        
        # å¤„ç†æ¯ä¸ªé¡µé¢
        for i, page_num in enumerate(pending_pages, 1):
            print(f"\nğŸ”„ å¤„ç†é¡µé¢ {page_num} ({i}/{len(pending_pages)})")
            
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            self.update_page_status(batch_progress, page_num, 'processing')
            self.save_progress(progress_dict)
            
            # å¤„ç†é¡µé¢
            success, message, output_file = self.process_single_page(pdf_path, page_num, output_dir)
            
            if success:
                print(f"âœ… {message}")
                self.update_page_status(batch_progress, page_num, 'completed', output_file)
            else:
                print(f"âŒ {message}")
                self.update_page_status(batch_progress, page_num, 'failed', error_message=message)
            
            # ä¿å­˜è¿›åº¦
            self.save_progress(progress_dict)
            
            # æ˜¾ç¤ºæ€»ä½“è¿›åº¦
            completed_count = len([p for p in batch_progress.pages.values() if p.status == 'completed'])
            total_count = len(batch_progress.pages)
            progress_percent = (completed_count / total_count) * 100
            print(f"ğŸ“Š æ€»è¿›åº¦: {completed_count}/{total_count} ({progress_percent:.1f}%)")
        
        # æœ€ç»ˆåˆå¹¶
        print(f"\nğŸ”— åˆå¹¶æ‰€æœ‰é¡µé¢è¾“å‡º...")
        final_output = output_dir / f"{pdf_path.stem}_merged.md"
        if self.merge_page_outputs(batch_progress, final_output):
            return True, f"æ‰¹å¤„ç†å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {final_output}"
        else:
            return False, "é¡µé¢å¤„ç†å®Œæˆï¼Œä½†åˆå¹¶è¾“å‡ºå¤±è´¥"
    
    def get_batch_status(self, pdf_path: Path) -> Optional[Dict]:
        """è·å–æ‰¹å¤„ç†çŠ¶æ€"""
        pdf_hash = self.get_pdf_hash(pdf_path)
        progress_dict = self.load_progress()
        
        if pdf_hash not in progress_dict:
            return None
        
        batch_progress = progress_dict[pdf_hash]
        
        # ç»Ÿè®¡çŠ¶æ€
        status_counts = {}
        for page in batch_progress.pages.values():
            status_counts[page.status] = status_counts.get(page.status, 0) + 1
        
        return {
            'pdf_path': batch_progress.pdf_path,
            'total_pages': batch_progress.total_pages,
            'status_counts': status_counts,
            'created_time': datetime.fromtimestamp(batch_progress.created_time).strftime('%Y-%m-%d %H:%M:%S'),
            'updated_time': datetime.fromtimestamp(batch_progress.updated_time).strftime('%Y-%m-%d %H:%M:%S'),
            'output_dir': batch_progress.output_dir
        }
    
    def clean_cache(self, older_than_days: int = 7):
        """æ¸…ç†æ—§çš„ç¼“å­˜"""
        cutoff_time = time.time() - (older_than_days * 24 * 3600)
        progress_dict = self.load_progress()
        
        cleaned_count = 0
        for pdf_hash, batch_progress in list(progress_dict.items()):
            if batch_progress.updated_time < cutoff_time:
                del progress_dict[pdf_hash]
                cleaned_count += 1
        
        if cleaned_count > 0:
            self.save_progress(progress_dict)
            print(f"ğŸ§¹ æ¸…ç†äº† {cleaned_count} ä¸ªæ—§çš„æ‰¹å¤„ç†è®°å½•")

def main():
    """æµ‹è¯•å‡½æ•°"""
    processor = PageBatchProcessor()
    
    # ç¤ºä¾‹ç”¨æ³•
    pdf_path = Path("test.pdf")
    output_dir = Path("output")
    
    if pdf_path.exists():
        success, message = processor.process_pdf_batch(pdf_path, output_dir, page_range="1-5")
        print(f"ç»“æœ: {success}, æ¶ˆæ¯: {message}")
    else:
        print("æµ‹è¯•PDFæ–‡ä»¶ä¸å­˜åœ¨")

if __name__ == "__main__":
    main()
